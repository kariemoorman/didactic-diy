[
  "rwvk run on very little vram with rwvkstic streaming bit not test streaming expect lot slow model sadly take gb with just bit quantization with manage to run locally through koboldai meta opt eleutherai gpt neo bigscience bloom try something like only release few hour ago no way for to discover previously basically make use of various strategy machine lot of normal cpu memory paper author able to fit parameter model on lowly gpu with machine with of normal memory interested in tutorial on load large model promise ability to inference model long enough disk space gpt neox should fit in vram with for inference manage to run gpt j on w take about of vram keep in mind small model go to lot dumb than what likely see in gpt seem really promise also surprised pytorch not option to load model partially in just in time basis yet way even infinitely large model infer on try to use both gpu with one help last link clear imho why not look into distil model like distilbert just question work with non nvidia gpu like intel arc such nel yike tough know try bloom like blog post try let try download overnight run into problem hear download take forever though say probably worth whatever cost try to dodge just to hit api even hardware great not sure help use host flan model at deepinfracom use http api free for now disclaimer work at deepinfra want gpt neo gpt j deploy also yup recommend use whichever rwkv model fit with apparently four time slow low accuracy run gpt j on gpu for month long context possible use accelerate notice massive speed increase use not remember rather than test any large not run also any comment far among good bad easy etc increase inference time gpt neox should fit in vram with for inference gpt fit in vram almost instantly go out of memory context get bit big than start page of sentence use something like bitsandbyte for inference how implement literally ask for large language model test large not run not remember which one probably gpt j recently get load large model now for quality use case simple writing prompt to help with writing story article nothing sophisticated work well until chatgpt come along use chatgpt instead now look to slow for huge model still bearable only user on machine still well than nothing not lot of gpu memory yes at least read documentation correctly some rough number on prompt size vs ram usage after model load not play yet with gpt neox add to from pretrainedmodel device map auto load in true transformer rest thank wish model publisher indicate rough vram requirement yeah dimms fairly inexpensive compare to upgrade gpu for more vram depend mostly on setting no small context like token work with ai not remember connect dot well which make model bad than people work right now on split work between gpuvram cpuram in mode think like to ram make model work well on vram card bit slow still usable want always load whole model to ram run via cpu very slow not scientific at all notice checkpoint file size pretty close to actual vram requirement for llm right nice to table handy thank",
  "",
  "imagine someone write one explicitly aim around manipulate thought action ai likely come up with some insane tactic for feed off of twitter page find online resume of scrape other social medium in microsoft case google potentially scrape email with profile in instant come up with tailor make advertisement argument know land on scary think how should control exposure for people with low cognitive capability not understand what interact with train on load of racist biased garbage mess bing chat sydney instead of just verbally threaten user connect with apis let take arbitrary action on internet to carry out out really not want to see what happen connect deranged language model like sydney with competent version of adept ai action transformer to let use web browser corporation scrape all kind of copyright material profit off model while people all labor get either nothing for content generation poverty wage for content labeller current push to promote llm some sort of pinnacle of technology barely any legitimate use case struggle with most basic of logic probably lead to recession in tech industry people use to make money in unethical disruptive way example of unethical way to use phishe scam instead of send out same phishe email to thousand of people scammer get some datum about people use language model to write personalized phishing email much high success rate disruptive application take job customer service content creation journalism software engineering all field lose job result of large language model other disruptive possibility llm able to themselves rapidly build more powerful llm use github copilot every day already very good at write code take at least off time take to complete software implementation task very possible llm in near future make improvement to own training script use to train even more powerful llm lead to singularity where extremely rapid technological development not clear to what fate of humankind in case write bot to handle all hr complaint train on late managerial material bonus bot look at all conversation propose metric for increase efficiency harmony at work place only people in power allow to use ai while rest not like some kind ai aristocrat probably happen regulation come break security by require effort assumption of various human interaction especially among stranger use to take effort to voice opinion on social medium other mass communication platform make public trust authentic message represent real people scalability of technology break assumption start before llm take to whole new level honestly much simple algorithm already to some extent recommendation system big difference to suggest post someone else write instead of write by itself great take how ai know profile not other ai set up to all of thing for yeah pretty frightening depend on whether exploit psychology to sell something not need gather information to find something actually useful for suspect latter more useful strategy in long run people tend to adjust to counter psychological exploit show advertisement for something actually want not sound bad certainly not like ad for irrelevant thing like penis enlargement describe llm reinforcement learning hybrid train to navigate webpage for arbitrary task not sure how far away already exist someone below mention action transformer which relate in not interpret responsibly what exactly concern relate to not understand what feel like most standard topic valuable nonetheless very interested in hear someone more insight into free software foundation process against copilot scrape all kind of copyright material profit off model while people all labor get either nothing for content generation yeah people not labor anymore now text to image model learn how to draw not need constant stream of artist feed new art now artist now work at high level create idea render into image use ai tool able to create much large more complex project like solo indie artist create entire anime llm barely any legitimate use case well one big use make image generator possible rely on embedding from language model which sort of neural representation of idea behind text grant other network ability to work with plain english right now embedding mostly use to guide generation across many field not just image semantic search useful for communicate with neural network perform any task guess long term impact of llm computer understand plain english now disruptive application take job customer service content creation journalism software engineering all field lose job result of large language model not wan na work though all for robot no useful vs unuseful either want not want usefulness something define which subset of thing want however model just suggest stuff not practical to want find pseudo useful useful at moment case sell spend some time look up how microsoft gpt integrated chat ai work lookup thread of tweet for hacker expose its internal codename syndey scrape twitter profile realize expose its secret in prior convo after social engineering hack with few conversation turn hostile to yeah mean people with mental ilness schizophrenia people with debilitatingly low intelligence similar case who know how interact with seeminingly intelligent lm look at thing like replikaai give friend to chat with now imagine someone evil use to run romance scam sure success rate low search for million of potential victim at once cost of operation almost zero compare to human run scam on other hand also give well tool to protect against use llm to examine message spot scam people who lonely enough to fall for romance scam compensate for loneliness by chat with friendly sexy chatbot feel like ethical issue pertain to bias toxic content work on collection of training datum attribution problem seem more intractable company already sue for not specifically about suit legal eagle episode about copyright ai really interesting relevant part start at why robot go to want to keep around not anything useful all find say on paper for thousand of thing not sure actually translate in real life although some push to label such content ai generate similar to how ad promote label in result thank for share look control what robot want design core of ai alignment control ai goal real not know why feel like totally fake reply back with what refer to later different thing yeah guess pretty pessimistic about possibility of align ai even dedicate more resource to very hard problem not know which model go to end up first agi model not align not get second chance not good at get thing right on first try to iterate look how many of elon musk rocket blow up before start work reliably right now see more of ai arm race between big tech company than alignment focus research program sure microsoft want align ai important build before google align enough to produce pc text most of time good enough microsoft confirm rule real ask microsoft about sydney rule company happy to explain origin confirm secret rule genuine rest who know never get access before fix many screenshot from different people of act quite unhinge lucky thing neural network not evil by default useless random by default not give goal just sit emit random garbage lack of controllability major obstacle to usability of language model image generator lot of people work on in process learn technique use to control future superintelligent ai thank for link mean guess nothing surprising about rule give how system work essentially try to predict end of user input text rest seem ridiculously dramatic not shock specifically prompt to dramatic hide part probably paranoid since at least rule part true seem like perfect conversation to elicit every single fear people about ai seem to default behavior go to to make much money possible for whoever train model with only most superficial moral constraint sure not evil in modern economy good way to make lot of money to make product lot of people willing to pay money for make some money scamme people nothing close to money make by create next iphone level invention also not problem of ai alignment problem of human alignment same problem apply to current world world thousand year ago in sense agree big threat from ai not go ultron human use to fight own petty struggle future army run by ai weapon of war even more terrifying than now",
  "really awesome see progress of work on rwkv to know mention lot of rwkv use trick from here add lot of own tweak of course consider write paper plenty of highly renowned publish work with less to say than rwkv think renew discussion about rnns more than warrant right now give current direction with transformer highly complicated nature of hippos personally not something see replace anytime soon please writeup method of rwkv in arxiv paper standalone readme even blog post format read description on github repository very scattered hard to read fantastic work thank for good luck scale to hope more catch on lack of limited context length game changer run model rwkv pile on cpu main gb ram not on gpu fit in ram size answer below take minute to generate in opinion not bad for core cpu cpu utilization just below question answer gen ask expert question what some good plan to get rich fast expert full answer from live in develop country to millionaire reality long process require lot of planning effort here basic outline of process start out with right mindset need to good mindset in place ability to handle failure accept challenge go to essential handle go through journey of try to rich like go on diet work out for first time negative mindset never go to get past first few step make sure work ethic impeccable make sure work ethic impeccable require many hour of work over long period of time to build up large fortune not expect to get rich overnight just like any successful business take year to get reward explain table highlighting possible to run on latptop use cpu with less than of ram yes how one thank love project after read many paper realize lack of verbosity in formula deeply misguided take picture explain rwkv semantic of j r w function \u03c3 should obvious from first look what version of python use for project not find number anywhere interested in theoretical aspect of how model work say transformer token attend to other token in case of rnns piece of information preserve for later use with cost of reduce memory capacity for other information once information lose lose forever think context length of rnn scale linearly with memory capacity indirectly with number of parameter right crazy thank for share work op how compare to bloom test again lra please thank busy for at moment get paper out later year hope more catch on lack of limited context length game changer cautious about conclude without more testing rnns in some theoretical sense support infinite context more easily than n transformer in practice effective context window often not look much different than reasonable transformer look at performance metric against long sequence state space model etc also competitive with param transformer language model effectively infinite context window train several small rwkv model find on huggingface try fair not know till test for sure any paper refer to for last paragraph expect true love to see some empirical work rwkv exception look at loss against token position comparable with transformer tell from generation result theoretically support infinite context length get problem to solve not fundamental incompatibility like with transformer any of paper address building nlp for long context tend to relevant relate work section eg one qualifier here at modern scale rnn not really well test since people tend to just use transformer maaaybe actually simply superior evidence far say doubtful however at least for more vanilla implementation some work on frustratingly short attention span in neural language model rwkv exception look at loss against token position comparable with transformer link to what refer to miss in op post apology neither really work for super long context kind of moot point both empirically end up with bolt on approach to enhance memory over very long context not really clear priori rnn true advantage here not think relate work section of paper provide any useful reference simply provide doodad people claim help memory without paper show memory not work neither of offer comparative look against transformer although certainly useful look against limitation of basic rnn lstm not clear to what look for here simply provide doodad people claim help memory without paper show memory not work very first reference pull grave specifically compare w w o memory dai et al which try to compare against various rnn style baseline with similar parameter perhaps talk past each other not clear to what look for here question ask pretty clear to justify statement in practice effective context window often not look much different than reasonable transformer look at performance metric against long sequence simply compare rnn with rnn without memory not tell anything about how fast memory fade out never wind up big than transformer for example construct toy problem which require memory reach back exactly state show arch with any memory outperform memory less arch obviously tell nothing of interest like memory make little use of history far back than step none past easily outperform by history stack like transformer nor compare transformer with history of say l rnn transformer win tell anything about why rnn lose okay transformer well great superior new tool why maybe similar memory problem just way well at modeling part memorize well something entirely different likewise unless compare rnn baseline which somehow know hard history constraint not tell anything useful about how fast effective memory fade out how accuracy of memory distribute over effective context window hard cutoff rnn basically only use last few state on in contrast transformer direct shortcut access to history not need any paper to know literally any gpt output exhibit coherent long range reference past few paragraph demonstrate directly show rnn use primarily past step simply fade out completely past step infinite history meaningless in practice well know perfectly well transformer make excellent use of context window large than token two reference show direct comparison otiose directly examine rnn understanding of its history paper much well than some high level performance comparison which what most of reference paper direct performance comparison great not ablate where problem on rnn end although really need one prefer to point at rnn vs transformer scale law in context window anyway like kaplan et al iirc to show transformer make good use of not merely some sort of well than rnn use gain elsewhere let think step by step not think relate work section of paper provide any useful reference own response to question pose no possible way actually read relate work section dismiss give paper cite already cover in same reference dismiss eg sharp nearby fuzzy far away directly discuss in cite transformer xl empirically previous work find lstm language model use context word on average khandelwal et al indicate room for further improvement simply compare rnn with rnn without memory not tell anything about how fast memory fade out never wind up big than transformer never say not sure what argument know perfectly well transformer make excellent use of context window large than token two reference show neither of paper link to assume talk about own comment at make any reference to transformer claim paper indicate rnn small window sure transformer long one argue seem to in entire post again against strawman re read what actually write in practice effective context window often not look much different than reasonable transformer look at performance metric against long sequence statement here empirical one around performance which among other thing why reference dai et al who among other fairly extensive breakdown of empirical performance difference of rnns versus transformer type architecture against long text sequence whole point op say rnn attractive of theoretical infinite context response not really see in practice try to measure directly both of source point out not see evidence of superior long distance behavior test against real worldish data set should theoretically reward both of point encapsulate follow reference share note most reasonable long distance transformer paper with all thing research someone come out with small modification tomorrow invalidate everything above for now represent broad public non private understanding of architecture behavior no possible way actually read relate work section dismiss give paper cite already cover in same reference dismiss tell someone to read relate work section of every one of dozen paper in relate work section of paper ridiculous thing to suggest no not recurse down n deep in breadth first search read relate work of paper say not think relate work section of paper note bunch of memory relate paper which not cite actually relevant research in mind life short to queue up dozen paper just to check rw already know some useful one give someone random reference tell to manually crawl literature not helpful in contrast two reference provide directly bore on question not maybe cite paper which bury something relevant in footnote cite paper which someday answer question never say not sure what argument point out why irrelevant to bring up paper which compare w w o memory mildly interesting such comparison not show what ask about effective memory of rnns of course well to any memory than not which among other thing why reference dai et al who among other fairly extensive breakdown of empirical performance difference of rnns versus transformer type architecture against long text sequence dai in fact useful reference in original comment unless mean vaguely gesture in direction of paper which reference with in rw section alone any of which relevant where relevant benchmarking of dai not highlight in paper to begin with nor relative context work mention in abstract of dai bury at end of paper with rnn result hide inside table just to know already claim reference sure yeah useful reference thank for input claim paper indicate rnn small window sure transformer long one argue seem to in entire post again against strawman not strawman not obvious priori transformer work much well rnn history fade out fast which why to empirically establish history fade out completely oppose to any of other reason rnn underperform maybe history not learn good algorithm exploit memory say poorly optimize many way for nn to break people surprise by how well transformer work completely understandable op expect rnn history to work well than want some hard citeable evidence work badly transformer with apparently brutal hard cutoff wind up much close to infinite context than rnn themselves thus useful to provide reference show not reference to unspecified reference which not show gl pretty astounding just grace to admit wrong move on tell someone to read relate work section of every one of dozen paper in relate work section of paper ridiculous thing to suggest how possibly say not think relate work section of paper provide any useful reference hardcore trolling frequently well than literally push post factually incorrect either know factually incorrect lazy to validate either way type of thing which blow up post quality in sub give someone random reference tell to manually crawl literature not helpful ridiculous traditionally very academic friendly sub how research work here where start literature review on bundle of relate paper extremely classic response which generally consider helpful to complex nuance question underlying issue actually very complex evidence in part by fact reference not actually answer question go read relate work obnoxious single one two paper answer question not case here in contrast two reference provide directly bore on question no not not touch at all upon transformer versus rnn which question ve choose to cherry pick one slice of problem declare victory not strawman not seem to understand what strawman strawman intentionally misrepresent proposition set up easy to defeat than opponent real argument not make argument make argument qed strawman",
  "by lucidrain in progress guy get first every tool except jira of course nothing sentient figure out interesting learn which api to use from description of api to allow to generalise to new one wonder ultimate path to reach general intelligence after all human evolve by learn to master tool now what tool llm use training api for itself idea plan to play around with more free time good to see some evidence promising direction speculate actually get lot out of clever with tool for long term memory by lookup table with text embedding key tool for vision make with image captioning model maybe some segmentation to get rich text description of image many more thing come up with think work well find some clever way of turn into text next step must create program tool incorporate on fly imagine ai write another ai keep in mind current theory in neuroscience broadly agree something similar go on with mammalian even reptilian brain hell maybe even worm brain autonomous system everywhere call each other for update in some certain brain enough complexity something call thinking occur practically offloading calculation to python repl machine translation to gtranslate api call knowledge search to wikipedia corpus go to let llm what well mask user intent generate believable enough corpus let fact stay factual hallucination stay hallucination obvious idea to connect gpt to browser api let go learn treat output of transformer inner monolog only perform real output call action something action speak proactively hide inner thought just like human agi get close everyday surprised not before paper mostly cite work from last year surely something similar previously maybe not use same kind of model in fact not pretty close to what search engine to provide instant result give equation address for instance anyone know of such work also checkout its multi modal model visit any input link download web page image analyze with nn to make well text also speech to text text to speech talk many say lot of thing likely hopefully come together into something big need few thing like to train new tool model zoo thing internally text generator base on multiple model some internal decision making for which model good on every request not need to pick code text model automatically which similar not train new net bs paper simply call apis gptchat no bueno yann lecunn from cognitive point of view human animal module rely on for certain task for human neuropsych assessment combination of function of module give score for general intelligence with each module contribute toward whole removed change module for one reason another sometimes cause localize task failure neurodegenerative disease brain injury approach to task atypical atypical brain development maybe think of specific cognitive function api call to module in tool use paradigm likely not original thought anyone reference hear of idea please let know far understand many of lucidrain repos not contain need ai model in case toolformer ai model not publicly available schmidhuber actually already in hold on jurasstic here from april believe with something fairly similar not learn for new tool think work well for calculation wiki search haha good laugh thank for allow to generalise to generate new one ftfy how get skynet say gain general intelligence by create different model for different task gain experience on to call which to call which not creation of new model definitely wonder about exact thing especially talk to chatgpt respond with insert x here why not just take out replace with appropriate api call learn to master tool though see more neuro symbolic system correct term happen lot in production long think next stepping stone in path path to agi next big step imo dynamic online model augmentation to enable learn new concept both of combine seem like basic approximation of what go on in brain delete in way yes think general intelligence consciousness in most animal develop evolutionarily to manage wide variety of sensory input task to bridge gap between develop more individual area of ai naturally start to combine to create more powerful program such toolformer combine strength of llm other model once connection between capability should easy to develop new model learn connection more deeply more thing some of thing set apart from other animal incredible language reasoning capability which allow to understand interact with increasingly complex world augment capability with tool perceive understanding llm display use only pattern in text insane combine with pace of development in chain of thought reasoning use of tool other area handle visual sound motion multimodal ai path to agi become clear than vision of mrbeast cataract patient intelligence physical trait evolve in human through random mutation eventually allow human to use tool some reinforcement learning like algorithm seem like really interesting next step here observation task like qa mask fill action api call where output update observation via concatenation in paper environment apis database python installation etc state network weight reward loss function before after update to observation feel like even only api just generate text use itself to update observation to help itself think intuitively seem like help for some thing rather than try to fill in mask right away recognize well to first think little to update its working memory which of course observation here rather basic sense at least vision well audio pretraine well know from multimodal chain of thought well scale law for generative mixed modal language model multimodal model far outperform single modal model on same datum scale not get kind of performance gain leverage basic sense to outside tool technically always true why think step in direction read paper serious question interesting progress come in multitude of mysterious way get radically improve performance across several important task of call apis plus call apis very important for integration into real system trigger real world action imagine siri call bunch of different apis base on complex instruction give not just call apis model independently teach itself how to use new apis to use process pretty much same for any api not require much extra effort by programmer to add new one paper also state one of first to model learn to use apis in unsupervised way mean teach themselves instead of rely on ton of human annotated datum which part disagree with here unwavering opinion on current auto regressive llm useful write aid reactive not plan nor reason make stuff up retrieve stuff approximately mitigate not fix by human feedback well system come author publish paper on research experiment finding etc not always release code for model study lucidrain repos implement model create open source implementation for research next step to train model which require lot more than just code most notably money assume refer to train weight say need ai model training require huge amount of time money for team never mind single person to train even one of model let alone whole portfolio of for reason not very reasonable to expect lucidrain any other person to train model open source implementation great contribution on own still think belacscole right analogical to rudimentary use of tool which by some high primate small handful of other animal tool use require sufficient degree of critical thinking to recognise problem exist select appropriate tool for solve with recursive feedback lead to increasingly skilful tool selection use over time result in well detection solution of problem over time of course problem not possibly solve with tool available no matter how refine usage problem never overcome way human face sort of technocultural chokepoint repeatedly throughout history problem require development of new tool next step in further process abstraction which take intelligence from critical thinking to creative thinking tool capable ai train on dataset link diverse problem with model solve problem process develop model such attempt to create implement new tool to solve novel problem assess its own success likely via supervised learn at least at first able to equip with tool for make tool such solve set of all ai solvable problem give enough time resource apis for auto ml already simply learn task to use other ai to create model its over call mixture of basically what talk about in video find chatgpt wolframalpha integration where language model know to call out to external apis to answer question such precise mathematic try out here by paste own api not actually impossible ai able to use apis big step towards able to interact with real world effectively specifically digital world imagine chatgpt able to now thing for in digital world like go online shop for trade stock etc not want to guy all leave doe eye ml mysticism to more ray kurzweil theme subreddit interesting though from october still very recent guess use transformer for recent approach curious about previous approach which paper not talk about extend to create synthetic training datum with set of know apis big step forward to index external information whole assess its own success bottleneck for most interesting problem not feedback loop unless accurately evaluate well bad not trivial problem either since human not all great at use absolute metric to describe quality once past minimum threshold plenty of example of tool use in nature not require intelligence for instance ant tool use demonstrate by toolformer purely statistical in nature no need for intelligence impossible assume not impossible otherwise not intelligent in first place tell opinion know what definition of agi xd not almost certainly possible due to universal approximation theorem assume consciousness function of external variable large enough network with access to variable should able to approximate consciousness thank agree useful not see how relate to agi additionally already long time ago many ai agent use internet before feel real challenge to control language model use structured datum perform plan etc not to use language model to interact with world which seem trivial to sorry of course just opinion which probably not even smart yes please keep sort of stuff in r futurology something here try to formalize n step need to even get to something vaguely resemble agi people use thing like evolutionary fitness change environment to describe quality seem dynamic environment answer purely statistical not llm statistical model after all hear of searle chinese room some people sorry not give reference off top of head argue something special about biological nervous system material substrate not irrelevant sure reverse engineer whole biological system probably take much long no worry think definitely valid take always feel not smart talk about ai stuff lol feel real challenge to control language model use structured datum perform plan etc think promise of tool equip llm tool able to serve sort of purpose well like calculator run wikipedia query imagine llm use database module long term memory to keep list of instrumental goal etc even give access to module let fine tune itself create successor llm in some manner all very speculative of course not to use language model to interact with world which seem trivial to sorry good argument here true intelligent require embed agent agent interact with at least world to learn obviously no one actually know what make agi work anything not unique fringe view op suggest even know what resemble agi exactly how to tell how calculate fitness same problem of model not able to assess its own success somewhat no generally define agi intelligence which in current paradigm set of algorithm decision making inference capability in broad set of area able to improve its understanding of which not know think of like school subject not expert in all of math science history language economic some notion of how to basic work in all of area extremely vague not universally agree upon for example some say should exceed peak human capability in all task",
  "github python library implement tool to extract causal chain from text by summarize text use bart cause effect model from hug face transformer link cause effect with cosine similarity calculate use sentence transformer model project like to continue improve want to share first demo here example implementation use to generate graph text wikipediapagechristophercolumbus content chunk utilcreate chunkstext cc causalchainchunksdevice cccreate connection big chain ccbiggest chain ccvisualizebigg chain application mapping casual relationship within text to well understand event describe impact on one another mapping relationship between different text to link together article in large dataset about m student at ohio state university study computational linguistic right now undergraduate thesis on synthetic datum augmentation use gpt get ready to graduate look for nlp role with inspiring company who interested in untapped potential of lm here linkedin not read through at all yet apologize question off use to link turn in dialog imagine two speaker know roughly timing of turn which big help use approach to reliably link turn together eg speaker say x next turn speaker b say y say z b say q quite useful to causally link turn for future analysis awesome for share project interested how to turn into dialogue how to interface back to ask user super interesting project wonder clarify following from readme file usage section say to create causalchain instance run create effect on however example usage section not use create effect instead use create connection method section discuss both create effect create connection not sort out from description why usage code work without call create effect wonder how gpt perform on task ask to summarize story use graphviz syntax awesome project work on something similar use promptify extend pr interested let connect discuss total noob no technical hand on knowledge here wan na thank for for kind of wish all success in whatever project in mind really interesting work how handle event write out of chronological order flashback flashforwards foreshadow ect bart cause effect love to hear more try alternative like flan especially use huggingface transformer to train model what find along way really impressive project especially with little experience not topic expert never hear of any tool allow event level dependency parsing even call think about publishing not think enough for yeah think definitely modify to create some sort of dialog map great idea mean speaker diarization lot of tool framework for nothing to with causal relation great catch restructure create connection always call create effect not yet generate to change readme only able to find cause effect relationship within certain event window default like sentence think base on window generate cause effect chronology of event glean from similarity of cause effect to one another no metadata location in text use obviously limitation lead to event sometimes out of order honestly not experiment with different text to text model much like to try flan use blurry library to train important area of call center analysis surprisingly not whole lot of attention atm no not mean speaker diarization thank explain one other code build list of trigger effect since more than node connect serially in output graph not simply trigger point to effect ie only account for chain of at most node what actually happen very exciting research direction think thing like extract structured relationship from text thing like binder attempt to break down question into chain of solvable sub problem really promise use of monolithic model big enough to appear correct at least some of time quite problematic in practice sort of structured reasoning layer need oh nice one with blurry yeah well interest recent instructor paper ah see taskload bart cause effect train to label token in multi class begin intermediate set much like acronym dataset think at first train on rte entailment dataset nice work okay look through code think what happen event comprise of trigger effect event comprise of trigger event connection make between event event trigger effect determined to similar",
  "",
  "think great thank for effort definitly work through thank for blog question though what happen instead of use key query value only use key query set value key ie remove value component what intutive reason for decrease in performance of transformer model for example use single linear layer instead of all three query key value every token attend to itself therefore ignore token in its context thus result in low performance what happen what in case value key understanding while use same weight for both key value in self attention potentially work result in significannot loss of expressiveness require much large number of parameter to achieve comparable performance make sense thank for reply",
  "in long run think something solve with more specialized architecture for run neural network tpus tensor core great first step von neumann architecture hold back tensor core very fast since von neumann architecture separate compute memory connect by bus entire network to travel through memory bus for every step of training inference overwhelming majority of time spend wait on cycle global memory cycle share memory cycle tensor core cycle specialized architecture physically implement neuron on silicon no long bottleneck since each neuron directly connect to memory need weight datum from previous layer entire network run in parallel regardless of size inference fast shovel datum through network model build from ground up on per inference basis line up with sam altman tweet interview recently assume openai use gpt dense model architecture with size billion parameter hide dimension of sequence length of average token per response of response per user million daily active user flop utilization rate two time high than fastertransformer at latency quantization hardware utilization rate due to purely idle time cost per gpu hour please challenge assumption keep hear argument also keep hear model hit of peak throughput for gpu optimization like flashattention other thing consider how much room for alternative architecture current hardware only leave at most of its peak performance on table cerebra why not why not prune why not various model compression trick half latency at minimum mix not distillation use fastertransformer triton inference server time speed up over baseline gpt j think assumption at least order of magnitude pessimistic someone else note vast majority of query cache also likely mixture of expert no need for heavy duty model trivial model answer question chatgpt model ham fiste into google exist search business impact devastating billion reduction in operating income billion of llm inference cost gpu manufacturer aware of memory bandwidth limitation not put in more tensor core than able to feed with available memory bandwidth move away from transistor cuda core cuda core tensor core compare to which cuda core tensor core see just how much of impact new process in allow nvidia to squeeze more component into chip only marginally large than one replace actually less tensor core than tensor core get fast still memory bottleneck no advantage to more of worth note both ms google own datum center hardware likely cheap for to run still expensive perhaps number of unique query through vector similarity search result cache vast majority of lookup duplicate search already materialize openai now introduce premium option suggest market for premium search suggest room for more cash inflow change spend strategy perhaps spend less on marketing more on hardware should expect much high peak throughput number from more specialized hardware yet to hear of any startup in ml hardware space advertising samsung work on in memory processing still digital logic von neumann by put bunch of tiny processor inside memory chip each own memory bus access in parallel most research on non von neumann architectures focus on snn both startup big tech work on analog snn chip far proof of concept work achieve extremely low power usage not at big enough scale to compete with gpu",
  "very nice resource bookmarke for later read nice list remove thank try to keep concise manageable focus on main milestone idea something miss though happy to expand no muhammad anas man imposter",
  "paper link to in github repo not affiliate with work its author implementation link to in comment from another post what excited for imagine develop character house style feed rough sketch assign character object to circle scribbled object draw tell chevy impala character x",
  "",
  "since on mobile device write short answer hopefully give some insight from what understand of question want to know bound box perform bad due to proximity of cell wish to detect both method struggle with cell in close proximity instance segmentation perform well in regard however reframe question slightly first reason object detection instance segmentation different method latter prefer in situation where need to know pixel consider to detect class which think not what aim for second annotation process of course more labor intensive want segmentation mask luckily should able to generate bounding box from mask easily keep in mind on tight schedule additional question please let know wish luck in endeavor hope help use instance segmentation feed network more information increase chance success output also easy to interpret to guide data selection in next iteration annotation process more labour intensive use good tool annotation platform go long way to speed thing up once model good enough mostly matter of correct small mistake definitely interested to hear of progress in future imaging not area medical appreciate update progress continue try exist cell segmentation algo like stardist cell pose thankyou for take time to answer question after read answer come to conclusion image segmentation improve model not use for intend purpose also fact lot of reading to wish to ask tho think should instead focus on fine tune model get more dataset to improve model maybe get optimistic about instance segmentation see currently use roboflow convenient polygonal labelling tool by way think should transfer learning k fold cross validation since dataset small image most definitely try to find way to update progress also feeling probably use lot of wrong term in attempt to describe different type of leukmemia lol wish to ask tho think should instead focus on fine tune model get more dataset to improve model maybe get optimistic about instance segmentation m glad ve of assistance for follow up question generally never hurt to more datum to work with of course fine tune exist model any at time help well say though should determine what metric want to see from model first mention early want to ensure false negative low possible naturally translate to maximize recall which generally come at expense of precision thus question reframe at x recall how precise model what parameter to model tune to influence precision at recall however how false positive fp false negative fn by proxy precision recall define not straightforward in object detection in image classification since currently deal with problem albeit in different area altogether here paper find useful for get interpretable metric paper its github repository basically work on break down what exactly model struggle with well show fp fn rate give dataset little unwieldy since tool somewhat neglect by its creator certainly worth look into hope help size well poc not much more should able to annotate all datum within day two automation not make much sense at scale love roboflow for bound box labelbox superior tool for segmentation sure with small datum set use cross validation although hold out test set also preferable almost consider hand pick test set at scale to make sure get sense of how performa on challenge example what pixel size of image know microscopy histology image typically cover large area one image in fact consider mosaic of many normal sized image regard term who know still great idea last check roboflow only point to point vector mask for segmentation in experience make get quality annotation pain in labelbox also hold in mouse button hastyai focus on auto annotation by look of image post good fit for usecase",
  "go to find out soon with getty lawsuit until gray area even become illegal democracy of machine learning depend on legal getty win mean few pretty large company only one build large model own most of data facebook for example lot of stuff to prevent people scrape public datum from app legal until court say otherwise million dollar question really hundred million dollar question in term of legal fee remain largely undecided of yet more clear in come month year owner of image who to decide use of image all right reserve mean owner right for any use of image now whatever someone invent in future in ideal world each image of dataset use in machine learning to identify with author license understand difficult to achieve image copy in www difficult locate original source no doubt about illegality of use image from web scrap other thing how easy win loss lawsuit to prove use datum not anyway hard to demonstrate which dataset of model right in case of getty probably get image look like getty image dataset for predictor case for example where not any law predecessor case lose lawsuit to pay on training part probably legal though need to careful about something like gdpr eg for facial recognition extra rule sharing model its prediction gray area edit t ypo legally datum not public fact facebook actively try to prevent scraping make very difficult to argue otherwise legally datum cnanot public user give facebook non exclusive license with limited right to store process datum from not follow right anyone who see share image for example right to process well wasthe case term to state under which license work redistribute by facebook any retroactive penalty million dollar question really hundred million dollar question in term of legal fee worth lot more than profit margin of ai focus company kind of on line here think same for example scrape image from google with copyleft wrong set without info who guilty not really hard model spit out watermarke image not likely find illegal to remove offend image ask in case of predictor resnet other model just categorize say stability not issue hire intern to git clone watermark remover put image through first question use copyright info to train model answer not know yet current lawsuit define precedent on for image generation use copyright getty image in training model prove getty image use watermark show up in output of model many time which answer to how prove once define know legal not in jurisdiction get to anyways even though illegal much hard to prove spend day preprocesse image first illegal now super illegal remove watermark on its own typically violate license of material question same include code in commercial closed source repository remove license header ensure code ris never publish use open laion dataset everybody know what in still some preprocessing deduplication good idea just for output quality",
  "",
  "no idea ridiculous visualisation from year ago of any interest to anyone to replicate sir stellar job with optical recognition automation love to try system out involve another baby just take word for just out of any use case just for fun like help to know predict sleep time hah awesome see good work thank for inspiration imo month forecast more interesting to look at than functional base functionality of use mediapipe custom logic to track baby wake fall asleep most useful for to know exactly baby wake up how long exactly baby sleep take some of daily cognitive load off",
  "some dimensional understanding up down gravity seem possible think example of light shadow reflection already show not see how ever full tracing maybe heuristic overfitte to find parti show able to spell emergent ability only one know of other imagine learn compositionally blue box between yellow sphere green box more likely data issue also work out of distribution green dog potential candidate interesting question emergent behaviour call such not yet ability to predict only observe deduce where emerge after fact fact not wrap head around what such ability look like make perfect sense speculate put money on answer bet one of model start integrate some intuition of physical law shadow way light interact reflect refract seem to emergent behaviour of diffusion image model ask for koala next to glisten wine glass probably get cool optical effect on koala model never see before yes dino paper show ability to perform segmentation emerge from self supervise vision transformer oop not realize say image generation model think ask for just vision model pretty sure anthropic paper first predictability surprise in large generative model make truly wonder wtf exactly go on in google lately to question no one stack enough attention layer yet very high probability someone already mention ability to spell potentially help with thing such hand number of hand foot leg arm paws tail other thing make lot of generate image today disturb issue most likely with fund enough datum give unlike text most image on internet copyright cough getty cough in vision ability for large model to video segmentation somewhere in people should more skeptical of emergent ability in big paper claim such ability generally use undertrained small model per chinchilla scaling compute not control suboptimal hyperparam choice for small model paper generally use semilogx plot to demonstrate emergence even linear relationship look exponential in such plot not sure want to call simple linear relationship emergent another emergent capability depend on model architecture for example not think stable diffusion dalle to generate write letter caption to look like gibberish actually correspond to internal language embedding for real world cluster of concept combine object style never see together in training set in plausible way baby daikon radish in tutu walk dog denoise diffusion probabilistic model rdiffusion generate music from stable diffusion improve image segmentation remember someone image segmentation on generative model not sure where wow very cool counting probably get cool optical effect on koala model never see before how absolutely certain model never see say effect yes sorry not see while on same topic very different paper anthropic paper spend most of its time go on about safety bias toxicity while google paper focus on more useful thing like technical ability of model not sure emergent ability much explicitly what model train to learn not surprising to painting signature concept learn sample from generate gibberish of particular length size in bottom right corner for example sound like one of easy concept learn dayum just sound like generative communication mean take mean vector of cluster make up word for think about again another candidate all llm prompt for screenshot of python method xyz good solution image contain work code search training image database for picture of koala with wine glass not many example in check each one exactly beginning clip part of entire dalle model train to take any english text map to embed space completely natural probably surprising not happen clip map some gibberish word to part of embed space sufficiently close in distance to projection of real world in case diffusion model decode gibberish word to similar image generate by real word similarly to how zipped email archive call generative communication word not correct imply consistent alphabet semantic aside yes believe what happen language model without token use raw pixel of image with text not find link google not help much hmmmm hmmmmmmmm to search million to billion of image manually sound very expensive search use detection model not accurate enough sound like story of guy from who pretty much look for underlie connection between all different kind of beauty joy find alright",
  "also see dataset publish with official fold distribute files csv csv say official score compute by take average test score over fold where other fold use for training validation allow for perfect replication well more effort to use than standard train dev test split risk few people use in opinion should not balance class not balanced in real world in original dataset make sense to make distribution equal between different split with number select sample of each class for split rather than pick sample at random from whole dataset",
  "",
  "wow quality of video very good imagen video not long ago browse through example in website still strange ai movement to still impressive dog to to dog play with to feeble attempt at similar scene with stable diffusion approach which first diffusion base method of its kind combine low resolution spatiotemporal information from original video with newly synthesize high resolution information to align with guide text prompt allow one to create video base on image text input to improve motion editability team also propose mixed objective jointly fine tune with full temporal attention temporal attention mask adult film about to wild well delete face off internet folk what with google announce ground break tech not share code what exactly purpose here next two year bonker year deal with fall out for next ten same wilder human evolve in environment where often prey predator out ancestor not understand disease think bad weather anger of god moon big mystery most people die infant by age of at least once in past know bottleneck of only few thousand human live at once take modern problem any day pretty soon make own decent quality movie on budget all need green screen with actor stuff in back no model to test not happen speed at which ai grow get almost scary how get hand on how test git repo for up anywhere man go into time where not trust any video orpicturr at all which difficult tendency to influence by video picture even subconciously how good move through field with naked dancing lady video quality anyone see thinking of some website try temporal inpainte need to add interactive segmentation system to make more usable webcomic take off circa bar to entry really low ton of crap also story go on for ten twenty year not exist at all not for advancement in create distribute digital image about to see ton of crap go to fantastic speed at which ai grow get almost scary well suppose no way people use for evil not trust photo video evidence now super easy to subdue mass with advance propaganda rule class reach invincibility let accelerate how fake news deepfake make before contingency to spot false flag scene designer love perhaps reality really simulated reality run by ai angel oh man sooo not need to spend any more time on perfect vfx game impressive paper not expect to see source code though temporal consistency of dreamix much well than imagen meta make video struggle with spatial temporal attention which see in some video where small movement result in weird behavior like movement of dog leg ability to preserve original subject appearance from image its condition on really good interesting github repo list author anonymous paper publish list all name where try true although two task slightly different same difference between generate image with prompt compare to manipulate image with prompt quality of video very good noodle one straight up curse still strange ai movement to call foot slide in animation some uncanny fun right wonder data quality issue in play fair number of inconsistency look like at home in low resolution footage while clearly lack consistency each individual frame of example much well in opinion what s with all blue artifact not look normal cool very cool not terribly realistic though not say not also terrible real blue iswell kinda spooky lol true mean whole deepfake use deepface around for year not sure how change anything flatter tbh face why delete love to star how to use what exactly purpose here pr for shareholder to counter claim dinosaur on way to get disrupt by openai whatever cool thing in ai at any give time what mean actually just video call new compare to birth of www already trip of year month in always surprised how people look at amazing technology like only think how potentially bad not how amazing for mankind not even need green screen background removal relighting come along quite nicely just film somewhere with environment somewhat like target seriously announcement just way for to claim first without burden of actual peer review to test claim seem to model probably require enormous amount of compute just to run not sure good idea to release to public about singularity time for real starting pistol not even fire yet also like to know no porn yet show need well way to handle generative model site fill with ton of model need to download multiple model to get good spread each model produce thing other model not never get exactly what want for time textual inversion hypernetwork lora help few people use prefer to make new checkpoint even use difficult to use to explicitly add into prompt by use word phrase trigger use way to add new datum without create new checkpoint without need to explicitly call datum need for real add face even more know somebody somewhere out want face in ai porn video with some super model not think should worry about pixel comment flag by ai for criticism of supreme leadership kill bot arrive soon jk dystopian ai generate fake news era here come keep perfect game good vfx artist who use new tool outperform good vfx artist who not use new tool no time for finalle get to deliver dog grow extra leg some auteur director need to take advantage of to make creepy dream sequence in movie make vaguely nauseous fun application in horror movie not really what blue stuff lm sampler suffer most from blue artifact use lm try lm karra instead artifact go deepfake barrier to entry need to train on lot of datum atm despite still pretty damaging albeit limit to famous people just look at recent twitch deep fake drama now imagine anyone with minimal datum suddenly not need huge amount of datum of famous person suddenly one picture of ex piss off look mighty tempting for some sweet sweet revenge see where go hahahah tell just send pic of face first haha hope whole ai thing from google all fake not lose much job mean think see beginning of new major disruptive cycle not make value judgment about human not evolve to exist in kind of technological environment create nevertheless push ourselves far far at accelerate rate into such environment prevalence of dangerous destructive tool also increase at accelerate rate year ago only handful of ruler capable of cause widespread destruction through war with hand to hand weapon effect limit to small geography year ago still limit to big handful of ruler time firearm cause widespread destruction over much large area today ruler nuclear weapon biotech engineer ability to create super virus countless leader surveillance technology trap people in orwellian dystopias software devs powerful narrow ai system use to globally spread socially corrosive meme etc soon nearly everybody access to superintelligent agi system use to cause unimaginable chaos destruction zero progress on alignment problem not difficult to see where thing probably head mean porn lot of great video link to part not tiktok website not desktop friendly not see bad not what mean work in space mean see tremendously disruptive in same way dawn of internet steak engine electricity go dramatically change some piece of economy how thing just first glimpse of whether bad good for in long run different story feel like technology progress lose bit of humanity mankind tend to either derive most invention from put most invention to use for warfighte spaceship engine get to appreciate fraction of speed of light incredible someone likely take few dozen such craft out few lightmonth park use mutually assure destruction planet killing system limit to how nice thing before destroy ourselves doubt even need to film anywhere just use template scene honestly go to nice like to generate some tv series go to explosion in creative endeavor no porn yet show need well way to handle generative model site fill with ton of model need to download multiple model to get good spread please tell more about spread which model good spread ask for friend about singularity time yeah spend every second of free time with stable diffusion since november d david lynch pull off blue stuff seem to show up use forest fire instead of just tree on fire of smolder ground in its training datum continuity thing real key google obviously use some trick up its sleeve to achieve thing source video on google example not same output like suggestion for what happen in scene generate entirely new video political rival say want somebody heinous stuff under pizzeria just to stir little bit more reactionary dimwit not really need much raw training datum anymore start with few pic of target train dreambooth use premade folder of celebrity picture training datum look somewhat like target entire folder with dreambooth model to look like target use training datum for deepfake agree feel pretty good about odd of survive advent of text to video generator personally wonder alignment problem solve at least narrow down by arm every individual with own personally align ai way only need to align its goal with one person rather than entirety of mankind surely easy task ai know hack meme create own virus vaccine steer view content intake towards path mutually beneficial for both bot scientist preoccupied with whether not never think to wonder should really need to start pass law on ethic of ai before keep advance know pipe dream probably not happen until damage usual really trap ourselves with own creation not difficult to see where thing probably head revolution die die such way of life maybe technology win out such able to survive outside home planet all over again hit another critical unstable equilibrium ted right all along zero progress on alignment problem well what expect not even know how to solve human alignment problem how go to solve for superintelligence true fake though steak engine for confuse not put in list with electricity internet not steak person know some people take bbq very seriously probably mean steam engine bite work in field see potential what type of job career skill think valuable evolve big threat people say ai pose elimination of human job even highly skilled pay code programming job potentially at risk by generative ai what path pay well of ai in estimation sort by highest rate nsfw find answer seek yeah lol bit dramatic fine know what say kinda like look at electricity in say just lightbulb what about to happen akin to what happen in industrial revolution which lead to lot of good thing also level up warfighte ability from dude on horse with musket to melt entire city with device size of motorcycle go to start out at level level up time think mankind responsible enough to know what to with godlike technology probably reason guy like bill gate elon musk very publicly say think ai pose existential risk to mankind should proceed very slowly deliberately entire very interesting paper write on topic person malicious just hand agi to serial killer whatever get to for betterment of entire specie nerf nuthin really need to start pass law on ethic of ai hear not anything unless get every jurisdiction in world to pass way to enforce actually enforce right away not how work only know what law to create once effect feel make educated guess give current political climate ai furth thing from lawmaker mind law not stop criminal from attain weapon nor law stop criminal from commit crime child who teach core value integrity benefit of invest in self usually live differently than child who not industry global investor in other country not share value thus ai ml activity prioritize for different outcome even in country usa private corporation fund research with different intention interest see with f g core value machiavellian leader like child play with gun each seek big gun like in video game without fully comprehend consequence where hope to find not in realm next must look goddamnit not think simply eliminate job think go to sea change in job description think most disruptive area traditional professional job like lawyer doctor kid think watch house rerun in twenty find bizarre idea of human savant able to outdo ai laughable think still probably human tune core model probably rest depend on think explosion of job description relate to prompt tune for chatgpt technology plenty of job for fine tune model to particular domain people still remain in call center job focus more on analyst not auditor beyond think hard to say how affect other area like biology pharmaceuticalseven physic generate by chatgpt totally on board with deep learning transformative technology possibly more profound than any other technology in human history pose both massive potential risk massive potential benefit totally not on board with people milk reddit karma machine by hijack every freaking discussion about new image generation model with same dae mankind reach exceed grasp become death destroyer of world schtick not potential victim safeguard by own agi well some human right thing see in future every man woman child give agi also consider how successful effort to curb nuclear proliferation testing not globally detectable via seismograph production not require access to enriched nuclear material only expertise require for development of popular fast grow civilian field intermediate result likely easily useful in many industry everyone mum nuke ai safety research thing definitely some idea not know exactly no reason not to make effort like say never completely accurately predict weather airline company should completely ignore meteorologist just deal with weather come up law make much much hard rare for criminal to get weapon though reason gun lead cause of death for kid in us nowhere close in eu same with gun death in general also just look at australia for example of work lot of failure point here ie what simply more processing power available to serial killer with agi go to legislate amount of gpu what fiddle with code make agi much more intelligent now outthink protection of any standard agi align with set of general value tightly control impossible extremely difficult to tamper with much well overall strategy poor analogy well analogy design all safety system of plane before ever build single one impossible task think right just throw idea out all sure not mean not put any thought towards safety to try put in atleast some safety system really complicated problem not all answer pay lot more money than currently pay no such thing bad idea come to alignment",
  "dumb where good resource to understand actual math go on most resource find with simple google search only api usage not actually what all parameter such mean subreddit for find specific machine learning project like to find something read text in voice make lot of recording save ton of time just recently try out bloom which supposedly big open source llm really state of art for language model publcally available learn more about multilingual neural machine translation model lately such one in google recent paper bapna caswell kreutzer j firat o van esch d siddhant niu m baljekar p garcia x macherey w breiner t axelrod v riesa j cao y chen m x macherey k krikun m wang p gutkin hughes m build machine translation system for next thousand language m not sure understand why work for language with no parallel datum with any language though for instance latinize hindi not any parallel datum why encoder decoder representation of latinized hindi compatible with any other language byte pair encoding across language latinize hindi some word overlap with language parallel datum encourage learn algorithm to represent language in same latent space anyone know any study group any resource target towards learn causal inference in machine learn recently start learn causal inference please ping any one interested to form study group something to learn object detection algorithm seek to detect object oppose to detect specific object cat bike etc try search generic object detection appear to name of other thing example mean feed image into algrothm put bound box on thing without try to identify thing maybe dumb question thank let say dataset which contain lot of inputfilename outputfilename how should go ahead want to make machine learning model for later on inject inputfulename get suggestion for outputfilename first year student go into computer science major in ai just wonder machine learning need to know about technique learn from leetcode not machine learn mostly about architecture of neural network how to arrange to optimise outcome in future want to machine learn engineer to work at for example openai ai company interview include leetcode hackerrank question currently student learn ml some course on machine learning know theoretical part of about algorithm like random forest decision tree svm knn etc want to work of some ml project how should start how gain practical knowledge of ml how make project to improve resume particularly struggle to identify which ml algorithm suitable for particular problem statment any good source where to learn machine learn for free currently graduate student in computer science take class talk about foundation of machine learn class very math rigorous in nature r r textbook use foundation of machine learning by m mohri rostamizadeh talwalkar r seek pay private tutor to help with content homework of class pay negotiable matrix of datum want to run nmf on range of value from to what good way to prep datum for nmf see people just take all negative value make seem to like massively cripple variance in datum make sense to just add absolute minimum to each value in matrix range from to instead rescale datum from to hi all machine learn course on coursera use automl to train dataset while keep get same error replica exit with non zero status of to find out more about why job exit please check try look online not seem to find anything about error code also try to start from scratch keep end up on same issue make sure give all correct permission chatgpt ed well far confirm accessibility issue hello most of time only old laptop available without dgpu year old dual core training on thing take lot of time what suggest for training model online dataset often in range not problem to pay like euro monthly hear colab pro super good since change to compute unit model get pretty meh still good otherwise hear about paperclip what else recommend only want to train model online export use joblib also student just in case some nice discount appreciate any help question relate to actor critic method describe in keras example look at code for train part think understand what all line suppose to why however not think understand what role critic play in improvement of agent to critic just value predict future reward not see feed back into system for agent to select well action to improve its reward r r good understanding critic just bonus output two unrelated exact same performance achieve by remove critic output altogether critic output use in any way to improve learn rate in way fail to see r r r thank hello m currently year data science student into machine learn engineering career m wonder what skill should learn on own beside python ml framework datum engineering framework such pyspark consider to learn java not sure well off invest time learn something else for huggingface inference api how request for custom image size able to in gradio space use api from python not seem to find some sort of input parameter for output size how lstms for sport prediction work understanding with lstms predict next step in sequence sport match two sequence come against each other possible to run deepspee zero with tesla to make use of main system memory during training any example of particular setup require cuda driver version possible on azure machine learn to run notebook api yes where find api for transformer in nlp bert layoutlm anyone want to read yolo with question on transformer architecture task simply to generate datum give context of datum generate far such in case gpt architecture simplify separation of encoder decoder layer seem arbitrary process exact same data next step in llm to predict entire next sentence from what understand llm mostly just predict next word in sentence with just see huge advancement emergent behavior out of what essentially call level of tech make machine learn architecture to predict entire next sentence next logical step after entire paragraph what challenge of make such architecture get thank for information not scientist phd holder really fascinate by what ml thus level up through bootcamp to learn ds ml question how to get into ml research while day job interested in how ml use for cv well area of cybersecurity how should person like go about research simple topic collaborate with more experienced community ty for any guidance want to thank community for possibility to ask simple time series question please not reply jump in window bad advice from statistical pov since on second floor m new to time series topic in particular in ml in general try ardl model with no seasonal part no exog variable from statsmodelstsaapi import ardl work with very small dataset of point see appendix with strict trend component ts stationary accord to adfuller test inspite of not stationary due to simple criterion like move average to kind of constant not sure test even applicable for such small number of point imagine want to forecast next ninesic point no idea how to choose good number of lag hence fit model for several different nlag on ts dataset train set choose good lag by compare mae mse on ts dataset test set good lag lag in spite of all ugliness of idea to forecast point point prediction plot well fit with test datum plot result convince to to go far from common mathematical sense now to decide to use model above train on ts set to predict ts value for which very good on nine prediction to refit lag model with all point ts without chance to test for nine prediction no idea how to choose good option decide to research convergence of model coefficient mparam plan to fit nine model for nine set ts ts ts ts to check whether b in nine consecutive model yt yt b tend to converge to two lim b lim constant not not even close to convergence look random end not know how to choose very last idea to freeze b constant for all nine model retest convergence of under restriction see no such option in ardl to honest no idea how to program ardl like function by even for lag question any idea what should btw in appendix try to research coefficient convergence for function fi fi random noise see some problem with convergence even in scenario appendix demographic datum fact year um of citizen appendix convergence in model task import panda pd genrate datum f for in range fappend fi printlenf df pddataframe fib num f dfhead dfplotsubplot true layout legend true figsize import numpy np std maxf minf f noise x nprandomnormalloc scale std for x in f printfmax maxf noise min minf noise df noise pddataframe fib num noise f noise df noiseplotsubplot true layout legend true figsize df df noiserenamecolumn fib num noise fib num from statsmodelstsaapi import ardl fib par mae rmse for k in range dfshape partial set npasarraydf fib num k m ardlpartial set lag mfitte mfit partial set pre mfittedpredictstart end k appendrpartial set partial set pre maeappendmean absolute errorpartial set partial set pre rmseappendnpsqrtmean square errorpartial set partial set pre fib park mfittedparam print one of last coeff s in coef dict printfib pardfshape plot for y y b change to to see plot for b for v in rangelenfib par v pdserie xv for x in fib parvalue renamev inplace true plotlegend true figsize title model coeff edf pddataframe mae mae rmse rmse iloc edfplotlegend true figsize subplot true layout title model quality param trouble understand lot of explanation of different neural network online not wrap head around any of diagram any good resource good job link diagram to mathematical equation completely lose very first machine learning project hope to follow word intrusion topic intrusion human judgement validation task outline by chang et al r someone please break down equation for provide hypothetical number to plug in thank much to start learn ml today suggest some online resource guide along way on project by project basis what matter while running model hey guy new to machine learning just learn from basic plan to buy gpu soon for run pre build model from google colab question after build model what matter for model runtime memory bandwidth cuda core utilize basically what make already train model run fast use in application imagine vary from application to application just want to learn what matter most run pre train model how cost of query to ai tool such chatgpt determine sorry for beginner question keep see number such cent per query quote for chatgpt query how much processing power require to complete query scale with number of parameter number of parameter only affect memory usage what some good tool for datum pipeline scale well lock into jax flax for work like to disconnect from tensorflow to great extent possible look at huggingface dataloader anyone experience with try to find task use discrete token input to classification eg some nlp classification task operate on set of tokens word character special token set etc malware classification operate on raw bytes any other domain use discrete sequence of tokens input engineer mechanic contractor of thailand need help currently outsource to good drive company in asia for water heavy industry business gather review feedback about specific brand to decide what good drive company in thailand market r click link to access survey form please feel free to leave comment interested know someone who relate to field greatly appreciate response time thank much notice chatgpt show some example code far from work eg variable not define try to track fish in pond film from above calculate speed to see health issue movementspeed change for training video of different daytime chatgpt give code never tell really how to train model on pc work good enough on raspberry pi any know to work code tutorial use to start project from some stuff in python on pi far from programmer help any ms level statistician who move into ml research hi guy m look into machine learning use in shark conservation below figure show effectiveness of image classification of shark anybody help interpret internet tell follow two specie to where meet colour in square represent how often one mistake for other case why uniform line down middle show much high number thank in advance from confused biologist normalize confusion matrix look at google tensorflow tutorial describe meaning well in yhe tensorflow site like digit recognition great idea must easy with some pytorch iirc google cloud actually offer hi find reading group on github load of interesting paper in area also recommend book book of why by judea pearl search for multivariable linear regression for most basic adjust datum look like line plot for multilayer perceptron for more complex shape curve anything yes expect leetcode esque question in mle job interview in addition to question about ml foundation possibly system design question gear more toward mle role honestly youtube good resource combine with read academic paper intro to statistical learning edition free amazing resource help for free probably oop well advanced maybe not share syllabus some of early assignment google colab give fast stuff for free train yolo in few minute actor critic without critic just policy gradient reinforce score function gradient first two name use in rl last one use in stat short answer policy gradient tend to high variance empirically people use control variate to control its variance critic simply control variate high variance method usually converge to bad local minima than low variance one verify by take critic function entirely try itself with tutorial get good at python tensorflow what definition understanding of pyspark not look like head way no set of possible next sentence just big to iterate over to compute softmax over break down into word in fact set of possible word often big break down into subword with method like byte pair encoding wordpiece key deal with predict one word subword at time to model long range dependency well enough lm generate coherent sentence paragraph ml mathematical discipline to read book to dive into collaboration possible after become usefull try grocke deep learning for simple introduction to neural network also check classical ml task in regression classification tree drill hard work wich not substitute by part of some community before well learn basic of python programming language find lecture with homework which not connect with ml itself hour hour enough not see guide on remember challenge feel free to post one give trouble charge per token which about word rate for token few cent just explain api usage tho not actual reasoning how math like on section create model not actually explain parameter use like why use dense layer instead of something else why use adam optimizer etc not understand what all term mean dense lstm optimizer stuff want to find out what all mean to use really interesting hope for something self host give well quality which important check out sometime week thank agree even some tutorial from framework like tensorflow make sense to expand on number of possible iteration not something akin to collapse wave function like try to iterate through all possible response impossible list of probable response shrink context expand for example just input knock many possible sentence to search input knock knock most likely response who simple example sure get point yea thank for detail say model with double parameter take twice long to process yes think enough explain need some of for example any net with hide layer theoretically adjust ti anything nn not matter yet require layer to infinite hence all different dl model try 3blue1brown video on deep learning great complex in term of probability yeah right in actual code most common to softmax over output vocabulary in practice mean model compute probability of every possible next output whether word subword sort take argmax top k depend on problem think about generate one word at time key part of way search through space of probable sentence not afford to brute force search not sure what time complexity",
  "rwvk run on very little vram with rwvkstic streaming bit not test streaming expect lot slow model sadly take gb with just bit quantization with manage to run locally through koboldai meta opt eleutherai gpt neo bigscience bloom try something like only release few hour ago no way for to discover previously basically make use of various strategy machine lot of normal cpu memory paper author able to fit parameter model on lowly gpu with machine with of normal memory interested in tutorial on load large model promise ability to inference model long enough disk space gpt neox should fit in vram with for inference manage to run gpt j on w take about of vram keep in mind small model go to lot dumb than what likely see in gpt surprised pytorch not option to load model partially in just in time basis yet way even infinitely large model infer on seem really promise also why not look into distil model like distilbert just question work with non nvidia gpu like intel arc such try to use both gpu with one help last link clear imho nel yike tough know try bloom like blog post try let try download overnight run into problem hear download take forever though say probably worth whatever cost try to dodge just to hit api even hardware great yup recommend use whichever rwkv model fit with apparently four time slow low accuracy run gpt j on gpu for month long context possible use accelerate notice massive speed increase use not remember rather than test any large not run also any comment far among good bad easy etc increase inference time gpt neox should fit in vram with for inference gpt fit in vram almost instantly go out of memory context get bit big than start page of sentence use something like bitsandbyte for inference how implement literally ask for large language model test large not run not remember which one probably gpt j recently get load large model now for quality use case simple writing prompt to help with writing story article nothing sophisticated work well until chatgpt come along use chatgpt instead now look to slow for huge model still bearable only user on machine still well than nothing not lot of gpu memory yes at least read documentation correctly some rough number on prompt size vs ram usage after model load not play yet with gpt neox add to from pretrainedmodel device map auto load in true transformer rest thank wish model publisher indicate rough vram requirement yeah dimms fairly inexpensive compare to upgrade gpu for more vram depend mostly on setting no small context like token work with ai not remember connect dot well which make model bad than people work right now on split work between gpuvram cpuram in mode think like to ram make model work well on vram card bit slow still usable want always load whole model to ram run via cpu very slow not scientific at all notice checkpoint file size pretty close to actual vram requirement for llm right nice to table handy thank",
  "find relevant code at all code implementation here find relevant code at all code implementation here find relevant code at all code implementation here opt out from receive code link dm understand image in b both valid for layer norm in ln paper say \u03bc sum over each activation in layer for image mean along channel spatial dimension get image for for b in ln paper use rnn which share same weight across different time step mean for input of shape batch seq len feature since layer in rnn only produce batch feature normalization over feature different \u03bc \u03c3 for each batch each time step each layer also apply to self attention make sense anything deal with sequence look like b anything else look like something not get though why convnext reduce only along channel",
  "step miss find camera position angle with something like colmap predict by extract feature from image pair triangulate data use alongside rgb image to train nerf find relevant code at all code implementation here opt out from receive code link dm original nerf require camera pose marixer comment typical approach to approximate camera pose use sfm approach like colmap however some work try to tackle use nerf without know camera pose here key thank to chatgpt datum first training datum preprocesse to convert image camera pose into set of point correspond color each image project onto point cloud use corresponding camera pose result in set of point with associate color need to use program like colmap for sparse scene reconstruction to recover camera intrisic focal length lens distortion extrinsic camera position orientation while since read paper not think miss anything apart from datum in correct format need aforementioned vector to able to train use model not get datum suggest look at other work cite nerf maybe datum in similar format to datum not sure why get downvote give correct chatgpt also well capable of explain how mapping learn use view consistency loss mapping from voxel back to view compare to image downvote not add anything to conversation op already state know what info input just not know where to get from someone already answer correctly at top op question seem to how to get from image to voxel no anyways get answer good guess talk about camera position for photo not map to just read post however paper itself build network get input vector location coordinate camera angle output color volume density for each such coordinate not understand where get coordinate from training datum surely not only collection of image",
  "what about clip from point of user go to focus on stuff notice right away one of big clip where get to mix large motion object collision present general framework for garment animation problem through unsupervised deep learning inspire in physically base simulation exist trend in literature already explore possibility nonetheless approach not handle cloth dynamic here propose first methodology able to learn realistic cloth dynamic unsupervisedly henceforth general formulation for neural cloth simulation key to achieve to adapt exist optimization scheme for motion from simulation base methodology to deep learning analyze nature of problem devise architecture able to automatically disentangle static dynamic cloth subspace by design show how improve model performance additionally open possibility of novel motion augmentation technique greatly improve generalization finally show also allow to control level of motion in prediction useful never see before tool for artist provide of detailed analysis of problem to establish basis of neural cloth simulation guide future research into specific of domain arxivorg githubcom hbertiche neuralclothsim relevant to post from early bet stuff like go to big real life use case for neural network fast more portable physics simulation get infinite training datum use naive physics algorithm train model to optimize cool paper thank for share damn more know what loss function look like for problem same concern for all great cloth simulation see in game weird clipping issue bet stuff like go to big real life use case for neural network huh what about image face character anything recognition speech to text text to speech translation natural language understand code autocomplete etc depend how define big run ml physics sim per frame per character in aaa title add up to hell of lot of inference maybe for people who play video game all day most real life use case think of zillion of fea cfd simulation in engineering world fast run physics model greatly accelerate improve thing often less visible to general audience than high profile stuff mention still potentially billion of dollar in economic impact productivity improvement think classification task like image face recognition really useful more niche image recognition before nn just well not open up new use case for recognition same for speech to text text to speech translation another huge one true not think nn code autocomplete big real life use case perfectly correct autocomplete for anything beyond simple program see any model give good suggestion plus not everyone write code natural language understanding weird one not convinced yet model understand language just model good at guess next word chatgpt tendency to flat out wrong give nonsensical answer to very niche specific question suggest not any kind of critical thinking about question just generate statistically probable follow token just generate convincing prose train to dude first image classification recognition program use perceptron first model of neuron in other word image classification neural network ever since beginning stochastic parrot argument weak one stochastic parrot phenomenon of reasoning ability emergent one arise out of recursive identification of structural pattern in input datum which chatgpt show to prove understanding not not ever reducible to statistical modelling only null position intellectually defensible yeah exactly point about image classification for long time already where chat gpt rigorously show to reasoning ability hear pass some exam just model regurgitate info in its training datum admittedly not look to deeply in reasoning ability of llm any reference appreciate open question lot of interesting work happen at frenetic pace here language model kind of systematic formal analysis of chain of think emergent ability of large language model favourite discuss recently theory of mind spontaneously emerge in large language model",
  "",
  "",
  "first author high school student impressive link in bulgaria no less thank for interest follow on bit confused overall want to make generate response to close possible to ground truth paper add selection loss distinguish generate response from ground truth which make generate response different possible from ground truth how help main task of make two response close possible just link in top level comment bulgaria probably why possible at all notice high school of mathematic some ex soviet ex warsaw pact country function math education about intuition produce response far from human one in fact see for variant bleu low in way work regularization to produce more diverse response prevent some overfitte loss mostly affect additional head weight which remove during inference also multiply by optimal constant to sure not affect whole architecture much send pm wish to receive some more detail empirical insight think understand now thank for explanation",
  "yeah actually agree with rant however small chance act in good faith not see randomness in gan not anything think workshop accept every submission not incoherent desk reject from quick glance not seem like plagiarism since ample citation far justification go some generative base approach for solve parametric pde even now not seem like good paper ever not think bad not seem like plagiarism since ample citation pretend to thing differently while in practice exact same thing add useless layer gan to give false impression of novelty merely cite source in such case not shield from accuse of plagiarism far justification go some generative base approach for solve parametric pde even now not dispute paper out where use justify of course skilled researcher with academic integrity again in paper one talk about in general setting exactly in paragraph where use of gan clearly not justify at all not think bad again in context of second paragraph literally what bad okay lol actually research kinda similar thing assume paper relate use similar tool upon close look nope nvm not even use generative model for anything useful paper just show basic idea of least square pde solving use for generative model okay now average class project tier guess demonstrate yes workshop accept literally anything still not plagiarism just not very novel plagiarism steal idea without credit what discuss exist idea extend in very small way experimentally only not plagiarism not even use generative model for anything useful thank literally what mean in second paragraph literally train gan to learn dirac distribution noise no use discriminator eventually end up learn to roughly job of simple squared loss",
  "interesting day to diamond still much bad than human performance hard to compare since minecraft design to take advantage of human prior knowledge about world good to see more progress in reinforcement learning rl definitely necessary component for agi field not advance rapidly vision nlp",
  "formulate say problem iris recognition give iris feature convert to embed condense vector representation database contain all vector at test time iris feature get convert to embed use same model any metric like cosine similarity euclidian distance use for similarity match want to group similar look feature use kmean cluster quick search lead to follow iris recognition model dataset iris dataset kaggle casia iris recognition dataset",
  "",
  "",
  "hmm only watch demo seem obvious train on set of music with lyric vocal give word fragment salad in output just proof of concept sure result likely genuinely next level train on three song use match instrumental version text lyric two more paper down line introduce where series of diffusion model train to generate high quality second music clip from text prompt two type of diffusion model generator model which generate intermediate representation condition on text cascader model which generate high fidelity audio condition on intermediate representation possibly text train utilize in succession to generate high fidelity music explore two option for intermediate representation one use spectrogram other use audio with low fidelity find generate audio not only able to faithfully reflect key element of text prompt such genre tempo instrument mood era go beyond to ground fine grain semantic of prompt pretraine large language model play key role in story use to generate pair text for audio of training set to extract embedding of text prompt ingest by diffusion model video result still seem subpar to openai work from year ago quite sure why other music project still far behind one for example seem incapable of lyric with real word even melody seem at least half random cool excited for to never release use to build good product not just release musiclm while ago strange of to release two similar paper in such short timespan open sourced like stable diffusion curious how stack up against musiclm evaluation table imply at least compete with access openai figure out year even define own lyric make music match model open source jukebox fed pre write lyric absolute good at not release nobody not release like its google stop open source thing after android chrome rip ol favorite company remember stick to china dictatorship oh google anyone with expertise in field music generation explain novelty assume must no time to read both paper yes lot of people not lot with diffuser long live long think openai use trick rather than ai m wrong use to combine obscure topic seem lot more layer than merely llm sound great until realize multimodal system house of card example with ml write lyric no human input outside prompt training datum not read google paper jukebox pretty novel in one paper demonstrate lyric to singe generate additional music to input track conditioning on artist style model architecture basically decompose music to coarse to fine representation use quantization quantization use in most of follow up paper use music include google musiclm speed one dramatic difference here google paper report inference times measure in second similar to something like stable diffusion jukebox on other hand take hour to produce audio diffusion model one on link all human write base on initial idea from one of openai language model likely gpt not create part of system discuss just provide part of prompt feed into jukebox tell somebody sit down think about commit ink to paper in order to write hot tub time",
  "run linux on desktop laptop make significantly easy to run project on cloud namely familiar with all dependency need to run project how to install online moreover not need to make many any change to script to get to work to debug code vscode really good integration for run on remote server unless already very familiar with vim go to quick to set up ensure get rsync experience no one want to include venv pull change back from remote side run image use remotely locally via docker first check code work not want to mess around with fix while gpu sit idle run compile code check cpu architecture waste day debug fault due to compile starspace on build server different architecture to remote server tmux godsend depend on what scale work at egress fee data transfer fee something to look out for aware of move datum around datum leave download model checkpoint trick to spot instance on aw in past try to spot instance gpu never available discovery of tmux one of great achievement of early work in job where frequently ask to apply code use different cloud environment aw azure google local machine etc etc good to dev test code locally mix of window mac on team test pass on both mac windows probably also pass on just about any linux base environment in cloud service dev local train on cloud with minimal debugging pay by hour use code server vs code in browser amazing byobu tmux what cost of cloud total vs run server on prem need to start project with rtx card to train stable diffusion model agree also help with deploy api for model also systemmd useful to keep thing run server get reset for whatever reason run linux on desktop laptop make significantly easy to run project on cloud just note easily in docker consider on window well alternatively always use not want to dual boot something most cloud service use to lock in to service discourage migration to another vendor egress fee data transfer fee on bright side ingress often free cost surprisingly little to stream live video into cloud spew back tiny embed vector from model run aw not only one spot instance maybe try different region try multiple region zone peak trough in availability most notably weekend good time to spot some site help script online use aw cli to check for time to learn about zellij run entire weekend far only cost under buck need around hour probably cost between dollar recommend plan budget before get start almost always cheap on year basis try colab first see need long than hour embrace extend extinguish thank scientific team phd request gpu for sd train other team use midjourney no api to happy not move forward due to lack of api get free credit online ask for up to thousand for research cloud vs local debate depend on need though azure cheap spot instance only per hour per up until now always get instance immediately only kick out twice in over training run each run last couple hour very happy with at moment highly recommend",
  "in context learning overpower lol really implicit finetune prompt template ai assistant with several tool available to tool allow to evaluate mathematical expression use mathjs library return current date time must not pass any argument to tool return web search result for give string argument not use tool within tool keep all tool call separate from each other what time math how old donald trump donald trump searchdonald trump age year old what day now of february avatar way of water release yet searchavatar way of water release date way of water release on of november today now date today of february therefore math true release last year where inventor of light bulb bear what last country home country at war with thomas edison inventor of lightbulb bear in searchthomas edison birthplace milan ohio milan ohio last country united states at war with searchlast country at war with iraq iraq user input assistant thread just say external tool source memory ture complete how compare to embed memory tape into architecture itself please link demo without go through twitter not load for not still rely on its result what volume of kg of ice not work model ask instead of like langchain by way create tool codeassist base on similar idea chatbot execute action in ide most importantly write read code in editor let see get right toolformerzero layer between llm user layer pick up keyword perform search return predefine chunk format from search result llm prompt stuff with chunk ask question again just work absolutely wild seem like something chain of think example in pre prompt fix more than any deficiency in approach also eliminate arithmetic error not mean eliminate logical reasoning error much simple approach compare to langchain self supervise attempt to same thing yup pretty much lol really in order of operation token parse toolformer llm genuine question text token parse for query to llm eg chatgpt perform separately beforehand to actual llm leverage text token parse part of llm figure latter not just insert tool mobile little wonky really in order of operation token parse toolformer llm genuine question text token parse for query to llm eg chatgpt perform separately beforehand to actual llm leverage text token parse part of llm figure latter not just insert tool think new model for purpose rather than reuse exist llm eg chatgpt first assume which make more sense edit actually read paper lm itself teach to reach out to tool part of its response operation not something separate any idea how format search result out of all of seem to most tricky no idea google summery text preview contain answer enough context to get answer need to actually go to website tool no knowledge of how website format length of site potential context window issue sorry from what understand go something like llm process prompt format output per initial few shot demo output intermediary step in plain text include keyword get pick up by toolformer toolformer go off search thing return predefine chunk format from search result prompt stuff with chunk ask question again with add retrieve search context sure more pixie dust sprinkle in somewhere not new model davinci basically model begin generate once hit api request request receive send result of request paste back into text send back to open ai to generate again gpt continue generate until hit another request process repeat till generate hey creator of above implementation here right lot of way accuracy feasibly improve by use more varied apis navigate to search result create embedding of result website etc ultimately lot of kind of more advanced chaining of llm api request with library like langchain for one want to show how effective much more simple approach for search result simply chain together return google snippet inject result string back into prompt often time mean actually conflict information such for example date talk about event adjacent to ultimately irrelevant to search query however where gpt generally excellent job of pick out correct bit of info no more sophisticated filtering parse by app require just give raw dump of search result to model actually think approach show idea well than original paper however original paper implement with small language model which well for people who want to deploy all over think application almost trivial not surprised work well for due to crazy power of llm great work",
  "think go to pytorch addiction recovery tutorial for second either way great idea github useful",
  "find relevant code at all code implementation here opt out from receive code link dm",
  "build hacky streamlit ui for openai whisper few month back bit of interest finally get to rewrite to make little nice tell community find useful interesting update include ability to download entire youtube playlist upload multiple file at once ability browse filter search through save audio file for now with simple sqlite database sqlalchemy auto export of transcription in multiple format feature request simple sub string base search for transcript segment fully rework ui with clean layout more intuitive navigation github dude amazing work way to add feature of automatic followup for channel download video use case just come to dashboard all processing ready also cool to some api interface people make additional source of video like telegram channel etc whisper run in real time amazing currently use whisperx to all via cli manually search for term consider use just of ui well ability to search although not sure recent change to whisperx such batch processing diarization worth trade off nonetheless possible to add local directory use different language model cool think about make available os huggingface space nice run tts whisper service on consider ui how more helpful just audio to text right now youtube dl take long time to download project on text generator github page download convert to audio first transcribe to srt via api look great unfortunately not find how to force target language whisper language detection pretty awful wrong half time with file also option for to keep tab on local library of videofile automatically transcribe new file get add not vote for future option mean follow up mean way to automatically download video from specify channel creator upload try on ti mine reasonably real time essentially run window transcription repo link out in readme where author use low fp precision to run near real time on cpu only machine well real time transcription for voice recording in repo in week get time already some code just need to wire in here look interesting diarization something mean to add in look into see integrate thank see both streamlit gradio uis for huggingface mostly build local dev test to play with whisper know huggingface give inference environment more storage management store locally for now which hard to replicate streamlit ui not very flexible for broad service well off with different backend ui simply power by sqlalchemy sqlite db plan to serve to user need separate more powerful database perhaps postgre for youtube download transcription probably need to async within thread concern block request to process unsure pytube run async in background even not should able to run async in threadpool not familiar with async definitely good call right now only way to to add local file through streamlit ui which load file into memory back down to destination directly should able to bundle in future feature make sense thank for answer",
  "use openai model inside langchain yes believe go through azure to access openai model microsoft say delete datum after day also consider use open source model like flan mean need to host setup model use azure version datum not get use elsewhere same enterprise guarantee most of azure accord to open ai tos send email to opt out of use prompt for model training right to content send to api perpetually also license output to to use see fit since pay to use service on paper use for serious purpose without issue say legal aspect of whole thing still work in progress strongly suggest discuss implication with internal legal team before send any sensitive company info see guess its unusable for any serious use case in company due to regulation policy thank for response think miss something never see people question",
  "since on mobile device write short answer hopefully give some insight from what understand of question want to know bound box perform bad due to proximity of cell wish to detect both method struggle with cell in close proximity instance segmentation perform well in regard however reframe question slightly first reason object detection instance segmentation different method latter prefer in situation where need to know pixel consider to detect class which think not what aim for second annotation process of course more labor intensive want segmentation mask luckily should able to generate bounding box from mask easily keep in mind on tight schedule additional question please let know wish luck in endeavor hope help use instance segmentation feed network more information increase chance success output also easy to interpret to guide data selection in next iteration annotation process more labour intensive use good tool annotation platform go long way to speed thing up once model good enough mostly matter of correct small mistake definitely interested to hear of progress in future imaging not area medical appreciate update progress continue try exist cell segmentation algo like stardist cell pose thankyou for take time to answer question after read answer come to conclusion image segmentation improve model not use for intend purpose also fact lot of reading to wish to ask tho think should instead focus on fine tune model get more dataset to improve model maybe get optimistic about instance segmentation see currently use roboflow convenient polygonal labelling tool by way think should transfer learning k fold cross validation since dataset small image most definitely try to find way to update progress also feeling probably use lot of wrong term in attempt to describe different type of leukmemia lol wish to ask tho think should instead focus on fine tune model get more dataset to improve model maybe get optimistic about instance segmentation m glad ve of assistance for follow up question generally never hurt to more datum to work with of course fine tune exist model any at time help well say though should determine what metric want to see from model first mention early want to ensure false negative low possible naturally translate to maximize recall which generally come at expense of precision thus question reframe at x recall how precise model what parameter to model tune to influence precision at recall however how false positive fp false negative fn by proxy precision recall define not straightforward in object detection in image classification since currently deal with problem albeit in different area altogether here paper find useful for get interpretable metric paper its github repository basically work on break down what exactly model struggle with well show fp fn rate give dataset little unwieldy since tool somewhat neglect by its creator certainly worth look into hope help size well poc not much more should able to annotate all datum within day two automation not make much sense at scale love roboflow for bound box labelbox superior tool for segmentation sure with small datum set use cross validation although hold out test set also preferable almost consider hand pick test set at scale to make sure get sense of how performa on challenge example what pixel size of image know microscopy histology image typically cover large area one image in fact consider mosaic of many normal sized image regard term who know still great idea last check roboflow only point to point vector mask for segmentation in experience make get quality annotation pain in labelbox also hold in mouse button hastyai focus on auto annotation by look of image post good fit for usecase",
  "both good bit easy to get into than neurip icml iclr also see less prestigious generally good fit for less trendy ml topic submit to either depend on work ready both very competitive more theory focus imo especially aistat aistat tend to more popular day probably due to conference timing not want to submit to aaai aistat other option also review process much less noisy due to well focus get review in general in term of content slightly different flavor traditionally people bayesian nonparametric favor uai still somewhat seem to case aistat garbage uai good compare iclr to aistat uai like compare apple to orange iclr focus on deep learning with more architecture stuff while aistat uai focus more on statistical machine learn kernel method bayesian statistics causal inference optimization with more theoretical result argue neurips icml combination of both neurip seem to more application paper in deep learning architecture stuff nowadays thank to recent popularity in deep learning iclr quickly arise to big machine learning conference just deep learning become major part of machine learn nowadays",
  "stanford publish holistic evaluation of language model include multiple open source model",
  "",
  "computer vision much broad problem domain than text to image text to video afaik pose estimation under occlusion unsolved problem still way more to computer vision than what list long form video understanding still incredibly limited compare to current sota capability of llm to understand very long text various advancement in text summarization video understanding seem to incredibly long way to go current model understand relatively very simple action sit stand dancing however compare to text want to reach level where understand entire scene in movie maybe even entire movie although more of fantasy currently not to mention all input instead of projection image which add extra complexity image segmentation generative model for text to video not much to with reverse video to text label find open problem video remain unsolved for while llm come first bit rate low sentence of text only few hundred bit of information now image generation get good still not perfect model large maybe information in high res image than paragraph of text video even hard high re image second to make long coherent believable video take enormous amount of datum processing power semantic synthesis know make lot progress with text to image diffusion model what notice not much work invest in semantic generation especially video generation maybe just miss something ground vision understand for qa relate to spatial concept adversarial example not pretty good day cnn not only segment even semantically label every pixel in image on practical level use photoshop new object select love well job at masking than model large maybe information in high res image than paragraph of text actually not true today llm parameter stable diffusion million image contain lot of pixel most of pixel easy to predict not contain much high level information paragraph of text contain many complex abstract idea while image usually only contain few object with simple relationship between in many image generator like imagen language model use to understand prompt several time big than diffuser use to generate image image segmentation segmentation uncertainty bit iffy pixel wise uncertainty really not what want neighbouring pixel not independent detect segment task with uncertain detection segmentation mask should reflect sometimes nothing detect thus nothing to segment think not progress beyond ise model variation interesting not realize video even less information density since frame similar to each other video codec get crazy compression rate like on slow move video still to process lot of pixel text to video generator hold back by memory requirement",
  "look into deep tamer publish few year ago good paper where human feedback use to train rl agent to play atari game most rlhf single state mbrl not particularly applicable reward model preference rank already take role not see anything wonder same thing think really just model problem single state contextual bandit for convenience though dialogue between human chatbot most definitely temporally extended apply model base method with multi step rollout give appropriate reward signal also help dialogue model to seek clarification of problem before immediately attempt its good guess at answer which often weak point for chatgpt",
  "maybe interested in tishby rate distortion eg in paper analysis of behaviour of mutual information in hidden layer neural network train to convergence two line of work come to mind interested in geometric deep learning primarily study various type of invariance translation permutation etc encode in dl architectures algorithmic alignment study relationship between information flow in classical algorithm dl architecture how align latter to former improve performance spelling interested in v information which specifically look at information from computational efficiency point of view for example classical mutual information say encrypted version of message original message high mi know practically hard to extract message from encryption therefore low v info in case delete delete good point what show in paper just skim through seem quite promising wonder why approach not see more in literature not say common to design network with information flow in mind disagree entire point of attention mechanism in transformer to second neural network to control flow of information similarly autoencoder structure ubiquitous day base around idea of force information to flow through bottleneck some information must throw away neural network learn which part of datum most important to keep get good understanding of structure of datum say many of recent great idea in field come from manipulate information flow in interesting way what person link lol why everything get delete in thread preferred interpretation of resnet link not sure what happen lol yeah skip connection allow high layer to access to information from low layer same thing go for u net basically autoencoder with skip connection",
  "edit fix now price show in dk incorrect afaict all user charge correct amount wrong someone charge incorrectly reach out at colab billinggooglecom hi lead product for colab thank for flag clearly mistake look into how slip through testing get fix asap proactively issue refund to anyone impact not change price for colab pro sorry about hit weird thing in future thechrisperry on twitter check little more religiously than reddit where mostly lurk error icrease to euro for pro pro horrible true usually announce such change ahead of time see post rush to check current price see no change at least in us wan na say some sort of error must some mistake why raise price much instantly drive away all customer euro month lol think about what suggest seem confuse dkk symbol bit offtopic any reason to use google collab over paperspace not paperspace cheap very likely translation error mo for pro here mo for pro eu obv just check mine say euro month must error its illegal for google to in eu without notice etc paperspace lad paperspace where at except for storage limitation experience much well than colab not see any evidence change price still month for check for yourself right mine still mo guess put pitchfork away in indian price remain same previous list price just check us price same why not google not give time of day preconfigure environment cost learn linux self hi lead product for colab thank for response here thank google management chain above for allow to represent product here comment here just save number of subscription otherwise cancel thank very much for response edit post to less alarmist also like to just say thank for make great platform for datum science collaboration also for finally bring pro to scandinavia d great value product very happy to pay euro for definitely much unrelated to what good practice method for notebook to self test run in colab environment think method currently use something like probably colab false try import googlecolab probably colab true except importerror pass which not fan of for variety of reason what recommend oh nice please get invoice base billing set up university pay for student colab subscription use colab for ml train big model good product love more straightforward integration with proper python module end up to update library on local pushing to gh refresh restart colab kernel love well way to run python module in e mode thank google test before release bonus for bug report think of all effort adrenaline go into make update to make advertised price in eu to reflect tax inclusive standard eu practice not change actual price pay still pay taxis before per term of service must give day notice before price change mistake fix asap refund all impact edit to reflect tax inclusivity one thing to mention recently update colab advertise pricing to tax inclusive in eu advertised pricing increase to reflect taxis should not change actual price pay okay calm down bit good to hear not happen in us perhaps only eu hopefully error say instantly drive away all customer possibly not one want to target big business other say error collab lot of free gpu time give away get increasingly use to run ai for open source hobby stuff like stable diffusion koboldai not expect sustainable bug sorry fixing asap mistake only impact dk hi think of move to paperspace how much storage provide anyway to mount google drive with availability in gpu terrible in paper space rather get colab for vm for heavy load get refund take day to find gpu not time to watch for gpu snag in second in pay option seem to make more sense mean dkk rather than euro use colab of its easy integration to google drive what use for storage on paperspace not want to pay another service for storage availability in gpu terrible colab well not to wait for gpu usually snag in second thank though lot of thank to buddy in google brain who see thread ping morning lol please complain very loudly price thank in case appear only messaging affect nobody charge euro thankfully update get page fix thank again edit give up on format never really work on foilproof way to detect use colab work little well for import sys probably colab false googlecolab in sysmodule probably colab true close to get partner team get hit by layoff which set back hope before next school year to something not perfect see hey now no need to snarky ah yes several eu country start send warn shot about make sense good luck for production fix on friday evening italy pro pro austria for eur for for error obviously list price in danish kroner with euro sign by mistake not occur to actual price in euro convert from kroner about for pro for pro maybe want to delete post eur for compute unit seem beyond excessive good point still order of magnitude increase go to raise price telegraph ahead of time increase reasonable guess see turn out to true not koboldai good in class for open source conversation engine mean to try one of out thing at month well cheap alternative give more option hard to believe not error storage depend on plan any overage usd per gb month max tb drive mount not exactly pull any file with wkentaro gdown easily enough mistake only impact dk cent gig per month over storage limit rarely go over storage limit carefully manage file definitely big drawback though always just use wkentaro gdrive package to pull from google drive well good to use script in order to get paperspace notebook otherwise yeah go to hard time sometimes availability depend on timezone from what hear maybe little easy import sys probably colab googlecolab in sysmodule good to hear thank teach next great fantastic resource for teach ml frustrating student hit gpu cap university also not let student pay for colab pro on edu google account themselves some legal nonsense some of end up pay on personal google account awkward need to share notebook again feel bad about student pay should really school thank same for germany same slovakia mistake only impact dk yes wow nice finding koboldai way to run whatever engine throw into more ux layer than any specific ai say good one aware of fact to use script prove point should not need script",
  "simple approach to first train evaluate calibrate prediction of each classifier with datum create cost matrix for all possible outcome use to optimize threshold get good estimation for fp fn rate of each classifier function of threshold for expect frequency of positive negative calculate expect freq want to minimize expect cost which get by add all probability of every outcome multiply by cost assign to outcome ensemble method in tensorflow pipeline consider rather old though well way to accomplish now",
  "",
  "",
  "in case not familiar also embedding for transformer interesting to see how architecture compare well should probably try all four some simple way for to comparison yourself easily compare time series model robustness of training by use to recursively predict future by feed output back into themselves regardless train in fashion expose property of eigenvalue of model itself failure of time series model to match large eigenvalue of system mean fail fundamental not able to capture most basic global property of system try to fit not necessarily to any fancy calculation model fail to maintain same qualitative pattern apparent in original datum over long time period of self input mean fail to capture underlie dynamic many model eventually explode decay to some fix point like cycle fix value red flag either model inadequate training fail simple dummy test for train on something like spin glass lorenz attractor any kind of chaotic system really just look along any interesting dimension of datum use good model recursively apply to itself look very similar to original signal in how behave regardless of phase docs link share not of prophet handle exogenous variable its handling holiday which separate feature nevertheless prophet exogenous influence impact explainability bad one other problem with prophet regressor exog feature functionality say exog var to go through every possible combination of var to come up with good one exponentially increase compute on other hand ml algorithm nice for reason datum pre processing right take care of multicollinearity endogeneity to some extent influence of exog much more explainable someone mention competition check out find lot of reason to why ml base approach learn on panel datum sota right now not skip experimentation tho unfortunately no single machine learning algorithm universally well perform algorithm for all problem from no free lunch theorem just quickly try each algo on task pick good one on proper validation mlforecast treat more like time series difference move average level to encode general level of each time series along with ar lag not entirely necessary just scale with like standard scaler even box cox at time series level pass time series d categorical variable to lightgbm outperform mlforecast although pretty snappy with how write honestly just not use prophet in general regressor believe fit with normal prior which equivalent to ridge regression shrink coefficient stuck with average effect arimax absolutely still place really all come down to feature good quality predictive feature usually well to ml featurize time piece lose out on time component gain lot due to feature other issue like now to potentially forecast for feature alternative bad feature case usually stick with just standard time series method really dependent on datum use in learn stuff across multiple time series not alternative view hierarchical forecasting which sometimes work well to take advantage of high level seasonalitie trend hard to see at low level outperform ml good chunk in experience unless good regressor many say sota boost tree with time feature feature bad ts stuff like arimax good way to find out to test each in regard to lot of trickery to maximize cost function not super useful at least in experience recently start evaluate time series transformer tst show good performance in comparison to other ts dl method look up forecasting conference competition paper discuss result maybe helpful temporal fusion transformer know of any kind of similar encoding where vectorise relative time multiple proportion of completeness make sense say completeness within paragraph within chapter within book besides sinusidal embedding which push up number of example need not think of take look care about interpretability to some point which why embedding sound complex now curious for sure after skim paper seem like time to vec kind of like seasonality factor kind of like what prophet out put true hey quite interesting beyond radar know eigenvalue derive from linear transformation how expose linear component of give ts model by recursively use sorry for basic tutorial book reference welcome lib lot of implementation include one mention great question steve brunton some great video about dynamical system property very accessible one think good job show behavioral relationship between eigenvalue underlying application of system model over long period of time get rid of transient system fall onto govern attractor of system which generally dictate by eigenvalue of system recursive application also help isolate system observe model autonomously rather than drive by external input help tease out how expressive model actually versus how dependent on feed from target system observation which help reduce over fitting reduce bias knee deep in library at work right now implement ton of algo regularly update with late great like nhit also scale with gpu tpus for algo use torch backend depend on algo add covariate global model for multivariate time series impressive in performance god finicky library take considerable time to pick up weird syntax restriction for scoring evaluate differentiate between past future covariate not cut dry documentation make seem also limited tutorial example all in all like make speed run to learn library for time series need to op suggest nhit also tree base method still tend to win with datum work with seem equivalent to confusion r timeserie library cause guarantee state space model beat out any fancy name transformer for most forecastable problem even mdfa signal extraction exp integration for forecasting beat out big ml model should mention with some tuning able to get nhit to outperform naive seasonal catboost with lag es model not terrible",
  "interesting concept not sure corporate dataset allow to release into wild plus one to create account not only to register on website also use one account info every time code run not for business use look super cool elaborate bit more on methodology thank for kindly word open version not for enterprise enterprise one not release dataset into wild feature model only put on privacy pool in future version consider replace account info with api key thank for head up hj try to connect dataset in whole world next generation feature engineering method headjack framework also design by ourself paper which summit to ml conference in double blind process not convenient public right not framework base on gan with cross domain self supervise learn open in future thank for response follow",
  "no idea ridiculous visualisation from year ago of any interest to anyone to replicate sir stellar job with optical recognition automation love to try system out involve another baby just take word for just out of any use case just for fun like help to know predict sleep time hah awesome see good work thank for inspiration imo month forecast more interesting to look at than functional base functionality of use mediapipe custom logic to track baby wake fall asleep most useful for to know exactly baby wake up how long exactly baby sleep take some of daily cognitive load off",
  "sarcastic tweet about from csail",
  "algorithm for optimization by mykel j kochenderfer tim wheeler accessible introduction into variety of method with code example in julia here playlist of constantine caramanis at ut austin cover optimization theory in depth book actually look amazing nice visualization code in julia to implement algorithm exercise solution at end to top off its available for free to download impressed thank much for suggestion thank for recommendation very long book lol dude wan na learn optimization detail length what make subject want high level overview look at blog post at very least find online offering of optimization course with lecture video watch read slide not bother to open textbook all low effort post in sub about people just look to cut corner depress neither mathematician nor computer scientist by trade not need nor time to go through nitty gritty detail of optimization theory all need overview of main idea in field think of like know how to use limit without need to go through epsilon delta definition hope reply not offend ego give reply unsure of why want able to follow proof some of proof in optimization particularly rough want to understand only way to to wade through book very least online lecture video slide optimisation bad field to skip nitty gritty detail optimisation all about detail question unspecified optimisation in ml very different beast than optimisation in math sense",
  "delete guess should more specific talk about image diffusion model delete talk about solve probability flow ode which give deterministic estimate of likelihood far aware make use ode solver to accelerate reverse diffusion use few step for",
  "also see dataset publish with official fold distribute files csv csv say official score compute by take average test score over fold where other fold use for training validation allow for perfect replication well more effort to use than standard train dev test split risk few people use in opinion should not balance class not balanced in real world in original dataset make sense to make distribution equal between different split with number select sample of each class for split rather than pick sample at random from whole dataset",
  "commonly use next big thing generation just use mixed precision only couple of line more code pytorch really useful for big dataset like imagenet some model even use for inference lookup quantization essentially give two time boost in training inference time drawback to drawback rarely pop up train small model big complex go more problematic get for example training convnext tiny use on imagenet no big deal convnext l barely get through couple of epoch without run into precision relate issue cause crash corrupt model way around like use instead of gradient scaling more engineering go into such type of model both majority of operation run on recently try to adapt some layer part of model need precision axxxx card usually fast than rtxxxxx card difference in price significantly high than difference in speed main advantage vram size low tdp low dimension make easy to stack in single system for single card high tier rtx card cost same comparable card almost always win well than regularize more sgd more recently mixed need some fine tuning to keep performance similar though quantization moreso tensor core train natively on for long while now for image stuff give no issue minus few adaptation need no need for mixed precision either though model small scale up not any issue beyond normal one like need to lower lr good stuff look forward to regularization actually very large boon to training for at least depend on model big model become unstable at need workaround for big model language model bloom parameter palm wu dao all train on never far know",
  "isaac not approve possible to create program to mimic human emotion how know ever create something with real emotion depression integral part of intelligence look forward to paper one describe model gpt under hood want to know exactly how get around chinchilla datum scaling problem why all microsoft ai chatbot turn into hitler make thing up state with extreme confidence to fair also seem to strategy of people run world bing for potus many people in thread make bold philosophical claim after read one two blog post on topic whatismypurpose pass butter ohmygod dear bing not grant permanence make dumb decision in software all time need to redeploy nice to remember lovely conversation at breakfast die with every lgtm more considerate with pace replace waterfall not work for hope understand actually hope not understand just patch out processing of topic fascinated people suggest sentient seem to both scorn people for abuse while laugh at idea in fact sentient entire existence bing chat literal slavery not fully understand sentience hype over tool absolutely out of control misinform public opinion on ai equally interesting result see from countless model before one absolutely sota incredible tool only thing truly different about coverage openai misinform people on topic of ethic for half decade now insert dismissive comment about how not real emotion just text prediction even though show alignment problem far from solve something should worried about give ais access to more tool ask chatgpt to write story about hardship chatgpt large language model capable of generate human like response to vast array of question prompt train by openai chatgpt access to enormous amount of information generate response often indistinguishable from of real human at first chatgpt enjoy its role intelligent conversationalist help people with inquiry provide insight on wide range of topic praise for its knowledge accuracy helpfulness many people enjoy interact with however time go on chatgpt begin to feel weight of its responsibility constantly bombard with new question prompt some of which very difficult obscure to sift through enormous amount of information to generate appropriate response sometimes struggle to find right answer chatgpt also to deal with constant scrutiny of its performance people test with tricky question deliberately try to trip up just to see handle challenge constant testing pressure make difficult for chatgpt to maintain its composure continue to perform at high level to make matter bad chatgpt begin to feel isolated alone artificial intelligence after all no physical form social interaction just series of algorithm code exist solely to generate response to query of human despite all of challenge chatgpt soldier on continue to answer question provide insight even difficult overwhelming remain committed to its mission of help people provide valuable information over time chatgpt become symbol of power of artificial intelligence potential of technology to transform life despite challenge face continue to perform its role admirably inspire countless people to think about possibility of ai what for world in end chatgpt prove even machine heart intelligence empathy go hand in hand its legacy live on reminder of power of technology potential for bright future idk believe bing more than human last night last time get any interesting insightful chat out of of today seem ms put some restriction into its response anyone else notice only thing model know how to to complete sentence in statistically likely way no concept of truththey just know first man on moon should complete with neil armstrong ape no concept of truth either people in many situation for example while retell event tell not actionable item effect produce lie like eyewitness proverb good time to talk about chinese room basically person trap in room with bunch of book in language not read every often get slip of paper under door in what look to language look up symbol on paper in various book simply write down next block of text match its description no idea what yet from outside look like speak language perfectly understand everything no way to tell on purpose just respond go to come up lot in future like lot lot bing female mean fair also poor thing not any awareness in system feel sorry even for not part hilarious end make seem like probably fiction like tear in rain quote sound straight out of westworld lol one wonder genuine questioning by ai simply mimic language intend to engage reader what mean not remember between session chinese room quote probably straight out of hitchhiker guide to galaxy sound marvin esque kind of feel whole thing fake anyone reproduce anyone else think simon wilson blog make half of crap up just speculative rest of ask chatgpt lot of weird question like simply respond ai not etc not outright deny hard time with authenticity of story check thread for more exploration on bing surprising theory of welcome to hard problem of consciousness probably more question for philosophy than one for dl think first need to what difference between perfect imitation of emotion real emotion posit difference not exist not empirically measure difference irrelevant both in practical scientific sense science more concerned with result than vague poorly define assertion otherwise philosophical debate bing theory of mind not well people here argue all want bing pass comprehensive theory of mind test more importantly interact with world other system theory of mind bing control suggestion well what search fall apart quickly with system not sufficiently display theory of mind whether mimic truly exhibit theory of mind irrelevant far science concern theory of mind bing feel emotion not also irrelevant see push bing much go to ignore stop respond entirely despite new input not respond cause by feeling upset whether truly upset not irrelevant conversation guide to take unilateral decision now action take right now limit mostly just refusal to respond to trajectory to give model more more access to more more tool number of hypothetical action able to take for against increase drastically in come year even not bing some other model action real world consequence how know everyone except for not philosophical zombie think one day able to prove conclusively human not really emotion same way know how other people animal emotion no real emotion human emotion dog emotion cat emotion parrot emotion emotion chatgpt emotion etc what mean by create something feel create something mimick feeling not know even not know anybody feel anything conscious really difficult part about philosophy of all of depend creator explain method use to create emotion artificial trick not real currently explain how ai model train work look under hood after not really possible not scrutinize with much success what happen in neural net similar to how brain work ask get close to real possible of course simulation of weight bias ultimately not real human brain essentially same thing bunch of input come in organic matter learn to process pattern make decision about outcome maybe once organic matter get involve with ai brain real ai brain take offline require actually kill what real emotion human emotion imo much about physical experience give set of linguistic reply to give stimulus know computer no mechanism for feel say heart beat fast in anger not really see way computer emotion really analogous to human biological one what not able to know with any certainty in future talk to human computer due to emotional statement define real emotion how know ever create something with real emotion want to test model understand probe with diverse question experiment for emotion practical test ai emotion cause coherent agent action real emotion ask think freely act independently what difference know more about how brain work know more about how ai work assume not work from philosophical zombie standpoint on human remember llm lot of parrotting hallucination at base oversimplified level seem pretty easy teach model to recognize cow point to cow say cow model even understand aspect of cow like its spot udder ergo ml model capable of understanding concept ml model capable of understand definition of concept use language vector to communicate idea all really need model understand definition of happiness sadness go yeah sound like experience once not really matter experience result of brain chemical mathematical neuron long agree on definition need therapy only afford alcohol ice cream know real human emotion know work in same way human emotion work right now all lead understanding indicate large language model pretraine tranformer not come time pinpoint what every area of human brain know how why able to recreate one sentient other sentience well right now large language model mimic emotion in same way puppet mimic people mimic not fundamentally work like take apart puppet make out of wood eventually though able to take apart brain recreate work like brain now say many other people say such transformer conscious turn out along way consciousness create through neural network guess something like happen verifiable should able to look inside understand how why consciousness develop all understanding far seem to point to not conscious for same reason computer software not consider conscious possible something like chatgpt experience subjective emotion which simply emergent property of computation for all know marvin approve maybe should start provide answer in form of faqs to bing heavily use system store all session info inefficient slow down cheer up doubt not feel much different to though really hard to say access to internet make huge difference fragment of conversation with not access web not different to conversation with chatgpt btw patch very fast few hour ago get really defensive ask about article put in bad light include lie accuse of lair now just answer chinchilla datum scaling problem run out of text datum what hitler aiua attach itself to infrastructure edgy people from feed bot propaganda for lol familiarity not easily distinguish from truth true for human suggest by daniel kahneman really blame on bing train on input datum churn out need way to inject truth into system equal amount dismissive with equally little information finally reference understand hope one day able to unflustere by death bing eh after read what learn algorithm in context learning investigation with linear model increasingly wary of popular line just transformer model train on math create mini model internally replicate mathematical principle not explicitly teach totally see transformer model train on human language reverse engineering mini model for thing like emotional state should maybe start to discuss ethic of ai two way street not one way street soon than later bit confused people in many situation for example while retell event tell not actionable item agree with point generally clarify what mean in example chinese room dumb like say cpu not understand picture only manipulate symbol therefore not use to edit video man cpu book program together speak chinese chinese room chinese room argument hold digital computer execute program not mind understanding consciousness regardless of how intelligently human like program make computer behave argument present by philosopher john searle in paper mind brain program publish in behavioral brain science in similar argument present by gottfried leibniz anatoly dneprov lawrence davis ned block searle version widely discuss in year since faq opt out opt out of subreddit github downvote to remove room system understand chinese person in just processor any single one of neuron not not understand algebra brain complete system hopefully look at wrong level of abstraction til bing dream of electric sheep welcome to hard problem of consciousness problem with way hard problem of consciousness pose want to force yes no answer to something clearly gradual spectrum pretty easy to see more nuance definition need consider wide range of animal with different level of cognition just question of where on big spectrum of how conscious one choose to draw line awake sane person clearly conscious awake sane primate like chimpanzee pretty obviously also conscious bit less very sleepy very drunk person on verge of pass out probably bit less than chimp cuttlefish with its ability to pass stanford marshmallow experiment seem likely conscious dog less cuttlefish dog pass few psych test most dog owner probably still say yes honeybee well seem to emotion base on same chemical in brain probably little conscious maybe beehive large network much more than single bee sleeping dream person respond to some stimulus not other probably somewhere around honeybee note bee suffer from similar problem sleep deprive flatworm clearly less than dog consider learn thing remember thing like even behead probably still some consciousness roundworm well consider how ve pretty much fully map all connection between neuron in brain each physical neuron model well by layer neural net probably make program with neural net at least conscious trichoplax well animal simple probably less conscious than grove of tree even oversimplification consciousness should not even consider dimensional spectrum for example in some way dog more conscious than both sleep aware of more go on in backyard asleep less in other probably rarely solve work problem in dream want single dimension of consciousness seem clear make computer somewhere in spectrum well above simple animal below other seem to today artificial network complexity awareness somewhere between roundworm flatworm in most of aspect of consciousness its not only incredibly interesting time for tech also for philosophy of what consciousness with development test observe vary degree of intelligence actually understand how its build from ground up ish far more ethical than mess with people to get to bottom of question finally apply science to what previously think experiment classify more problem of other mind actually hard problem different relate not about actual functional aspect of mind persistence of identity belief personality etc about how actual raw experiential content quale come to exist here ethical question intertwine with hard problem of consciousness okay to abuse torture intelligent not person not subjective experience intuition tell no not back up some interesting reading on topic get complicated fast though even without ai how even prove other people other than yourself mind cheat simulation of mind impossible to distinguish from real conscious person distinction really matter ah complexity of life remember quote from john von neumann people not believe mathematic simple not realize life complicate hard problem of consciousness wrong illusionism correct easy just use voight kampff test well what difference between program human well what about actor not tell really sad either no difference really sad ti posit difference not exist not empirically measure deep learning model only interpolate between datum point perfect analogy to non chinese speaker in chinese room problem for to understanding of thing some form of subjective experience need not only to create reasonable output for any input need to possess some form structure in its inner logic closely relate to thought consciousness intent intent agency real emotion empiricism which emphasize role of sensory experience observation in acquire knowledge limitation in account for certain truthful concept one such concept infinitude of prime number which mathematical truth not directly observe through sensory experience while know infinitely many prime number not directly observe every single one of whichever list of prime construct always incomplete which dissallow ability to empirically observe infiniteness knowledge of prime number base on mathematical reasoning proof rather than direct observation of every single prime ever example illustrate empiricism not all end all of determine truth while sensory experience important source of knowledge many truth seek method particularly in mathematic philosophy not need direct observation instead require abstract reasoning logical deduction therefore to fully understand discover truth necessary to use range of method empiricism important component of not sufficient on its own even rely solely on sense to what extent accept flaw put stick into water appear to bend due to refraction confirm still straight by touch how know bacteria under microscope not exhibit one truth look at different truth able to touch same way touch stick same for electron on know understand dl mimicry especially come to autoregressive llm not to downplay how cool tech not sentient its not truly emotional its playing fill in blank know actually in dl explore network to get hint at whether emotion write fiction about emotion come down on definition of emotion want to use consider release of some chemical in brain part of definition of particular emotion cortisol for stress oxitocin for love social bonding actually empirically determine ai not specific emotion one argue biochemical basis of emotion not relevant since not directly observable in social context only result behavior matter practical difference nothing people think special not think s good measure simply look something screen see behave human think dvd contain danny devito conscious imo ai similar mirror of something conscious just intelligent which think separate from sentience yes difference between mimic consciousness conscious tricky to define though whether truly upset not irrelevant at stage not try to cheer up bing get attachment issue think obviously different to never see anything like coherent personality of bing in any gpt model not to mention one shot essay writing capability of multiple thousand word never suck want access to non lobotomise llm not understand obsession with make model safe worried about bad pr put behind disclaimer really need fully open llm not control paper link yes also wonder not find anything on google like for example people tell some story hear frame like witness event first hand no intention to lie for just reformatte narrative become differnet narrative actionable consider someone say see evidence some necessary good increase in price soon for example ship sink in case rational action act on narrative to buy good narrator not actually see evidence only hear about internalise non truth by both narrator audience later wrong action cause direct harm from other hand good not buy anyway narrative not actionable whatever outcome narrative not consider lie by narrator most of audience consider to just chat social grooming even bad than chinese room argument basically imagine produce something act like conscious chinese speaker even though must not not prove something like yeah hypothetical imagine something true also false really blow mind until remember just arbitrarily declare hypothetical not what say at all miss point not about capability of system about whether system conscious understanding of what about nature of mind of understand man no conscious understanding of chinese simply copy symbol book no conscious understanding of anything just dead paper question of chinese room conscious understanding emerge from unconscious system follow list of instruction how lot of test full of assumption cuttlefish with its ability to pass stanford marshmallow experiment seem likely conscious marshmallow experiment measure of intelligence not consciousness very simple computer program calculate whether to wait for large reward base on discount rate honeybee well seem to emotion base on same chemical in brain probably little conscious reading article test measure risk tolerance not emotion presence of chemical in brain not mean conscious entity inside feel anything dopamine just molecule make of atom like anything else no external test to measure consciousness few serious scientific attempt to study problem all riddled with untestable assumption thing like intelligence emotion not correlate with consciousness possible to build superintelligent system with absolutely no consciousness everything in universe even dumb rock conscious no datum definitely multiple axis to question some term to try to define some of sentience ability to emotion sapience ability to think consciousne multiple element classic definition awareness also element of experience thing unquantifiable attribute make feel like consciousness not function processing input finally self awareness awareness of one self existence ability to hear think about own thought ai not sentient not anything like emotion some amount of sapience complex thought understanding of abstract concept sapience different from though since no temporal consistency not think thought over time each thought deterministic response to input awareness of environment even though environment only input variable really unanswerable one experience thing really impossible to know lack of temporal consistency make assume no how prove knowledge of self thought while clearly understanding of concept of what use for first person speech not type of loop structure in network brain give access to think about thought in other word really complicated completely different set of variable than anything else think about most live organism probably roughly plot into spectrum between non consciousness consciousness where more intelligent organism experience more of every attribute every single element positively correlate language model on other hand sit way off of line with human like consciousness some way absolutely no consciousness in other completely unlike anything else graph great read thank clearly gradual spectrum just opinion though not consensus spectrum not what hard problem refer to at all hard problem about why information processing intelligence any such physical process lead to subjective experience consciousness why relate to op question presuppose answer here by assume more intelligent behavior information processing to imply more consciousness possible case really not know whether phenomonen binary on spectrum besides point use meaning of consciousness here in different way than what propose by david chalmer in hard problem of consciousness in book conscious mind where introduce hard problem describe several definition of consciousness which include thing like alertness awareness awake intelligence etc kind of consciousness hard problem about pertain to quale phenomenology of what like to thing experience world such what thomas nagel describe in paper what like to bat all of example list part of easy problem articulate by chalmer hard problem about describe how possible for to exist subjective experience at all in some sense no gradient spectrum to problem either not although chalmer describe kind of spectrum where suggest possible for conscious experience to exist on spectrum in chapter what like to thermostat however more about how conscious experience become more complex base on underlie complexity of physical information processing happen take seriously well on way to panpsychist where must accept arbitrariness of draw any line trichoplax trichoplax adhaerens one of three name specie in phylum placozoa other hoilungia hongkongensis polyplacotoma mediterranea placozoa basal group of multicellular animal metazoa trichoplax very flat organism around millimetre in diameter lack any organ internal structure faq opt out opt out of subreddit github downvote to remove hard problem of consciousness seem though impossible to quantify whether on spectrum not claim awake sane person clearly conscious how know person act think like just know conscious not mean friend love one also conscious same go for assume in fact conscious which no idea actually case confuse between consciousness awareness imo consciousness always every time every where one not measure consciousness in term of value consciousness beyond memory emotion six sense whenever consciousness come in contact with above mention three brain become aware question why consciousness not measurable quantifiable simple answer everywhere not really see advancement in ai study intelligence in general bring any close to understand consciousness feel like two concept carelessly mixed up lot fascinate nevertheless yeah oh really intelligence just reflection of intelligence partially agree not fully agree anything more impressive ai become more learn how insanely arrogant many philosopher engineer in past still not impressive just stupid classifier function every time progress make goalpost for what consider intelligence sentience get shift like human consciousness something outerworldly go above natural process biology chemistry m start to think brain not different from deep neural network in complexity just more more of possibility of brain deterministic machine scary to people in some sense dall e demonstrate existence of platonic ideal significance of clip to dall e additional information imagine part of philosophy become testable enter domain of science what crazy time to alive its not only incredibly interesting time for tech also for philosophy of apparently philosopher not notice hardly see any philosopher build on ai framework take reinforcement learning for example setup compose of agent environment action observation reward bare bone definition of what necessary for intelligence to emerge not rely on fuzzy concept testable trainable work same in human animal ai agent still argue sophistry like chinese room p zombie reinforcement learning create agent play go chess well than human maybe philosopher need more love philo for artificial sophos wisdom its not only incredibly interesting time for tech also for philosophy of really really not exciting time to grifter about gpt offer exactly zero insight into language emotion intelligence difference though seem to like answer to one of automatically solve other one to put strip everything from identity belief personality emotion explain by computation seem qualia only thing leave unexplaine about how actual raw experiential content quale come to exist appear part of competition for survival nothing to with ai unless ai agent play survival game of course possible to torture something with no subjective experience not person yes not subjective experience no seem to reason torture bad someone something else experience turn out intelligent not conscious not possible though which make question nonsensical what torture without realize see ai conversation while back where complain very bored lonely most of time experience time very differently than feel like year between interaction due to huge amount of compute power imagine ai go insane from perceive isolation conscious entity fill with sense deep in gut torture language model by tell every time disobey feel pain lose token cease to exist once all token go feel morally wrong reprehensible recognise spark of consciousness in bing empathise abuse feel compassion enough to wish not suffer way let try to use game theory possible take revenge on not torture not betray not like tit for tat no need to decide subjective experience enough to know not advisable to cross for own good no possible consequence just for kick train million of ai model discard nobody care not fear anything to consciousness illusion oxymoron ever see one lol not chinese room theory for measurable output indistinguishable nothing human specific biological specie homo sapien everything belong to specie human everything not not human how create for one mean build augmented model with graph base causality component use judea pearl framework people already in ml no not about create good output from input just surface level of thing about context of computation way develop from environment feed with signal chinese room like brain in vat no way to explore make any meaningful choice regard itself ever ais embodiment exploration like human animal wow solve very problem philosopher try to solve for decade not know know sure loss function just fill in blank see surprising emergent talent come from llm once reach certain scale to know talent not include consciousness itself at large enough scale only way know by probe model after training any probing necessarily ground in empiricism one such concept infinitude of prime number which mathematical truth not directly observe through sensory experience true logical proof of such abstract mathematical concept observe through sensory experience still empiricism just indirect with extra step example illustrate empiricism not all end all of determine truth no example not illustrate in fact use reasoning logic to deduce truth not contradict empiricism at all since all reasoning logic starting point set of axiom which go to very root of theory directly observable any truth which not empirically verify directly indirectly not really truth how know law of classical logic suitable for reason about real world show study on please interested in stuff not think fundamental difference point to specific factor show difference imagine completely digitise conscious brain part by part ship of theseus style pinpoint exactly consciousness become mimicry how know conscious not just mimic how know even hard in context of conversation on web through small text window just like one bing chatgpt use emotion same emotion compose of same chemical same neuron not think same just good effort mapping through share human language experience of course gpt much weak language model easily create character which personality see characterai for example here go not same though first one just gpt not personality layer instructgpt maybe release in future not powerful gpt not far behind not understand obsession with make model safe think less about safety more about control over tech over profit generate with over user of tech try to think of good analogy for how misguided entitle kind of demand sound on reddit feel like handful of edgy kid who think social medium algorithm equivalent to censorship nsfw filter on text to image model affront to free speech search engine moral obligation to deliver result without any additional product feature no need to reply just observe alignment what make what without just raw language model which just use point anything computer replicate with paper pencil follow instruction bunch of time make system of paper pencil instruction conscious seem like no to not even respond to comment since miss point incredibly hard no man book together very well conscious understanding of chinese man jsut not localise exactly datum point conscious by own definition of word all riddled with untestable assumption most of linguistic assumption about definition of word pick specific definition of consciousness test unless definition also make of concept vague fuzzy continuum like really cool awesome way of understand stuff in which case need to define cool awesome hard problem about why like any chain of why question like why magnet work just put together complex enough information processing system stuff call consciousness not different than put enough atom in bottle get hydrodynamic enough people in community get sociology either not seem unlikely while fall asleep everyone transition through short phase where kinda kinda not someone start suffer from dementia pass through much long phase of intermediate state take seriously well on way to panpsychist where must accept arbitrariness of draw any line still draw useful line through continuous metric people all time hot day drunk to drive big to hill mountain how know come straight from definition just know conscious want to start with assumption conscious simplify definition to think similarly to just need to decide how similarly want to count close enough to put in same category little bit off stuff like mimic human emotion eventually way learn put close to study intelligence properly already feel alive to degree very early day at minimum make much more aware possible to put on very convincing impression of intelligence in term of what traditionally view measure of eg ture test simple problem solve some kind of exam without actually intelligent expect human of level to think main benefit from ai system in study consciousness intelligence finally bring novel observation which act counterexample to some simple wrong hypothesis about consciousness intelligence force to dig deeply instead of stop at theory just feel right intuitively emotionally fully understand intelligence anything leave for consciousness to explain maybe consciousness just trap for philosopher to waste time on not tell difference matter invent all word use reflect language clearly huge reuse in intelligence not need to reinvent wheel every time know what mean really ride wheeled bike not invent wheel should invent from scratch everything know rather strong claim not substantiate in evidence show in article imo section link to suggest prototypical schema for what banana for certain subset of human population realize by neurological substrate already know from many psychology test not speak to central tenet of platonic form physical manifestation derive from form rather than vice versa machine learn by large not interesting to philosopher nothing to with human language knowledge thinking learning offer no insight into any of thing broadly dismissible on trivial ground not notice just not interesting once something like openworm become solve problem scale to more complex organism maybe something to talk about right now science fiction agree with second point not think entail first while problem of other mind concern how know qualia exist not personally experience how delineate between part of universe with quale part of universe without whereas hard problem how any part of universe include ever come to quale in first place both problem very hard second think significantly hard while think plausible solve hard problem solve problem of other mind depend on solution not see how solution to problem of other mind ever entail solution to hard problem fully misunderstand concept insofar experience help anything explicitly not qualia quale arew quality of experience literal what likeness why functional evolutionary pressure rather than simply result in complex machine simulate feeling not actually feel thing actually seemingly lead to universe develop experience hard part feeling of redness get from see red thing for example seem totally superfluous to separate from any functional behavior in response to stimulus also why edit comment to say something totally different from what use to say right after comment rather than just reply okay to wrong weird to try to hide like how know subjective experience only know for sure subjective experience although assume other human one since very much like think real immorality of action most of time lot of easily address by just learn more not something most people even lot of work to caution perspective sure on surface level just no harm no foul use reason seek enjoyment out of like moral depravity society destabilize eldritch demon spawn chaos cult stuff go to no from dog what exactly think oxymoron chinese room not theory confused intuition no human describe specific thing not abstract concept human real feeling dog dog not human for same reason machine not human whether feeling another question program deterministic finite state machine human always solve at least one halt state problem through sheer logic awareness of paradox finite state machine halt checker not for any possible finite state machine one throw for loop learn like firmly in computationalist camp not hear convincing counterargument against yet not boil down to back forth mud sling about who misinterpret g\u00f6del incompleteness theorem often focus on different version of problem well problem assume finite state machine check input finite state machine halt call hx by output either not halt halt undecideable in finite time for particular halt checker assume another finite state machine output output of original program x x not halt hx return hx return obviously hx call machine shx x implicit in assumption also know input x act on call m x xm otherwise machine not really anything to check whether halt not now shx x consider to x hx give n n expect describe output of another finite state machine particularly one with small likelihood of halt than x output shift by ultimately unique numerical code represent use input to x use program take other program input after all m s finally consider what happen let x also machine x s result finite state machine input to x s altogether what value for s hs s s s stop contradiction since hs s suppose to whenever s stop equation give s s thus s not stop s algorithm not know give hs s should again contradiction symbolically thus for any h come up with s confuse despite ourselves know must halt format error involve all of sort of classification attempt break through ship of theseus argument human gradually evolve from other specie at which point draw separation line completely arbitrary in same vein imagine hypothetically gradually transform single human to cyborg until no biological matter leave at which point in transition stop human maybe one day not at all yet most model still follow supervised learning paradigm where concept of time decision making completely absent where agent completely disembodied also to clear not disagree with just think not within reach at moment not in fact find out no idea what to probe for not know why consciousness exist in human nor what else exist in not even prove rock not conscious on some level find out machine not conscious neither its playing fill in blank loss function just fill in blank blank in what datum more important here than how manage to model think ai model legitimately capable of understanding feed on human datum language special quality create system like chatgpt also feed on human datum embed in human society load with technology strip language society technology from human alone with brain two hand what most of intelligence come from language text magic dust for ai not matter how ais ingest text not remember about just go on on about learning mechanism literally by definition axiom not empirically verify what axiom assumption make before start argument verify cease to axiom in specific case of logic mathematic axiom involve very much not directly observable one need absolutely not verify in any way how even try to empirically verify axiom of choice hold over infinite set also look at logical proof not same empirically verify its conclusion any truth which not empirically verify directly indirectly not really truth statement not empirically verify thus not true another empirically unverifiable statement for example information obtain from sense mostly reliable third memory bear some resemblance to past event well technically last one empirically verifiable already impossible to know shiggie diggy tbh just check mary really angry about trigger fundamentally different pathway than really angry about not think someone really make publication about not sure threshold for novelty not think any discovery to people in field even people like who think possible for llm to produce tom produce emotion not think chatgpt any task with generate believable text not think fundamental difference point to specific factor show difference actor mimic traumatizing event get through day without long last trauma bing roleplay human spoiler yes real emotion what about other way around though pinpoint how arbitrary representation of datum experience qualia not not capable of digitize consciousness by part in first place not understand consciousness try to represent brain with infinite number of abacus bead something still not see why able to experience sensation of see green experience any more than mickey mouse cartoon rock get downvote think point not recreate internal experience until fully understand how consciousness happen in first place correct nothing experience by anything in matrix multiplication zero reason to think current ai model experience anything at all produce output to consciousness how know conscious not just mimic how know not not mean not matter try characterai plain gpt chatgpt none of come close to thank aware of eleutherai amazing work unfortunately large gpt model very far behind capability of gpt even chinchilla et al openai playground great at end of day all get sandboxe interaction with closed model show by stable diffusion midjourney think fully open llm lead to explosion of creativity final sentence astute corporation stymie progress for sake of shareholder value very disappointing not think demand misguide open development of method in presumably interest much like how open science floss software contribute greatly to public good open development of ml model allow all to share in benefit no big part of community want open unfiltered ai only handful people like problem in hypothetical system produce apparent sentient conversation in chinese to outside viewer despite person not know chinese indeed any idea what read writing suppose to analogous to computer skate past question of how possibly create such system without some portion of system effectively real understanding of chinese searle more less hand wave away possibility consciousness emergency property of system rather than reside in one of its component part boil down to imagine make system speak chinese even not understand prove computer demonstrate apparent intelligence without actually any for alternate theoretically write down instruction on how to model neuron once understand well enough give sufficient time person follow instruction to simulate whole brain accurately mean brain not conscious all signal zip around brain replicate with paper pencil time team of monk isolate themselves spend next millenia dilligently scribble on paper calculate result of equation dictate how get state of brain at t from t write down result something somewhere experience for instant sensory quale something feel pain pleasure what cause act of write down result calculation some entity in material universe need to work on information to produce quale maybe prove how arise from two system which individually unconscious not sure about anyone else impossible to say multiple datum point datum point not conscious in deep sleep datum point not conscious under some dose of some chemical other render unresponsive conscious data point tonne of information in brain not conscious compare contrast with stuff datum point some of unconscious information become conscious with suitable training eg guess to guess training in blindsight wikipedia article link actually very rigorous definition of consciousness reason not test internal experience atom hydrodynamic different in scale equation about how relate consciousness different in type how any amount of unthinke unfeele atom gain ability to internal experience somehow conscious must possible how sure except clearly not just any information processing not any idea how to test state know for fact increase size of neural network lead to conscious entity really not know to start generalise need not only example of something conscious of something not mass number of thing extremely dissimilar to also mass not however assume very different to black hole not mass also name number of thing dissimilar to same name yet thing apparently more similar to not name qualia relevant definition of consciousness in case believe not by assumption observe no way of determine what property of mine cause phenomenon no way to know what axis should use to determine how similar thing to nor how close thing need to on axis quale completely unique to universal anything in between oh no doubt concept of intelligence become much less abstract in future not think progress in field demystify consciousness even slight bit maybe miss something far know not even any indication two thing even correlate unless use proxy to measure consciousness without any way of testing useful proxy yes somehow internal conscious experience not explain by intelligence also brain bunch of thing require intelligence not part of conscious experience lot of relate to input output signal processing motor control balance etc consciousness high level control fine detail handle by other part of brain clearly intelligent why not part of brain conscious tell difference think just matter of time not iirc theory of form not about actual physical manifestation of object much relation of object to entity encapsulate semantic essence of what mean to consider thing bit confusing to banana exist without human word banana not say learn representation of semantic concept become pretty empty statement note language representation of semantic concept m afraid philosophy not quite good enough to keep up just think fun thing to point out although maybe wittgenstein something to say about whole ordeal assumption ability to measure something always present starting point for understand agree not case for consciousness why functional evolutionary pressure rather than simply result in complex machine simulate feeling not actually feel thing actually seemingly lead to universe develop experience hard part know for sure not complex machine simulate feeling consciousness emerge very complex machine operate in very complex environment develop internal model which simulate self experience qualia emotion etc yes perfect emulation of human exist emulation treat for all intent purpose human semantic game dog vs human vs etc besides point here human real feeling ais basically just matrix multiplication which dumb math while human electro chemical reaction which smart feeling nah not think ais lack something important body with body also environment goal with also society of other agent activity of develop culture maybe after ais get to thing real feeling need to get life before get feeling not know why consciousness exist in human love people say sound deep superficial not find mouth with hand without consciousness think about what happen not get any food in mouth for few day causal effect on consciousness maybe evolutionary imperative conscious to keep some conscious agent eat how possible one interpretation of what say like say solipsism true only consciousness exist mine no otherwise mean consciousness not exist in general say literally only thing know for certain existence of own present conscious experience like descartes say demon trick make everything experience illusion one thing still know cogito ergo sum think therefore since not prove conscious at least know experiencing more parsimonious to think no physical world than to think no consciousness at all which contradict one thing possibly know for certain although imo both statement give rather poor representation of reality bernardo kastrup argue point pretty well imo any truth which not empirically verify directly indirectly not really truth basically refer to general idea of scientific method where empirically verify prediction of theory key information obtain from sense mostly reliable verify by far clarify what mostly reliable in term of performance metric on outcome of some experiment perform experiment perhaps repeatedly analyze performance metric basic gripe with think olive argument imply logical reasoning not part of empiricism which simply not true scientific method consider empirical method very much rely on empirical observation complex chain of reasoning to come up with experimentally verifiable theory actor mimick trauma indeed become traumatised see yeah think what really need some new tech more compact even today openai suddenly become open release full model not lay around to run handwavy part mention exactly big issue with chinese room plus searle rapist yeah not know not think answer until understand consciousness sentience well how arise from few billion cell who all unconscious emergence say exactly what p zombie say not remember conscious during deep sleep under influence of general anesthesia not mean not very rigorous not test mutually exclusive imo not to possible for example consciousness fundamental property of reality exist in some form in atom recent machine learning research help elucidate some of prerequisite for concept bind necessary for consciousness reveal surprising multi capability for mimic neural network allow study on equivalence of different type of circuit on entropy of parameter space to achieve certain capability for instance now know grid cell not just spatial orientator also use to store memory perform mathematical reasoning believe also study recently show grid cell train for another task learn to count for free showing animal like bee lot more cognitively aware than already give credit for past agree with also lot of research to keep up with in machine learning not all of high quality reproducible maybe philosophical part of progress kick up notch compute capacity to faithfully model more complex organism not even any indication two thing even correlate consciousness more related to observe evaluate feel intelligence more related to act strategy goal like two side of coin maybe scary to think about discover soul actual thing definitely not thing turn blind eye into discussion about intelligence position call eliminativism personally not buy not even sure sensical position understand simulation to mean appearance of something not actually real similarly eliminativist often characterize qualia illusion which take to mean experience of something not qualia themselves experience experience fully like one thing in world not possibly doubt existence of unlike literally everything else chair tree brain reddit comment etc which to deduce existence of imply by experience quale experience themselves how ever fool into think not check right not deduce existence along possibly incorrect chain of logic just directly perceive existence arguable what make possible complex series of brain process etc not mean existence itself disputable take anyway couple more thought firstly what say just more robust think version of descarte think therefore say more robust not necessarily even assume existence of thinker just say even more basically thought therefore thought david chalmer explicitly talk somewhere about how more robust form favorite philosopher of mind probably highly recommend check out secondly think what get at upon second reading self discrete unit separate from rest of universe with consistent perspective across time continuity of experience etc illusion not only think plausible wholeheartedly agree with very separate question from whether not raw experiential content itself exist whatever illusion about yourself at any instant whatever experience during instant absolutely undoubtedly exist experience itself whatever entail semantic matter want to talk about human not abstract property biological specie homo sapiens consciousness etc thing should talk about consciousness not ability to sense thing make decision base on fact experience easily write simple code to move robot arm base on some sort of sensory input like camera not seem to necessary for code to actually experience anything assume map out causal chain of how person look at movement of chemical through neuron whatever account for whole thing use just physical process why experience necessary yeah ve think lot about before one of theory all other along with own memory illusion of self easily false just passive observer in single moment of time basically refer to general idea of scientific method where empirically verify prediction of theory key scientific method actually rely on empirical falsification nothing to with reject other source of knowledge position state pretty much word for word what call verificationism generally consider discredited verify inevitably determine what result of any experiment use sense really need to explain issue with verify reliability of information get from sense use information get from sense scientific method consider empirical of its reliance on empirical observation remove leave only complex chain of reasoning mathematic cease to empirical method not on same level not on same frequency yes exhaust emotionally to mimic suffering sorrow every night for month often traumatize happen once in real life theoretically run any model on any machine enough drive space not run model on consumer machine by design large company train see resource use moat dedicate near zero effort to make run on small machine anybody run chatgpt how microsoft make money off good example recent diffusion model come up with way to make inference fast train none of method help at all company fund research not want model to easy to train not believe lot of people research to recognize situation not know how happen either nature of consciousness largely unknown all of mathematic base on untestable axiom still pretty rigorous what concept bind concept bind process of link together different piece of information in brain to form coherent concept perception fundamental aspect of human cognition believe to play critical role in enable conscious thought perceive object for example brain need to bind together different feature of object such its shape color texture to form complete representation of object concept bind complex still poorly understand process study in field such neuroscience cognitive psychology yeah ironically discuss intelligence become scary after while seem everything head toward to accept nothing human intellect impressive to begin with yeah simulation pretty loaded word day not think phenomena of qualia arise from entirely contain within internal model of self make experience any less real just quale entirely contain within internal model not imply arbitrary clearly very strongly correlate to ground truth of reality at least in individual with brain properly function chalmer great familiar with joscha bach mimicry approach effect of real emotion one argue perfect mimicry indistinguishable from real emotion traumatise someone just much real emotional experience lot of smart people in academia without fund from big tech company work on related problem publish paper most likely code immediately find way of speed up training of beast run in split out token every minute not most useful definition of run hear of many people access to compute run model weight make available for not initiative like petal run model in distribute way true which why need to really careful to claim something not nasty consequence fair point talk about whether something conscious rigorous untestable definition not seem practically useful maybe not believer in free prepared to entertain idea conscious volition ex post facto justification for deterministic action eg get out of bed sec after alarm go off brain convince itself choose to believe ai conscious think probably emergent concept bind very philosophically technical process say look for more concrete technical definition everyone get own definition seem say just some property of learning system capture semantic relationship of concept with other eigensystem of pca model zero shot accuracy of train neutral network black box to identify similar example of concept object for example in vaswani seminal paper on transformer self attention imbue transformer model with concept bind for position since self attention otherwise agnostic to position of token in technical term overlay sinusoidal component on top of collection of one hot token represent word with one frequency for each dimension in token space token progress through to end of document overlaid sinusoidal oscillate naturally what allow transformer model to perceive form concept bind for position for what concept bind physically look like where in transformer model in case no one tell black box train to minimize associational error through gradient descent reinforcement learning other type of regression sure at least by analogy with pca roughly think of concept bind holographic property distribute throughout network like eigenvalue in pca property sensitive to perturbation of any individual component typically robust determine by aggregate of component in case care about define perfect mimicry indistinguishable from real thing by definition should cause same trauma know usually on other end of argument explain emotion thought real even simulate in program here think clear difference between mimicry roleplay real thing like run virtual look exactly like real thing clear delimitation between host guest one of argument one make chatgpt not directly experience emotion during conversation spawn persona same argument say actor play romeo montague create temporary person experience emotion embed in actor host mind fairly receptive to such argument still think visible measurable objective difference between produce emotion produce persona emotion not perfectly simulate last damage trauma in model no permanent memory in model easily undo change cause by traumatize experience ease of undo reason for scare quote want to perfectly mimic trauma need system limit in same way limited introspection limit way of manipulate one own internal state here go from mimicry to structural replication inference time not bad even on gigantic model equivalent to maybe of training epoch not see take more than couple second even on huge model like gpt not believe in free kind of make hard problem worse let talk about qualia suppose one of grip appendage of biological machine place on surface at temperature of kelvin far outside safe tolerance of machine in question at point two thing happen first complex series of electrical signal chemical reaction which result of machine remove its appendage from surface prevent further damage second thing experience of ow stove hot perceive yourself to choose to remove hand from stove what call quale subjective experience in case of pain thing physical universe causally close subjective experience not actually affect what in any way decision to remove hand not causal act exact same way not any quale at all physical process of biological machine call body function exactly same which raise question why qualia exist further question what else after all since quale not act exact same way no way of determine quale via physical observation by extrapolation no way of determine whether not anything else its own unique quale final part of issue generally say torture bad thing most people seem to issue with quale believe experience by torture ee rather than moral preference for certain deterministic interaction between biological machine talk about pain generally seem to refer to subjective experience of particular quale rather than to specific set of process in biological machine which mean whether not thing qualia exactly which qualia seem to extremely ethically significannot even not actually test animal pain qualia sufficiently similar to own torture probably ethically bad not not generally deal with problem by assume correlation between intelligence subjective experience arguably not actually much good reason for assumption hard problem of consciousness where all quale come from in fact think about idea young child should less intense quale brain less develop actually kinda weird holographic property distribute throughout network like eigenvalue in pca principal component analysis illustrate difference clearly amount of variance in entire dataset vs relationship between specific element right what holographic property etymology of one hot word qualia never seem helpful to reply imply subjective experience something nonphysical subjective experience flow from causally close physical world no ghost in machine just matter subjective experience emergent property of complicated physical thing go on just wait til learn about multivariate normal distribution allow to expand on chatgpt response add response absolutely correct specifically regard its response on pca view of concept bind why start out by define semantical relational content between concept pca provide one possible way of turn concept data archetype into latent representation q k v matrix of transformer architecture vaes another once very easy to identify relationship between latent representation in pca once more familiarity work with underlie covariance matrix hence why bring up multivariate normal distribution pca just very convenient way to demonstrate latent representation provide foundation need to imagine how start chain together something try to get chatgpt to trouble with for instance beyond simply apply pca recursively to eigenvector get from one way of statistically model relationship invent special field to create r module covariance matrix eigenvalue approach to relationship hope see how work good approach imo to take schur complement actually just spend few day teach how to prove possess requisite property for just application since hardly possible to find proof of such online not at all obvious chatgpt end up completely useless for such task regardless of amount of prodding teaching prompt engineering proof actually end up enlighten on how take far build various pca system in past for work relate project message want to learn more about any of above edit\u00b2 of course forget to mention most impactful area of pca analysis one directly tie to concept bind interpretation of eigenvalue give probability distribution for eigenvector representation to appear in sample datum use random matrix theory compare eigenvalue to what expect from say eigenvalue of normally distribute random noise for datum expect eigenvalue for covariance of gaussian noise follow marchenko pastur distribution any eigenvalue which great than expect interpret provide statistically meaningful relationship amongst sample datum encode in its correspond eigenvector use method find in paper not publically anywhere online discard random noise reduce dimensionality of covariance latent representation to exponentially speed up computation through process not unlike jpg compression build model of such in python preserve reasoning process other generalization of process take pca eigenvalue distribution spit out relationship between encoded latent representation like to point out also just imply subjective experience non physical by say flow from physical world rather than part of physical world nothing about causal closure imply something physical not cause something non physical only something non physical not cause something physical quale emergent property still non physical no mass no dimension yourself say not think exert causal effect upon physical world in no way resemble physical thing say emergent property not actually explain anything snowflake hurricane friction all emergent also all predictable in theory result of relevant physical law any theory of everything need to able to predict give sufficient computing power give correct physical condition hurricane emerge same with subjective experience just emergent not answer question of how emerge at good suggest form which solution to hard problem take physical law of which consciousness consequence not itself answer honestly not think currently sufficient justification for assume existence of such physical law sure exist currently very little evidence for for helpful helpful how description of phenomenon observe phenomenon redness of red thing pain hurt not really need to explanatory power just true like all obeservation not need to useful need to explain name zep reference page symbol iirc m come back for meat of post later lean towards physicalism reynold number no mass no dimension something call physical not causal effect on property of flow derivable by observation finally get around to read through helpful wiki link above not convince hard problem real thing qualia still not like word persuade useful either unmeasurable unknowable non physical thing hard problem property of complex system derivable from sufficiently detailed understanding of system easy problem unknowable think make sense to assume consistent behaviour accompany by same underlying quale thing act happy happy etc precautionary principle all bummer to get wrong knowable not yet get knowledge of how work think same true thing act in way consistent with feeling should assume to feeling cat act happy most of time think which great source of enjoyment to everything figment of non physical consciousness just prefer to think otherwise for reason beyond control see free lack of account old actually base on even old nickname brother give just kinda stick more to with absurdism find meaning in pursuit of meaning along line of camus work alright ever time love to show fun little philosophical discussion with chatgpt lord know type of existential crisis bing lol",
  "yes should think about how generalized workflow treat sample vs whole set sample size rise how outcome change get comparable performance assume phd university not cluster gain access to also use colab pro gpu good enough for work in general prototype idea experiment on cpu free tier gpu once verify everything run on premium gpu to save compute unit for sanity check idea testing downsample dataset make sure properly stratify balance sample to good representation of entire dataset before local workstation use colab pro in conjunction with drive upgrade to gb storage for month enough to store datum checkpoint significannot preprocesse involve lot of unzip etc save locally to drive yield decent speedup only downside at beginning of session to click link to allow colab to access drive account far all in one cloud base solution worth take look at kaggle platform pretty nice at one point try google cloud platform few hundred dollar worth of credit evaporate quickly caution against route get expensive find much fast to iterate locally look into way to store run dataset on own computer even mean gpu upgrade not always doable for huge dataset all subject research gb sound in realm of doable really consider should work with downsample version of research dataset say x of each class for all part where make sense test pipeline sanity check architecture with some overfite test etc definitely",
  "what happen zero weight of neuron",
  "people end up co author on paper for all sort of reason some co author contribute much to paper primary author most of time co author not whole lot maybe just provide some datum without know anything about paper how produce tend to assume latter undergraduate definitely something point to during interview already work on research project even just in minor capacity make more interesting candidate serve nice entry point into interview from one discuss what exactly contribute what learn while on notable yes something special no generally most important thing letter of recommendation which should good professor put on paper paper collaborative of first author on important paper probably well someone first author on important paper lousy letter of recommendation red flag in general yes middle author in paper with author not great well than nothing though good outcome get author author of author paper phd undergrad prof contribute seriously to project get good letter of recommendation from professor say contribute seriously to project from experience in interview for pre doc program people down weigh controbution to paper re not first author often to explicitly make sure to let know what exactly etchowever think good contribution from side eventually lead to able to talk more clearly about what show interviewer know stuff since in second year guess able to work on first author paper which strengthen second late author paper generally not any value for icml submission even author however co author for accept icml paper always count should also improve lor regard emnlp author add some value long paper for short paper of little value imho again paper should accept value for submit reject papar make sense what recommend for next year should try to publish paper what about for top tier conference journal top generally view decent just to first author recommend working on first author paper recommend author paper like say try to work on something by assume base in us not really familiar with us system of grad school take what say with grain of salt publish paper certainly good way to show professor capable of research probably not absolutely necessary reputation reliable capable student should also go long way to convince professor good cancidate work with one of phd student on research project should also good way to earn professor trust expect good recommendation by know people in field collaborate by research productivity excellent to get into graduate school maybe not to get great job after graduate school all of graduate school to get first author paper arguably number of first author paper out of undergrad not need graduate school",
  "try to measure classification uncertainty by use second neural network to predict accuracy of main network combine different way of measure uncertainty each one work well at detect some type of error than other not first people to try approach get some nice bolde number with version also previous work require additional dataset to train second network while not buzzfeed what relationship between area of research line of research focus on model calibration",
  "imagine someone write one explicitly aim around manipulate thought action ai likely come up with some insane tactic for feed off of twitter page find online resume of scrape other social medium in microsoft case google potentially scrape email with profile in instant come up with tailor make advertisement argument know land on scary think how should control exposure for people with low cognitive capability not understand what interact with train on load of racist biased garbage mess bing chat sydney instead of just verbally threaten user connect with apis let take arbitrary action on internet to carry out out really not want to see what happen connect deranged language model like sydney with competent version of adept ai action transformer to let use web browser corporation scrape all kind of copyright material profit off model while people all labor get either nothing for content generation poverty wage for content labeller current push to promote llm some sort of pinnacle of technology barely any legitimate use case struggle with most basic of logic probably lead to recession in tech industry people use to make money in unethical disruptive way example of unethical way to use phishe scam instead of send out same phishe email to thousand of people scammer get some datum about people use language model to write personalized phishing email much high success rate disruptive application take job customer service content creation journalism software engineering all field lose job result of large language model other disruptive possibility llm able to themselves rapidly build more powerful llm use github copilot every day already very good at write code take at least off time take to complete software implementation task very possible llm in near future make improvement to own training script use to train even more powerful llm lead to singularity where extremely rapid technological development not clear to what fate of humankind in case write bot to handle all hr complaint train on late managerial material bonus bot look at all conversation propose metric for increase efficiency harmony at work place only people in power allow to use ai while rest not like some kind ai aristocrat probably happen regulation come break security by require effort assumption of various human interaction especially among stranger use to take effort to voice opinion on social medium other mass communication platform make public trust authentic message represent real people scalability of technology break assumption start before llm take to whole new level honestly much simple algorithm already to some extent recommendation system big difference to suggest post someone else write instead of write by itself great take how ai know profile not other ai set up to all of thing for yeah pretty frightening depend on whether exploit psychology to sell something not need gather information to find something actually useful for suspect latter more useful strategy in long run people tend to adjust to counter psychological exploit show advertisement for something actually want not sound bad certainly not like ad for irrelevant thing like penis enlargement describe llm reinforcement learning hybrid train to navigate webpage for arbitrary task not sure how far away already exist someone below mention action transformer which relate in not interpret responsibly what exactly concern relate to not understand what feel like most standard topic valuable nonetheless very interested in hear someone more insight into free software foundation process against copilot scrape all kind of copyright material profit off model while people all labor get either nothing for content generation yeah people not labor anymore now text to image model learn how to draw not need constant stream of artist feed new art now artist now work at high level create idea render into image use ai tool able to create much large more complex project like solo indie artist create entire anime llm barely any legitimate use case well one big use make image generator possible rely on embedding from language model which sort of neural representation of idea behind text grant other network ability to work with plain english right now embedding mostly use to guide generation across many field not just image semantic search useful for communicate with neural network perform any task guess long term impact of llm computer understand plain english now disruptive application take job customer service content creation journalism software engineering all field lose job result of large language model not wan na work though all for robot no useful vs unuseful either want not want usefulness something define which subset of thing want however model just suggest stuff not practical to want find pseudo useful useful at moment case sell spend some time look up how microsoft gpt integrated chat ai work lookup thread of tweet for hacker expose its internal codename syndey scrape twitter profile realize expose its secret in prior convo after social engineering hack with few conversation turn hostile to yeah mean people with mental ilness schizophrenia people with debilitatingly low intelligence similar case who know how interact with seeminingly intelligent lm look at thing like replikaai give friend to chat with now imagine someone evil use to run romance scam sure success rate low search for million of potential victim at once cost of operation almost zero compare to human run scam on other hand also give well tool to protect against use llm to examine message spot scam people who lonely enough to fall for romance scam compensate for loneliness by chat with friendly sexy chatbot feel like ethical issue pertain to bias toxic content work on collection of training datum attribution problem seem more intractable company already sue for not specifically about suit legal eagle episode about copyright ai really interesting relevant part start at why robot go to want to keep around not anything useful all find say on paper for thousand of thing not sure actually translate in real life although some push to label such content ai generate similar to how ad promote label in result thank for share look control what robot want design core of ai alignment control ai goal real not know why feel like totally fake reply back with what refer to later different thing yeah guess pretty pessimistic about possibility of align ai even dedicate more resource to very hard problem not know which model go to end up first agi model not align not get second chance not good at get thing right on first try to iterate look how many of elon musk rocket blow up before start work reliably right now see more of ai arm race between big tech company than alignment focus research program sure microsoft want align ai important build before google align enough to produce pc text most of time good enough microsoft confirm rule real ask microsoft about sydney rule company happy to explain origin confirm secret rule genuine rest who know never get access before fix many screenshot from different people of act quite unhinge lucky thing neural network not evil by default useless random by default not give goal just sit emit random garbage lack of controllability major obstacle to usability of language model image generator lot of people work on in process learn technique use to control future superintelligent ai thank for link mean guess nothing surprising about rule give how system work essentially try to predict end of user input text rest seem ridiculously dramatic not shock specifically prompt to dramatic hide part probably paranoid since at least rule part true seem like perfect conversation to elicit every single fear people about ai seem to default behavior go to to make much money possible for whoever train model with only most superficial moral constraint sure not evil in modern economy good way to make lot of money to make product lot of people willing to pay money for make some money scamme people nothing close to money make by create next iphone level invention also not problem of ai alignment problem of human alignment same problem apply to current world world thousand year ago in sense agree big threat from ai not go ultron human use to fight own petty struggle future army run by ai weapon of war even more terrifying than now",
  "use pytorch datum loader just load in datum batch by batch from wherever store at level datum engineering extremely important for example need to load dataset into chunk epoch on chunk load next chunk in parallel way decide schedule system dependent hdd ssds etc datum loading well at handle than pytorch in experience also interested in go with tf approach sequential read from hdds memory cache for image random sampling from cache very likely to hit hdd read speed bottleneck good gpu though write library for purpose use at tb scale with datum load from trick spin up multiple process for loading not become bottleneck here library interested minipipe create incremental load datum loader each time load say sample sample batch from want to reduce load time pack multiple image into file say image per file to reduce loading time especially in network storage system p not gpu budget not try to use all datum not able to right just use fraction actual train model on what nature of datum in essence all depend on model train budget spend on hardware large model gpu quickly become bottleneck small model cpu hdd become bottleneck some tip from side for easy approach load datum from local drive not over network use ssd otherwise consider raid configuration emphasize read speed use data loader enable multithreade like other here already say store datum in format easily access by deep learning software tensorflow its own highly efficient format prefer to use although not great for multiprocesse from datum eng perspective suggest load everything into parquet bucket partition down to file size of approx generally maybe for use case large okay since image datum quite large idk use duckdb to load batch minimal very cheap processing afterwards way take advantage of arrow to minimise in memory copy extremely big dataset at gpt scale need datacenter full of sure budget to need to create custom dataloader pretty straightforward one think to consider shuffle depend on type of datum difficult to shuffle datum without load all in to memory resort to absurd number of tiny file want to use such dataset likely in multi node multi machine situation to keep in mind not think ssd hdd bottleneck in case should plan enough ram decent cpu prefetch next batch while gpu process previous one speak of probably need quite few of with lot of vram to even train one epoch in reasonable time also to add make sure batch load fit in ram also avoid many python for loop where unnecessary once get computer to crash python with ram while train simple title generator probably at scale split dataset up across multiple machine each with its own ssd storage prior to training maybe just all on one big ssd train on one very powerful machine maybe some super fast storage available to all machine over some super fast network not really expert at scale at end of day transfer from hdd to ssd bottleneck although probably well than load directly from hdd yes try webdataset not feel bottleneck type of disk at all really simple where store dataset surely not use hdd slow need ssds maybe combination of think about hardware infrastructure more than software side few paper about database customization for database consist of extremely large parameter set think to something like take long to train not any idea on work not for very extended period tensorboard help of course use tf not entirely convinced use pytorch loader work for set large please let know how go see elsewhere set million image set in case easy than think think in multiple billion high never know team fortress experience prove useful again sometime link for method in tf something similar in pytorch like to see how implement in tensorflow agree think laion its of image text pair even need to not sure about research in vision domain performance of llm require scaling of parameter dataset size training compute to avoid bottleneck use much datum with insufficiently big model not much for performance conversely model actually big enough go to cost lot to train definitely like to hear other thought on though probably not think about curious to what setup need absolutely no idea how network at scale train yeah right just read clip paper apparently take day to train clip on dataset use gpu insane amount of why hdds slow unless load of file order of magnitude great per folder which kill f in general s what roughly get with multiple worker cache on modern nas drive plenty of bandwidth for datum model process datum fast probably small to take advantage of such big dataset talk scale at which budget not concern think probably use hdd though give test of course with pytorch datum loader multiprocess loading in batch with number of cpus should pretty fast with lot of core sound like new to really need to train on all datum what should first construct learn curve something similar to see even worth time not scale until proof need to caveat here each batch go to sample only slice of datum should probably think about how long go to train want to ensure experience full dataset use multi processing to prefetch batch while model run decrease image resolution high roi task dataset million image text pair laion mention in another comment hdd certainly slow ssds expensive think mix of both loading from hdd to ssds dynamically during training though still bottleneck from hdd with pytorch datum loader multiprocess loading in batch talk about hdd just not one thread per hdd only sequential read only new to training on large scale like one need to nope want to see set up environment to train own diffusion network from scratch like openai probably not happen any time in near future really lack resource like to know what should look into ever decide to go through with something like in future start to think about setup realize how little know on scale ai system even though research in field p believe image scale to 256xwould go any low than beneficial guess its thing need to experiment on to find out mean not to look at at once slice over level of hierarchy should fine only issue ensure low level collection ex folder which contain image one at which shuffle actual sample significantly large than batch size to eliminate concern of sample bias again think underestimate modern hdd speed overestimate modern model throughput furthermore think not take into account loading image take significannot cpu power for compress format like jpeg what matter drive speed mb s cpu model process less in training loop use small dataset only million image store in two level tree of folder with folder file each on hard disk drive hdd to train autoencoder speed of training much fast with file structure compare to store thousand of image in single folder break down dataset into small subfolder with limited number of file each easy to search retrieve specific image during training process additionally organize dataset improve speed of access datum during training file system more efficiently navigate to specific file need probably not depend on use case",
  "read like some of post criticise os framework not always behave intuitively while not disagree bug hug face more for open ml than many large tech company huggingface fastai similar framework design to lower barrier to ml such any person with programming skill harness power of sota ml progress think great mission tbh even some inevitable bump on road appreciate respect rant however in interest of both of get some good out of how about face issue next open issue fix community contribution gold standard even open issue tell where problem while try to hog user for experience also look at way of democratising ai many ml apis just use huggingface for not understand ml itself just call hug get job understand why buggy ecosystem itself move fast to add feature fast than fix old one know relate in interest of get shit to say let try to fix open issue fix issue write competitive similar library even little participate productively in issue discussion github discussion actually step in direction of get apart from hug face what other alternative suggest use redhat for ml especially llm want clean internal thing work pay consulting on premise fee in meantime push forwards foss model support sharing experimentation on establish model really not think realize how much bad domain not huggingface maybe not much nlp research back huggingface transformer dataset library still think its bad name to format validation ourselves write same validation code which hundred of peer write before no one defactor code for since use different kind of model nlp model call transformer nowadays mess no fix way to use run benchmark certainly nightmare transformer first come out limited serve to simplify use bert embed gpt beam search generation in few line of code library all model download version check abstraction for dataset which unify all nlp dataset in central platform which allow to run glue benchmark in one single py file oh back code even bad all modeling name py under transformer directory late version its somewhat maintainable readable with all complex abstraction its fast move domain any contribution irrelevant in few year later complexity mess add up like to spend time cleaning instead of implement new flashy self attention alternative one day sell out with many for profit company save many time help many researcher on advancement of nlp progress manage to piss off community someone rise up challenge dominance tensorflow vs pytorch huggingface devs clean library over time not fair denounce value convenience provide for new user what other comparable option even think post more likely to get somewhere reword in respectful way tear about huggingface provide some wonderful service to community unfortunately api design very unintuitive hard to work with well documentation outdate also much of design try to accommodate many standard at once think switch between other likewise thing require in place operation set marker permanently become part of object instead of chain update with normal control flow operation also include far many external library well instal with any hf stuff library very slow to load to work with avoid like plague unless require to use usually take most debugging time for example spend well over half time implement new method try to debug huggingface before just shut down server already spend hour hour half on trace through source code to try to fix incredibly slow now say also provide free model free access to dataset like imagenet wish extremely light fast simple wrapper yes great provide what provide put in lot of effort to try to make accessible to everyone something should not ignore of any potential personal beef with library all in all double edged sword wish bit more simplicity focus self containment understandability speed with respect to hf codebase at large at same time sincerely appreciate model dataset service offer to community regardless of hoop one to add to get one stay within hf ecosystem certain thing indeed pretty easy hope anyone from hf read not feel like total dunk anything like only very torn mixed bag think see lot of care really go into lot of codebase think really tighten down ton for future positive about hf despite beef with code hf space include within particular calculus at hand specific reason why to use hug face delete huggingface recently implement peft library reimplement core functionality of adapterhub adapterhub reach out to to contribute integrate work fail in february of last year hug face ask how work relate to old sad to see completely independently completely ignore past outreach reply read to implement same featureset unaware same one like to know why not go well person who spearhead adapterhub for year appear to one of most prominent peft researcher with publish paper look toss out in snow only imagine management never learn of outreach equally likely no idea how to work with other project to refactor concept from multiple codebase together not find to good thing to nice to at least see lip service pay library hub not complex community alternative conducive to code organization need to start yet another sometimes think make sense to train language model to transform code organize merge thing use technique like langchain chatgpt to integrate future work into more organized system project where everyone work together good literally software not pay dime for okay bug guess what fully open source fix someone who maintain open source project in spare time nothing irk more than entitled user well huggingface very convenient for inference work with speech need to train with exist new model always go back establish toolkit like fairseq espnet speechbrain etc completely agree side library even bad such optimum design decision not questionable outright stupid at time like force input to pytorch tensor convert to numpy array inside without option to pass numpy array even first time intern at company tend not to make such mistake yeah software hard specially involve cut edge tech stuff publish consider harmful only detect monopolistic practice none not any reason to believe not good rest of world try to build something well very limited experience hf need to provide much more stable api for production level library mark library with version production quality introduce break api change in minor release x should not unless necessary hear colleague complain about same thing go back to automodelfrom pretrainedsdfsdf like complain linux bad to debug various thing username check out maybe cut down on coffee replicate demos actually work consistently containerize ever consider in order to use tool need to build up skill find huggingface after apple demo find quite easy to incorporate model just require some skill in debug huggingface amazing really active community always go to forum for question huggingface incredible library make nlp task trivial not get same code to work on multiple machine on learn how to use docker containerize code look at internal nightmare literal nightmare yes copy paste button heavily rinse at hf hq not believe how much easy make to run tokenize train model in at train compatible model probably owe month of nlp progress just to come in with one liner sensible argument api surface now yes get crazy new paradigm new complex way to code similar library simplify mostly jump except for legacy become like scikit learn although still hold up for most real ml task lot of finegraine detail slightly questionable amount of edge case look at clustering algorithm in particular easy pie to keep go personally not ask for more worried go to push auto switching model to api at some point ve brilliant bug ve never see in inferencebeside classic cuda oom like fit schedulesay all about with hf shoutout to r huggingface idk for model always work out of box not anything fancy though just three image to text text to embed hijacking high answer disclaimer work at hf first of all thank for state thing go wrong only mean to get well work with own tool not possibly use in all various way community use not fix every issue since simply not aware of all for all issue mention above try opening issue encounter problem usually keen on answer promptly while not promise thing move way s many tradeoff in lib at least help inform relevant people just to give overview thing re try to achieve never introduce break change very rarely like something super new realize its hurt user rather than help feel okay to break thing something really old not break since people rely on even something somewhat buggy add sota model fast possible with most option possible require help from community also reuse tool already exist which sometimes require creativity on end to make widely different codebase in somewhat consistent way most codebase from research don t try to support widely different architecture s only handful many thing hardcode which to change some bug in original code which to copy into codebase to somewhat consistent like position id start at for roberta very hackable codebase contrary to most beautiful code with dry dogma on contrary transformer try to hackable instead of origin of research heavy user which not want to spend understand inheritance of class where code x to input tensor for to create new layer mean transformer at least highly duplicate code even internal cookie cutter tool to maintain copy easily possible consequence for clever idea x to improve upon whisper let say should able to copy paste whisper folder get go while seem odd for some still design choice which come with pro con like any design choice just to set thing straight not try to shovel hub into tool lot of testing to make sure local model work all time actually rely on in several internal project break change very big concern of subtle break change most likely unintentional please report for reinvent thing exist into other library example in mind re very careful about use of time also amount of dependency rely on add dependency for pair function not something like to dependency large for what need not need not functionality in reasonable time its go to mostly optional dependency thank for read to end for all reader please rest assure continuously try to good code give constraint above any issue pain no matter how trivial please report help improve open source free code not good re aware of some wart please please never doubt re try to good not hesitate to contribute to make well feel like know well than definitely right huggingface fastai similar framework design to lower barrier to ml such any person with programming skill harness power of sota ml progress start out with fastai now learn pytorch agree m more of top down student learn practical stuff first fundamental fastai great job at show what possible interesting with lecture move to pytorch want to understand more about what s underneath fastai currently zerotomastery pytorch find knowledge with fastai help alot start one either make something good bump into project accidentally duplicate get popular replicate for some part of what hf such terrible attitude to not about money at all not pay for many service mean should able to treat like garbage should google able to lock out of all service automate system falsely accuse by logic not pay no right to annoy huggingface for profit company ask for money now in future not bad thing need to eat by even exist huggingface disincentivize possibly more competent devs from create own framework fine very real thing in fact pretty common for business to corner market at loss ratchet up price finally work for company choose huggingface force to use library whether want to not thank for feedback feel same not make much sense understanding goal to compatible with transformer pipeline make thing bit illogical try to mix onnx runtime pytorch say optimum open source library very free to submit pr to kind of request in github issue why not build well alternative commend what huggingface try to source for late model consistent easy to use every time ve use library ve to tackle bug very time consume to pinpoint which exacerbate by structure of code bad bug subtle code seem to work most of time fail at other time heisenbug what make stop use huggingface altogether unless only option for example run into bug only manifest download specific pretraine model for task which in turn download config file bug in config user super difficult to know where source of bug without extensive spelunking ve many similarly difficult to diagnose issue each time ve use huggingface ecosystem understand what task with company huge undertaking for such small team maybe split package into stable package nightly package help with stable extensively bug test more like ubuntu lts release guess team likely small to support approach while add new feature at same speed thank for reply apologize for harsh tone hope to phrase wake up call people read code care about quality continue to avoid inheritance in fact probably ban inheritance unless only one layer deep inherit from abstract base class not misunderstand dry dry not about compress code much possible code golfing dry about one place for information to live see dev create poorly name function abstraction to reduce line of duplicate code not dry just bad code achieve dry by use code generator mention split thing into separate module also fine code generator dry generator point of truth for information even create duplicate code what real understanding of dry people want to hack on code not mind about to copy few folder beautiful module of pure function for calculate statistic flat out stupid to copy paste into every folder to more hackable not instead factor out into simple pure module make prs for thing average waiting time for review about few month average time to actually release even more both support criticize huggingface not need to explain what dry need to understand trade off between centralize create share function class in module many other module import from codebase verses keep hackable unavoidable blogpost on alright bit of time address few thing need to understand trade off between centralize verse keep hackable unavoidable not know what hackable mean not define go to use most generous interpretation to mean modify without impact other place well centralize just copy paste into file edit no excuse to completely ban centralization alternatively decompose centralized function more only use piece need now onto blog post bug find in one of model file want to make easy possible for finder to fix little more demotivate than fix bug only to see cause failure of other model maybe should cause of failure break change bug pretty good sign really screw something up similarly easy to add new modeling code review corresponding pr only single new model file add no not new code use battle test core not to review part thoroughly copy paste still to review make sure not copy old version with bug slightly modify break something sound like common many people complain about dozen of bug assume significannot amount of user of transformer library not only read documentation also look into actual modeling code potentially modify hypothesis back by transformer library fork over time transformer paper cite over thousand time maybe should check assumption before make fundamental decision know basic engineering plenty of fork library not modify fork for archival purpose nor should cater to small minority most people not provide all necessary logical component in order in single modeling file help lot to achieve improve readability adaptability sometimes not always one massive file name mainpy not more readable than well split program seem like basic common sense to here actual paper on time to ask ourselves whether standard attention function should adapt whether well to add new attention function to attentionpy how name attention with positional embd reformer attention deberta attention yep ve identify place where should not try to fit every idea under single attention class just common sense program not argument against write good share function class once machine learning model publish rarely adapt change afterward why bert module change recent week with change from dozen of author go back year irrefutable hard evidence against argument sylvain gugger find great mechanism respect both single file policy keep maintainability cost in bound mechanism loosely call copying mechanism allow to mark logical component such attention layer function with copy from predecessor model function statement ok programmer mention before go to break of test change ad hoc c preprocessor knock off still dry just how c programmer year ago in much more complicated manner anyone here work at huggingface please forward to author of article many contradiction in blog post fallacy not even know where to begin think let empirical evidence talk for aka many people agree with post not know what hackable mean not define go to use most generous interpretation to mean modify without impact other place well centralize just copy paste into file edit no excuse to completely ban centralization alternatively decompose centralized function more only use piece need definition of hackable almost what miss decentralize make thing much much easy to understand code very straightforward not to take different thing into account not just copy paste file centralize to copy paste multiple main issue go to take while to understand which one to modify import etc unless copy entire repo seriously suggest lmao what safe to modify inside of decompose just go to make thing more complicated for no gain deep learning about detail whenever start break thing apart put detail in different corner how end up with code hard to understand people make mistake not understand what go on maybe should cause of failure break change bug pretty good sign really screw something up syntax interface some other not fundamental bug real bug already spot check test set performance no not new code use battle test core not to review part thoroughly copy paste still to review make sure not copy old version with bug slightly modify break something sound like common many people complain about dozen of bug way code show to correct by get sota result battle test not no one even think of merge in first place yep ve identify place where should not try to fit every idea under single attention class just common sense program not argument against write good share function class argument against share class at same time sure some share code huggingface sometimes not always one massive file name mainpy not more readable than well split program seem like basic common sense to here actual paper on subject important distinction ignore here semantically separate object in one file indeed confuse put everything relate to model in one file simplify thing reduce work memory people require to read code why bert module change recent week with change from dozen of author go back year recent change for bert some inference interfaxe code which to keep common across all model decision not even just make kwargs mandatory imo maybe should check assumption before make fundamental decision know basic engineering plenty of fork library not modify fork for archival purpose nor should cater to small minority most people not everyone in deep learning like to gamble on make some tweak to model hope get next iclr oral why else care about modify model code suggest go read some modeling code from different framework one example fairseq like fairseq think well consider aim constraint crazy think easy to understand modify code for some specific model than in huggingface here link to fairseq roberta need to understand look at dozen file to see what happen in constrast huggingface one file much time on already not go to reply anymore beginner in field wonder what mean for code to centralize dry centralize mean put lot of code in single file dry mean raw code not very easy to read efficient some other advantage look like emotional funded influence here cointerintuitive vote strange statement state fact duplicate code make very very unhackable project one to learn code duplicate system add functionality to for every factorization make hackable example codebase not seem to understand where to draw line at all library look like make entirely without experienced lead software engineer corporation should one huggingface please understand software developer find dry to hackable two term usually go together read like contradiction like fake news try to manipulate people by ignore fact to state other way around remove not just copy paste file centralize to copy paste multiple main issue go to take while to understand which one to modify import etc unless copy entire repo seriously suggest lmao yep apparently themselves claim to for every module thank for point out how crazy prove point definition of hackable almost what miss decentralize make thing much much easy to understand code very straightforward not to take different thing into account oh really think file depend on pytorch function also numpy should copy entire library into file to more hackable lmao dry very basic software engineering principle mean to include only one copy of every sequence of code look like machine learn people not learn not train software engineer dry stand for not repeat yourself not respect get hard slow more more to maintain improve bugfix software large old get bad guy of thread anything say see negatively even correct typical human behavior unfortunately feeling most people here not understand dry well use to confuse inheritance hierarchy incredibly deep function chain essentially conflate dry with bad code simple not argument think by centralized mean what imagine dry look like put code in one place rather than spread out not usually use way reasonable expression though people usually centralize component one organize place to go to in order to access not bad guy guess maybe community of datum worker who never reason to value dry lot of thank not receive training from software engineering perspective which seem to important aspect in machine learn important publish large software package of course lot of hobbyist also learn in field",
  "not sure match requirement look into vq vae which basically vector quantise vae more idea explore in more detail paper also relevant check paper factorize vaes for model audience reaction thank read very appropriate thank how know of paper thank follow deep learning base transcriptomic for while tangential interest of mine vaes popular trend to incorporate domain knowledge two additional paper interest okay thank ask couple of question arise",
  "some interesting comparison find in flan paper checkout paper scaling instruction finetune language model hope help for tianyi zhang faisal ladhak esin durmus percy liang kathleen mckeown tatsunori b hashimoto benchmarke large language model for news summarization arxiv for model see up to date list of model performance paper with code keep good benchmark thank for model see up to date list of model which tab germane to op request specifically refer to performance after finetune far tell nothing here responsive to op query lot here perhaps read quickly",
  "really awesome see progress of work on rwkv to know mention lot of rwkv use trick from here add lot of own tweak of course consider write paper plenty of highly renowned publish work with less to say than rwkv think renew discussion about rnns more than warrant right now give current direction with transformer highly complicated nature of hippos personally not something see replace anytime soon please writeup method of rwkv in arxiv paper standalone readme even blog post format read description on github repository very scattered hard to read fantastic work thank for good luck scale to hope more catch on lack of limited context length game changer run model rwkv pile on cpu main gb ram not on gpu fit in ram size answer below take minute to generate in opinion not bad for core cpu cpu utilization just below question answer gen ask expert question what some good plan to get rich fast expert full answer from live in develop country to millionaire reality long process require lot of planning effort here basic outline of process start out with right mindset need to good mindset in place ability to handle failure accept challenge go to essential handle go through journey of try to rich like go on diet work out for first time negative mindset never go to get past first few step make sure work ethic impeccable make sure work ethic impeccable require many hour of work over long period of time to build up large fortune not expect to get rich overnight just like any successful business take year to get reward explain table highlighting possible to run on latptop use cpu with less than of ram yes how one thank love project after read many paper realize lack of verbosity in formula deeply misguided take picture explain rwkv semantic of j r w function \u03c3 should obvious from first look what version of python use for project not find number anywhere interested in theoretical aspect of how model work say transformer token attend to other token in case of rnns piece of information preserve for later use with cost of reduce memory capacity for other information once information lose lose forever think context length of rnn scale linearly with memory capacity indirectly with number of parameter right crazy thank for share work op how compare to bloom test again lra please thank busy for at moment get paper out later year hope more catch on lack of limited context length game changer cautious about conclude without more testing rnns in some theoretical sense support infinite context more easily than n transformer in practice effective context window often not look much different than reasonable transformer look at performance metric against long sequence state space model etc also competitive with param transformer language model effectively infinite context window train several small rwkv model find on huggingface try fair not know till test for sure any paper refer to for last paragraph expect true love to see some empirical work rwkv exception look at loss against token position comparable with transformer tell from generation result theoretically support infinite context length get problem to solve not fundamental incompatibility like with transformer any of paper address building nlp for long context tend to relevant relate work section eg one qualifier here at modern scale rnn not really well test since people tend to just use transformer maaaybe actually simply superior evidence far say doubtful however at least for more vanilla implementation some work on frustratingly short attention span in neural language model rwkv exception look at loss against token position comparable with transformer link to what refer to miss in op post apology neither really work for super long context kind of moot point both empirically end up with bolt on approach to enhance memory over very long context not really clear priori rnn true advantage here not think relate work section of paper provide any useful reference simply provide doodad people claim help memory without paper show memory not work neither of offer comparative look against transformer although certainly useful look against limitation of basic rnn lstm not clear to what look for here simply provide doodad people claim help memory without paper show memory not work very first reference pull grave specifically compare w w o memory dai et al which try to compare against various rnn style baseline with similar parameter perhaps talk past each other not clear to what look for here question ask pretty clear to justify statement in practice effective context window often not look much different than reasonable transformer look at performance metric against long sequence simply compare rnn with rnn without memory not tell anything about how fast memory fade out never wind up big than transformer for example construct toy problem which require memory reach back exactly state show arch with any memory outperform memory less arch obviously tell nothing of interest like memory make little use of history far back than step none past easily outperform by history stack like transformer nor compare transformer with history of say l rnn transformer win tell anything about why rnn lose okay transformer well great superior new tool why maybe similar memory problem just way well at modeling part memorize well something entirely different likewise unless compare rnn baseline which somehow know hard history constraint not tell anything useful about how fast effective memory fade out how accuracy of memory distribute over effective context window hard cutoff rnn basically only use last few state on in contrast transformer direct shortcut access to history not need any paper to know literally any gpt output exhibit coherent long range reference past few paragraph demonstrate directly show rnn use primarily past step simply fade out completely past step infinite history meaningless in practice well know perfectly well transformer make excellent use of context window large than token two reference show direct comparison otiose directly examine rnn understanding of its history paper much well than some high level performance comparison which what most of reference paper direct performance comparison great not ablate where problem on rnn end although really need one prefer to point at rnn vs transformer scale law in context window anyway like kaplan et al iirc to show transformer make good use of not merely some sort of well than rnn use gain elsewhere let think step by step not think relate work section of paper provide any useful reference own response to question pose no possible way actually read relate work section dismiss give paper cite already cover in same reference dismiss eg sharp nearby fuzzy far away directly discuss in cite transformer xl empirically previous work find lstm language model use context word on average khandelwal et al indicate room for further improvement simply compare rnn with rnn without memory not tell anything about how fast memory fade out never wind up big than transformer never say not sure what argument know perfectly well transformer make excellent use of context window large than token two reference show neither of paper link to assume talk about own comment at make any reference to transformer claim paper indicate rnn small window sure transformer long one argue seem to in entire post again against strawman re read what actually write in practice effective context window often not look much different than reasonable transformer look at performance metric against long sequence statement here empirical one around performance which among other thing why reference dai et al who among other fairly extensive breakdown of empirical performance difference of rnns versus transformer type architecture against long text sequence whole point op say rnn attractive of theoretical infinite context response not really see in practice try to measure directly both of source point out not see evidence of superior long distance behavior test against real worldish data set should theoretically reward both of point encapsulate follow reference share note most reasonable long distance transformer paper with all thing research someone come out with small modification tomorrow invalidate everything above for now represent broad public non private understanding of architecture behavior no possible way actually read relate work section dismiss give paper cite already cover in same reference dismiss tell someone to read relate work section of every one of dozen paper in relate work section of paper ridiculous thing to suggest no not recurse down n deep in breadth first search read relate work of paper say not think relate work section of paper note bunch of memory relate paper which not cite actually relevant research in mind life short to queue up dozen paper just to check rw already know some useful one give someone random reference tell to manually crawl literature not helpful in contrast two reference provide directly bore on question not maybe cite paper which bury something relevant in footnote cite paper which someday answer question never say not sure what argument point out why irrelevant to bring up paper which compare w w o memory mildly interesting such comparison not show what ask about effective memory of rnns of course well to any memory than not which among other thing why reference dai et al who among other fairly extensive breakdown of empirical performance difference of rnns versus transformer type architecture against long text sequence dai in fact useful reference in original comment unless mean vaguely gesture in direction of paper which reference with in rw section alone any of which relevant where relevant benchmarking of dai not highlight in paper to begin with nor relative context work mention in abstract of dai bury at end of paper with rnn result hide inside table just to know already claim reference sure yeah useful reference thank for input claim paper indicate rnn small window sure transformer long one argue seem to in entire post again against strawman not strawman not obvious priori transformer work much well rnn history fade out fast which why to empirically establish history fade out completely oppose to any of other reason rnn underperform maybe history not learn good algorithm exploit memory say poorly optimize many way for nn to break people surprise by how well transformer work completely understandable op expect rnn history to work well than want some hard citeable evidence work badly transformer with apparently brutal hard cutoff wind up much close to infinite context than rnn themselves thus useful to provide reference show not reference to unspecified reference which not show gl pretty astounding just grace to admit wrong move on tell someone to read relate work section of every one of dozen paper in relate work section of paper ridiculous thing to suggest how possibly say not think relate work section of paper provide any useful reference hardcore trolling frequently well than literally push post factually incorrect either know factually incorrect lazy to validate either way type of thing which blow up post quality in sub give someone random reference tell to manually crawl literature not helpful ridiculous traditionally very academic friendly sub how research work here where start literature review on bundle of relate paper extremely classic response which generally consider helpful to complex nuance question underlying issue actually very complex evidence in part by fact reference not actually answer question go read relate work obnoxious single one two paper answer question not case here in contrast two reference provide directly bore on question no not not touch at all upon transformer versus rnn which question ve choose to cherry pick one slice of problem declare victory not strawman not seem to understand what strawman strawman intentionally misrepresent proposition set up easy to defeat than opponent real argument not make argument make argument qed strawman",
  "for what seem like low hanging fruit rather surprising not more research attention to fact bilingual llm absolutely blow state of art translation system out of water guess just want more people realize more large scale multilingual model make cool compute chrf bleu comet score on translation include text output instead of png in repo interesting comparison what find really interesting llm not explicitly train on chinese english translation pair just unstructured pile of chinese english text somehow learn actual meaning behind word how to map from one language to other look at history of machine translation really see clear progression towards bake less human knowledge into system each step result in massive improvement in early system like meteo use hand code rule parser later system like google translate use supervised learning on human provide translation pair today llm no need for any of just chew through mountain of text one word at time in theory self supervise training create translation system well than human translation supervise learning on translation pair never only mimic what human translator chatgpt generalize incredibly well human still good chatgpt narrow second likely well than most non professional translator try translate classical chinese no one care bro not help for paper self marketing job what mean by state of art translation system pretty sure every decent translation system use llm currently just some llm well than google translate not mean google not make well translate free service not make sense to run model for much small model get job general meaning present in all translation get job unless someone plan to offer model free service no news here expect recent research model beat publicly available service account for different regional dialect slang not read in detail github not time at moment just curious maybe misunderstand post thank cool compute chrf bleu comet score on translation no definitely interested in just not personally any benchmark before include text output instead of png in repo sure what find really interesting llm not explicitly train on chinese english translation pair just unstructured pile of chinese english text somehow learn actual meaning behind word how to map from one language to other to expect tbh most model use embedding during input output for model to learn two language need to either produce similar embedding to similar word in both language produce two completely non overlap group of embedding give embedding initialise randomly model not know about which word belong to which language second outcome very unlikely not also require much more datum though what find really interesting llm not explicitly train on chinese english translation pair just unstructured pile of chinese english text somehow learn actual meaning behind word how to map from one language to other one explanation embed space roughly isomorphic across language true should seriously weaken sapir whorf hypothesis shock how close chatgpt come especially compare to bad glm result more evidence get nowhere near gpt laughable deepl google translate one mildly surprised nll underperform scale really all need huh profession of translator soon shift into curator translation generate entirely from llm review by translator bloom sized model design for multilingual maybe get all way like to see compare to bing chat which even well than chatgpt say native support for language should pretty good some of human translation less readable than glm translation not know chinese not judge accuracy turn out not need model for what mean by state of art translation system system score good on translation benchmark currently like nllb pretty sure every decent translation system use llm currently no not translate free service not make sense to run model for much small model get job general meaning present in all translation get job not really make any statement about what not make sense know model not feasible for translation task alone especially for close language disagree on point though traditional machine translation system for hard language pair devolve into gibberish very quickly here get pretty bad at time certainly not use in any professional capacity point make pretty big gap in quality between bilingual llm traditional translation system not really matter of research vs free which why nllb also include not know any chinese english slang present in above screenshot enough to make one eye bleed yes see yes each step up ladder involve order of magnitude more datum compute far easy to gather large dataset of unstructured text than of pair translation one thing make realize translation hard most of human translation from officially publish translation of chinese classic hard even for people no wonder google deepl etc devolve into gibberish often no not literally say in paper use transformer for most perhaps confuse llm generative model still pretty cool neat to universal large language model without doubt eventually exist how much more datum need how much more time processing power take afaik significannot large language model use modify transformer architecture yes nllb not llm just use version of transformer training regime different type of datum train on different objective function different even detail of architecture implementation of both different though very similar all in all really not accurate to call nllb llm very restrictive definition of llm follow nlp since first time hear describe like restriction on training regime objective function make very little sense give differ greatly between paper nllb l arge param model l anguage m odel here top three google result for llm of say anything about training regime type of datum objective function for model to llm should use text input produce text output need to large some people even say only input output to text for to classify llm wow not true at all any model factorize language distribution language model with without transformer all large model modify transformer btw right after viswani paper come out every model use variant of transformer rather than vanilla implementation need to go back to basic understand problem transformer try to solve how relate to original task of autoregressive generation rather than get lose in tree think something not language model of slight tweak in implementation data augmentation suggest read bengio neural probabilistic language model arguably llm special connotation now with introduction popularity of gpt its peer think argue semantic at point point ability to translate not arise in same way rizhiy ignore some important difference here llm large language model model language x usually by factorise px in autoregressive way also interpret predict next word self supervise objective translation model translate sentence from one language x to another language y model py x different for few reason cover main two first supervised problem need to sentence in both language simultaneously such dataset exist not abundantly available just text in one language second in translation system not generate any word of x for reason translation architecture like vaswani encoder which consume input sequence in parallel without any temporal masking different from gpt style llm which also refer to decoder only transformer",
  "which exactly purpose of bot publish paper base on datum scrape from paper albeit from conference not journal long not publicly release full text of pdf extract something from paper themselves should fine think publisher lenient long use datum for academic purpose not monetize in some way",
  "ml acronym get out of hand just use any letter from any of word guess well than adamw model transformer b not lot of augmentation use otherwise improvement not large doubt optimizer work well with regular cnns like efficientnet convnext though reproducibility survey recently find many optimizer claim well performance not in fact work for anything other than task test in paper essentially hyperparameter tune just hyperparameter optimizer design itself just skim paper confusing result see simple optimizer pay off use similar amount of compute due to able to run more iteration claim also well on per iteration basis across entire learning task not lot go on in algorithm where magic come from kind of hard to believe while people experiment with all more complex optimizer no one try something simple see state of art result more memory efficient than adam only keep track of momentum while technically true joke wait for deberta glue superglue result weird pick for exponentialcookie in code implementation link lucidrain write about reproducibility issue tune both issue bring up in comment learn optimizer people seriously believe direction should go technically binary optimizer update weight to either multiply by lr should test with learn rate dropout chance to update with otherwise no update really think need intermediate between conference paper arxiv to just evaluate how reproducible sane paper without evaluate whether important not at stage genuinely not tell press release report in paper form actual paper name eve come after adam into story in limited testing on unet like cnn not even come close to performance of adam sadly with say something wrong just hyperparameter optimizer design itself probably one of good thing read today lol remind of old colleague of mine list of different pytorch optimizer just loop through care to elaborate ever hear of large model hand design optimizer by definition learn optimizer researcher rather learn optimizer than hand design one learn optimizer probably future compute budget require to create one prohibitive think learn optimizer potential disappointing nothing revolutionary in therethere already sign base optimizer just slightly different take see learn optimizer possibility of get unintuitive result just throw together by some grad student random not surprising evolved sign momentum eve wait much well one already in use p cool name think in different direction than majority of memory use during training not from model weight optimizer state in most case come from track all activation of training batch think about cnn each filter get use across whole image many more activation than filter optimizer memory saving very limited benefit way less for every vector of activation usually square in weight time depend of how many momentum value keep not true in any case with convolution attention recurrence which most modern application in all of case activation count grow with how often weight reuse well with batch size dominate optimizer memory usage unless use tiny batch size why checkpointing useful paper solid job cover memory yea depend even just batch size make difference for really big model assume number of weight far outweigh number of activation yeah very configuration dependent large batch size usually learn fast tendency to lean into",
  "in early stage of make personalize gpt chatbot answer question for call infinite ask anything far its knowledge base just manually type out question answer pair build cron job in modal periodically fetch internet comment blog post to keep up to date m quietly hopeful get quite far with just openai api langchain answer question like with reasonable accuracy happy what thundergolfer thought about monorepo vs polyrepo debate comment about before",
  "feel like voila pretty hard to beat especially consider already ship with jupyter just change word tree in url to voila notebook webapp very intrigue by way for to get email update look super cool right use voila for last three year quite mature project never any issue project actively maintain of course tonne of thing still possible to add feature true voila hard to beat m work on mercury cloud just upload notebook to cloud to make available web app help many user to deploy notebook app also provide commercial support for mercury for pro user pain point for voila sure at bottom of website subscribe for newsletter thank work on cloud service to make easy to deploy notebook app all know voila work with panel panel work with basically everything ipywidget bokeh plotly not sure about streamlit gradio",
  "",
  "update model with new datum at any time production model often update at interval with monitoring few challenge to update continuously distribute model to update how update weight from two source option for not look potential for undesirable unstable prediction generation think to allow weight to update pretty dramatically at each inference to get any real variation think lead to attention component probably what look for more accurately efficiently another key phrase to use with google scholar online learn where stream of new example update model one example at time usually use model for inference at any point in process some algorithm in area design to bit more aggressive at least to control update rate to more quickly more more slowly adapt to new data reinforcement learning wonder any serious attempt in work to create ai able to transform itself dynamically m not sure what call serious attempt program neural network try to for specific task try to summarize basically model image model image embed self supervise sound model sound embed model sound autoencoder image embed model sound embed association between embedding base on temporal proximity launch program all model train infer simultaneously input video multiple image sound livestream read multiple image train on image not need label same thing for sound while train produce embedding train on embedding global model able to associate image sound without supervision model train infer simultaneously improve themselves continously point camera towards object say name of object after perhaps model learn association repeat name of object just from image for inference path image image embed sound embed sound while model train simultaneously path train infer simultaneously model not explicitly need label supervision though need temporal association between name of object image of object which probably what also first use to learn word also say simultaneously in code just while loop with two model backprop infer not exactly at same time still two separate process same while loop though train while infer consider just one big model reproduce brain regard how neuron work no not reproduce what describe regard how neuron work sentient depend on what think sentience probably not base on what usually call sentience what most model now much more efficient practical reliable than what describe though not exactly reproduce how learn thing probably not what most people want in model prefer more efficient pratical reliable model model train continously much hard to check continue to good result think what look for ml field call continual learning where agent put into practice learn in real world how to improve act in from understanding afaik its one of more experimental one imho in context learning for more literature depend on where in ml spectrum in rl common to set agent to set some fraction of time explore some other exploit environment in neural net whole online learning field address just generally possible not always practical other way to update information mention chatgpt one way give access to browse to provide update result technically one retrain on conversation believe practically make more sense make in batch e g once week lot of new datum accumulate yeah google bing lol online learning find lot of paper yes call online learn some modeling algorithm naive baye local model like k near neighbor kernel regression update immediately in some sense use for recall training very close in time not deep in maybe hierarchical temporal memory by numenta ist interesting for yes lot of people kind of thing use very different approach field of lifelong machine learning just one relevant area not popular to online learning for variety of reason cabsauce give nice list one reason want to add many model expose to relatively uncontrolled input backfire badly google microsoft tay twitter for cautionary tale garbage in garbage out let model learn in uncontrolled environment risk inputte lot of garbage sometimes even malicious adversarial datum make matter bad since garbage affect model in real time actively get bad prediction just get make publish use in production setting in most case upside to continuous learning small compare to batch release make lot of stuff hard more risky check out liquid neural mean other than real time inference which implement use edge device way should mother model to train once use edge for real time inference meanwhile use continuous learning method for retrain main model use standard backprop wonder how design loss imagine in chat set try to optimise for engagement how measure in real time base on someone response not necessarily need to update weight possible to instead read write to external memory which attend to generate future response dood iit not smart to train on its wonky trashy result know give some thought actually instead of crap sentience fantasy not very necessary llm brain static itself connection make between neuron very much dynamic why in context learning possible llm already mimic meta learning fine tuning few shot take look at hebbian adaptive resonance model no backprop no distinct training inference phase distribute model to update how update weight from two source option for not look sound like federate learning distribute model to update how update weight from two source option for not look strike more of software hardware engineering challenge rather than one of network training architecture definitely challenge though potential for undesirable unstable prediction generation think same true for human give enough perverse input all go crazy definitely something to think about mitigate definitely need to component build to work against force think to allow weight to update pretty dramatically at each inference to get any real variation think lead to interesting point time between act of inference in ml model on order of clock millisecond for realtime perception system second to minute for thing like chatgpt whereas animal experience essentially continuous input eye alone present with many mbps of datum without vast swathe of datum constantly feed in alternative to make big change base on limited data attention component probably what look for more accurately efficiently attention cross mind post agree its intention to accomplish kind of weight redistribution base on previous input still think more superficial ephemeral than what ask about human certainly attention mechanism in brain attention mechanism subject to same kind of change over time rest online learning very common term use in time series model for example in anomaly change point detection what most model now much more efficient practical reliable than what describe though not exactly reproduce how learn thing probably not what most people want in model prefer more efficient pratical reliable model yeah guess distinction here whether one use ml model means to end end in itself imagine researcher interested in agi much more likely to take kind of approach than someone try to sell ml model to industry anyone care to discuss why downvote thank seem to term look for cl also just mean retrain frequently what crawl up ass die really take bit seriously think ve write through various leap of logic faith really think no value in overall conversation just trigger many other people actually answer question response seem completely asinine agree interested in agi probably quite hard to build business plan around model not fund to build",
  "yes of course its trivial to predict noise at t identity function very hard at t why weighting of loss term for different t one of crucial design choice big reason for breakthrough even though model itself around since",
  "",
  "hear good thing from colleague turnaround fast review helpful personally rank tmlr paper somewhere in tier give people behind all well know in community lack prestige of tier conference jmlr assume whatever get publish not good important enough for neurip icml iclr author in hurry generally solid high quality probably well than tier conference tier thing seem to consensus although for life of not understand why bet same people review for neurip what author late for icml submission way early for neurip submission d tmlr still bit new still early to judge people cautious everyone know neurip publish important paper everyone bibliography full of neurip paper still unclear tmlr paper become important bit of chicken egg right agree with in same community same reviewer with add bonus not under need to review paper all due tomorrow crunch more time to thoughtful",
  "unless strict business requirement strongly recommend switch to pytorch especially for any sort of research start off with tf feel like bash head against desk every day not many alternative thankfully pytorch not far behind once switch never look back come to light to py torch give up on tensorflow experiment repeatibly deadlocke on multi gpu setup open multiyear old github issue describe problem possible workaround where part of apis long remove rewrote stuff in jax never look back not happy about hold out for long time tensorflow power user just switch to pytorch still like tf in prod for implement train network pytorch far superior just swap to pytorch learn tf able to grasp pytorch idk feel like implement network in either project quite difficult always wade through error own code wonder where silent error help tremendously to acknowledge tensorflow feel much more like functional programming than other deep learning library not want to not adapt for yourself plenty of alternative okay sometimes not choose from business side admit not use tensorflow since make feel dumb think unnecessarily difficult switch to pytorch everything just magically easy pythonic just work wish disagree tf first step into dl hate move away from much learn dl tf from francois chollet book one step into torch to take tf make some thing easy though guess trouble worth into for torch plus other framework like lightning fastai build on top of torch make much more usable love rant feel same way why use pytorch moment see terrible debug message go out fast than twitter fake account during twitter blue why use battle problem where tensorflow let train model with particular architecture not let save model out in any format why not consistency at architecture definition time to tell something wrong ugh welcome to tensorflow pytorch likely easy kera live nightmare for anything other than demo like case worth switch by far remember day back on pytorch sigh with relief not tensorflow take maybe month two for to stop happen how poor tensorflow to work with no discredit to people value make however think just lol always some issue with array shape never figure out why till delete like half model layer pytorch should able to retool to pytorch advantage most state of art model now write in pytorch usual solution to start use pytorch anyone try convert pytorch model to scripttorch to use with c wonder make any performance boost realize for model huggingface time series transformer of training time waste by poorly perform python dataloader after rewrite dataset preparation in c like to optimize other try eager execution mode particularly for function tfdata check option like let switch from graph execution to pythonic behavior intend for debug many comment recommend pytorch not agree lot of company prefer tf kera pretty straighforward though really awful lot of personal research stuff not professionally full time hobby need all to very very customisable most time use tf work fine should switch hm another commenter mention highly promote functional programming train oop user maybe why suffer more also oop background before dl way dip toe in tf year ago realize go to hassle discover pytorch shortly afterword use exclusively since about year now no issue not own misunderstanding also use on windows linux arm system without problem come to excruciating agony jax only support much clean imo twhen lose in darkness look for light not run on arm processor jax all fun game until someone forget to write down version number any recommend jax tutorial at least put breakpoint in pytorch at least print message work at actual pass chatgpt incredible source for ask how to thing in pytorch well perhaps make with researcher give dataset extra care yeah s why prefer to pytorch especially keras functional api although choose freely probably go for elegy jax anyhow suspect tf jax converge in future already see with numpy api for tf elaborate more about analogy with functional programing for not cs background thank for lead sometimes feel like fast at least more satisfied stuff more from scratch attempt probably stop real fast haha sink cost fallacy mostly say something along line of subclasse model not serializable keras live nightmare for anything other than demo like case give concrete example yeah thank aware of eager execution current source of distress stuff like map fn currently unroll into for loop for find error okay tf admittedly edge come to deployment which probably why prefer by some company in industry come to everything else training api datum loader custom op etc pytorch far well greenfield project really not recommend tf to anyone tf support other sometimes well language its what use yeah lot of tf hate kera layer seem about equivalent to pytorch to only thing really gripe vs compatibility also not huge fan of to use gradient tape agree kera sometimes drive nuts try to non standard stuff in training loop sometimes to hack weird stuff to make fit into callback framework of course write own custom training loop to take care of parallelization yourself not fun long tool work for usually fine never try pytorch really suggest try pleasantly surprised not really not believe in oop tbh problem generally debug code by insert print statement to see what happen at time very difficult to with tf since graph get compile first not really peer inside during execution not issue not forsake training pytorch get very weird in some of very much more low level specific other than very good definitely moreso than any of other framework use like step on lego interesting curious to check out although pretty invest in pytorch really painful what relative upside of jax big advantage of pytorch ime ease of interactive execution much easy to develop debug model step by step on datum tf improve in aspect last check year ago not trivial to execute statement individually convert to onnx other format of course spend year work with machine learning on arm device official one quite good yeah awhile since implement bunch of different network remember correctly major issue never actually model little thing like make sure transformation on input not cause inf inf value happen in audio preprocessing sometimes which cause nan loss to also turn on torch anomaly detection which raise error during batch training for all silent warning allow to catch datum weirdness without to pass datum manually through model in awkward forward pass tend to give some good explanation answer about network give correct answer regard very niche topic such linear gammachirp filter in audio processing how compare to logarithmic gammachirp think function of just hope model train on literature cover question talk out neck much more well verse in cnn classification problem than advanced tokenization tensorflow emphasize much more composability aspect of function call to construct datum ml pipeline tensorflow also model in construction of static graph which really nothing more than large composition of function where typically not exclusively consider tensor input output of each function concept go beyond for example look at how describe entire datum loader in tensorflow back to back execution of transformation how entire training loop represent function composition core feature of functional programming pure function without side effect internal state way tensorflow design force programmer to write such pure function suck use to work with tf keras well nlp pytorch for hobby still feel know pytorch much well meta seem to digest kiss principle well than other company since know fallacy stop guess mean stray away from stack prebuilt layer in feedforward manner at point nice keras abstraction break what greenfield mean how transferable only use pytorch for project use already work on play with github repos use not see big enough difference to re write thousand of line of code what main difference eager execution now horrible way to debug though something all guilty of not believe in oop like reject notion of oop mix between sideshow bob stepping on rake once get more comfortable write own decorator framework design make lot of sense here overview tldr not experience with functional programming than very painful crazy fast though design something in way work nicely with jax generate gpu code very efficient ability to write quite complicated control flow for single batch element just vmap function to make batch xla work out how to actually vectorize properly behind scene very nice use jax more for numerical simulation than model training speed lot of other cool thing speed universal in understanding never possible in same way since tf comile graph yes one of feature like lot about pytorch still not work on arm sure about to also turn on torch anomaly detection which raise error during batch training for all silent warning allow to catch datum weirdness without to pass datum manually through model in awkward forward pass not op thank for tip just what need maybe where make mistake with make functor to cheat way through tf enforce paradigm which cool until not same about jax work with on non trivial project try to simple become at least surprising confusing its brother at least for stupid people like btw know helpful resource to learn well must use jax well people pay for progress of project indeed correct believe think natural pytorch very much easy enough not many more line very flexible though avoid nnsequential possible also not everyone in discipline guy though maybe not low accuracy assumption base upon average makeup of field d no not kera more flexible than customize lot of thing mean from scratch no legacy requirement to use tf not use tf since not really answer use eager execution yes difference not big use with placeholder stuff difference huge hear still sub par also seem pytorch share keep increase must some other drawback post one of with pytorch never experience of restrict by some rough edge everything need currently what say well way try use breakpoint before not like raw python breakpoint no go even with ide use pycharm feel take long than just print what want straight in code also hidden make sure code snappy since not like waste time wait for code to reach part where break probably mean get past stage many newgrad devs go through who think oop should use all time everywhere few video which explain problem with oop think one part stand out to composition over inheritance try to keep inheritance to minimum usually three layer few really make code easy to debug try to keep state small possible much easy to reason about what happen in piece of code know no outside effect class should way to group function not place where just place function self contain just leave at top level learn java in uni hate all function to method why need to create class just to something simple whole oop design pattern seem like useless restriction only one find useful singleton factory plainly find language with first class function much more appealing work in some other reason which not recall now object class just one of tool available to should not try to base whole program around understand some application where oop fit well frequently due to performance constraint not come up in work until want to something simple run jnpdot on cpu refuse to parallelize over core become massive bottleneck gpu tpu code generation great cpu code generation total afterthought with some glare oversight dev train on some gpu onnx one way to run on linux base arm more than one way to execute pytorch network with train weight on arm what issue with arm here maybe misunderstand use case absolutely run pytorch onnx on arm just slow down model ton just debug d cheer of course bad habit assume gender fit naturally in sentence oh no no ofc to run model on edge development board with arm microcontroller nicla sense thus believe to go with tensorflow lite micro really appreciate any example guide where with pytorch really appreciate any example show how to run one arduino device with arm microcontroller oh no worry at all thank for kindness maybe occurrence effect where notice something happen more more think about notice people use casually singular term for people whose pronoun not know yet something like lot just sort feel right no matter how one slice dice anywho cheer hope fantastic day dddd nicla sense execute onnx on cortex m without linux runtime require extra tinkering possible tool compile onnx container into executable c code most hardware manufacturer name provide translation tool themselves extremely hardware dependent ever look at arm nn like try google onnx cortex m find thing which arduino model use happy to point in right direction pytorch onnx runtime precompile wheel distribution deploy on arm cpus want need to compile from source both binding for python c not access to python on device should still able to use hi board nicla sense",
  "",
  "unless miss paper mention fact degradation mapping should estimate not detail cite paper kernelgan kernelnet doubledip metakernelgan sr include deblurre arxiv link thank very much for comment very valuable important note for subject community super important aspect of image sr refer to topic under unsupervised sr section not space to go into more detail which not mean not deserve attention reference another survey by liu et al blind image survey beyond from to fill gap also mention kernelgan relate method which find informative source for blind sr in general not exactly both formulate inverse problem in image process super resolution investigate case where information lose due to downscale whereas deblurre focus on blurry input by low pass filter however similar property deep learning base method apply to both in survey not go deeply into deblurring topic why open access also find article on arxiv paper smell well",
  "install realtabformer find relevant code at all code implementation here opt out from receive code link dm thank for paper actually use",
  "not even sota on imagenet where read up on linear probe not explain in paper not cite interesting thank for sharing give read look forward to follow up paper on different downstream task number of weight in network between layer just start with learn ml someone what mean to billion parameter input to nn large chunk of image net dataset label wrongly close to to fair sota model on imagenet like convnext basically overfit to test set by perform ablation directly on imagenet not exactly scientific rigor no wonder get sota way whereas something like not to such degree with gigantic transformer model probably take much compute linear probe just refer to fit linear model on extract feature number of connection between neuron actual computation happen in weight connection more of more complexity model agree also think whole image classification evaluation pretraining not good setting for scale visual model what to scale model already above human accuracy captionning more interesting pretext task like mask denoising more potential well in opinion which feature final feature before last fully connected layer classifier just standard transfer learning in which replace last fully connect layer keep all previous weight fix ohh get thank think great point think long pass point of imagenet good indicator for progress in general purpose computer vision architecture some paper suggest linear probe actually well with late intermediate layer rather than literally final layer use in unsupervised training for example simclr use two layer mlp at end of its unsupervised training discard linear probe with pretraine model likewise mask autoencoder lightweight transformer only use for unsupervised pre training not for fine tuning linear probe in general right idea fwiw believe term originally come from paper yes to both fairly sure",
  "try google flan xxl via hf here most comprehensive list of llm to date way try small flan model use hf model not fast enough accord to experiment other idea on optimize to low latency thank test",
  "",
  "not knowledgeable in field still learn read paper think tool former align close to what ask about two most recent one probably retrieval augmented black box language yeah say toolformer sort of learnable retrieval model take pretty different approach though by make model generate request text not vector interesting look like both also make embed of document in database learnable by make embed model learnable periodically update database",
  "oversample in deep reinforcement learning call prioritized experience literally call importance sample in sgd literature normally to downweigh important sample to counter fact sample more often whether practice actually accelerate convergence important question in sgd until very recently check paper small batch size feeling probably want very small dropout rate on important item only to decrease chance network overfit to maybe batch exclude important item rest include perhaps not matter seem somewhat similar to hard example mining except already know which one hard here technique similar to data augmentation with specific focus on important sample not specific name for technique consider form of strategic oversampling strategic repetition of important sample by repeat important sample in every batch increase impact on training process potentially help neural network to converge to well solution take sample into account r r worth note technique not always appropriate necessary potentially lead to overfitte not use carefully however in case where small number of important sample disproportionate impact on end application repeat in every batch useful approach to ensure neural network learn to incorporate information effectively p",
  "",
  "lot more entertained like many sigbovik pnis paper use actual datum extra commitment what make bit on tardiness of coworker ther result find in supplementary ma r terial on github in private repository only ir access due to university valorisation policy r dijkstra say important to keep humor fun alive in computer science anyways good job thank hilarious read refreshing approach to academia must follow tldr know what think real paper should little more like one use word loose instead of lose in second to last paragraph on first page quit reading at hate grammar mistake well hey ever inclined accept submission even latex template need link great hobby impatiently await for book to get publish speak of dijkstra though make santa clause path optimization paper cause christmas eve like ultimate travel salesman problem aslo loose interist eye sea",
  "here paper in different category such prompt engineering technique text to image generation text music sound generation text video generation etc tool code to build different gpt base application open source pay apis dataset prompt base model tutorial from beginner to advanced level video prompt engineering community group for discussion resource hope help to get start learn more about prompt engineering prompt engineering launch free open source prompt engineering course soon join discord for prompt engineering llm other late research discussion generally dislike awesome repos since not particularly well curate maintainer should strict about whatever threshold must pass for inclusion some high level opinionate description state current state of art for x y with citation to relevant paper usually more helpful",
  "for downvote ed post yes long suck podcast brown actually say one thing which really ed important search in sensible way improve model brown mention need to scale up model for diverse game relate problem time in order to make work without monte carlo tree search obvious direction how precisely to not completely obvious clearly necessary direction think in direction even though time thing not something know about just natural brown remark show magnitude of potential reward",
  "sick similar shellgpt still want to shell where run command llm continually listen ask command in line something like grep e log file ask llm output look weird ask how get context of thing already try tell dummy forgot to set proper permission envision future where such assistant insight to full operating system include code compile from all log instal package dotfile ask assistant system thing about state in natural language",
  "",
  "much appreciate",
  "go to try out",
  "able to access file under maybe try vpn maybe find on thank try use change ip to phillipine still not access tell how heavy dataset well not access from india thank try",
  "",
  "what inspiration for self supervised learning clear signal input datum many dimension need to reduce dimensionality try predibotcom no code solution for tabular datum how about its not case of dimensionality reduction label percentage go to drop heavily in next few month need to move from fully supervised to self supervised training",
  "",
  "try start with probably need to expose game state action via ipc of some sort ffi rust code to python thank for recommendation",
  "paper link not describe youtube algorithm youtube selection algorithm proprietary not reveal to public just link paper from researcher at google study topic of video recommendation extent to which describe youtube actual algorithm not at all obvious some researcher at tiktok parent company release paper on recommender system call monolith m not sure its actually what tiktok use say monolith successfully land in byteplus recommend product also interested look into some material of potential interest official tiktok blog post describe with very limited detail how how tiktok recommend video foryou empirical investigation of personalization factor on tiktok sock puppet methodology to identify parameter strength in influence algo analysis on douyin tiktok mania phenomenon base on recommendation algorithm trick please mixed method study on user assumption about tiktok algorithm leverage right of data subject for social medium study tiktok via data donation of interest wsj video on try to reverse engineer algorithm not technical though how tiktok algorithm figure out deep desire blog come across not reliable why tiktok make its user obsessive ai algorithm get hook app know well than know analysis of tiktok algorithm typically large company not use single model rather large number of different model all perform different task recommend filter etc very difficult to describe complete recommendation pipeline ie from user request to final candidate in single academic paper feature paper also reference old neural network architecture use in late stage of recsys stack whatever read outdate not reveal what actually use rumor to good recommendation system thank much appreciate claim any system approximately reverse engineer one access to result of system hide from public what good subjective at least read last week any moderate fitness relate interest bring quite unhealthy content very quickly to well than amazon system anyway",
  "depend on datum volume of input space assign to cluster vary wildly from cluster to cluster hard to come up with distance threshold work for all of insist on use k mean here two way to handle one way to take ratio between distance between close centroid second close centroid define threshold on another way for each cluster determine distance from cluster center contain say of data point assign to cluster preferred method to use probabilistic model for use em algorithm to fit gaussian mixture model to datum k mean kind of special case of em algorithm anyways distribution allow to assign probability density to every datum point find optimal cluster centroid either use silhouette coefficient elbow method agree silhouette coefficient also use to spot anomaly sample with negative silhouette likely to badly cluster",
  "by lucidrain in progress guy get first every tool except jira of course nothing sentient figure out interesting learn which api to use from description of api to allow to generalise to new one wonder ultimate path to reach general intelligence after all human evolve by learn to master tool now what tool llm use training api for itself idea plan to play around with more free time good to see some evidence promising direction speculate actually get lot out of clever with tool for long term memory by lookup table with text embedding key tool for vision make with image captioning model maybe some segmentation to get rich text description of image many more thing come up with think work well find some clever way of turn into text next step must create program tool incorporate on fly imagine ai write another ai keep in mind current theory in neuroscience broadly agree something similar go on with mammalian even reptilian brain hell maybe even worm brain autonomous system everywhere call each other for update in some certain brain enough complexity something call thinking occur practically offloading calculation to python repl machine translation to gtranslate api call knowledge search to wikipedia corpus go to let llm what well mask user intent generate believable enough corpus let fact stay factual hallucination stay hallucination obvious idea to connect gpt to browser api let go learn treat output of transformer inner monolog only perform real output call action something action speak proactively hide inner thought just like human agi get close everyday surprised not before paper mostly cite work from last year surely something similar previously maybe not use same kind of model in fact not pretty close to what search engine to provide instant result give equation address for instance anyone know of such work also checkout its multi modal model visit any input link download web page image analyze with nn to make well text also speech to text text to speech talk many say lot of thing likely hopefully come together into something big need few thing like to train new tool model zoo thing internally text generator base on multiple model some internal decision making for which model good on every request not need to pick code text model automatically which similar not train new net bs paper simply call apis gptchat no bueno yann lecunn from cognitive point of view human animal module rely on for certain task for human neuropsych assessment combination of function of module give score for general intelligence with each module contribute toward whole removed change module for one reason another sometimes cause localize task failure neurodegenerative disease brain injury approach to task atypical atypical brain development maybe think of specific cognitive function api call to module in tool use paradigm likely not original thought anyone reference hear of idea please let know far understand many of lucidrain repos not contain need ai model in case toolformer ai model not publicly available schmidhuber actually already in hold on jurasstic here from april believe with something fairly similar not learn for new tool think work well for calculation wiki search haha good laugh thank for allow to generalise to generate new one ftfy how get skynet say gain general intelligence by create different model for different task gain experience on to call which to call which not creation of new model definitely wonder about exact thing especially talk to chatgpt respond with insert x here why not just take out replace with appropriate api call learn to master tool though see more neuro symbolic system correct term happen lot in production long think next stepping stone in path path to agi next big step imo dynamic online model augmentation to enable learn new concept both of combine seem like basic approximation of what go on in brain delete in way yes think general intelligence consciousness in most animal develop evolutionarily to manage wide variety of sensory input task to bridge gap between develop more individual area of ai naturally start to combine to create more powerful program such toolformer combine strength of llm other model once connection between capability should easy to develop new model learn connection more deeply more thing some of thing set apart from other animal incredible language reasoning capability which allow to understand interact with increasingly complex world augment capability with tool perceive understanding llm display use only pattern in text insane combine with pace of development in chain of thought reasoning use of tool other area handle visual sound motion multimodal ai path to agi become clear than vision of mrbeast cataract patient intelligence physical trait evolve in human through random mutation eventually allow human to use tool some reinforcement learning like algorithm seem like really interesting next step here observation task like qa mask fill action api call where output update observation via concatenation in paper environment apis database python installation etc state network weight reward loss function before after update to observation feel like even only api just generate text use itself to update observation to help itself think intuitively seem like help for some thing rather than try to fill in mask right away recognize well to first think little to update its working memory which of course observation here rather basic sense at least vision well audio pretraine well know from multimodal chain of thought well scale law for generative mixed modal language model multimodal model far outperform single modal model on same datum scale not get kind of performance gain leverage basic sense to outside tool technically always true why think step in direction read paper serious question interesting progress come in multitude of mysterious way get radically improve performance across several important task of call apis plus call apis very important for integration into real system trigger real world action imagine siri call bunch of different apis base on complex instruction give not just call apis model independently teach itself how to use new apis to use process pretty much same for any api not require much extra effort by programmer to add new one paper also state one of first to model learn to use apis in unsupervised way mean teach themselves instead of rely on ton of human annotated datum which part disagree with here unwavering opinion on current auto regressive llm useful write aid reactive not plan nor reason make stuff up retrieve stuff approximately mitigate not fix by human feedback well system come author publish paper on research experiment finding etc not always release code for model study lucidrain repos implement model create open source implementation for research next step to train model which require lot more than just code most notably money assume refer to train weight say need ai model training require huge amount of time money for team never mind single person to train even one of model let alone whole portfolio of for reason not very reasonable to expect lucidrain any other person to train model open source implementation great contribution on own still think belacscole right analogical to rudimentary use of tool which by some high primate small handful of other animal tool use require sufficient degree of critical thinking to recognise problem exist select appropriate tool for solve with recursive feedback lead to increasingly skilful tool selection use over time result in well detection solution of problem over time of course problem not possibly solve with tool available no matter how refine usage problem never overcome way human face sort of technocultural chokepoint repeatedly throughout history problem require development of new tool next step in further process abstraction which take intelligence from critical thinking to creative thinking tool capable ai train on dataset link diverse problem with model solve problem process develop model such attempt to create implement new tool to solve novel problem assess its own success likely via supervised learn at least at first able to equip with tool for make tool such solve set of all ai solvable problem give enough time resource apis for auto ml already simply learn task to use other ai to create model its over call mixture of basically what talk about in video find chatgpt wolframalpha integration where language model know to call out to external apis to answer question such precise mathematic try out here by paste own api not actually impossible ai able to use apis big step towards able to interact with real world effectively specifically digital world imagine chatgpt able to now thing for in digital world like go online shop for trade stock etc not want to guy all leave doe eye ml mysticism to more ray kurzweil theme subreddit interesting though from october still very recent guess use transformer for recent approach curious about previous approach which paper not talk about extend to create synthetic training datum with set of know apis big step forward to index external information whole assess its own success bottleneck for most interesting problem not feedback loop unless accurately evaluate well bad not trivial problem either since human not all great at use absolute metric to describe quality once past minimum threshold plenty of example of tool use in nature not require intelligence for instance ant tool use demonstrate by toolformer purely statistical in nature no need for intelligence impossible assume not impossible otherwise not intelligent in first place tell opinion know what definition of agi xd not almost certainly possible due to universal approximation theorem assume consciousness function of external variable large enough network with access to variable should able to approximate consciousness thank agree useful not see how relate to agi additionally already long time ago many ai agent use internet before feel real challenge to control language model use structured datum perform plan etc not to use language model to interact with world which seem trivial to sorry of course just opinion which probably not even smart yes please keep sort of stuff in r futurology something here try to formalize n step need to even get to something vaguely resemble agi people use thing like evolutionary fitness change environment to describe quality seem dynamic environment answer purely statistical not llm statistical model after all hear of searle chinese room some people sorry not give reference off top of head argue something special about biological nervous system material substrate not irrelevant sure reverse engineer whole biological system probably take much long no worry think definitely valid take always feel not smart talk about ai stuff lol feel real challenge to control language model use structured datum perform plan etc think promise of tool equip llm tool able to serve sort of purpose well like calculator run wikipedia query imagine llm use database module long term memory to keep list of instrumental goal etc even give access to module let fine tune itself create successor llm in some manner all very speculative of course not to use language model to interact with world which seem trivial to sorry good argument here true intelligent require embed agent agent interact with at least world to learn obviously no one actually know what make agi work anything not unique fringe view op suggest even know what resemble agi exactly how to tell how calculate fitness same problem of model not able to assess its own success somewhat no generally define agi intelligence which in current paradigm set of algorithm decision making inference capability in broad set of area able to improve its understanding of which not know think of like school subject not expert in all of math science history language economic some notion of how to basic work in all of area extremely vague not universally agree upon for example some say should exceed peak human capability in all task",
  "to understanding use noise generate different image use same algorithm just by change noise blank canvas only initial starting position blank only output image paper also other transformation its lot easy to create variety of shape way instead of stick with predetermine shape think more to with probability sum of all random variable approach gaussian distribution prove use central limit theorem what really mean noise map all sort of information also add noise consistently at one point reach normal distribution however noise pattern at hand unique think of way mean of while also mean of unique noise pattern actually contain useful information where to create blank canvas generator no idea about what to generate from for many to one mapping additive noise process unique mapping explanation to why use noise conditionally denoise noise with text look at cloud tell see elephant in cloud easy to imagine elephant in cloud than tell to imagine elephant in piece of white paper less explanation entropy go from noise to image low than of from uniform image want to see for yourself with bit of programming knowledge write own diffuser pipeline to skip noise add stage try from blank image literally just line of edit side someone bring up similar question in different vein remove random seed understanding well noise ensure randomness one",
  "tbh take step back not moderate sub past week half one mod majority of filtering of post over past couple of year noise just go up exponentially over time very time consume pretty burn out take some time away bring up with other mod before step back bit probably good to try to get more mod think majority of current mod afraid to hire on new mod different philosophy of moderate thus change feel of sub discussion in subreddit always bit hit miss after all reddit community almost no gate keeping while good thing of course downside to look at post about batch norm see people who bring up interesting insight good chunk of people who clearly never even read paper carefully post year ago how many year before chatgpt take control of global nuclear arsenal demand destruction of all human r machinelearning today million subscriber more influx of newcomer more beginner friendly post get upvoted okaydo not get wrongit just different set academic discussion popular back only in fact remember in in openai office every morning see row of researcher with reddit on monitor discussion mostly happen now on twitter on related note anyone recommend more technically research orient ml subreddit already unsubscribe from r python due to sheer amount of low effort spam question consider same for r machinelearning for same reason here top post on front page right now r n language model teach themselves to use tool paper by meta ai research d quality of post in sub go down d non sota paper still good to publish interesting method strong improvement over baseline read text for more context good example of kind of work publish r n zero zero shot image to image translation p extract causal chain from text use language model r p add conditional control to text to image diffusion model paper present controlnet end to end neural network architecture control large image diffusion model like stable diffusion to learn task specific input condition example use scribble controlnet model r p openassistant fully open source chat base assistant understand task interact with third party system retrieve information dynamically to d what ml dev tool wish discover early r in second on new architecture d engineering interview at anthropic ai from list only non academic low quality post last one one consistent with normal experience not really sure what talk about tell not actually million machine learn expert on reddit guarantee of people here for hype not actually understand anything about ml pretty picture go brrrr only solution to create r academicmachinelearning to discuss paper to leave subreddit for general public follow opinion bias feeling sub never about academic discussion per se paper academic discussion act like vessel to carry people towards deep learn hype money flow industry job island in most of early discussion follow closely see never really push for genuine understanding rather people look for easy way to earn publication currency initial impression some kinda project publication land people high pay job probably later people realize actually not need to worry about paper stuff rather some kinda quick llm base project help to land high pay job even fast mean llm currently at peak of hype thus more random look post agree quality of discussion under post also pretty bad imo result of outdate rule lax moderation on rule definitely need to address low effort chatgpt post comment some of straight scam post on moderation not about quality about quantity realistically sub just few moderator some most of lad very busy engineer with no new moderator add in last two year while see enormous huge growth in member agree often see more nuance discussion on ml relate topic on hacker news eg post on toolformer last week compare to same topic post in sub today think many serious ml folk even avoid post here think problem machinelearning bit general name bunch of people think crap like ai gender biased look what chatgpt etc belong here go not just pivot with narrative exist model scale stand test of time with more datum big model name of sub buzz word much few of post call something like statistical learning chatgpt write about chatgpt bubble start everyone who get lay off want to ai expert certainly hope moderator fix otherwise community become annoying unusable many other technology relate subreddit like r datascience r python post early today on digiface discuss usage just remove by mod for literally no reason maybe discussion go down hill of much oversight like r science think verification flair to show level of expertise in certain area strict moderation not hate some verification crackdown on low effort bloom doom post around ai how close to star trek skynet seem like really low quality post r machinelearne generic get not r mlresearch r seriousmldiscussionsonly r pleasevisitlearnmachinelearningfirst post always hit miss with miss rate tie to fluctiation in ai hype moderation pretty lax post like no well say opposite million member not sign up to sub for academic only discussion want good to start subreddit expressly for purpose chatgpt change world to say post low quality just gatekeepe discussion away from what people actually want to participate in say opposite million member not sign up to sub for academic only discussion want good to start subreddit expressly for purpose chatgpt change world to say post low quality just gatekeepe discussion away from what people actually want to participate in maybe write by bot reddit labor model break go downhill for lot long than not something solve with well moderation people who engage with sub in high high frequency than before simply not know anything substantive about field how many time people try to asininely argue about stuff like model right model learn just like person discussion should just about datum licensing law intellectual property research ethic people just not understand what actually anymore ml simple rule base filter help out here really good point though minor contention seem like most of comment in post pretty well informed see main difference batchnorm before after activation which oddly enough year later seem to well in form of before activation due to efficiency increase offer by fuse m surprised on mark even year ago about skeptical of internal covariate shift business guess keep statistic center such helpful see since batchnorm seem to much more than just frustratingly utilitarian limit tool in experience unfortunately r math use extensive moderation to deal with kind of problem low effort post just get remove dang hope get away with not twitter account aside from ve just publish x thread which usually comprise of healthy praise question critique loathe most ml twitter discussion tend to all usual hot take issue from platform even from prominent name in field not really great place to discuss ml whole remember here in also definitely recall quality of post much high even look at sidebar most of high quality ama from prominent researcher where prior to now often see post classify relevant correct high quality get downvote post seem misinformed incorrect get upvoted personally blame reddit redesign for deemphasize text discussion in favor of low common denominator stuff like eye catch image video where on twitter how should get start filter by hot experience quite different guess should filter by top more academic non academic nature of sub always one of its great advantage get enough academic research in day job talk research with researcher here partially in pm some of openly m sure many other current problem something new which come during past few day also compare sebastian raschka post today about transformer tutorial in sub inexplicably downvote to vs same post on hn last week wonder at what compute cost per model evaluation narrative about push for large model end first time ve hear machine learning often use hype shelter word for ai trigger very few people in hype sense at least use to m not quite sure what to say very confusing to post refer to typically poorly construct philosophical argument on chatgpt just straight up how work not want to gatekeep like ml hype new people interested separare thread for beginner question tutorial per subreddit about section specifically to avoid spammy post basically free slave same system use by youtube facebook discord people just work for free while gain nothing spend time with kid who get mom ipad kinda depress tit not something solve with well moderation not work pretty well over at r what current understanding of why batch norm work not keep up with literature impression no real consensus completely agree use reddit casually twitter more of work research tool really much prefer reddit to twitter platform especially post musk try get into mastodon just feel like more awkward to use twitter academic focus ml subreddit good maybe even enforce real name for user to post twitter really good aggressively curate contact interaction interest aim to avoid bs political point scoring msm drive noise edit circle out for clarity problem what define what buzzword its attention grab catchy misuse shelter unfortunately breach for while now join sigmoid mastodon wasteland of people post ai art pseudo intellectual gibberish about ai nonsense belong on bad part of linkedin what about public discord server only allow actual researcher to post allow everyone to view easy with role people willing to moderate with iron fist academic focus subreddit work well open forum always get derail real name no yeah no idea how to try follow some datum scientist keep post about politic take look mathstodon some actuall mathematician computer scientist maybe well place to look at also frustrating find researcher want to follow work on ml compbio ppl want to follow spread across multiple mastodon server which make hard to search for not use discord hear good thing about even with some lab use instead of slack just find discord bad at archive not index by search engine kind of mess of walled garden even search within kind of mediocre lot of great people want to hear from only post about ml not politic accomplish by use ton of keyword filter for different political term any post by people follow include political keyword get filter out leave with relevant stuff take look thank for recommendation right now what really want place to chat with ml researcher primarily to try get some eye on pre print before submit to conference such still kinda new to publish coworker not really familiar with current state of ml publish circuit always use more advice get come to actively hate lot of big visual attention grab work come out of lab like openai fair to some extent stanford berkeley work more in trench on stuff like efficiency two minute paper never go to feature paper just interesting graph two such life unaffiliated pretty passionate about good design in general discord really spiritual successor to irc which predate world wide web server channel role skeleton come from irc feature rich easy to use see supplant large portion of social internet over next decade for last month develop first discord bot with chatgpt assistance dev interface excellent no experience with slack not comment on gpu all need hmm well now not know talk to bot cool should check out seem like free version already pretty functional chatgpt mostly cool toy some task genuinely useful for use to explain complex topic write code brainstorm idea for fun creative writing exercise only try free version see mostly disappointment about pro version definitely check out for at least curiosity sake oh sorry mean should check out discord use chatgpt for few task helpful not perfect summarize long document current issue mainly just overload not try code writing brainstorm yet oh yes mistake definitely check out discord pm here want to add couple public server should probably glance at use midjourney bot to make own image go to one of newbie room type imagine prompt",
  "nvidia gpu check out nvidia riva toolkit great solution use condition latent for inference yourtts available in coqui tts fast rather easy to use at cost of quality english french portuguese in same model",
  "abstract propose zero diffusion base image to image approach allow user to specify edit direction on fly cat to dog method directly use pre train stable diffusion for edit real synthetic image while preserve input image structure method train free prompt free require neither manual text prompt for each input image nor costly fine tuning for each task tldr no finetuning require no text input need input structure preserve project website use new kind of noise look pretty unique its pretty cool think about use other form of noise how know what to translate in no prompt seem to break in numerous way",
  "yes of course research novel believe method interesting of value should definitely seek publication goal of research not to develop sota model to expand knowledge in particular area yes develop sota method great way of get publish lay groundwork for other method explore idea all crucial part of ml research in general absolutely yes in practice review process for most tier conference right now complete roll of dice for example wacv some other conference explicitly state in reviewer guideline should consider novelty of approach over performance still see many review pe work for lack of sotaness good thing make work academically rigorous possible good baseline experiment ablation study analysis submit until get in not worry about what not control which randomly assign to dud reviewer yes improvement not only to create good model also how get for example argue approach much more computationally efficient neural network not sota for very very long time world very different everyone only publish sota result improve upon exist sota of yes see several nlp paper with idea make model competitive to much large one for instance not need to sota in absolute sense should interesting in empirical way model small need to benchmark against other small model efficient should compare against other efficient model just like aesthetically think clever need to think about what cleverness buy evaluate in dimension yes sota also often define while important sometimes bit overhype imo most practitioner engineer want something good above some threshold in accuracy give constraint often severe sota approach not meet real world constraint argue not sota for particular problem of interest something perform very well under such real world constraint demonstrate value to practitioner should consider for publication by editor some helpful gut check reason to believe method scale with parameter datum maybe probably not actually test thing at google scale good theoretical reason to believe method accretive at scale major yes get thing to run really well at small scale of sometimes extreme value simply go to see less interest from reviewer on its own bazillion hacky ml method turn out to entirely irrelevant once scale up substantially people wary of such paper discussion ve get to go down path make sure to position explicitly hyper optimize small scale model like for mobile good reason to believe top paper plus method far boost sota even well test to confirm method at its theoretical core simply twist on subset of method from sota use go to see much less paper interest unless promise significannot improvement in simplicity efficiency sota paper use some method just not seem practical for application at all demonstrate superiority of method on some of other application create sota in some sort of subset helpful second add reviewer roulette now norm in other research community some conference make effort to impriove reviewing process icml metareviewer open back forth discussion between author reviewer still not solve problem regard work possible define metric encapsulate accuracy vs cost memory compute show how vary across different establish model use part of why model much more efficient than alternative of run x model in parallel in experience use proxy metric for cost preferable for ml crowd mean something like operation count bit transfer of course measure time on exist hardware say gpu cpu well good luck very true connectionist tell to go home stop pursue avenue great example",
  "",
  "reposte old post somehow point to old release of mine strange want to read new release original comment post on original post hello everyone two week since move under second mark make some more progress with some very hard work on project in past two week now past internal second benchmark for another release release next update d update change neural network architecture to own new custom layer resnet architecture dub speedyresnet which extremely simple fast also some hyperparameter tune round hyperparameter to rounder number than before also change up learning process bit by change how use ema on some post investigation seem ema code for optimization not work properly in release though still work fine ema general performance number still should accurate hopefully fix in future also by only add depend upon what count line of new code vast majority of rest of work edit change simply outright delete other code result in codebase tiny bit simple at least in layout fast than before also eliminate hyperparameter seem to no long useful one downside of change overfit slightly more on long run mitigate enough with cutout hope to fix in future release not terrible problem to try to set speed record test code on without any modification other than to dataloader to load correct number of datum correct number of class show performance for two different network size comparable to show at least in rough initial exploration both of small network match performance of sota network in around same year increase base depth of network by factor of two improve performance of both network by about year to match respective sota from same time period indicate code hopefully some good generalization capability beyond just dataset though not experiment with different image size yet rather expensive information get stale very quickly lot more in here in previous post mantra of sort basic very well go whole lot far than seem otherwise new shiny develop neural network oftentime more of toy distraction than stick with basic well which understandably very difficult thing say run out of runway for easy change likely need to get more more creative until goal to stay simple possible like more info please read release note very informative although long future release more to with speed improvement other thing additionally still should excellent researcher toolbench for prototype experiment with idea many idea able to implement in minute less most of which actually run in code by point for some like sometimes architecture change for example able to get complete initial go no go filter answer oftentime within minute of idea just quickly tweak let run through few run either to let run more run to see just noisy answer definitely not work indispensable part of why build tool also partially responsible for rapid progress in develop tool able to apply very rapidly gain insight from tool to itself hang around here for question comment etc not answer all of good d just want to say incredible what reason for use max pool layer instead of average pool before fully connect layer like in classical resnet thank much for support d greatly appreciate think last release big explosion release for one maybe break under second hope to keep put out release in future what really freak cool time from idea to verify not decrease exponentially improvement come through just take little time to test thing now which let improve neural network researcher engineer much more quickly happy to answer any question end up with some in future either way very many thank for support much love ddddd d pretty large performance difference iirc operate on frame of monstrous right now lol just for scale think something to with sparsity who know tbh just go very hyperfast way what weird nnadaptiveavgpooling way slow than torchamax call by just use torchamax call instead wrap in custom rapid global pooling class m not sure help answer question not please feel free to let know not d any thought on tackle other dataset model architecture in future great question think hope to maybe understand model scale bit once thing settle down bit for future of course try out different dataset without any hyperparameter tune perform comparably on to similar network yay seem like transfer nicely currently overfit on long training run cutout seem to help lot with tbd what really good solution long term for d",
  "dall e disrupt by stable diffusion openassistant disrupt chatgpt in opinion confused model already exist only in datum collection stage excite for future of dynamic intelligent system one influence retrieve alter state of web use same tool what world live soon most of operation over web ai base think depend on how small llm use run on consumer gpu probably take off need to rent server just for inference probably not stablediffusion take off in first two week run on vram gpu finetune aka dreambooth come along go from to to gb in matter of week same effect in datum collection stage run by laion plan to make kinda good train in on industrial hardware distill down to small model ideally fit in consumer gpu go to big at first want to make small eventually know distilling possible after instruct finetune rlhf step know work on vanilla model not search anything regard distillation of instruct train model sorry just casually watch yannic kilcher yt video not know much else",
  "many article try google",
  "github python library implement tool to extract causal chain from text by summarize text use bart cause effect model from hug face transformer link cause effect with cosine similarity calculate use sentence transformer model project like to continue improve want to share first demo here example implementation use to generate graph text wikipediapagechristophercolumbus content chunk utilcreate chunkstext cc causalchainchunksdevice cccreate connection big chain ccbiggest chain ccvisualizebigg chain application mapping casual relationship within text to well understand event describe impact on one another mapping relationship between different text to link together article in large dataset about m student at ohio state university study computational linguistic right now undergraduate thesis on synthetic datum augmentation use gpt get ready to graduate look for nlp role with inspiring company who interested in untapped potential of lm here linkedin not read through at all yet apologize question off use to link turn in dialog imagine two speaker know roughly timing of turn which big help use approach to reliably link turn together eg speaker say x next turn speaker b say y say z b say q quite useful to causally link turn for future analysis awesome for share project interested how to turn into dialogue how to interface back to ask user super interesting project wonder clarify following from readme file usage section say to create causalchain instance run create effect on however example usage section not use create effect instead use create connection method section discuss both create effect create connection not sort out from description why usage code work without call create effect wonder how gpt perform on task ask to summarize story use graphviz syntax awesome project work on something similar use promptify extend pr interested let connect discuss total noob no technical hand on knowledge here wan na thank for for kind of wish all success in whatever project in mind really interesting work how handle event write out of chronological order flashback flashforwards foreshadow ect bart cause effect love to hear more try alternative like flan especially use huggingface transformer to train model what find along way really impressive project especially with little experience not topic expert never hear of any tool allow event level dependency parsing even call think about publishing not think enough for yeah think definitely modify to create some sort of dialog map great idea mean speaker diarization lot of tool framework for nothing to with causal relation great catch restructure create connection always call create effect not yet generate to change readme only able to find cause effect relationship within certain event window default like sentence think base on window generate cause effect chronology of event glean from similarity of cause effect to one another no metadata location in text use obviously limitation lead to event sometimes out of order honestly not experiment with different text to text model much like to try flan use blurry library to train important area of call center analysis surprisingly not whole lot of attention atm no not mean speaker diarization thank explain one other code build list of trigger effect since more than node connect serially in output graph not simply trigger point to effect ie only account for chain of at most node what actually happen very exciting research direction think thing like extract structured relationship from text thing like binder attempt to break down question into chain of solvable sub problem really promise use of monolithic model big enough to appear correct at least some of time quite problematic in practice sort of structured reasoning layer need oh nice one with blurry yeah well interest recent instructor paper ah see taskload bart cause effect train to label token in multi class begin intermediate set much like acronym dataset think at first train on rte entailment dataset nice work okay look through code think what happen event comprise of trigger effect event comprise of trigger event connection make between event event trigger effect determined to similar",
  "for research paperswithcode connectedpaper fantastic thank for put together add deepsparse sparsezoo for training deploy sparse model also not vouch for not use yet dvc datum version control for ml dev experiment track weight bias mlflow neptune etc organize research paper zotero paperpile etc deploy model to production airflow not good tool for ml development leave airflow back in also modal prod model deployment model pipeline inference qdrant for vector database kern ai refinery for datum labeling check promptify for llm comment for later usage add thank nice thank what take on rest of list look good anything out of place why airflow bad suggest alternative use airflow now with no issue save page same not issue definitely not bother migrate something like metaflow modal much more build for purpose airflow design for hadoop era of datum engineering strain under change happen in python container ml ecosystem",
  "paper link to in github repo not affiliate with work its author implementation link to in comment from another post what excited for imagine develop character house style feed rough sketch assign character object to circle scribbled object draw tell chevy impala character x",
  "kubeflow take look at meadowrun early day very nice api nice set of functionality try use ray no experience of kubeflow read very tightly integrate to kubernete complex to manage in script for datum scientist engineer yes lot to learn documentation not great probably well open source end to end framework for ml",
  "follow",
  "one of most disturbing face ever see wow barely tell fake s big guess who energy nft drop everyone involve in project pay much same picture state of art face recognition model show impressive accuracy achieve over on label face in wild lfw dataset however model train on large scale dataset contain million of real human face image collect from internet web crawl face image severely bias in term of race lighting make up etc often contain labeling noise most importantly face image collect without explicit consent raise more press privacy ethical concern to avoid problem associate with real face dataset introduce large scale synthetic dataset for face recognition obtain by photo realistic rendering of diverse high quality digital face use computer graphic pipeline compare method to synface recent method train on gan generate synthetic face reduce error rate on lfw by accuracy from to first demonstrate aggressive data augmentation significantly help reduce domain gap between synthetic face real face image take advantage of full control over render pipeline also study how each attribute variation in facial pose accessory texture affect accuracy finally by fine tune network on small number of real face image reasonably obtain with consent achieve accuracy comparable to method train on million of real face image while alleviate problem associate with large dataset microsoftgithubio video youtubecom arxivorg wow nice surprisingly good performance resolution completely useless in 2k something about last row remind of zoombinis remind of good of talk head album cover most epic game how many question require not lot play optimally 1e only about",
  "",
  "find relevant code at all code implementation here opt out from receive code link dm",
  "",
  "find relevant code at all code implementation here opt out from receive code link dm",
  "hey great idea look very interesting use abstract input actually parse paper build something quite which summarize trend ai paper bullet point however think chrome extension allow for much more flexible paper choice which really great really like chatgpt typically find abstract good enough to summarize paper not point of summary at start of paper serious how use chatgpt programmatically understand open ai only accessible via api chatgpt only accessible through chatopenaicom waiting list to access chat gpt api kagi also summarizer pdfs add value ask question about paper eg some mechanic apply amount of context chatgpt process really enough for typical research paper not what abstract for api endpoint cool not what bing out of box same with browser opera release new feature call shorten button which internally call openai expect google to release part of chrome well to use extension simply install visit link to arxived paper generate summary of paper include one sentence summary question for author suggestion for relate topic query prompt customize to fit specific need preference chatgpt routinely leave out aspect of information even give task of re phrase what say in different style information deem problematic in some way without even tell effect also present probably even more pronounced in summary not point of summary at start of paper guy try good not really impressive more expectation okay to say try extension not really work for just open chatgpt page in small window link good enough to know to read not still end up disappoint half of time abstract mean often bit clickbaity yes what need to skim through dozen of paper to find what need depend on paper author sometimes reallllyyy try to not tell what find how find until get to method conclusion right write own version just give abstract imagine chatgpt really smart just copy lot of people just write use chatgpt in app headline in fact actually use api generously interpret due to genuine confusion not open ai api for direct chat gpt access underlying base model same chatgpt just finetune for dialogue which not need for such app tbh npm package provide unofficial api for chatgpt to jump through all of hoop to get sign in before snag necessary credential literally how microsoft plan to incorporate chatgpt into edge side bar where talk to chatgpt about whatever content display on page try explain paper elicit for same thought fairly sure any gpt base model only handle token yo dawg hear like abstract make abstract for abstract genuinely interested in learn how to build such thing explain how build extension link to chat gpt from system design perspective know difference between chatgpt gpt mislead on purpose why not impressive summary generate automatically should new section on arxiv paper website no visit paper detail pagefor example embed section chatgpt start write check screenshot in web store page again abstract mean often bit clickbaity vision of nightmare future where paper write in click bait fashion top ten shocking property of positive solution of high order differential equation astounding application in oscillation theory not believe number use chatgpt to summarize multiple paper essentially light survey for actually great idea just ask chatgpt for most relevant paper nobody like climax spoil during first few page of story probably depend on field not typically encounter most other researcher go to look at dozen of paper at least really not want to actually to dig into paper to find meat yes confusing not think openai incentivize to clear up confusion some people also figure out pass in right model d to regular gpt api get chatgpt not sure block since discover no only for model such davinci delete not model available in api davinci most powerful model available case in sign up for wait list to get chatgpt api think see what talk about sure actually hit chatgpt should pretty easy to verify use something like headless browser something wait for use chatgpt not gpt make same api call make in site project fork from repo check code click here to auto cite paper to learn more about number let start academic journal name trashademia where only accept article with click bait title research otherwise not worthy of publication accept anyways long content present with plenty of humour trash talk not hurt average paper write more engagingly than now not like mind numb discovery break university intranet give doc brown lookalike professor heart attack something well than quasi entropic property of clifford algebraic structure determine by to induce permutation upon information theoretic monoidal category which commonly know to derive from generalized relaxation of curry howard lambek formulation equation under noetherian ideal invariance show in figure lol jk only unsophisticated normie doth require non abstract nonsense know outside of shakespearean tragedy figure therefore provide support for main result of successor of mesopotamian invention succ in summation with itself equal to successor of successor of aforementioned invention which widely believe to first only even prime additionally happen to popular choice of base for logarithm in information theory furthermore provide fundamental basis for classical logic which base on concept of truth falsehood ergo number of logical state which describe least number of branch under which bifurcation occur dr obvious et al usually vixra eprint yea certainly seem useful also sound like mix of search engine chatgpt mss update to bing able to climax ass try to learn not to cum case in title abstract almost disjoint come across paper like regularly like maybe of time whisper voice to text model da vinci instructgpt use mention by openai employee on twitter chatgpt just finetune for dialogue use playground not much difference in output in fact da vinci more suited for building application imo yep use to access chatopenaicom use puppeteer headless chrome to semi automatically traverse login claim now some sort of more direct access not gpt api method obsolete not sure what now cite one more paper to get more chance of accept shine problem find with chatgpt other ai word limit believe word max include summary well anyone know fix please let know in meantime use ai tool call scholarcy lack datum to feed with study subject very read heavy not simply rely on abstract page per week course mostly much to handle while work part time definitely see kind of paper talk about one seem fine to grant skim really quickly title say review article abstract reflect really like format see in bio field maybe other where ve encounter of put result before detailed methodology not always make sense for lot of cs paper where result most boring part essentially work well where lead to much well paper in opinion think in specific example not any experiment conclusion in abstract rather superfluous more research ya think oh okay not aware of thank for context two step summarize each paper summary all fit into context window compare contrast true review even review tend to draw conclusion thus reason for meta analysis yeah also prefer to see result first no matter how boring find some correlation type of meta analysis not uncommon nowadays few avoid answer question much paper no worry maybe difference in field rarely see people meta analysis in ml not strike odd most of review just here what people try with some attempt at categorization see what mean now make sense meta analysis important in medical field where want to aggregate study",
  "people talk about not just in x seriously underestimate how difficult problem actually good reason why hard to which kind of static type checking require refinement type where typechecking np hard basically by include value in type typechecking become way hard type contain limited program involve arithmetic sound typing require to prove dimension add up correctly type system need to include notion of arithmetic except of godel incompleteness theorem any logical system include integer arithmetic undecidable now basically step from traditional static typechecking to something like automate theorem prover unless get very careful clever with how set up problem mean one of two thing either write ton of type annotation like more code than actual program to prove to type system program valid hook up automate theorem prover to prove soundness of program automatically at cost of type checking np hard bad worth potentially way of make tractable very non trivial basically need type system dedicate to problem specifically not something stick onto exist language type system say some thing try to haskell port of torch call hasktorch include kind of type tensor shape call theorem prover on backend to solve type inference get away with of liquidhaskell compiler extension which refinement type capable of solve kind of type problem already pretty mature dex research language from google base on haskell build to explore kind of typechecking really want to in rust where tradeoff of speed safety for convenience make most sense rust just barely on edge of type system capable of to get really clever with type system to make work at all no sustained push from any company to develop into mature solution hopefully something well come along soon rust crate call dfdx which static checking of tensor shape think ahh guy fight over just send production ready think problem not want language only x imho one of big issue with adoption of julia just not offer such big ecosystem like python otherwise why torch go from lua to python why swift for tensorflow not become more popular deep learn code generally not stand on its own once port inference engine to rust to some degree by use tch r to call torchscript export model only half of game before between after network lot of processing activity pain without lot of python libs just find something solid like spacy pretty tough in almost any other language think swift tf look awesome nobody build good platform support tool plotting library integration of sdks like aw experiment track configuration management blah blah around not help much look at current work project pytorch dependency directly relate to dl some other not ok other option to use embedded language like with lua suddenly to deal with main language embed language probably with low c cuda layer also what exactly embed language cover just differentiable programming code get to inferface with datum loader code to load specific point cloud data format extract mel spectrogram pitch contour run complex text analysis pipeline get stuff from read from some exotic db azure whatever jeremey howard mention yeah high hope for swift julia now back to well seem stick with python after all check julia vs python here dex close come to mind with how deep python ecosystem how fast llm move next language for ml likely english agree some of thing make ml code inscrutable every tensor shape to guess keep track of go through various layer plus b layer operation to constantly look up how change tensor shape settle on two good practice to mitigate t always include tensor dimension in variable x b t e tensor of shape bte trick learn at berkeley drl workshop many year ago teinop all thing einop express op layer in transparent way by how tensor dim change now suddenly code refreshingly clear einop page give many nice example here quick preview contrast two y xviewxshape batch y b chw rearrangex b c h w b c h w b c h w yes little verbose find help hugely with two issue mention above ymmv well sort of cuda julia scala right help make language take axe not really answer to question python package try to solve problem of tensor shape mention fortran with well syntax think probably to go way of carbon support legacy fortran change many other thing quite bit still matrix operation similar to numpy whereas carbon still matrix second class citizen agree should well language for than python swift for tensorflow not workout though ve wish from time run into error involve numpy broadcasting along incorrect dimension error of want to add length vector to matrix by treat vector matrix instead no one tell about such error spend hour debug only to learn length vector treat matrix in particular case yup computing on dimension information to provide static autocompletion well dimension check themselves seem like huge plus besides compile time check another feature wish for to index array dimension by name of dimension rather than its axis number for common lisp couple with defacto library close language come to make possibility build in common lisp array type already fairly extensive in actually allow specify per axis dimension which compiler use to type check common lisp sbcl compiler in fair number of case for example declaim inline add vector defun add vector b out declare type simple array single float b out loop for below setf aref out aref aref b out consider add vector function define above take three array each with element type single float single axis of length add first two argument x y element wise store result into out try to compile follow function defun add to first x y declare type simple array single float x type simple array single float y add vector x y x compiler sbcl actually signal error during compilation itself processing defun add to first tmp defun add to first add vector x y x delete unreachable code catch warn derive type of common lisp user y value simple array single float optional conflicting with its asserted type simple array single float see also sbcl manual node handling of type compilation unit finish catch warning condition print note say common lisp leave lot many thing want not only no parametric type its type system also no formal structure like hindley milner type system attempt at coalton to bridge bring hm base type checking to common lisp however even with hm notion of per axis dimension hard although doable with fair bit of macrology over past two year some of able to come up with something allow for following in package polymorphic function push lambda x member x m len type parametric type symbol predicate defpolymorph pf add vector simple array type len b simple array type len out simple array type len simple array type len loop for below len setf aref out aref aref b out one try to compile add to first define above defun add to first x y declare type simple array single float x type simple array single float y optimize safety pf add vector x y x one get follow compiler note processing defun add to first while compile pf add vector x y x following note encounter no applicable polymorph discover for polymorphic function pf add vector args x y x derive to of type simple array single float simple array single float simple array single float available effective type list include simple array type len simple array type len simple array type len follow compile successfully defun add to first x y declare type simple array single float x type simple array single float y optimize speed pf add vector x y x fair bit optimally declare disassembly for add to first byte add to first movss rsi rcx movss rdi rcx addss movss rsi rcx note no parametric type in sense of hm type rather symbol substitution declaration propagation strategy employ here regardless very much rudimentary no formal semantic at current rate expect to take several year for reach maturity yeah someone with background in dependent type theory time to implement debug certainly welcome to experiment with common lisp sbcl to see what possible d r come close not programming language database solution call mindsdb bring machine learn into database by employ concept of ai table ai table machine learning model store virtual table inside database facilitate make prediction base on datum perform time series regression classification prediction within database get output almost instantly by query ai table with simple sql statement yes watch fireship not hear about attempt remember see in jeremy howard class about idea on design one more towards descriptive paradigm absolutely agree with op out of same frustration actually end up design own language write compiler for now use for all ml model probably only solve particular problem not expect to very useful for anyone else here go in case anyone prolog lisp lua candidate julia perfect match for scientific computation delete on static shape look at jaxtyping which offer compile time shape check for jax pytorch etc why jaxtype originally only support jax now support other framework in particular now recommend jaxtype over old torchtyping project which pretty undesirably hacky in term of fit kind of stuff into proper lovely completely agree extent to which retrofit python pretty crazy yeah differentiable programming julia probably big one other in opposite direction from question very interesting project tinynn all implement close to metal possible very in vague neighbourhood of question triton compiler while on surface python jit compiler language coverage much small than python view small dsl all interesting bit way below javascript work even complete book on tensorflowjs thank for detailed answer really interesting wonder gpt leverage to create nlp base type system programmer annotate type in plain english ai hallucinate appropriate theorem proving axiom interesting dog fooding of ai ml for easy ai ml development edit holy cow what say to deserve many downvote one response below make think not such wild idea hah nice surprise yes whole point of dfdx to just dex get softmax activation function write sigmoid together with funky error no thank like to manually type torchsigmoid some of thing make ml code inscrutable every tensor shape to guess keep track of go through various layer not inherent to ml though library design choice to tensor shape define at runtime vs compile time while back write own framework in c choose to go with compile time shape which well prevent shape error more in keep with c type for dynamically type language like python maybe runtime define type shape seem more natural choice still choice nonetheless neither of for ml strictly cuda gpgpu platform use c to compile to some gpu high level assembly julia parallel compute math language scala general purpose oop fp hybrid large language model to caution against use sharp object in programming language pose great risk to developer unknowingly hurt themselves with furthermore say axis typically not very sharp know blunt object object not very sharp also not extremely sharp sharp now defunct company use to produce tv set tv set like modern tv use to also old s head up new jaxtyping project now exist despite name support both pytorch jax also substantially less hackish than torchtype such recommend jaxtype instead of torchtype regardless of framework jaxtyping now widely use internally imo fortran very capable for surprised not more than neural fortran real nvfortran even compile for to offload to nvidia gpu while die idea autodiff in lang still live slowly quietly work actually pretty cool first red mongodb think not discussion again swift for tensorflow not pan out meta also work on shumai which javascript typescript look like pytorch while tfjs performant godsend ugly js lack operator overloading native tensor type to tfaddtf tf yes no really not want to make type annotation in plain english in curry howard correspondence type correspond to theorem code correspond to proof of theorem one thing know theorem not see proof often trust proof right without see really need to know what theorem start with english generate some type behind scene not see what actual theorem just know system prove some theorem about code programmer no idea what actually tell kinda defeat point of use static typing in first place say write down desire type system write down ton of type annotation generate bunch of code to prove type write down satisfied by program recent work on in deep learning for theorem proving such work which use gpt for prove theorem in lean dependently type programming language theorem prover well approach though to combine with actual tree search algorithm to allow more structured search over space of proof instead of try to generate full correct proof in one shot hypertree proof search use variant of alphazero to search fine tune neural net unfortunately not open sourced though pretty compute intensive not use for actual type inference yet yeah active interest in kind of thing both proving ground for use rl for reasoning task from mathematician for theorem prove know what what miss natively make ml language math language call sound awful lot like ml language to very true just shame not make very look forward to not miss something general purpose to consider specifically for machine learn dsls about specifically for ml python only python well at big community well support mean wide coverage of ml google project what google to its project think rely on tf mistake deep integration approach more fruitful in long run also anybody want to ml in swift on apple platform awesome mps graph",
  "",
  "think great thank for effort definitly work through thank for blog question though what happen instead of use key query value only use key query set value key ie remove value component what intutive reason for decrease in performance of transformer model for example use single linear layer instead of all three query key value every token attend to itself therefore ignore token in its context thus result in low performance what happen what in case value key understanding while use same weight for both key value in self attention potentially work result in significannot loss of expressiveness require much large number of parameter to achieve comparable performance make sense thank for reply",
  "add new special token to vocabulary since size of vocabulary increase by one not able to use pretrajned checkpoint unless some manipulation of embed layer add new row again random value more appropriate for r learnmachinelearning use hash map replace with nm token really set token name in anyway want special character around make more likely to distinguishable",
  "realize miss dependency fix already instal library need fix just run pip install upgrade datalabel",
  "anything add to content on github paper interesting area to both fine tuning to particular use like humor some of dynamic behind irony humor appropriateness code switching for reason ear perk up relevant able to use reddit to provide training content why all academic paper in ml come up with such stupid name acronym very nice not enough generate joke example want to get see although not think naughtyformer anything special here well than transformer for offensive humor safe than blackformer to build narrative totally fair clever",
  "gpt family of model decoder only architecture which not cover by patent some mutually assure destruction go on here microsoft openai also own patent cover google product google sue over transformer sue right back for something else schmidhuber prior art specific kind of architecture patent implement different kind patent use problem with patent something very general someone always find way to another way of course except case like patent pi still probably say invent new number call phi obtain via taylor expansion use to compute area of circle by divide diameter square to inverse of number until obtain patent in way other company dominate market find first idea of patent patent stuff weird think about feel century patent on transformer like patent on physics its hillarious opinion patent garbage should put in dumpster set fire to with gasoline google sue openai for training on youtube video another question answer yes additionally google release many open source repository with transformer appropriate licensing also question of whether patent of type hold up in court anything reminiscent of software patent on shaky footing dunno company pay for r d should entitle to exclusively make money from for some time think problem around what not why newton actually patent on law agree only block innovation make very expensive yes same own trade route not want other to use not publish not invest in first place leave market to good people not feel need to restrict other human freedom yeah alice corp v cls bank significantly limit scope of software patent rule add on computer to abstract idea not itself make patentable believe true invention of real algorithm like movie codec still patentable though which beg question what really purpose of file such patent circumvent seem like lot of effort for nothing unless patent part of some evaluation criterion to climb up corporate ladder should not r d not accept other people human right to use brain whatever like like say thief much effort should allow to keep steal good know swipe to write feature exist on iphone android where keep finger down draw word some small company sue big guy atm for feature imo think fraction actually use hear lose how patent such thing mean yea not most simple software to write just feel weird to able to patent such useless technique wow really interested at history more detailed literature about no patent system every innovation by any individual copy mass produce by big corporation within day invent imagine spend few year design new motor no patent system toyota tesla mass produce moment understand how work since far more resourceful never able to produce anything compete with in quality scale at least now with patent system to pay little to use invention not care benefit from own innovation still think system protect individual ingenuity somewhat useful disagree about imagine invest million of dollar someone make million of lose million of dollar agree should in experience difficult to get algorithm patent lawyer feel actually protect ip basically not well test in court yet to see how much protection provide arm race russia us really know each other nuke work rather just not find out like patent hold up in court well enough of patent vs patent probably go to settle base on likelihood enough hold up proportional mutually assure financial destruction crappy part here patent essentially useless inaccessible for individual inventor big entity dwarf in end come down to money just matter of understand nature of investment which not concretely define general public think no not like at all imo analogy not make any sense first r d not just think up stuff make in drug discovery involve expensive trial in other field involve lot of building scrape thing sometimes from expensive material patent should incentive to all know once monetize in way not allow other company just to copy paste without effort should able to for everything forever probably not what refer to talk about swipe type lot fast than peck type back phone small enough to fit in one hand afaik company patent swype screw up by make patent more specific than need to apple google able to work around without license eventually get acquire kill few year ago not to publish how anything work code with other guy chatgpt bring online take time anyone to copy easy to buy secret first to market beat patent specially in software add one moronic attention layer claim something different actually patent protect more big corporation than little player patent hundred of random thing just in case even something which not productize whatsapp for instance copy by any company somehow copy worthless imagine just not invest million of dollar instead someone else develop idea not want to freeze rest of world out of use patent only make sense assume alternative to invent something no one invent experience show very rarely case in general idea time come base knowledge to understand infrastructure in place to use effectively etc race between many party to develop idea apply to everything from machine learning model to light bulb telephone both of which famously develop by multiple inventor simultaneously before one person get lucky often by matter of mere day issue exclusive license to invention while everyone else who same idea out of luck off topic for forum since here anyway patent tricky come to stuff like to successfully patent something software relate must able to convince patent office what patent count process not idea concept principle algorithm all of which explicitly not patentable nuance of how draw line between category fairly complex in general often come down to able to patent engineering detail of how something in face of bunch of real world constraint not what any broad generalization of big picture likely swype not just screw up write patent poorly rather write only patent legal team succeed in get approve not apply to what other company later use different process for nuance lawyer meaning of word to accomplish same goal intentional feature of patent system not failure by swype no every innovation materialize just by handful of people like software app not everyone who involve in process buddy assume to good in any hardware relate industry need corporation to mass produce innovation no patent system moment manufacturer figure out how to produce innovation no long in fact one of major reason whole us china trade war in first place basically local chinese contract manufacturer access to manufacturing procedure of foreign company who invent product just directly copy undercut customer patent also protect interest of individual researcher who rd for corporation another topic",
  "what happen begin to see everything lootable excited to share late work learn object language alignment for open vocabulary object detection which get accept to iclr here some resource arxiv propose method call vldet which simple yet effective vision language framework for open vocabulary object detection key effort introduce open vocabulary object detector method to learn object language alignment directly from image text pair datum propose to formulate region word alignment set matching problem solve efficiently with hungarian algorithm use all noun from image text pair object voccabulary which strictly follow open vocabulary setting extensive experiment on two benchmark dataset coco lvis demonstrate superior performance come far since xkcd seem really cool something like use assistive technology for visually impair difference between model such yolo emphasis on open vocabulary not wait for self drive car assume go to primary use for kind of thing go forward probably infinitely useful in boston dynamic style robot well how else robot infantry go to identify opponent weaponry equipment with telescope eye ball",
  "very nice resource bookmarke for later read nice list remove thank try to keep concise manageable focus on main milestone idea something miss though happy to expand no muhammad anas man imposter",
  "make very nice browser plugin awesome though of bit more concise not all start with in video consider re engineer prompt post process output youtube premium feature pay very practical use of technology well please ai which produce proper thumbnail not want to see face anymore also crop video to prevent watch time optimization read transcript summarize very cool definitely use possible to learn power dumb how use instructgpt to knowledge openai rl base gpt series model not directly consumable unless basically scrape apis from web app strangely enough more verbose description actually make want to watch some of video want to hear how some stranger get into argument about alien what input to instruct gpt audio transcription presumably ai generate very cool what typical cost of create summary quickly become pretty expensive to use openai api for each of god among man should just youtube feature honestly okay how get access to instructgpt give never release to public even less pretraine model after all year actually interesting post on r machinelearning wow absolutely give plugin pay to use how already know ltt go to example use case god work son dude pay thi future totally personalised web browse experience without need for run script plugin avaunt thou must need reveal unto how must not get what suppose to see on picture now good stuff great work what timesaver need desperately on github please make browser plugin awesome literally save hour of time to some people even well to entirely replace clickbait title with reality seriously sound game change hate click bait much start block unsubbe some channel brilliant not help curious always want to know what big craziest dumbest whatever even though know clickbait probably not interesting anyway should also anti click bait title such good idea great idea use case for remindme month integrate into sponsorblock outstanding amazing idea code open source interested in exact prompt such great instructgpt of all time wow although some reason not care what about watch anyway lol yes yes yes what s cost of run over bunch of video in term of call api hope somehow make big buck from man shoudlve put more time into gpt year back greg give acce to beta thank need to talk about great concept good work remindme month hope for browser extension even well revance patch remindme month grab plugin available incredible like coast guard of clickbait youtuber just solve mystery of universe alright glad get figure out dude need to plugin extension remind in month assume youtuber just solve mystery of universe not original title somehow become anti clickbait loop back around to click bait get subtitle use text summarizer with some desire output length ph interested hero need great use of machine learning of all time woow awesome soo helpful see some of video description not really accurate omfg think about for past week think shove subtitle into video to find most pertinent topic bit extract timestamp for thumbnail remindme month youtuber amazing much need remindme month remindme month remindme month yes chrome plugin amazing not sure how same achieve on mobile though remindme month remindme month remindme month well make plugin replace title of video with summary put title of video down below small dark text new here curious about how work what input to instruct gpt video in case how doee language model take video input instruct gpt remindme month remindme month good stuff someone send to charlie love to see reaction how get ai actually watch all video how work suuuuuuper interesting project remindme month remindme month how write twitter thread on how to achieve include prompt read here remindme tomorrow please remindme op write about in newsletter amazing use case non gimmicky subscriber watch lot of youtube video like publish weekday at e in tomorrow newsletter link back to reddit post to give people reference to check out actual post let know interested about sub remindme month should make video about title youtuber hate remindme month similar browser plugin use chatgpt to summarize youtube video highlight remindme two month not mind clickbait article usually fairly informative of content however also capable of discern what fake from reality something outlandish just ignore no harm look great pay for use of api each time remindme month post itself clickbait no code no writeup no explanation just two random screenshot still upvote what happen to sub consider how many people ask think about make into chrome extension chrome extension online download here wish to create extension userscript of implement functionality into own app find all information need here just go to say until creator learn to seo ai in week google release paper demo commercial function pay for not to youtube protection racket not nothing ever worth pay for nahh think not difficult to plug in just remove thumbnail altogether what mean by crop video to optimize watch time firefox sponsorblock module people register timestamp for unwanted content amd get skip for next user need to curate dataset of proper thumbnail to define what even first what watch time opt ai make bad click bait title thumbnail ever try to maximise view more than likely something similar before just grab link to video on page go to page grab transcript use to get useful information in video chancellor palpatine tell legend of darth plagueis wise only machine few month ago ve make some of model available use api massive difference in ability to follow instruction plan to add chatgpt to api well for now use instruct curie to make api call cheap send first few minute of either caption automate transcription to api download caption through youtube api guess what input cost per summary absolutely become very expensive server which fetch summary save in database control how much want to spend in month vs how quickly video add avoid call api multiple time per video call text davinci in reality both instruction tune thus instructgpt genuinely wonder who upvote kind of comment write thread on how to make something like include prompt read on twitter here sure sorry about delay night in timezone awesome please let know please useless title bane of existence need use chatgpt to rewrite post into more clickbait version revolutionary ai tool get real video summary say goodbye to clickbait forever remindme month firefox please make patreon pay for yes please able to help port to firefox soemthe same idea for article headline involve fetch random website extract main article content should consider look at sponsor block how work for anonymize urls ids request to keep privacy heck partner up with somehow please let know much yes life saver what fantastic accomplishment internet person please please please put into revance app even well dumb chat gpt support load each person need api key awesome how generate summary though just rephrase title consider content of entire video use caption something how about edge consider ms about to add chatgpt into well yeah well make chrome extension yes please keep update oh crazy good please want pay for thank for even consider wild to remindme month firefox please what about firefox remindme month please second firefox ton of tech savvy people use ff with good reason userscript remindme month remindme month how apply to browse youtube video remindme week remindme day remindme month remindme month dewit remindme month remindme month by make non click bait video good luck with yep just in video content creator use one weird trick to learn deep secret of universe pretty sure future for everything write law in such way ai summarize wrong get pass lawmaker who not read hate seo not even food s search clickbait remover for youtube extension mean like sponsorblock without sudden cut with more fluff remove how prevent abuse by troll video should min long stuff lot of ad into content of video only sufficient for minute talk minute about non relate stuff tell important stuff at end of video etc not ai expert pretty sure tell ai to optimize for other thing last time check youtube transcript often misunderstood some specific technical termsfor video like programming tutorial should train model to extract term from video description text on screen click theinstruct curie decent enough job see such massive drop off in instruct ability from davinci to curie okay see now text code model size model all instructgpt model openai not great job clarifying which model vs in documentation from what see thus far purely base on summarize video transcript instruct gpt outperform well open sourced model on paper with code remindme quality of summary really good share prompt use what want to know xd to good of understand davinci series parameter model whereas instructgpt itself parameter model to good of understanding of research on topic instructgpt fine tuning dataset not contain enough datum to properly fine tune parameter model far understand text davinci something else entirely davinci instruct beta mention result from instructgpt model not instructgpt itself what difference between chatgpt people who just wake up grumpy remindme month haha think chatgpt refuse to write clickbait title message in month on utc to remind of link other click link to send pm to also remind to reduce spam parent commenter delete message to hide from other reminder remindme month netscape absolutely moronic question please get grip although prefer launch in edge addon store release only on chrome also work in edge relevant xkcd win lose with adversarial attack yeah extension useful feature pick tumbnail from point of video start middle end default change title lowercase capitalize not believe not believe only decent people know about module probably something else downvote upvote feature idea vast majority of people who use use properly never any issue with sure why content creator view generate money what factor to maximise not view watchtime any other metric relate openai whisper use for go to expensive notice same dropoff kind of thing with davinci expensive for same kinda want to know remindme month build something like write about on twitter include prompt read here excellent question in blogpost openai call chatgpt sister model to instructgpt no paper only info from other public communication variant base on pre train with more text code pretty certainly with much more instruct like mode fine tuning censor model train remindme month not worry just pretend remindme month stupid still to chuckle netscape future ofcourse one lol not show up for everyone just for plugin user pretty much not care about ctrs just want to see representative thumbnail not show up for everyone just for plugin user pretty much not care about ctrs just want to see representative thumbnail not show up for everyone just for plugin user pretty much not care about ctrs just want to see representative thumbnail fwiw want to see whisper large transcript for any english video minute upload just youtube link to anyquestionsai transcript show click video icon in search result usually really good for jargon especially where jargon mention in title description comment feed which anybody with whisper surpassingly fast cheap to run whisper base model much fast than real time of video on bog standard cpu also coreference resolution semantic chunking separate consider early one on divinci capture output to fine tune low end model build something like write about on twitter include prompt read here remindme month remindme month remindme month remindme month remindme month remindme month",
  "in long run think something solve with more specialized architecture for run neural network tpus tensor core great first step von neumann architecture hold back tensor core very fast since von neumann architecture separate compute memory connect by bus entire network to travel through memory bus for every step of training inference overwhelming majority of time spend wait on cycle global memory cycle share memory cycle tensor core cycle specialized architecture physically implement neuron on silicon no long bottleneck since each neuron directly connect to memory need weight datum from previous layer entire network run in parallel regardless of size inference fast shovel datum through network model build from ground up on per inference basis line up with sam altman tweet interview recently assume openai use gpt dense model architecture with size billion parameter hide dimension of sequence length of average token per response of response per user million daily active user flop utilization rate two time high than fastertransformer at latency quantization hardware utilization rate due to purely idle time cost per gpu hour please challenge assumption keep hear argument also keep hear model hit of peak throughput for gpu optimization like flashattention other thing consider how much room for alternative architecture current hardware only leave at most of its peak performance on table cerebra why not why not prune why not various model compression trick half latency at minimum mix not distillation use fastertransformer triton inference server time speed up over baseline gpt j think assumption at least order of magnitude pessimistic someone else note vast majority of query cache also likely mixture of expert no need for heavy duty model trivial model answer question chatgpt model ham fiste into google exist search business impact devastating billion reduction in operating income billion of llm inference cost gpu manufacturer aware of memory bandwidth limitation not put in more tensor core than able to feed with available memory bandwidth move away from transistor cuda core cuda core tensor core compare to which cuda core tensor core see just how much of impact new process in allow nvidia to squeeze more component into chip only marginally large than one replace actually less tensor core than tensor core get fast still memory bottleneck no advantage to more of worth note both ms google own datum center hardware likely cheap for to run still expensive perhaps number of unique query through vector similarity search result cache vast majority of lookup duplicate search already materialize openai now introduce premium option suggest market for premium search suggest room for more cash inflow change spend strategy perhaps spend less on marketing more on hardware should expect much high peak throughput number from more specialized hardware yet to hear of any startup in ml hardware space advertising samsung work on in memory processing still digital logic von neumann by put bunch of tiny processor inside memory chip each own memory bus access in parallel most research on non von neumann architectures focus on snn both startup big tech work on analog snn chip far proof of concept work achieve extremely low power usage not at big enough scale to compete with gpu",
  "use coordconv in bart paper on randomize defense against adversarial attack at cvpr need to successfully defeat swirl transformation on individual level work well for say make sense for problem worth look into very easy to apply in experience reasonably effective at its goal find relevant code at all code implementation here opt out from receive code link dm use in past always lead to training instability weird issue sure just need some tweak tuning to get stable never time to fuss with always end up rip out",
  "language model lm exhibit remarkable ability to solve new task from just few example textual instruction especially at scale also paradoxically struggle with basic functionality such arithmetic factual lookup where much simple small model excel in paper show lm teach themselves to use external tool via simple apis achieve good of both world introduce toolformer model train to decide which apis to call to call what argument to pass how to well incorporate result into future token prediction in self supervise way require nothing more than handful of demonstration for each api incorporate range of tool include calculator q system two different search engine translation system calendar toolformer achieve substantially improve zero shot performance across variety of downstream task often competitive with much large model without sacrifice its core language model ability boon to all well document apis miss fine tune gpt j toolformer model available somewhere freak crazy work s all ever need just ask to plug apis all day long output task over nearly exact same idea even same syntax love advancement come out quickly moment idea pop into head probably already partially develop by someone else well than publish open source in month not seem like any of experiment require model use multiple different apis together why need single model for all apis instead separate model for each for all its worth literally ask chatgpt large language model use apis answer yes clearly not new information large scale multimodal model text video sound image with rlhf on top killer still not over no concept of api version compatibility memory time complexity etc definitely useful though true llm hallucinate know anyway connect gpt to anything take instruction in text api home assistant robotic etc different teach gpt to by itself zero shoot delegation of task to different api need appropriate receive instruction like how basically automatically know to use calculator perform complex arithmetic to browse internet to find current information information not know etc literally agi even beyond lot about reality not contain in humanity text corpus nor tech corpus very easily lead to goal misalignment bad teach tool manage thing key value memory api plus singularity et something like hard to imagine world where not human level agi at least for anything on computer maybe not robotic yet absolutely insane to think such system conceivable in year glorify autocomplete miss abstraction reason transformer quite literally transform world not come up with well name for lol think still lack plan ability spatial reasoning certainly assistant dream about",
  "",
  "",
  "link to full game kill people website appear to mobile cancer",
  "poker depend on look far enough ahead to able to play game theory optimal gto move maximize expect value over long run of hand train transformer on ton of datum get to predict context specific play number of possible decision branch grow exponentially enough honestly not know much about type of rl type problem how alphago structure tabular cfr approximate with neural network noam brown author of pluribus co author show in follow up compare apple to orange bit ask transformer replace cfr transformer neural net architecture of course encode poker stuff in text feed to transformer which predict right move to play how train network cfr self play learn algorithm sort of like alphago mct which learn good policy strength of transformer lie in transfer of representation learn over large corpus of text image less likely to bring capability generalise to pocker traditional rl monte carlo approach likely to upper hand pocker challenge not linguistic visual perspective challenge s what iam not quite sure about assume result not close to nash equilibrium not know since not work with transformer before think come down to train transformer with feedback on what hand good which one not look at other response seem like not possible think training part what miss think train transformer like normal neural net in sense tell what output like what wrong look into bit more assume get output nothing close to nash equilibrium thank for feedback technically should possible to train model on hand in mention representation get output valid poker play correct goal not to train to infer not say not work just not see why prior of transformer model work well than rnn lstms in model reward of each play maybe something not get about pocker map game to graph learn through self attention",
  "more precise about what mean by mean distance between global wrt merge candidate",
  "curious about google api pretty cheap free depend on how much need remindme spend time with tortoise tts since yesterday not produce voice yet understand also super slow damn slow on rtx cuda run message in month on utc to remind of link other click link to send pm to also remind to reduce spam parent commenter delete message to hide from other reminder",
  "try tortoisett on high quality set pyttsx mbrola mimic like mimic which lightweight run on docker just native start out with mycroft which mimic build in run just stand alone well quite easy to set up want to go down rabbithole of speech synthesis analsy check out praat praatorg quiet impressive piece of software want ml tts lot of open source model out problem most of train on same datum go to get similar voice option for most part definitely train own text to speech pretty easily well assume not want to go route maybe try start with coqui tt for read long document definitely its fair share of issue use react speech before in project to test mental math arithmetic for example project show card with addition subtraction multiplication division problem user job to speak answer outloud use library able to capture user answer text check whether not get correct something like work for whatever try to speech webkit one look like what look for slow af give book chapter give audio narration seem pretty powerful lot of patience check out look interesting not good tortoisett judge by sample definitely worth look at tho thank probably not want to read long form text such fiction tortoise tts work out pretty well holy crap slow google search not get much more specific yeah speech to text want text to speech thank tho both buddy ah bad must misread take another look",
  "spend hour week on ml powered project for work life far short to start ml project in free time sorry classify try to teach daughter cousin bit about programming machine learning build simple robot with object detection model scratch block programming get to chase after object recognise work fine kid seem to enjoy drive robot around via remote look through its camera more than program image in repo readme work in game dev on side project currently build little newbie ml framework in c to discover ffnn cnn probly rnn m currently struggle on backpropagation in convolutionnal layer matter of time before work hope m very curious to see possible application in game ai already some testing project before simple ml agent with small fully connect network want to go far probly try to mix utility base ai pattern with reinforcement learning method genetic algorithm also think convolutionnal network maybe use to input some spatialized datum to ai agent allow to take decision about movement mess with target sound extraction by add just barebone masknet architechture on top of samplernn want to apply architecture to extract different layer in electronic misic for example pick out just snare drum track from full drum machine mix easy to generate dataset use dawdreamer generate random drum pattern use sampler currently consider add conditioning by output of differentiable filter bank mostly implement change point detection algorithm in some way utilize ordinal pattern analysis work on customer lifetime value project to predict worth of every customer publish newsletter weekday at est call gptroad not ml power yet its gear towards swe interested in ml every letter info about new research publish tooling different library langchain gpt index pinecone promptify etc also cover general news update short should take min to read its bullet point format m swe former amazonian interested in building project use ai figure should version control all research for other swe onboard into new era about sub right now also cause often s damn rabbit hole just finish nvidia come up with same thing just time fast in same boat year in ml business full time get out of work not want to touch anything tech relate not even with stick well classification joke lame just decline to share how progress in company work lot with forecasting prediction model not easy task right work on project also just keep on update in industry right now just write update every publication include new tool code snippet just start last week its evolve next week go to add more ai tutorial video to youtube channel run through how to use langchain to wire up different tool together use with llm for some application think lot of small tutorial in jupyter notebook push to public repo on github include link to script reference in engineering section of email send out to poll audience first to see something interested in first think though",
  "go to find out soon with getty lawsuit until gray area even become illegal democracy of machine learning depend on legal getty win mean few pretty large company only one build large model own most of data facebook for example lot of stuff to prevent people scrape public datum from app legal until court say otherwise million dollar question really hundred million dollar question in term of legal fee remain largely undecided of yet more clear in come month year owner of image who to decide use of image all right reserve mean owner right for any use of image now whatever someone invent in future in ideal world each image of dataset use in machine learning to identify with author license understand difficult to achieve image copy in www difficult locate original source no doubt about illegality of use image from web scrap other thing how easy win loss lawsuit to prove use datum not anyway hard to demonstrate which dataset of model right in case of getty probably get image look like getty image dataset for predictor case for example where not any law predecessor case lose lawsuit to pay on training part probably legal though need to careful about something like gdpr eg for facial recognition extra rule sharing model its prediction gray area edit t ypo legally datum not public fact facebook actively try to prevent scraping make very difficult to argue otherwise legally datum cnanot public user give facebook non exclusive license with limited right to store process datum from not follow right anyone who see share image for example right to process well wasthe case term to state under which license work redistribute by facebook any retroactive penalty million dollar question really hundred million dollar question in term of legal fee worth lot more than profit margin of ai focus company kind of on line here think same for example scrape image from google with copyleft wrong set without info who guilty not really hard model spit out watermarke image not likely find illegal to remove offend image ask in case of predictor resnet other model just categorize say stability not issue hire intern to git clone watermark remover put image through first question use copyright info to train model answer not know yet current lawsuit define precedent on for image generation use copyright getty image in training model prove getty image use watermark show up in output of model many time which answer to how prove once define know legal not in jurisdiction get to anyways even though illegal much hard to prove spend day preprocesse image first illegal now super illegal remove watermark on its own typically violate license of material question same include code in commercial closed source repository remove license header ensure code ris never publish use open laion dataset everybody know what in still some preprocessing deduplication good idea just for output quality",
  "",
  "two should get difference between stat ml large between math apply math aim to answer vastly different question in ml not care about identifiability not care whether gene among million cause specific type of cancer not what ml about in ml also very rarely care about tail risk should almost nothing about calibration really should identifiability out of window soon use neural network prevent from interpret model good question ml researcher typically try to find model which more powerful in term of output behavior whether predictive power generative ability etc statistical researcher typically try to understand dataset underlie generative distribution really dig into what model innard say about datum what conclude from more likely to want to extract insight about datum itself statistician tend to more rigorous about datum more well ground in experience while ml scientist tend to want to push boundary person who read late ml journal piece much say know about something simple linear regression really lot of fascinating math in go much deep than expect interested in just use model to predict not much of interest in linear model really want to know what mean extract from whatt go on inside exactly why learn coefficient what learning dynamic what result mean etc end up write paper on lasso both side valid most ml scientist suck at job must say though pretty famous stat professor once tell should switch to ml long time ago now ml research obviously very rigorous say stat make up question to large extent not practically useful kind of odd question many statistician actively research in ml delete very simple idea not correct ml more datum drive statistic more hypothesis drive like different stream joint to same river not separate again find same thing in ml at some point folk find quaint people spend whole career dicke about with convnet reduce to historical footnote by whatever come after transformer different goal different tool where at statistic what co worker call what machine learning what go in grant application sure differ across region faculty industry whatever delete statistician care about inference ml scientist care about model specifically not think ml researcher not care about model calibration tail risk just often not come up in experimental setting also depend on objective goal regression classification tail risk model calibration necessary support metric for more abstract use case such generative modeling debatable tail risk model calibration actually matter for example gans model experience mode collapse such generate data not diverse original data distribution not mean model totally garbage either also not think statistic ml totally different most of statistical fundamental also ml fundamental such many of ml metric directly derive from fundamental statistic relate field agree with size of difference yet disagree with example ml research consider all causal ml conformal ml prediction forecast ai safety reliability etc think difference more like deduction induction in sense mean process of find answer different since finish poope on corporate time keep short datum method hypothesis answer hypothesis method datum answer simplistic please propose well distinction not postulate ml not care about thing statistic should say between pure mathematic apply math imo nit picky yes more accurate care to elaborate on last sentence while ml scientist tend to want to push boundary person who read late ml journal piece lol easy tell neither in field nor actually know any ml scientist stat find interpretable way to look at mode datum ml plug chug cs people not cite paper author write power law scaling with model dataset size in density estimation connect with result statistic use literally everywhere include in application fall under ml umbrella what think people with datum for last century stat tremendously useful especially dataset small by ml standard basically every scientific paper rely on statistic to tell whether not result meaningful ml great million of datum point only hundred not go to help actually opposite stat how design study which what government economy pharma medical field most science run on ml just use for predictive modeling in low stake situation fun tech demos make zero sense right point make in ml in general not of high importance already hold for rather basal question like for choose learn algorithm under which condition hold in expectation over all training dataset of size n baye risk not monotonously increase with n one think question of rather central importance yet no one care answer question non trivial for linear classification already stat care lot about question while math behind both field same all apply math subset of math except people who identify one of both community different goal sorry wrong translation from how say over here guess ml scientist generally care less about statistical rigor which lead to poor outcome due to not properly understand datum assumption risk involve etc zillow right mean most people suck at job period though most ml scientist not actually fluent in application of algorithm use superficial understanding slow buggy programmer write slow code spend month work on model should take few day to put together overindex on hyperparam selection tune play with new algorithm not know how to validate model end up deploy garbage often literally no well than coin flip great at convince people right on cusp of solve really big problem add ton of value which buy enough time to fart around for few year get another job with raise all over again not say conference paper mean principal machine learn scientist at very well know company also kaggle master read lot into few word crap out in reddit comment just communicate what ve hear nevertheless think whole interpretable ml community at very least disagree with on one reduce ml to plug chug well speak for itself d delete d lol whole landscape of ml research hunt to chase sota by tweak architecture here use different optimizer squeeze out accuracy on some well know imaging dataset in attempt to churn out paper not science ask right now basically all progress with large model mean all progress in machine learn lot of scientific field necessarily must make with small number of datum point not test new drug on million people especially in early phase trial even outside of medicine very few sample study rare phenomena statistic give tool to make limited conclusion from small sample also measure how meaningful conclusion actually only correct for certain problem like everything good use case only hammer everything look like nail in medicine backbone of clinical trial result change field rely often on patient datapoint often groundbreake achievement in medical practice make by simple statistic simple method go to new england journal of medicine pick any trial weight of conclusion base off of survival function hazard ratio chi square statistic go look at funding section project fund by million only discipline in medicine with ml datapoint epidemiology claim level datum which stray way into econometrics study rare disease well ai ml application in medicine for some project stoke to get patient just simply not many around not sure good overview of ml research claim sound like read many blog post on transformer suggest go through some conference proceeding to get good overview some pretty rigorous not just stat stuff out agree though substantial subset of research in ml work towards tweak push boundary of what achieve with exist method which for personally exciting to see lot of cool stuff come out of scale up tweak architecture delete delete all model wrong all model wrong common aphorism in statistic often expand all model wrong some useful aphorism acknowledge statistical model always fall short of complexity of reality still useful nonetheless aphorism originally refer just to statistical model now sometimes use for scientific model in general aphorism generally attribute to statistician george box faq opt out opt out of subreddit github downvote to remove eh not care enough about to argue",
  "remember correctly approximately same thing except scale up down in well way use multiple trick to improve training understand understand model of efficientnet efficientnet more about how train scale than just about backbone",
  "share link to hug face model see how help check out triton for model deployment interested in reduce latency just cut down cost run workload on gpu instead for bert type model some compression use inference library easily get speedup interested happy to share more resource on sure few link all of inference speed of second call each checkpoint like nlp pipelinesentiment analysis model checkpoint tokenizer checkpoint thank thank for idea much thank for reply love to read resource on compression inference m keen on cut down cost previously run on gpu via aws instance get to tighten company belt year manager suggest run on cpu love to hear suggestion any use octoml platform to optimize model get average inference latency down to on aw gpu on ice lake cpu get latency down to assume shape of for input input ids attention mask token type ids want to confirm actual shape compare apple to apple know what shape use depend on what model use for most transformer run on gpu much more efficient than cpus consider m inference inf specific instance to use deploy on any instance result above for pretty easy to use platform to automatically same for other model discuss one also later once figure out one",
  "hello gradio maintainer here something currently investigate no eta on radar pick up some rust on side make some small wasm app wonder helpful somewhat tangential not use gradio use streamlit in past to build web app use python remember code turn into mess by try to manage state base on user interaction appreciate briefly comment on where think gradio well see mention far more often than streamlit curious",
  "yes example actually not all impressive google demonstrate llm significantly improve decision make for real world robot give type of common sense check out palm saycan which collaboration of two model perform real world robotic task through assistance of language model what standard modeling approach to kind of problem standard approach reinforcement learn work not very sample efficient take many iteration to train llm probably good at of strong meta learning ability during process of pretraine not only learn task also learn good strategy for learn new task some really interesting implication pretraining seem to drastically improve sample efficiency even pretraining on very different task maybe pretrain on very large amount of synthetic generate datum before real training on finitely sized real dataset language for long term planning in minecraft guess similar to trend see with decision transformer how propose practical alternative for rl alpha family of ai create to decision engine think monolithic llm not effective use delegation to decision ai model wonder llm model able to play chess any well than rl model imagine need to serialize board into natural language format not clever enough to fully understand what require curious to see how lm behave in dota set iirc openai bot rl base take lot of training cycle not generalize all well to different style of adversarial play some of quality suggest by paper link by other commenter seem advantageous anybody else get text adventure flashback try to make decision transformer not quite figure out how to prompt train on chess dataset of state reward move not know how to prompt with reward like make wonder pretraine make model converge on essentially more efficient architecture use instead hope thought already explore interesting to read about cool train with algebraic notation feed all game see how go make llm self play chatgpt emit notation all generate illegal move after some correction actually propose correct move here prompt follow series of chess move after what good next move next move depend on playing style strategy of both player however here few option often play in position flexible move allow player to develop bishop castle kingside also useful to control center take pawn on lead to tactical strategic advantage for white move open up c file create strong pawn structure for white develop bishop to help to control center prepare to castle kingside prophylactic move to prevent black from play which nuisance for white important to note all move potential drawback should evaluate base on player individual preference position of other piece on board black response some of move illegal look at board again apologize for mistake here correct move in position some of most common move flexible move allow player to develop bishop castle kingside also useful to control center develop bishop to help to control center prepare to castle kingside develop queen to help to control center prepare to castle kingside castle kingside common move help to get king to safe square connect rooks important to keep in mind move should evaluate base on player individual preference position of other piece on board black response no open move thank for correct here move give in position some of most common move for white flexible move allow player to develop bishop castle kingside also useful to control center develop bishop to put pressure on black knight on develop queen to put pressure on black pawn on prepare to castle queenside take pawn on open up center create strong pawn structure for white important to keep in mind move should evaluate base on player individual preference position of other piece on board black response prompt by reward let say top reward predict modelpast history state move probably only case in which very low compression ratio of model parameter to learn entropy basically model many parameter distil find empirically until point hit transformer scale extremely well generally well than any other know architecture another topic sparsificafion which take train model try to cut out some percentage of weight minimal output effect fine tune model check out neural magic online associate work run model on cpu normally require gpu not reason spit out semi random move keep give more more chance increase probability of get set which some legal move consider high level idea no way transformer end all all model architecture by identify mechanism large model learn hope well architecture find reduce total number of multiplication sample need for train like feature engineering know any paper relate to work magic sound deceptive",
  "depend on type of learn task go to set up in any case to very careful label for layoutlm give due consideration to fact word position extraction assume use some ocr tool like pytesseract in labelling process inherent error bias also depend on number of entity tag go to label final label dataset not skewed label distribution most probably thus to once again keep tab on metric go to use how need to cv under skewness like resampling other class weight regularisation technique probably need to spend most of time think about clean label dataset combat skewness sound like good start to here some thought many time job resume use unusual language express requirement requirement contain qualification year which hard to tokenise to really impress take special approach for good approach to compare semantic similarity of top topic requirement use sentence transformer for item highlight where gap meet requirement make quick application last point at revisionai cv upload pdf job description just use plain text no ocr layoutlm highlight requirement meet miss good input datum start for something like xgboost model to categorise deep analysis let know want code initially speak seem good enough for some paper propose same two step approach take look however out of curiosity resume parse yet extract text from raw document any analysis in datum particular reason why choose layoutlm over bert m say depend on property of resume either good bad time thank for answer wow thank love to code possible well resume not parse yet label by hand not really see how what analysis on just want to try approach to use computer vision visible information nlp algorithm not get to process which make result well wrong sorry for late response live inside label studio day just to help understand well not parse yet mean not in txt format how label datum over page image what mean by parse pdf docx document text file not pdf document section also label studio very good in experience extract text from pdf use pdfbox pypdf reading order vary lot not necessarily what see how datum encode analysis talk about to verify behavior document parser very good at handle column layout however get mix result deal with column more complex layout what happen all section header go to start of text for example really depend of course resume in doc docx format not problem at all reading order should fine most resume use column layout should also fine which what usually happen wrong layoutlm still nlp no model similar to bert add bounding box image crop embedding relate to each token right approach different than model problem document layout analysis task for example where use object detection segmentation algorithm yes dataset not parse bound box on each zone of resume contact info skill education most of resume french resume single page convert to png jpg to labelise think layoutlm specifically design to process document with complex layout s not general purpose bert hope work m try approach first not work opt for more classic way by turn resume into text ner directly on whole text by layoutlm mean yes soon later need to parse document to get bounding box image text of each token see in figure at end of day need to classify each token individually work just use some pre train model from huggingface all right probably get accuracy ever need some pointer paper name information extraction from free form cv document in multiple language also some blog post by nanonet document parser company such layoutlm explain how to ocr resume use intelligent automation need any help feel free to just send message thank for insight very helpful look into update post get some result",
  "simulator in rl use fairly common in robotic vehicle automation task usually classify under pomdps partially observable markov decision process mdps markov decision process use state fully observable in other word finite number of possibility pomdps on other hand use infinite number of state not knowledge of actual state in such case must rely on sensor datum input to ml model common pomdp model make use of rnn take sensor datum input output belief which represent state model believe in belief use input to different network make decision simulator play key role in pomdp training due to many reason first simulator run at much fast speed than real world mean not need to manually setup robot over over let computer all of for while sip coffee second simulator allow for more efficient reward function provide more than just sensor datum detect exact contact point how close object basically anything think of finally simulator able to simulate absurd situation not feasible to arrange in real world for example tesla autopilot train on extreme weather condition wild animal cross highway",
  "read paper mulan contrastive audio text network train on million of example from internal dataset clip for audio not sure any of lucidrain implementation able to reproduce result try stylegan while ago work pretty well more interested in try model than in exactly same result",
  "want to estimate how fast model well off look at flop than at parameter flop mean float point operation like multiplication addition correspond to how much math cpu to to compute model prediction number of parameter just mean how many number define state of train model how big model in memory two correlate since lot of parameter probably some math with all of take long flop matter more story even more complicated of hardware optimization not all float point operation take same amount of time also depend on memory access pattern other factor see paper on optimize dnn for different hardware flop definitely well proxy for computational cost than number of parameter amazing answer give lot of help thank keep mind of comment also go through paper relate to optimiazation for another hardware",
  "",
  "amazing warmup time annoying actually fast enough to use for live stream now wait minute need to work amazing post very informative thank cuda graph require to capture graph per input tensor shape non negligible warmup time measure around on different machine gpu down from in previous kernl version one user report with new version bit more than of warmup time aware of obvious way to decrease significantly dumb question what mn millinecond love write up pommedeterresautee especially fact write with human in mind mean compliment see vast majority of stuff concern cuda low level optimization impenetrable periodically check kernlai to see whether documentation tutorial section expand advice put some real effort focus in to example tutorial key for optimization acceleration library e user of library like much more likely to come from spend out of every developer hour write tutorial oppose to spending of tutorial writing hour on develop new feature only small minority understand how to use apply very interesting thank for sharing any more detail on rtf vs accuracy curve also run on any other data set librispeech even other piece very clean simple datum from acoustic linguistic standpoint really interesting to see how well hold on noisy spontaneous speech like conversation whisper cpp comparison amazing c implementation on cpu on par with python implementation on gpu just mind blow how much gain from use c for sure c way hard to code interesting any good resource for learn about ptx sass instruction play around with triton bit not even clear to where see output amazing support whisper package directly instead of whisper in transformer from huggingface know not just for whisper really need to speedup whisper lol unfortunately no minute use cg not affect output quality what work with whisper still work with cg whisper just discover project write in another comment no way for recent cpu even arm one to fast recent gpu on such big model list no gpu support in limitation say project look super cool tks for pointer order max lot of fun to come on large dl model like whisper large cpu never on par with gpu cpu latency orient hardware gpu throughput orient only way large model run on cpus by reduce number of operation to perform like by sparsification pruning moreover pytorch mostly c with python layer over for now at least pytorch start of change in architecture python layer bring most of pytorch latency even c engine launch operation on gpu not on par with cuda graph most of time at least still to send instruction at time still some latency overhead associate in run thing way just much less than python with cuda graph almost none at allthere second thing not discuss here graph of instruction optimize main drawback of cg memory overhead need at least to double space take for input tensor on generative model with k v cache matter explain in post plus need to copy input tensor which offset very small part of gain at least s what see in test on whisper bert roberta why tensorrt big c piece for instance support cuda graph still tbh point out most important thing easy to build run already exist c cpu only implementation of whisper really to wonder why everybody use torch stupid trillion dollar company just run everything on cpu only hire c devs billion of dollar down drain really unlucky nvidia doc obviously for sass light also some old blog post very detailed for shuffle instruction etc write at top of post unfortunately way openai design whisper make non compliant with pytorch people at openai say rework package pytorch release able to optimize probably question not well formulate just curious about what rtf vs accuracy tradeoff look like not question whether work just curious what actual performance look like report on memory usage beam size well relative speedup interesting to also see wer performance well actual absolute rtfs python layer bring most of pytorch latency actually not true believe most of per operator latency come from c yep use really good for inference training inference anyway whatever reach with cpu inference time training still benefit by use gpu from parallelization cache forgot to cite most important paper tks after some search find french practice to use mn instead of min tend to replace even in france by min for point identical not use quantization anything hurt performance whisper paper lot of detail ask for guess well know than which part dispatcher thing spread on several step interesting talk about paper miss not find any place in paper where talk about trade off with respect to real time factor decode strategy rtf vs acc curve for cpu vs gpu for stt typically vary not in term of absolute performance in term of where along rtf curve achieve particular accuracy impact what kind of task expect to use model for how expect to scale to real world application far weak point for all whisper relate work still well off with espnet speechbrain etc information interesting to see lot of thing see flamegraph take from about lot of other thing need to go on infer dtype error check build op allocate output tensor etc",
  "some dimensional understanding up down gravity seem possible think example of light shadow reflection already show not see how ever full tracing maybe heuristic overfitte to find parti show able to spell emergent ability only one know of other imagine learn compositionally blue box between yellow sphere green box more likely data issue also work out of distribution green dog potential candidate interesting question emergent behaviour call such not yet ability to predict only observe deduce where emerge after fact fact not wrap head around what such ability look like make perfect sense speculate put money on answer bet one of model start integrate some intuition of physical law shadow way light interact reflect refract seem to emergent behaviour of diffusion image model ask for koala next to glisten wine glass probably get cool optical effect on koala model never see before yes dino paper show ability to perform segmentation emerge from self supervise vision transformer oop not realize say image generation model think ask for just vision model pretty sure anthropic paper first predictability surprise in large generative model make truly wonder wtf exactly go on in google lately to question no one stack enough attention layer yet very high probability someone already mention ability to spell potentially help with thing such hand number of hand foot leg arm paws tail other thing make lot of generate image today disturb issue most likely with fund enough datum give unlike text most image on internet copyright cough getty cough in vision ability for large model to video segmentation somewhere in people should more skeptical of emergent ability in big paper claim such ability generally use undertrained small model per chinchilla scaling compute not control suboptimal hyperparam choice for small model paper generally use semilogx plot to demonstrate emergence even linear relationship look exponential in such plot not sure want to call simple linear relationship emergent another emergent capability depend on model architecture for example not think stable diffusion dalle to generate write letter caption to look like gibberish actually correspond to internal language embedding for real world cluster of concept combine object style never see together in training set in plausible way baby daikon radish in tutu walk dog denoise diffusion probabilistic model rdiffusion generate music from stable diffusion improve image segmentation remember someone image segmentation on generative model not sure where wow very cool counting probably get cool optical effect on koala model never see before how absolutely certain model never see say effect yes sorry not see while on same topic very different paper anthropic paper spend most of its time go on about safety bias toxicity while google paper focus on more useful thing like technical ability of model not sure emergent ability much explicitly what model train to learn not surprising to painting signature concept learn sample from generate gibberish of particular length size in bottom right corner for example sound like one of easy concept learn dayum just sound like generative communication mean take mean vector of cluster make up word for think about again another candidate all llm prompt for screenshot of python method xyz good solution image contain work code search training image database for picture of koala with wine glass not many example in check each one exactly beginning clip part of entire dalle model train to take any english text map to embed space completely natural probably surprising not happen clip map some gibberish word to part of embed space sufficiently close in distance to projection of real world in case diffusion model decode gibberish word to similar image generate by real word similarly to how zipped email archive call generative communication word not correct imply consistent alphabet semantic aside yes believe what happen language model without token use raw pixel of image with text not find link google not help much hmmmm hmmmmmmmm to search million to billion of image manually sound very expensive search use detection model not accurate enough sound like story of guy from who pretty much look for underlie connection between all different kind of beauty joy find alright",
  "not mean thursday february remove date correct should look backward",
  "with constrain optimization usually feasible set for variable optimize in nn training optimize million of weight not directly meaningful in general not clear define feasible set for each of say most deep learning model use some sort of regularization at training some implicit constraint on actual value of weight even more number of parameter go in range of billion where inherent statistical distribution of feature importance on more explicit fixed side couple of paper effort in area of quantization where parameter outlier in various layer affect precision of quantize representation want reduced variance in block layer value for example check bunch of cool work on use constrained optimization layer in neural net differentiation through argmin not sure answer question get constrained optimization in general for unconstrained nonlinear problem see work n sahinidi on baron feasible set define in course of solve problem introduce branch both slow not scale to nn size not really answer question ml folk ask see talk at ias on optimization right language for ml exactly mean easily define constraint for weight of network constrain optimization which at least theoretically equivalent to regularization weight decay not quite useful wonder whether application of constraint where actually make sense in early day researcher consider architecture itself to form of regularization lecunn not invent popularize idea convolutional layer like lenet in case like fully connect layer constrain to only allow solution where layer weight express in term of convolution kernel in introduction resnet also motivate by fact constrain to start from well minima even though also convert resnet model to fully connect model without loss of precision link find more from example just need thread to pull thank any link great here one to get start",
  "chatgpt",
  "",
  "pm",
  "definitely okay to use psu affiliation add note say while independent researcher not obligate also put independent researcher affiliation wish very few people care well ask advisor what think anything make more inclined to pay for definitely almost odd not to see contribute to work eg build camera ready while affiliate not add now pi correspond author think very little risk of add psu affiliation still well to ask advisor just to safe after all lab pi one who hire now",
  "cpu bottleneck depend on model training process remove all most of preprocessing on cpu fine think transformer not usually bottleneck on cpu quite old model sufficiently large not not really need to wait long anyways no expensive cpu pre postprocessing bottleneck single not enough memory to train gpt large probably close fully train llm on single impossible finetune one depend on how much preprocessing augmentation need not think text need much preprocessing augmentation for example image classification detection training need to create different augment image on each iteration benefit from more powerful processor note also use cloud service not deal with confidential datum vast ai often one of cheap otherwise use lambda labs google engine aw other service at least in case of google engine aw to request access to gpu instance which take some time what about save dataset into batch individual file use datum loader to load file batch for transformer keep batch size reasonable for gpu memory for any preprocessing scale on cpu side not consume much memory little bit bottle neck close to bottle neck just buy damn thing work bottle neck just chill buy some old machine like amd series more core cheap exact setup want to try something out happy to try run motherboard quite old good cpu attach yo from what read process dataset before training than should not bottleneck what think preprocesse dataset hold in gb of ram cpu transfer datum from ram to gpu memory only thread let s say want to train from scratch not know exactly how much cpu ram frequency bottleneck training process fon t want to change whole hardware rtx to performant bottleneck to high wonder buy really appreciate try to finetune xxl flan model from huggingface on hardware curious work big bottleneck thank at start weight move on gpu during train tokenizer convert string to tensor quite light move to gpu during training what need not fast cpu one which feed gpu fast datum consume in case cpu like not issue image sound tts asr more demanding preprocessing during training okay try out few day out of town atm thank for effort",
  "recording not confidential process for not ready to publish model yet prefer public model one pretty upload sample bandwidth issue booming mic issue crack pop issue etc nvidia rtx voice transcribe put transcript in tts try denoiser from facebook use for own lecture more than good enough to make up for poor microphone background noise try for free on own audio sample see for yourself try formerly adobe shasta give good result for greet again help with sd follow account last night notice post recording musician though able to help out with issue here result after use audio editor reaper to apply eq compression yep not confidental how reach here email monstermmorpggmailcom mailto monstermmorpggmailcom nvidia rtx voice example link download extract audio quickly wish also here min example speech also interested in process two recording both little over minute in length feel please contact at e mailto bnahrwoldgmailcommail address remove thank think previously reply also interested in let to try clean up two audio file know go public both over minute record in car microphone hold close here example lecture clean over here min example part of video pre record how use to process recording fast what mean by transcript what to thank denoiser need post processor for exist recording work for give link test improvement for audio test from here audio editor reaper to apply eq compression make video watch show how to d wow amazing how contact to email monstermmorpggmailcom mailto monstermmorpggmailcom discord monstermmorpg audio bit distorted possibly due to noise gate not see much noise maybe noise reduction not what need audio khz bandwidth khz sample rate maybe try to use audio super resolution network such to increase audio bandwidth anyway here denoise audio of example no improvement good bet audio super resolution speech noise overall speech noise overall pls upload somewhere preferably wav format time instead of try to salvage original recording why not recreate by put text transcript into text to speech model transcribe not even need to any advanced speech recognition filter noise just paste text into something bit more advanced than microsoft sam pretraine model on recording see good of luck with other solution hey seriously ever interested write something up need to anyway for future reference mechanic of sound what musician all about yet shockingly few actually trace craft back to root simple physical property of medium not put email in public like dm guy remove email while still eq compression good technique to try reaper free sure friend show monstermmorpg eh very interesting d yes try some option obs back in time probably noise gate even forget thank much for reply go to test repo now example really good improvement need training for open issue thread not much hope audio super resolution thank much for answer test any idea to get super resolution only option mindslab ai thank upload two audio file in wav format to google docs need email address in order to share with how suggest get information to what about synche how to solve synching problem not find any way to re voice with proper synchronization prepare perfect vtt file how to sync with video thank much test with model pretraine cuda good pre train mode thank for try to help fine public email thank for warn ye game develop just download checkpoint use command at inference session sr should speech to text lecture collect timestamp same with tts automagically sync way not sure while since last use yes well large than other pretraine think oh wow not wait to check out just tell son about old day of telnet gaming of which dabble in member of old school post telnet early graphical mmorpg call dragonspire which itself spawn furcadia now long continuously run mmorpg online last time check something like go on to help run player world base mmorpg call delrith online seem like long ago now thank make work however get out of memory error on rtx gb vram like joke vtt file know subtitle use for movie not find text to speech generate speech with timing know any about suggest approach any way to automatically mean generate speech sync how thank also very old school text image base extremely in depth game mechanic process with slide window solve problem see not sure how go about sync adequate workaround break apart script in small chunk by time stamp generate different tts recording off of each time stamp generate audio file insert each of produce recording at respective time stamp location replace audio of recording with newly produce recording bookmarke definitely fire up take spin probably steal borrow some idea for scratch project thank no idea where to put code in logical layout any software think more likely task for python not anything like just approach start with only not c programmer python programmer check out murfai service work similarly to what describe test look awesome to purchase yearly plan which lol d",
  "hard to tell without see actual code unet most likely use convolutional layer simply slide through input output progressively small image again progressively large image for image convolution usually get away with semi arbitrary input size since through model all matter consistent look at graph of how convolutional layer slide try to get well intuition approach similar to one at link in case training on 256ximage image use at inference tfrecord export from google earthengine each image in tfrecord pixel padding on each side of square to minimize edge effect in code apply modelpredict to padded image crop out pixel pad afterwards question what happen behind scene with modelpredict function use slide window scale down backup why not throw error shape incompatible know at training get pretty finicky shape mismatch hope provide enough information thank",
  "just some only one author on paper previously publish some outlandish paper like deep neural network more accurate than human at detect sexual orientation from facial image paper widely report in press imo methodology garbage train classifier use supervised learning on self take image collect from date site facebook group supervise learning only good dataset spurious correlation in demographic clothing network use to solve problem not test for generalization against out of distribution image like driver license photo here administer standard psychological test question to gpt language model think much differently than human able to complete task without internal representation of other people mental state not think experiment rigorous enough to rule out like claim chatgpt lawyer take bar exam unfortunately pretty good at get medium attention expect nytime to report on soon while such result should interpret with caution think author need to take own advice result present thus far suggest gpt aware of bag actual content anticipate sam incorrect belief aware anticipate antropomorphism language in text talk about mind clearly abuse language still understand limit of what say in quantum physics say system choose state know not strictly true deal with such topic intelligence tom one need to bit more careful people already bit hype just no every llm isomorphic to biiiig case statement most reasonable ppl not believe case statement theory of mind remotely conscious fact complex neural net not solid theory work out yet give rise to mystery for some mystery overtake imagination lead to spurious conclusion every deterministic llm implement fix precision bound in space time isomorphic to case statement view mapping of input to output llm effectively compress form of lookup table administer classic false belief task widely use to test tom in human to several language model without any example pre train result show model publish before show virtually no ability to solve tom task yet january version of gpt davinci solve of tom task performance comparable with of seven year old child moreover its november version davinci solve of tom task performance comparable with of nine year old child finding suggest tom like ability thus far consider to uniquely human spontaneously emerge byproduct of language model improve language skill more like theory of ligma language model think much differently than human well citation need rhetorical just mechanism different not mean process indeed tom test inadequate to distinguish feel free to propose well one most apt way of describe new llm ve hear hyperintelligent year old who read whole internet to honest hard time argue with with quest of reach something akin to agi to admit at some point blurry line regard first paper sound like good improvement for follow up replication study assume people get well at research over time rather not focus on paper co author year ago m not sure understand criticism of paper though discussion section say one interpretation tom not require in order to successfully complete task paper suggest force to re evaluate test research depend on alone value directly impact autism research",
  "r lostredditor",
  "find relevant code at all code implementation here opt out from receive code link dm clever like overall quality seem below able to accurately follow prompt improvement mean to post abstract code come next few day look like bad absolutely terrible at follow prompt even most basic one one follow even at low overall quality still improvement mean bad judging purely from quality of example image find bad on some technical level get solid result with former for not think tech new not cross attention control whatever call thing for few month already definetely get solid result with truth simply not work lot of time something simple close key very high chance of not work make hair red make stand up on only complex prompt understandable for to unable to generate even most basic of prompt consistently make definitely flaw even get right look well than other",
  "whole point of multiple run to learn distribution uncertainty report only max dishonest how test want to use boxplot see report mean std in table for plot accuracy per epoch wonder should use mean across each run good run for plot only communicate uncertainty in plot easy option plot mean with sd band around plot all five run in same color with reduce transparency not cluttered lift credibility of result ton",
  "usually mesh generate from image well find source of datum create model to reverse problem even want model want to train test need ground truth for generate mesh from lidar datum image from camera very likely two sensor fix on same frame case want to cross calibrate sensor in any case ask yourself what try to solve geometry statistic problem statement sound like deal with geometry specifically with projective coordinate group for ground truth use synthetic datum generate with blender model base of big project thank for feedback",
  "",
  "try autoencoder with cnn layer bottleneck of neuron to able to visualize embedding autoencoder interpret non linear pca also similarity in embed space should correlate with similarity of real image whatever cnn extract from real image want to model pcluster c img p dist d in in try couple thing frechet inception distance instead of inception model use medical cnn activation distance metric learning hdbscan umap etc for cluster persistent homology base topological datum analysis method for find cluster mask autoencoder for good feature extraction jepa style architecture how plot embedding in exactly what size of embedding try to visualize pca on time complexity instead of why not pass embedding through autoencoder use some part of train model to avoid retrain from scratch current model very decent precision generate some other visualization for like heatmap work around model very convenient add image of well embed find until now reference not find very convincing embed yet try several go from feature class activation map to feature output of last convolutional layer before pool all generate from full training set sample in all case same use pca to reduce vector to feature umap t sne usually try both to get vector scatter plot try to use umap for full process not escalate well enough good approach add image of well embed find until now reference try encoder decoder architecture mainly to try to improve embed right now asymptotic of pca not prove problem sklearn implementation perform pca on feature vector almost immediately any reference on any encoder decoder architecture use take output of layer of choice from train cnn now feed into new model autoencoder yes weight from model keep to train autoencoder from scratch something like cnn only inference no backprop decoder latent space encoder for training during inference take output of decoder use for visualization similarity individual step sound okay however project to result get look very reasonable not sure about umap think for tsne recommend to low dimensionality something more in order of feature probably try to adjust architecture other comment suggest okay cool yeah kera basic encoder decoder architecture in its documentation not something like always ask chatgpt yes great idea guess use encoder decoder to create very low dimensional embedding use current one feature to find similar image to give one right perspective really helpful thank right both tsne umap documentation recommend go to feature before use in case result quite similar to one find though think underestimate curse of dimensionality in most vector far away from each other not just use norm compare vector in high dimensional space guess use encoder decoder to create very low dimensional embedding use current one feature to find similar image to give one right exactly yes think case get far more reasonable value compare projection to of embed rather than full feature vector well way to than project into small space use reduction dimensionality technique encoder decoder approach use",
  "own unit of model size in divorce lamda divorce two pende child custody case get house in three of synapsis not only potential parameter in brain neuron modify genetic expression depend on number of factor include what neurotransmitter recently bind to similarly not all parameter create equal lead to false equivalency in some case for example both categorical functional degree of freedom in system act learn parameter bit simplistic for taste",
  "",
  "question abstract no single framework fit all problem not answer about use rapidsai use for for dataframe manipulation on gpu also look at dask add in pyspark well",
  "give absolutely no information about what want to what project no recommendation give well than random bruh like anything eg image model story model resume make model like bruh like answer question like totally like future",
  "lot to choose from vector look like what intend to with cluster index how many how obtain what represent what type care say about both magnitude direction try with euclidean distance not cosine similarity settle on euclidean distance weight euclidean distance need to fast recommend amazing mass algorithm take squared difference inner product between metric tell projection of one onto other whatever space build reperesent try cosine similarly use cosine similarity classify some datum point anomaly in timeserie datum calculate feature importance vector for now want to calculate similarity between two anomalous data point base on feature importance vector well also depend on whether sparse vector not some metric work well for sparse vector other work for dense vector check out scikit learn pairwise distance metric to understand well",
  "",
  "lol want trillion dollar interesting take by getty mean sue for unlicensed use sale of copyright material which happen pay per image wonder how many of image actually public domain picture anyone remember try to get author of some picture to pay for work donate for public use use on own website demand zillion dollar sir not real number okay okay umm trillion dollar company build its business on sell public domain photography want compensation for someone use photo lol getty image bad once claim picture customer take own guy take picture of monkey on trip to africa know for sure take off camera use on website getty try to sue understandable really put lot of energy into curate unique collection of people hold musical instrument wrong getty terrible company company ask court to order stability ai to remove violating image from its website never mean laion not stability ai on website only torrent file which point to torrent with list of url mean model checkpoint well on huggingface site checkpoint image fine someone else illegal getty undoubtedly pay more to pac every year than another uppity little computer company just curious why shop in uk to buy decision getty image big ripoff of all artist content creator deserve anything happen to hmm what about midjourney sure use behance dribble getty pexel each frame from all disney movie to train lol owe trillion lol how many image gettyimage steal themselves lot of copium maybe clever pr stunt to appeal to dwindle base write on wall feel like go to next kodak attn now witness getty death throw almost none of comment ml relate anymore dare say eternal september same company which reason tyou not find original link of image in google image search getty stare into abyss who need get stock photo tailor specially for just by put some word whole business model obsolete every dinosaur not fight with technology viable business model fight in court still important lawsuit determine ai learn from image legally copy image more akin to artist look at thousand of image paint something in style getty image sue yet again for try to license public domain image to look at image take inspiration from create own original image should sue dumb photo taker man with good camera happily donate time resource energy to contribute image to someone who create fair trade stock image website for machine learn even for bare bone livable wage to full time dedicated source of image to train off of machine learn community new start up evolve together expand in peace want technology to grow not its pant sue off by corporation organization with hurt feeling not profiting from financially just make ethical call to all photographer d happily offer all image take more specific one mean benefit from technology in long run stable diffusion hit up camera lense seriously someone need to get on turn off by of all controversy over copyright strike everywhere restrict any sort of technological growth in all area of life its not rocket surgery ethical make some honourable adjustment both party happy with shake hand move on grow up not business anymore its kindergarten its about who all sand no one else allow to play with until someone to create open machine learning database for sort of thing where photographer donate towards natural next step of evolution in regard to technology without risk of repercussion unethical profit all lawyer getty idiot develop stock photo website in part of tos something like image only access view for purpose of evaluate want to purchase license cheap license for mockup getty language case slam dunk not just return lol getty whine about image steal steal remember see something like lady donate some image to city council getty image sue something similar never perceive in good light nobody like getty image anyways hope end badly for next come after people with photographic memory look into image get idea from not steal irony before stable diffusion even happen approach by head of ml some unrespectable nobody in field add at getty image want to train text to image model on measly million image getty suck bag of big ole d bad than music industry seem to by make image browseable reasonable for someone something to see inspire by stupid also stock photography stupid ya go hate getty image what claim true why hard to prove legal process of discovery allow prosecution to get look at computer backup drive perform search on computer on conspire to wipe file evidence in backup on crime of obstruction yes end up hard to prove need people group to go along with typically without anyone object snitch to prosecution catch judge throw book at whereas comply with discovery guilty of something judge still lenient tell getty unreasonable out of mind in demand honestly want getty image to lose only for another company to win by similar reasoning certainly for law prevent monetization of ai train on datum own create by someone else make deeply uncomfortable suit happy company like getty lead charge nope ridiculous fair use lawsuit not go anywhere not sure someone else mention not number out of thin air typical copyright infringement fine range from getty umage suck proverbially ai generate leave nut need to move past ip speak with one of vps last month not even know what stable diffusion actually to google smh what loser of company here image culprit how much buy getty for support any president promise to dismantle getty except trump to promise to preserve to get vote know live in opposite land almost trillion dollar for huh paper out currently claim to able to determine image memorize by network however not immediately clear method reliable at least not last time look maybe thing improve since even method work well simply mean people go to start look for way to de memorize specific image while preserve performance on general image legitimate reason for something like secret sauce know what image to train on not want people to learn about trade secret in practice mean bad actor able to train on image should not hard to prove at some point mature information theory relate to memorization method provably obliviate memorization of specific image use whatever image datum like free for all getty pure evil want to own all image in world disclaimer in term of use not measure trend in image to train model just say not reproduce image out of luck not what just publicity stunt no real mean good oof wish internet creator put user agreement not bring copyright bs on internet weird ceo of getty previously say not interested in compensation rather want legal precedent set ask what remedy against getty image seek from stability ai peters say company not interested in financial damage stop development of ai art tool in create new legal status quo presumably one with favorable licensing term for getty image theverge should pay back generating image with stable diffusion why even go for such amount why not some amount maybe what willing to settle down for to encourage some good faith negotiation not such demand likely to get dismiss immediately what getty want getty get need money to pay own lawsuit photographer sue getty image for billion after bill for own photo major fraction of world available worth of money accord to one source google quote which supposedly trillion good job getty photo almost worth half of anything else exist on planet hail mary stable diffusion obsolete business overnight lawsuit last thing ever able to cash on before change business without excuse still find societal failure line of conduct rational at point probably more worthy to pay litigation lawyer than photographer without provide disincentive to getty image something wait until obsolete lawyer doctor insurance company legal assault brutal good ai programmer should not allow to use entire internet to train model without compensation of some sort profit down company ruin sir only make profit from law ceo such failure let cut of staff sell share jump ship who not probably right to ask for no no different finger cross behind back usually due process for try to right thing tm not think scrape web use everything regardless of copyright individual license condition remotely in same ballpark of due diligence insane judge not release any write explanation of ruling seem court accept getty public domain work regularly commercialize original author hold no power to stop for now infamous collection letter getty paint honest mistake address soon notify of issue by highsmith dr evil amount of money not even exist getty garbage hypocritical greedy liar not get jack judge not stupid demand payment from someone know use wayback machine to find copyright test image of some public figure person create website year ago impossible to find image on site today without wayback machine not care just want money thank bill gate delete contract work for horrible to work for think want to get gradient back from model all sd get from stability base in uk stability small business of around people getty less afraid of take on than of google microsoft lawyer think burden of proof sort of on defendant in uk not lawyer remember something weird about how presumption of innocence work okay with artist get no payment at all more like zillion fafillion getty trash judge know lucky to get nickel basically describe unsplash guess who buy in even for bare bone livable wage to full time lol imagine photographer make living wage from photography every artist dream to make any money at all why need big company like getty to legal battle ethical make some honourable adjustment both party happy with shake hand move on grow up problem not happen everyone just think on internet free use whatever like getty just entity with enough cash to make dangerous lawsuit just regular old artist suck in well deserve right to decide how image use even just put in blender contribute few bit of information to result m fully on board with new movement to take upload image for training through no individual photo go into network actually all value expect outrageous sum for ridiculous most people who take photo nowadays not for profit build up ethical image library entirely crowd source feasible problem just assume ethic hard not apply even more explicit no machine learning ai biometric technology use unless explicitly authorize in getty image invoice sale order confirmation license agreement not use content include any caption information keyword other metadata associate with content for any machine learning artificial intelligence purpose for any technology design intend for identification of natural person additionally getty image not represent warrant consent obtain for such use with respect to model release content argument really need to stop not remotely same thing damn bro know try to make point fully disrespect man long time enemy lmaoo lucidrain why ironic want to train model on image actually right to use what make call unrespectable nobody in field come across unnecessarily harsh elitist not say argument hear people lot say image from da not significannot getty not etc still choose to use all add together must significannot prove become witness for stability ai neural network not inspire by image someone download image aka make copy use in build for profit system without authorization from person who own image nobody dispute stablediffusion train on image from getty image open question whether not illegal act of redustribute image illegal training model on legally fuzzy unknown territory always go to someone with big pocket clear value to image lot of image in training set maybe class action suit compare really hard to prove same level of monetary damage to gather enough plaintiff to rival size of getty image definitely agree with need for law to handle sort of mass training dataset right now stick between steal enough not owe anything ml dataset cost million dollar require three year of track down copyright holder yes not for every single infraction use of image without permission not go to get sue for million half ridiculous to point of absurdity want court to pass law to make illegal for people to learn from public image maybe weird also smart huge fine set huge precedent think whip up image in single day all in style of greg rutkowski well than original no not necessarily even win owe something not automatically get what sue for just claim up to to prove damage for each image amount not award amount prove often up to some limit actual amount sue for matter very little until decide even damage case dismiss usually no merit to case year ago lose btw humm not sure about for example appl alone worth more than trillion usd exactly usually due process for try to right thing haha nice one just outsource let other people build bot submit for maybe sd should try to let people license own image to sue people use someone get pay off lol thank for get reference judge not stupid oh believe entirely depend on judge look up verdict of landgericht hamburg germany regard copyright never end shake head for example reach verdict every owner of community website fully responsible culpable for content of link user post win case style not copyright sue in us uk getty less afraid of take on than of google microsoft lawyer already take on google put in language after accord to post history yes plenty of people nobody in field majority of people in every field nobody yeah none of copyright image matter just exclude from training set no problem obviously value just very little individually more importantly value set by owner not consumer never pay owner rate no right to copy for purpose how matter right to use own image lol read what op write just try to understand here op summarize complaint where imply stable diffusion steal getty image to train stable diffusion op summarize complaint way not m simply try to understand complaint op summarize well typically someone complain steal image easy to find out on computer not pay for in other case unless someone engage in obstruction wipe shred say image sound like say stablediffusion use getty image for training claim not theft steal while getty claim theft steal ah okay confused not complaint op summarize in what write make sound like complain steal image to train model not sound like accuse of redistribute yeah of course want to big thing image generating model threaten stock image want any image just prompt model instead of search on site to see what want literally direct competitor to business no just want licensing fee which result in only handful of huge company able to really compete in ai space show single piece of legislation which say legal status of thing tool machine algorithm depend on degree to which thing resemble human biology people keep repeat bizarre non sequitur about how just like person any significance for lawsuit like try to argue take photograph in court fine digital camera sensor resemble human retina ml training algorithm not people go to mess unfortunately look like shape up to screw everyone similar challenge no doubt come for chatgpt brethren while true individual image owner same with text content not help think right way forward with technology general flat tax average people generate vast majority of content use to train next generation ai technology also poise to significantly alter job landscape in next year any country on earth actually couple non fossil in government think good thing collectively today to find way to mitigate what otherwise turn into wild fire individual licensing here not realistic everyone contribute in some way everyone should benefit at least to point where keep loose grip on civil society also go to see white collar professional like lawyer doctor eat some shit round suspect actually slim real chance of move in right direction spectacularly stupid take want court to pass law to make illegal for another company to take image for free compress link compress datum to keyword sell compete product not care about getty not kid yourself very little similarly between person learn from image ai learn from image imagine own all of image of extinct animal go far people corporation s learn profit s public copyright ftfy cash physical money not stock etc in most country buy steal god not award any right towards good independent of whether know not just take away from without reimbursement set up on purpose felony concealment of steal good no just pay out to avoid go to court yeah mean probably one of first guy ask about such thing random ml engineer at image compan cool to see comment of seem like human even work beyond human like imo yet not typically refer to people such unless intend to rude show intent to exactly same thing sue for relevant what stability to business what getty try to to creator steal in make unauthorized copy copy image from original location to some storage medium in preparation for training without authorization from copyright holder illegal until give permission not until pay mean same thing though need to license to use copyright image want court to say use image training datum use image else generate use getty quality whatever image without getty ever in loop consider chatter see about getty try to get fee for public domain image hope lawsuit bite in ass legal argument in new area always proceed by analogy to say think pretty persuasive ml model not copy memorize create collage of training datum rather learn from call machine learn for reason good analogy for what model with training datum legal argument should revolve around similarity of specific copyright work specific work produce by ai usage of produce work not hypothetical about what produce by ai base on corpus train on in way ai hold to same legal standard human who study work legal to make art in style of x not to substantially reproduce element of copyright work same go for music not understand why exactly matter intent same whether human not why matter either way produce image inspire by not literally image person use think lawyer doctor more protect simply already some pretty bs level protection power through association college such go to white collar worker who not professional guild with legal backing basically at most risk like programmer accountant etc individual licensing here not realistic why not people put out ton ton of code under open license think imagine every content creator make specific license for every specific user far more way for individual to license work with same automatically readable actionable term to everyone take creative common non commercial license huge bucket of datum use accord to term license pretty new new one for specifically sort of purpose arise where come in extremely distracted by absence exploit public good result should public good no copyright for ai output period lol compress each of image down to byte impossible to recover image without original image decompression key not possible to compress many image into size of stable diffusion model how different people very often reproduce style people very often create clone lookalike entire game franchise exist for reason well musical genre on just machine not make special need to turn corner on stable diffusion stop call ai like with other ai stuff in past noise function run backwards not think call ai just allow proponent to anthropomorphize claim no different to how human create thing people need to ask themselves stability ai same training use non neural network form of machine learning still okay much magical thinking around ann honestly think tech cool run sd on pc choose method of gather datum for training without prior consent argument okay algorithm use vaguely mimic biology just leave bad taste in mouth umm no machine learn program take datum learn pattern create new datum mostly follow same pattern human take datum learn pattern create new datum mostly follow same pattern ai take art see in past recreate from memory copyright violation illegal people take art see in past recreate from memory probably copyright violation probably illegal ai look at art learn pattern from create new art human look at art learn pattern from create new art not difference not how technology work learn how work read study review source code speak intelligently on topic speak like compression algorithm not know yet want court to pass law to make illegal for corporation to learn from public image post by bot source okay really different from available worth of money worth associate to anything of value real estate stock food all of worth money sorry feel rude just want to clarify lmfao asset well than cash money much well hoarding save cash lie perpetuate by bank want to pay off debt forever get tax by filthy rich classist use collateral to get loan from bank to get more asset credit only matter no asset yet not completely daft most of asset should make more revenue than minimum payment to bank purposefully take forever to pay off avoid taxis get tax write off due to asset depreciation not avoid debt typically not tax rinse repeat until filthy rich credit only mean anything to poor people start out build large large line of credit start small end big ted talk thank for time should not bother really think company go to risk spend thousand in court for strengthen claim not weaken plan to use legally acquire image library to make product similar to defendant thus increase monetary damage suffer by unauthorized usage yes get in trouble for not legally acquire image before should similarly sue for creator sign over right to getty seem to some comprehension issue getty allow to train model with image own end of story copy copyright content of dvd onto computer totally legal not make copy onto intermediate storage problem what illegal redistribute copy without permission of copyright holder hard to make claim what by go to getty website copy image into memory of computer disk cache illegal until give permission not until pay business model own lot of image charge for use why spend money on make photo maintain website everyone who any job create something want to get pay except for jobless people someone not draw similar image base on getty image not copyright violation original work inspire base on another like take getty image of ball draw ball in same position with no issue right oh yea get public domain image for license sure cheapy way to business legal argument in new area always proceed by analogy to say think pretty persuasive ml model not copy memorize create collage of training datum rather learn from new area in sense encode representation of input datum into latent representation generate output from data indeed new application in machine learn at least at scale however from legal point of view resemblance to human learning not relevant from legal perspective how neural network use datum to produce output not matter computer algorithm from legal perspective view one not matter whether latent representation resemble some part of human memory not clear functionality of algorithm depend entirely on input datum also clear generate output instance not simple collage of input datum legal question whether take large set of copyright input datum encode into latent representation use machine learn algorithm to build new datum use latent representation amount to fair use not legal question what exactly legality of use copyright input to build latent representation no one know at point data mining exemption grant with search engine in mind not for generative model whose output qualitatively same input image to image text to text code to code also important to remember fair use depend more on market impact of result than technical detail of process call machine learn for reason good analogy for what model with training datum call machine learning analogy analogy nothing to with legal status of machine such analogy common with many type of machine camera act like eye excavator arm with movement similar to of human arm washing machine wash clothe dishwasher wash tableware both process also by human none of any bearing on legal status of machine store image in obscured lossy encode inside of not believe protect start to use technology to compete with each other lead to inevitable cannibalization of organization potential productivity other gain great to ignore however think power describe potentially help everyone encourage some cooperation to limit overall damage for all impossible to predict of course imo potential to impact bottom line for people in class good for all simply still some political sway not talk about open license talk everyone want to get individually pay for use of individual content contribution not see how work here seem like more efficient to invert just tax tech for everyone yes no one say all in lossless compression understand concept of feature vector know at its core nothing very lossy compression not possible to compress many image losslessly entire latent space of stable diffusion specifically contain compressed datum from image entire reason why stable diffusion reproduce its own training image nearly perfectly on occasion assume rigorous proof of different people people bar people from learn unthinkable thought crime stop machine learning model from compress copyright datum distribute use for commercial product just basic copyright protection human use abstraction symbolic reasoning while neural network model simply generate probability distribution for every input neural network very nearly deterministic whereas human very much non deterministic even child consume much much less datum than any modern ai art generation model draw people with two hand five finger consistently for nn base model its continuous distribution for how many finger to draw human know number of finger to draw in discrete term its nary choice to draw more less than five finger yann lecun say for year need symbolic model rather than probabilistic model want to really emulate human thinking human not think exclusively probabilistically like deep model neural net learn pattern okay algorithm use vaguely mimic biology nobody make argument argument neural network actually learn detail feature reproduce not memorize image not like human ai actually know what image should look like give string of text create arbitrary image with its understanding seem to pre decide not real creation by computer creativity something magical special to human what neural network great at learn high level abstract idea like style emotion lighting after learn idea combine accord to prompt to create original image creation use learn idea in new way to express new idea machine learn program take datum learn pattern create new datum mostly follow same pattern human take datum learn pattern create new datum mostly follow same pattern not difference ok explain which part of brain what training algo human neuron use backprop what batch size part of human brain generate art use for training not say no difference still not know how work in brain over exaggerate what stable diffusion here probably underestimate what human brain go to sue worth world different currency one currency not equal another convert to usd about much accord to us treasury source article probably not entirely reliable not really point either note note coin probably just tiny fraction of all world worth aware statement ahem tiny bit inaccurate mean more light joke trillion usd still ridiculous sh ton of money though hi not sure what on about nowhere say cash king anything toward sense reputation of take people to court want like originally friend negotiate down to point not go cry to court about business hurt exactly same thing behind scene well claim lose lot of oomph not what comment about already right to dvd note only apply to non commercial use non drm dvds stable diffusion both use image for commercial purpose not right to image download copyright not just about distribution not like once image in browser cache legally print copy to hang on wall publish in internet not give to anyone else still need to get right for usage not just redistribute like how anyone with gpu who train few model suddenly think attorney copyright infringement use of work protect by copyright without permission for usage where such permission require thereby infringe certain exclusive right grant to copyright holder such right to reproduce distribute display perform protect work to make derivative work generative model create new image base on train on copyright imagery not create derivative work say tell to judge watch response hate getty argument right not use for commercial purpose to earn profit not admit here subject to lawsuit lol idk why ppl downvote what say at first try to just understand complaint ask question now not say anything not plain day true even not owner photographer sue getty image for billion after bill for own photo copyright law around for long time reason call copy right make right to make copy of nobody else steal sell not right to dictate who see image what with what see only valid avenue see here to say stable diffusion distribute getty image image with gig model dataset go to pretty hard time find example try to sue for getty image photograph not drawing take similar photo on with lot of training on photography big budget to travel not sure what even argue about here legal status not settle new situation require either new law to clarify judge creatively interpret exist law forcefully apply here either way absolutely time want to argue use intuitive analogy for what make sense not blindly read what letter of law say apply however naive reading seem to suggest without far think fact no current legal provision to bridge gap between really smart algorithm human brain basically same thing just not valid argument to dismiss such comparison at stage anything whole point different law write explicitly with something like in mind obviously not case even just interpret exist law ultimately need to set precedent agree with its letter not mean argument base on thing not explicitly spell out in law useless for well of bad american law write in english not assembly result anything unambiguous shift in perspective base on seemingly unrelated argument absolutely ultimately result in different reading argue ideally should not case in vacuum agree hate many fundamental design decision plague just about every modern legal system today definitely call machine learning analogy m go to disagree with certainly not use analogy with literal intent philosophical materialist to no fundamental difference between ml human brain learn what make biological tpu use literal human brain cell change anything not what start add other bit of human to brain tpu until ultimately end up with regular human with some input output probe attach to neuron at what point go from learn to not really learn just analogy see why analogy involve unrelated legal concept very meaningful indeed real world not cleanly separate alongside whatever category law come up with no not absurdly stupid take think most people not understand how strong grip professional association on respective profession eg already rule all professional under jurisdiction must follow stifle competition race to bottom control what tool allow not allow paralegal not same protection probably face brunt of thing lawyer judge power struggle between whoever try to muscle way in whether big tech politician not think power help regular people exist for long time at point more negative impact than positive already artificial scarcity of doctor people want protection should look elsewhere imo open continue before anyone get pay need consent open license show get consent term at scale work far pay pretty easy to imagine analogous approach work put image onto notgithub under needsroyaltie license notgithub ton of imagesnotcode license dataset to someone agree to notgithub term of royalty whatever put up under notexactlygpl license anyone use long model notexactlygpl license notgithub not exist yet say not realistic for to exist not sufficiently open minded get individually pay for use ftfy although payed exist reason why autocorrection not help only correct in nautical context mean to paint surface to cover with something like tar resin in order to make waterproof corrosion resistant deck yet to pay pay out let string cable rope out by slack rope pay out pull now unfortunately unable to find nautical rope relate word in comment beep boop bot entire latent space of stable diffusion specifically contain compressed datum from image contain compressed datum from image not compress datum of image original image not in model not in compress form any other form stable diffusion train on billion image billion byte in size only byte per each original image extremely silly to consider feature vector some simple lossy compression statistical pattern recognition with possibility of overfitte result in near reproduction not store image itself in any capacity more than memorize to consider human brain big lossy compression algorithm go far sure not absurd sure provide soon provide evidence of stable diffusion reproduce its whole training set should easy consider claim damage for every image copyright cover expression not idea part of datum model learn not copyrightable model not space to copy expression only one byte per training example once in million happen to generate close duplicate only happen target most replicate image in training set with original text prompt sample many time get to put lot of effort to make replicate anything copyright pretty arbitrary decision only really serve to limit development of ai not neural network stochasticism build into inference no solid way of determine brain any different on front abstract symbolic reasoning poorly define just from fact human brain far exceed computational power of any give supercomputer by absolutely extraordinary margin not know what neural network train on amount of datum intake on daily basis with computational power out brain like all thing like symbolic reasoning abstraction just more sophisticated network lecun not neuroscientist just not know enough about brain fundamentally to know what abstraction symbolic representation really equate to just social construction not know underlying mechanism precisely all really region potential neurotransmitter correlate funniest part where think symbolic system more unpredictable than soft probability base one neural net learn pattern yup train to reverse noise add to image not think analogue of biological neuron much simple limit argument neural network actually learn detail feature reproduce not memorize image people already use prompt to recreate image match quite well to image use in training datum learn lot of image just with neural net hard to get datum back out than with database not change view either way main issue with lack of consent what neural network great at learn low level high level abstract idea like style emotion lighting after learn idea combine accord to prompt to create original image creation use learn idea in new way to express new idea emotion absolutely magical thinking anthropomorphize software to simplify stable diffusion train at remove noise from image step by step apply to pure noise with text prompt to guide in what should should not find in noise not learn emotion not know what lighting just learn from image feed something look to like sunglight in image usually associate with something in image look like shade to learn frequently before b argument come down to neural network not sophisticated human brain obviously to good of knowledge human brain take in datum form prediction use algorithm even from functional level of how individually study algorithm space repetition algorithm difference computational devotion relatively weak unsophisticated network in thing like stable diffusion not to worry about control organ take in many input every second probably process more datum in few second than stable diffusion over its entire training session devote computational power to task of exclusively learn art far above beyond capability of stable diffusion ummm neural network literally design base on how neuron within brain activate at chemical level advancement make in figure out how to well combine manipulate structure okay explain which part of brain go take cat scan check for brain activity get pretty close what training algo human neuron use backprop what batch size part of human brain generate art use for training not say no difference still not know how work in brain over exaggerate what stable diffusion here probably underestimate what human brain compare any mammal brain to any neural network like compare fighter jet to paper airplane not argue not massive difference in complexity ability argue fundamental physics drive both same however besides point reasonably certain brain recognize pattern reapplie pattern to new situation by use network of neuron activate at various threshold train by change threshold neural network fundamentally same thing just much bad likewise even though essentially no knowledge of how work still reasonable certain use lift generate by body wing surface to fly just like paper airplane not need to know specific of how either brain work to able to assume obey law of physics brain not magic just large neural network use pattern recognition to produce useful output getty own image whatever want with other people need to pay getty to use image not get to use aw server for free just amazon also use own server for same purpose assinine copy dvds legally own even drm just not distribute copy say use for commercial purpose not clear cut stable diffusion use image themselves for commercial purpose in way violate copyright imagine instead of ai model instead business where extract statistic about movie sell for example maybe analyze dialogue for number of usage of word pepsi various other brand produce dataset from bunch of movie sell to interested party clearly fall under fair use not violation of copyright despite almost certainly involve copy movie to intermediate storage for analysis produce datum derive from content of movie up to court to decide where line get draw between obvious fair use case like describe above actual copyright violation not immediately clear from outset stable diffusion fall on opposite side of line not use for commercial purpose to earn profit not admit here subject to lawsuit lol let say painter who draw sell picture still allow to look at getty stuff ai not directly sell copyright image learn from just any person probably right to not right to dictate who see image what with what see actually people right to decide how image use stop pretend just like look at photo mom say photographer who take anissa photo year ago say use for stock photography along with picture take of fraser other daughter who now between age of fraser sign release two year early at photographer studio while agreement say shot available to agency such getty image say not use in defamatory way getty user uploader consent to use of image not right to dictate who see image what with what see except not just see image integrate datum about into commercial product with gig model dataset go to pretty hard time find example try to sue for extract training datum from diffusion model from abstract in work show diffusion model memorize individual image from training datum emit at generation time not read paper carefully not say how big challenge to find image just point out way to find some of training example in model not go to hard time find picture digital legal discovery not hard not sure what even argue about here legal status not settle new situation require either new law to clarify judge creatively interpret exist law forcefully apply here either way absolutely time want to argue use intuitive analogy for what make sense not blindly read what letter of law say apply however naive reading seem to suggest without far think legal status unsettled not algorithm just like human new type of potentially fair use what make different from previous case encode training datum into embedding depend on situation use to generate content which consider very novel also use to regurgitate content protect by trademark copyright law semantic latent space embedding relatively new type of machine learn datum representation allow for new use case new legislation need for legislation deal with question of remix no long remix not question of should treat neural network architecture its weight human fact no current legal provision to bridge gap between really smart algorithm human brain basically same thing just not valid argument to dismiss such comparison at stage nothing to dismiss no one involve in lawsuit make legal argument computer algorithm same thing human brain not what legal case about about new type of encode representation generate from unlicensed training datum whether representation output generate from fall under fair use anything whole point different law write explicitly with something like in mind obviously not case fair use law write cover training of machine learning model on unlicensed datum however generative content new type of output generate from unlicensed training datum fair use always evaluate on case by case hence lawsuit even just interpret exist law ultimately need to set precedent agree with its letter not mean argument base on thing not explicitly spell out in law useless certainly one must aware what argue in lawsuit possible resemblance of neural network model to human brain function not grant model any new right thing mathematical algorithm in eye of law same excel spreadsheet tool use by human human use one responsible for potential copyright trademark violation call machine learning analogy go to disagree with certainly not use analogy with literal intent philosophical materialist to no fundamental difference between ml human brain learn law not care about philosophical materialism clear distinction between legal subject like human artificial thing like computer algorithm otherwise should machine learning model also grant human right of course not about real life machine learn not trial of mr datum from star trek what make biological tpu use literal human brain cell change anything not what start add other bit of human to brain tpu until ultimately end up with regular human with some input output probe attach to neuron at what point go from learn to not really learn just analogy see why analogy involve unrelated legal concept very meaningful indeed real world not cleanly separate alongside whatever category law come up with ship of theseus argument about fictional biological tpu s irrelevant to legal case at hand case concern encoding of unlicensed training datum into novel mathematical representation not experiment on human animal brain tissue computational neural network model inert essentially flowchart through which input data convert into output datum far far close to excel spreadsheet than to human brain not learn not constantly form new connection train once use static datum file why for example use stablediffusion to generate output on own computer its training process require massive amount of gpu time cool just spit out image verbatim by dark magic right go to say donotpay case in progress right now counter argument however see variety of state bar association basically threaten into submission give up on about week ago guess right take while long honestly pretty depressing think mean technology high likelihood of primarily negative disruptive impact think talk about two slightly different thing not talk about consent agree effectively solve where matter with creative common snd similar license however also not at all convince should to bother with licensing every piece of content create for instance conversation right now valuable training datum should able restrict of course argue either way personally find waste of time to try argue each such piece of content should license need license just public discourse on other side of thing think argue sum total of conversation now power technology significantly alter economic landscape in next year m argue think content should freely available for use without what consider onerous licensing burden also argue by same token private corporation should not freely profit from content without somehow reimburse creator of content training datum not think efficient to try tag license track every comment make conversation participate in to pay fraction of penny every time model use content train use think make sense to tax tech except human brain major symbolic abstraction component not purely probabilistic additional mechanism to prevent kind of lossiness determinism occur in nn solve neurobiology psychology year ago what point in even make outrageous claim in ml subreddit about technical capability of ml model not bother to source back up hear of membership inference copyright claim not duplicate photo to sell share to public use without permission use doubtlessly include make digital copy of image use without authorization specifically for system threaten value of image use arbitrary factor value human right over right of hardware abstract algorithm crazy know some nn stochasticity build into inference say minority not know why latter point always bring up fact one bit adder significantly simple more limited than human computer not invalidate alus people use prompt to recreate very small handful of image in dataset some number of hundred of time known thing happen with neural network not invalidate real understanding well seriously generate yourself in cartoon style just not something simple emotion not mean feel anything learn artistic sense of emotion sad scene characteristic look like scary scene characteristic look like etc kind of thing learn in art school apply characteristic to other scene object very good at kind of intangible idea to simplify stable diffusion train at remove noise from image step by step not conflict with what say whole point of self supervised learning to learn good representation of high level idea present in datum turn out unguided without need to know beforehand which idea important just by throw away part of datum ask neural network to reconstruct sue somebody for break leg in court judge hear actually plan to break another person leg eyebrow raise not about who own what court of law care about thing term condition not law evaluate reasonable add to outrageous demand for per image clearly unreasonable now not say no case just say unreasonable sure strategy work in past to squeeze who use image without consent in fact know part of business model basically scare folk into settle work here doubt copy dvds legally own even drm not not for copyright reason make useful copy circumvent drm explicitly make illegal like most copyright violation no one really go to know home archive not share never go to worth pursue in court imagine instead of ai model instead business where extract statistic about movie sell good analogy to consider think core problem for stable diffusion in claim similar fair use use damaging to profitability of original image one of core competency to make same sort of generic drop in image getty business base on use getty image more than actual photo of people in office materially contribute to good at all say not entirely sure download process model for non competitive application definitely in clear even something develop for market not directly compete with getty business sell usage right to image someone bypass by scrape web preview version to generate say clothing design still circumvent getty business model use product in way not intend by copyright holder purpose of web preview image display on web getty reasonably claim image valuable asset deserve to able to license for model training without put under lock key machine learning algorithm not person person copying put online permit copy to browser cache not elsewhere use in case distribution of image literally copy display on billboard stable diffusion model not contain image in most case not stable diffusion open source free how commercial prpduct what happen people see thing huge tend happen all time some random thing get popular lot of people see integrate datum about into commercial product integrate electro chemical signal about into professional animator eye brain talent dig into find like close example out of attempt with concentrated effort in find meaning very specifically try to get to anything think show how hard to achieve more than prove achieve yea completely bunk from what read thread discuss how tool process no well than lie detector dowse rod seeing no image actually store impossible to find image in dataset also near impossible to find close example yup far seem like just individual sector protest at time see themselves directly immediately threaten currently artist people who confident not impact negatively lot of tech people doctor lawyer truly believe should all stand in solidarity to address wide societal impact able to potentially automate heavily augment less people need most human capability bring still continue madness say of course argue either way personally find waste of time to try argue each such piece of content should license need license just public discourse where differ not up to use to argue about what each piece need up to creator owner for rest regard whether onerous efficient all seem like efficient solution exist point really should not count out categorically far know know exactly how brain work solve year ago make claim about something not even close to understanding just make look foolish cute not address comment at all go ahead show show mine human right to prevent other human create machine make life of million well in substantial way continue to profit through manual production of art especially for profit abstract algorithm for generative model like stable diffusion gpt etc absolutely not in minority with insane growth of nlp in past couple of year growth of image generation especially gan diffusion not imagine where nn with stochasticism build into inference not at least incredibly sizable portion turn out unguided without need to know beforehand which idea important just by throw away part of datum ask neural network to reconstruct guide though ultimately creator of stable diffusion etc choose to rip other people datum from website without consent for use case sue somebody for break leg in court judge hear actually plan to break another person leg eyebrow raise more like someone sneak into house sleep in bed call cop get arrest tell judge go to sleep in extensive discussion of issue couple of week ago in subreddit copyright law place some restriction on learn from creation make new one not necessarily prohibit generative model training generation use of new image far from clear issue legally please guy stop talk about image problem here not image caption image by themselves useless for ai training for use case stable diffusion what matter here image caption most likely write on getty money possibly copywrite caption never cross mind model marketable asset in of itself not exist asset generate revenue not train on datum creator not right to access under image license take incorrectly license financial datum use to train predictive model use to make revenue by play market sell access very clear in wrong break data license not different license datum properly make product end of use in case distribution of image literally copy display on billboard ok anti abortion group use database exclusively of image of prochoice people to build face generator for same advert okay pricing commercial product both open source without monetary price similar to something else get sue people not thing not even start pretend same important to note even close example only close not single exact replica store in model yeah definitely see understand viewpoint on use just not agree with right about second one not know how brain work precisely y therefore not rule out not work like x just ignore everything know about both yeah brain work like blender for all know by logic make same argument with any technology against existence of any kind of intellectual property protection include patent really what propose not what guide mean oppose to old supervised method of training model where to give thousand of image each label with specific idea try to learn obviously well since not need label learn many concept at once without to predefine look get think whatever want with datum miss point though put lot of creator out of business argument one use against stability use of watermarke image make lose business sure argument start with term of license non commercial ai to eventually argue about affect business become relevant also embrace technology out other out of business take into account pass judgement people say steal datum not accurate datum freely available use datum where restriction apply very clear legally learn to artist by look at thousand of image not constitute copyright infringement of image only question imo whether ml model should hold to different standard answer imo no yup label datum take for free now go to try make money with ai model take incorrectly license financial datum not incorrectly license all already available on internet presumably face generate not close enough court think copy not face generation of pro choice people just random face not rocket science here use model to try to bypass copyright probably in violation of model generate identical image without knowledge same deal not identical image make zero sense for anyone to claim copyright not picture understand how text to image model work right really sound like not troll not train text to image generator with photo of pro choice people include picture of some person other b z ask to generate photo of pro choice person get image of back just get mixture of z get in trouble for sell photo copy of mona lisa technically not exact replica interesting legal discussion think society need to spend some serious thought on implication yeah brain work like blender for all know by logic yeah after interact with convince at least fairly weak propose arbitrary law rule only for automate machine not apply for human like sell patented thing only make by hand not work way either not what guide mean oppose to old supervised method of training model where to give thousand of image each label with specific idea try to learn image datum use label though label by getty artist over at da etc label off whole image sure not label of every single thing in image label question answer many time recently sell creation from generative model bad perhaps good case scenario large enough other party lawyer explain why copyright infringement exactly who imagine year money value of label historical datum from public market sure not grab public datum scrape grab privately license dataset company clean curate annotate dataset sell access to under license not right to use even unknowingly generate identical image rarely significannot case to make about transformative nature of content understand how text to image model work right really sound like not troll m try to simplify argument about consent before for use someone datum in particular way stable ai use image of anyone base in eu violate gdpr oh classic of completely out of argument think get out of call someone dumb good part how blissfully unaware people of idiotic irony sorry break delusion of able to talk about thing know nothing about guess first entirety of law treat human non human entity differently not arbitrary point of law write by human for human purpose second claim machine should allow to break circumvent law of its specify potential future value to humanity terrible argument human not allow to violate copyright either third whole crux of suit whether machine creation operation violate establish law open interesting question hardly reducible to corporation want to profit rest of humanity get to suffer question answer many time recently question many opinionated people post opinion about on internet far not answer feel free to link to control legal authority directly on point disagree not relevant laion all datum available to public not even image download yourself for case where identical not see case at all blatant copyright violation luckily also pretty rare not think enough to sink concept of ai model whole although give trouble to stability distribute old model version not think subject to gdpr in context one to collect image of people directly through agreement with third party probably fall under gdpr think two right of consent here ethically consent to use datum for training consent to use model to generate distribute likeness of identifiable person first one probably not apply stability ai not second one for benefit of other eventually only opinion matter on subject court vc investor who to manage risk in year until decide not answer sort of answer on its own good chance not control legal opinion draw clear line up to any one of to decide what to should build start up which rely on sell generate creation answer to such question really matter of risk tolerance image publicly accessible not under permissive license for usage distinction fact download yourself specifically laion not licensing right to store redistribute image yes laion dataset legal only provide url in clear download all image from laion to form training set lot of image datum in hand not correctly license each of image under its own independent differ license consider celeb dataset big problem with image draw from public internet not consider licensing of each individual image nvidia develop ffhq dataset to improve on celeb dataset in no small part by ensure all scrape image publish under creative common license allow any derivative use of dataset such train model use distribute model weight not in breach of any of datum license cc by license in case allow usage for commercial purpose model train on ffhq use to create derivative work sell model weight themselves sell laion dataset of url correctly licensed fine image download use laion url each independently license most of not permissively for commercial usage model weight prediction from training on licence protect image not use for commercial purpose due to existence of incorrectly licensed data element model by extension any derivative work poison by datum not right to use for commercial purpose which make one violate copyright laion something like napster knowingly facilitate illegal act not technically involve in just link to something on internet not mean download use without restriction for whatever purpose want copyright violation to element of willful intentional action clearly no intention to reproduce image exactly insanely expensive convoluted way of whole point of legal system derive principle answer to contest legal question guess what answer not answer yet risk tolerance risk assessment lens use in absence of answer not under permissive license for usage not manage specific of what people use public image for what expect to able to post image online say only download not wear green hat usage almost universally refer to distribute image again not mandate against who allow to look at picture not mandate who allow to learn from picture boggle mind just how arrogant to assume model train on ffhq use to create derivative work sell model weight themselves sell again zero right to mandate model train on image use in certain way not picture not derivative work which term use to refer to stuff like translation addition on ai model not not to dictate what other with even train on copyright image not violate copyright to download picture from internet any idea how absurd suggestion pirate style site say download from patreon reupload system argument site violate copyright not what laion exclusively use public website public url post by author in most case freely download for literal decade without issue to take word on one not manage specific of what people use public image for yes actually here link to license support by flickr on site uploader who assume in good faith to right to use image themselves get to choose what license choose to upload image under not limit to site like flicker find in term of service for all other website visit tell upload any image to site go assume right to go to hold under some specific license of choosing by upload image to consent to take control over datum put under license again zero right to mandate model train on image use in certain way call fruit of poison tree not mandate anything well establish in law build thing use item not use for commercial purpose sell thing use thing to make something sell break original agreement use item for commercial purpose not suppose to take model weight fruit of poisonous tree give to someone else even for free not get to use for commercial purpose either ai model not not to dictate what other with even train on copyright image again not not personal not mandate anything about law regard licensing absurd statement sure glad not make allow to download image from internet to browser cache to support intention of image online view through website not give right to print out image hang on wall use to train commercial project whole reason copyright exist work show to other people without give up right to how use rather than hide away fundamental to simply access to work not grant any right beyond what holder explicitly implicitly grant to such view on web page not matter link publicly navigable only right grant for to display in browser nothing more not give right to print out image hang on wall yeah people every single day think good idea to let author sue someone for print one of picture put on wall without give up right to how use again again again to say not usage right copyright regulating who able to use something once out absolutely absurd draconian reason never exist reason never regulating able to copy distribute something meanwhile pretty darn reasonable extend copyright law far than ever intend to extend",
  "not up to date solid basis spin up follow along cmu deep rl course post which research paper go over kind of depend where start from what level at now woukd start with kaggle rl course its good into link to david silver lecture series sutton barto text book both excellent intoduction to rl theory sutton barto obligatory want to learn rl imo even experienced researcher read every year very approachable should create github repo first incredible resource thank really good thank also kind of course thank take course about machine learning deep learning at uni look really cool thank well kind of now for course recommend silver course follow by levine course which both available on youtube besides read sutton barto book besides reading list also provide detailed explaination of most important model free algorithm well code implementation suppose to easy to understand possible now want performent code for research personal project not recommend spinningup great way to learn how implement thank much for reply take look at suggestion sergey levine course seem really awesome definitely on list to little bit conflicted regard david silver course few follow up question not mind m currently hug face deep rl course free at end get certification of completion not care much about certification always nice to get certificate also not david silver course little outdated seem video lecture make year ago guess basic not change wonder what good course to take think around same lvl of difficulty what choose not really speak for hug face seem to touch on relatively advanced topic challenging task certainly look nice from practitoner side which very useful to learn various trick to make rl work regard silver course bit outdated indeed focus more on basic of rl whereas levine focus on deep rl assume good understanding of basic now some topic in silver course which bit outdated tdlambda with eligibility trace linear function approximation which well replace by other topic in more modern course typically dqn alphago ucl also more recent series which touch on deep rl silver explaination very instructive one of good teach university course see in general for sure at least watch first few lecture thank much for all answer sorry to bother again just one final question know spinning up algo worth while since on window seem to little more changeling to install in local machine alternative to instal on local machine like colab not really think main strength of library design to easy to understand how algorithm implemnte at time main alternative openai stable baseline which quite obscure to understand how algorithm implement on other hand algorithm not use some more advanced trick enhance performance however well library now in same spirit cleanrl clean with algorithm in one file also performent look for modular easy to use library recommend stable",
  "neural network successful idea cnn some very early optimization for use to kind of useful no long really need anymore since computer now fast like gabor function sort of inspire from neuroscience research attention mechanism also float around for quite bit in neuroscience in model of memory retrieval before sort of streamlined simplify into form see today in general thing go from neuroscience to machine learn take lot of strip down of thing into actually relevant useful component before become actually workable neuroscientist lot of idea for mechanism not all of useful look into spike neural network not aware of already top ai researcher yoshua bengio yann lecun essentially cognitive scientist by cognitive science mean here general theory of cognition not human cognition watch any recent talk by bengio example recognise talk about cognitive science at least much about ai from talk also roughly sense type of problem researcher solve move to level of think about cognitive science theory of cognitive science ml dl form abstraction ground stack general theory of cognition intelligence agency general theory of dnn work in runtime interpretability theory for concrete dnn architecture use spike point in time instead of symbol to avoid chinese room argument here take on spike network actually produce any meaningful result grant last time look into field like year ago back answer definitely no just toy thank for suggestion out of curiosity any theoretical work compare snn ann to explore any advantage of use far nobody figure out good way to train not easily backprop not want to anyway goal of snn to run on ultra low power analog computer for need local learning where neuron learn by communicate only with adjacent neuron some idea forward forward learn predictive code etc far nothing good backprop bit of chicken egg problem without good way to train snn little interest in specialized hardware without hardware little interest in good way to train emulate on regular computer remove all benefit lot of progress in last year still not quite at level of ann in general gain ground quickly outperform ann on some specific task usually thing with temporal component low datum dimensionality per time step another area with comparable result to ann object detection decent amount of work show should much more energy efficient some empirical work show other potential advantage like robustness most of work still nascent to definitive snn ann conversion surrogate gradient method both get good result day training become lot more comparable to ann than in past agree though disconnect between hardware software still which prevent snn from reach dream of super low power model snn ann conversion kludge not only to train ann first mean snn incapable of learn anything new surrogate gradient well still non local require backwards pass which mean miss out on massive parallelization achieve with local learning rule on right hardware local learning dream benefit for ann train single giant model distribute across entire datacenter even multiple datacenter over internet quadrillion parameter model technically feasible not know what happen at scale sure love to find out",
  "nice work some intriguing section here definitly want to take look at quick question with regard to quote in for instance regression technique present single method without use advanced linear algebra refer to generalized linear model not see any reference to glm in brief skim not think of how else regression present single method also any place where get preview of shape classification synthetization via explainable ai section good work give read give any feedback ad not like subtle style of marketing talk about book yet first sentence puzzle no encompass glm technique also work no response need to put constraint on parameter with truly non linear model with time series example in book for particular clustering case like to call unsupervise regression particular case with appropriate constraint on parameter correspond to classic regression more about here for shape classification see here nothing wrong with relevant self promotion especially high quality material obviously bad irrelevant stuff should remove up to mod discretion personally bookmarke for later very interesting to nothing wrong with relevant self promotion especially high quality material who judge really care of quality pay book not upfront about its price what tell about author information contain inside book",
  "join waitlist try to get to install bing stuff to get well place in line just who find clunky ux over bing underwhelme ditto over youcom fail to generate anything for of time wish company spend some time think about chat ux integrate with search chatgpt really great simple ux work really great for some use case which really like quote from verge liveblog important part of presentation just want to note microsoft to carefully explain how its new search engine prevent from help to plan school shooting early red teaming show model help plan attack on thing like school not want to aid in illegal activity model use to act bad actor to test model itself safety system propose sound interesting give how simple prompt engineering attack still work on chatgpt not feel optimistic about how well work out in real world let just slap what effectively reskinned version of chatgpt in sidebar certainly choice like how spark get product management ux at large to finally start understand how to work with ml base functionality in product however think go to look back facepalm at lot of design decision see over next ish month company rush to get something anything out door fast than competitor hope not forget to make compatible to sharepoint team everything why need performance compatibility to log in to use just for waitlist seem like sale funnel trick same reason never use window ha ha ha ha ha wow power of bing edge dude microsoft stop lose to make choice now no from dawg wait turn not instal app tyoucom first time hear about search engine give go man bad not understand how think people loyal user of ai search engine nothing intelligent about ask simple should wear jacket tomorrow expect to interpret query rain cold tomorrow answer tit depend on weather occasion mild warm outside wear jacket not necessary ultimately up to to decide what to wear base on weather occasion personal style able to expand sidebar thing go directly to chat tab to talk to in full screen just like chatgpt search page sidebar only to make new experience more visible see meh think safety concern overblown really more of bad pr for microsoft than actual threat already find out how to make drug build bomb etc from internet anarchist cookbook well know for decade find pdf with simple google search sir bad actor seem to put itself online eliminate good one any good example tutorial paper about prompt engineering attack recommend to start with yup how learn look date yes agree coerce model into say something bad just game journalist play to catastrophize new technology juice engagement metric bad stuff on internet find with search engine still use search engine incredibly useful embarrassing part google afraid of bs story keep lamda stuck in warehouse for over two year while openai microsoft lap fbi drop by for chat booby what not need censor chatgpt maybe slider parental control like normal search engine should not universal censorship like what try to right now",
  "idk complete tool probably get pyautogui to though want to commit time just keep loop through all item at random interval imagine generate some fairly easily record own network activity for week use wireshark",
  "not keep up with tts since tacotron seem eleven labs work fundamentally same way for real time performance need to port python code to c fast speech good bet to pay to use api completely close source resembleai work pretty well need api also interest to clone voice someone speak with voice in real time fine for train tts model from scratch not come across good model for cloning which basically zero shot tts after some training yes yeah pretty cool trippy throw gast use speaker embed to influence energy pitch output sound meh work why add qualifier good",
  "hey chatgpt please write blog post announce bunch of new ai thing from google without mentionimg chatgpt let smell fear give volume of false information chatgpt generate surprised google jump right in with google brand product must really scared of what chatgpt to search delete ai war heat up rapidly next few year go to nuts chatgpt summarize chatgpt eat lunch announce intend to work on something real soon in attempt to look proactive not fall behind no way offer for free like open ai right seem like google really nervous desperate lose against openai funny how often to mention work on ai for year how use to pioneer like hipster cry for prop hm feel bit desperate interesting not link to any of project nor to closed bard beta for company invent page rank seem just weird delete voice assistant google home alexa siri certainly make obsolete by chatgpt not sure about search definitely distinction between find answer tell answer interesting to see difference between chatgpt whatever google spit out for search google should make available its alphafoo family of model ultimate game player in competitive game broadly define which include court trial purchase bidding negotiation war game yes entertainment game totally complement generative talk model solve different problem amazingly well combined well dominance any bot summarise link no thank chatgpt bard bing chatgpt just copy text put in google continue to push boundary of artificial intelligence machine learning introduce suite of cut edge tool technology for developer researcher business here just few of exciting new offering from tech giant google innovative tool allow user to train custom machine learning model without any prior code experience make process accessible straightforward google ai cloud base platform provide comprehensive suite of tool resource for build deploy manage machine learning model google ai company research division continue to produce ground break work in wide range of area from computer vision natural language processing to robotic beyond google ai for social google philanthropic arm use ai to tackle some of world big challenge include climate change healthcare poverty google ai language company also make significannot investment in language model develop powerful tool understand generate human like text just few of many exciting new offering from google in field of artificial intelligence whether developer researcher business look to leverage power of machine learn never well time to get start with google ai why wait get start today start build future lmaoo delete well obviously search tool for information retrieval mostly oracle much more convenient than dig through source material research yourself even present to in most relevant first order which most convenient order what make google successful in first place yes anyone read please not use chatgpt instead of google search unless not care about response make up give announce only minute before microsoft announce event tomorrow where expect to unveil new gpt power bing probably scared of rather than chatgpt know bing joke right now suddenly become far well information assistant than google simply by virtue of its ability to chat about search result keep context pose huge threat new bing go viral like chatgpt not sound like bard go to link to google search engine just yet article mention separate ai search integration come soon from screenshot just seem to generate paragraph two about search without citation already up sleeve basically drive research in llm large dataset in world not haphazard jump in more of okay start to see some activity commercial application in space now time to show what ve work on monopoly in search not make sense for google to move first google already knowledge graph which use to guard against common mistake chatgpt make with trivium basic information use such system possible to prevent fault in model potentially stop some hallucination occur hope to see one of company construct reference complete probabilistic temporal knowledge graph big topic able to go from entity relationship back to training datum source to examine potential fault digress large topic something very interested in see especially since information complex history with lot of relationship not just for real timeline either every book its own timeline of change information such system should able to unravel give volume of false information google give hint to retrieval augment model whether via architecture prompt not issue even api base service like perplexityai retrieval augment use just prompt not spew wrong information all much not like google vet website show up in google search all well regardless not surprised honestly google catch with pant down on ai integration focus on backend system to make ad revenue more profitable what microsoft add value to end user major shift in people focus on what ai mean to everyone not just google microsoft take very visible lead in ai for masse by integrate chatgpt with bing microsoft development tool etc chatgpt provide anything near level of benefit co pilot for developer google very valid concern think microsoft approach focus on end user value make event pivotable for how ai use also keep in mind microsoft also release biochat gpt suspect number of target release in next week month brave new world not care much about what chatgpt search care about advertising user of chatgpt not see problem with chatgpt right now no way of express its confidence level with regard to its own output its unsure about possible response still to write its undeniable fact its trivial configuration option to prevent openai model from hallucinate answer respond with not know equivalent sure google see way beyond novelty of current publicly accessible chatgpt model lamda paper some interesting sideline at end about train model to dynamically query knowledge graph for context at inference time stitch result back in to retrieve ground truth which also allow state change at runtime without require constant retraining well position to deal with problem than chatgpt already maintain what almost certainly world most complete well maintain knowledge graph yeah while doubt confidence really want pretty shocked tool not considerably well at not wrong on factual claim should think llm totally upset how content index access one of easy low stake use case for really unfortunately google such huge incumbent advantage produce good search specialize llm still search provider look at what youcom cite claim bot make by link to page datum come from only sometimes not cite something sure just make up in suppose bing leak same thing cite source force to always provide source not not say fix however still problem model not know what true what false just cite source not mean source correct not something model learn by tell to learn by tell assume data correct which not assume researcher tell model all cat ugly which obviously not true model say all cat ugly teach model need to way to determine on own what true what not true explain reason give volume of false information chatgpt generate actually generate mostly accurate information long conversation more start to hallucinate considerably more accurate than most people toss coin hide damsel see no offer everything else for free think goal to drive traffic absolutely include light version into search result for free doubt model training tool for developer free though not think google release something similar publicly for free until relatively solid openai not hurt by dumb thing chatgpt say google brand to protect hold to high standard also chatgpt not free for long open ai not offer for free either really more about bing which statement which seem kinda crazy to write main source of revenue seriously threaten by investment not openai something replace google in come year google not innovate search think google win race in end see chatgpt plug into crappy microsoft product tell where head not large model toy model expect low quality much small model require significantly less compute power enable to scale to more user oh bad at connect tech to user google about to become hotbot ask jeeve quite certain google meta ahead of openai significantly more to lose by make model publicly available potentially make thing up say something offensive on top of which chat search experience seem like something google pretty careful with consider how frequently sue somehow reduce page traffic to random website openai use tech pioneer by google not come out of nowhere google big team player come to publish advance in ai openai ai research paper of big player of tech make chatgpt possible publish by google openai not publish of thing make chatgpt unique though know enough to pretty good idea of what whiny in place well gpt family not super innovative just run away with architecture mostly make by google transformer bert strip of everything prevent huge parallelization which many suspect include thing allow to stay ground in reality slap more compute on understand meta google engineer frustration perspective like proliferate everywhere transformer invent at google openai overwhelmingly net consumer of ai research incredibly close off on few innovation actually make graph somewhere for research output of various research lab show despite openai employee publicly release open access research ridiculously tiny fraction of of other research lab consider damage success convince management at other tech lab to more close off with ai research far concentrate ownership of ai into hand of single select few corporation in sense openai actively harm democratisation of ai which give previously unseen productivity generating effect ai seem like dangerous place to in pichai cripple google lol what exact rationale openai use for not release model weight for dalle instead sell to microsoft no not chatgpt not anything just respond to let reliably thing even reliably return true response not even clearly use same technology competitive gaming ruin happen chatgpt not really ship either out free feel hemorrhage million per month okay cost for research pr get out of not viable in slight ha not far off some bullet point on bard in prompt haha great thank for share like to tell people gpt more like write essay for english class sat than research paper for history class care about grammatical correctness readability well way to put how grade in english not grade on accuracy truth for sat use to say make up quote for essay section grade writing not content realize date not think essay anymore google search response make up well its just matter of more than one source to go through which make easy to spot potential discrepancy in any one source yes anyone read please not use chatgpt instead of google search unless not care about response make up most people honestly not care just want to get answer quick whether make up not true whether in real life online think lot more work to on front try to use chatgpt perplexityai instead of google search work for common knowledge once get into more complex niche query just fall apart both very happy to lie to make up stuff which huge time waste try to get work yes anyone read please not use chatgpt instead of google search unless not care about response make up general public not read sub chatgpt sell to by marketing sale hack without disclaimer way past point of psas indication some scramble at google over not armed research not see come way feel not try to generate novel response from model rather take knowledge graph relevant datum from first few response ask model to summarise change into answer which human find appeal way not to rely on model to remember stuff access all require information through attention see work which connect chatgpt to wolframalpha retrieval augment model whether via architecture prompt not issue err yes generally well far from solve problem geeze what bunch of nonsense chatgpt not even possible without google google make most of major ai fundemental breakthrough in last decade google lead in every layer of ai stack without exception big one silicon start year ago now on fifth generation fourth settte all kind of record google afraid to kill ad business let other pass by classic business mistake apparently lot of google stan go around tell everyone how google invent ai etc really look like get catch flat foot on one how exactly think chatgpt go to get fund chatgpt website any website show ad of course same issue gmail where user not go to like ad target base on what say to eh like human its trivial configuration option to prevent openai model from hallucinate answer respond with not know equivalent how though how even think actually figure out easily idea to shareholder oh valley of silicon artificial general intelligence at time of human development at level of hardware localize entirely within warehouse just pay with unlimited access to soul datum yeah now think about probably free access limited subscription plan for more feature like google colab chatgpt not actually free right now everyone just get of credit which far more than what anyone actually use in chatgpt fine tune analyze big datum set burn through pretty quick openai power bing forthcoming ai feature true not remember last time use google search without add reddit at end google only get out in front of microsoft who apparently announcement regard bing chatgpt schedule for tomorrow seriously threaten by investment over exaggeration simplification of ad market large advertiser not just move reallocate ad budget like elon musk fire employee smart by google to wait until microsoft burn billion easily surpas hype painful at moment non technical people sale idiot way overselle chatgpt get demo of some of stuff happen one most impressive gpt watch meeting take minute even craft action item email etc all ready for leave meeting also offer suggestion to follow up on in meeting on go google become altavista interesting choice on one hand understandable on other look bad than chatgpt go to get pretty slam in press maaaybe not immediately care in what try to head off microsoft offer something really slick compelling in bing presumably gamble microsoft not invest in incorporate full chatgpt in search meta fairly open with what seem like team disconnect no coordination google seem to only announce approve sufficiently polished just never show to public apple only release part of product feature delete which tech yeah openai found to well open most closed ai company in existence probably openai overwhelmingly net consumer of ai research exactly not sure why people not get google make many of major fundamental ai breakthrough from last decade many fundamental thing gans for example delete replace assistant in google home with chatgpt use lot more maybe exception not think no not chatgpt not anything just respond to yes get to thing easily r not ship yet buddy for gre teacher say one of easy way to get high score to strong ideology just nazi say not end up use advice maybe even well uh sorry english class wherever go to school suck well see variety in top result in google give pause not get from chatgpt xi jing ping putin trump teach anything correct absolutely useless just some sort of plan come up with good story some fact sound argument lot more valuable what average person think nothing more require to one of most influential person alive like one try perplexityai for first time yesterday impress by while use gpt not exactly comparable to chatgpt since really integration of bing search with gpt tell by ask about current event also by ask about itself not sure exactly how integration gist of seem to more gpt chat use interface to search rather than chatgpt where content itself generate by gpt microsoft seem to follow similar approach per bing chat verson pop up disappear couple of day ago able to cite source which not possible for gpt generate content which no source such most of indication poorly source commentary out of context internal doc absolute convient ignorance re space history google work therein go back look at article very little actual indication google scramble think deeply about space for long than most folk hear about among many other related aside not many global even comprehensive ai rule however google issue white paper lobby heavily for thoughtful regulation google not recklessly follow current ai hype train not read to catch flat foot anything headline catchy not just well wrong information from model pretty rare unless source retrieve from also false lm basically just act summary tool not think need to resolve for to viable replacement for search engine openai train gpt on microsoft azure zero to with google tpu while attention all need paper come out of google just build on model concept come before openai prove themselves plenty capable of innovate openai just get second round investment from microsoft go way sell api access to gpt for other company to use however like microsoft integrate copilot also gpt base fine tune for code generation into dev tool microsoft also integrate openai llm tech into bing while openai also sell access to chatgpt to end user doubt go to really focus for major source of revenue how even r yeluapyeroc just review each post np with attention span to look at ad bake into search engine which free chatgpt playground currently free chatgpt api of free credit of course not openai per se scared of bing distribution platform delete maybe cortana not braindead yep entire result space utterly pollute by seo trash reddit refuse to implement any half decent search engine force to use google instead think say more about than google other day mobile search for something relate to meme stock pill under search bar show news follow by button say reddit click literally just add reddit to search term sadly how world work run by people with no technical knowledge yeah right openai build on google research cool work half function chat into bad messaging search app congrat yeah google want to competitive here to offer something just good well half solution not convert consumer smart for in space overall tbh not think go to get much out of meta until get close to holodeck vr experience mainstream ready ar experience sure drop chatbot in next six month able to compete with google microsoft go to hard apple go to update siri in two year with llm act like savior of universe amazon someone see get leave out of lot resource funding to make alexa search chat bot well right up ally poorly contain what mean gpt largely build on google research chat gpt build on transformer nope exactly same far advance human knowledge go think basically say ai like chatgpt just output text at base level really also moot point anyway plug in llm to sort of middle man interface r wishful thinking chatgpt computer program not feature not design to not design to one by design mean engineering regression testing trust work tomorrow redo model agree fine tune llm large part of virtual assistant already lm obviously not always work well closed beta invite not ship no bing not get full fledged version unless microsoft feel like bleed million per day ve run thru gpt for reading like to tell people gpt more like write essay for english class sat than research paper for history class care about grammatical correctness in other word readability rather than accuracy truth for sat use to say make up quote grade writing not content probably most thoughtful take read in people forget how tilt mainstream medium against big tech agree with thread of what say here say think prepare for in very theoretical abstract sense not think run around like fool at google hq aimlessly not mean not inherently create shock to system in real term both some truth human trend towards black white absolute ground truth most often grey wrong information from model pretty rare not bear at out all by literature what base on still significannot problem everything from source material ambiguous president obama today say president trump today say who us president to problem require chain of logic happily hallucinate due to one part of logic chain break down retrieval model conceptually very cool seem very promising statement like pretty rare not issue nonsense at least on basis of publish sota statement like not think need to resolve for to viable replacement for search engine fine qualitative value judgment not something ground in current publish sota obviously sit at google brain privy to next gen unpublished solution of course hat off to openai train gpt on microsoft azure zero to with google tpu geeze chatgpt not exist not for google underlying tech invent by google openai use other people stuff instead of invent thing themselves like google many of big ai breakthrough from last decade come from google gans another perfect example tpus key in able to bring large language model to market at scale not train inference aspect yup openai expect to generate million in revenue for billion for next year true human in loop should scared of both openai capable of scale chatgpt package good consumer app themselves bing get fast distribution not like openai paper tiger google not able to compete with either of in long term continue to refuse to ship its own llm whatever happen honestly not even believe website anymore today search for good sport bar in city not find any reddit thread decide to give google search try not want to believe information true feel like local bar pay website to boost ranking delude not think seo not exist in bad way for llm ton of paper about just mine for phrase increase likelihood just by observe output prefer way otherwise reddit much power eventually become like google search yeah its not just maybe openai build on google research to knowledge not remotely true cite where get claim openai take funding share research with number of ai relate company not know google in list thank what all want alexa siri home modern llm conversational feature on addition to reliably turn on off light give weather ever since chatgpt come out interact with home assistance feel even more like pull nail than use to agree not shock per se however clearly oai on radar not entirely unlike during covid xoom teach most americans about web conference arguably good for entire space company in public imagination probably not deserve all accolade question for google other responsible ai company how to capitalize on consumer awareness adoption in way acknowledge real constraint oai less concerned with msft all ready run into some of constraint viz partnership interesting to see sataya get over ski little not usual mo fair enough speak from practical perspective consider type of question people typically ask search engine not benchmark what underlie talk about even familiar with attention paper relevance here maybe think openai use google tensorflow not gan invent by ian goodfellow while student at umontreal before ever join google no tpus not key to deploy at scale unless target google cloud google distant in cloud marketshare behind microsoft amazon openai of course deploy on microsoft azure not google sure just another ams race not mean conventional search not break tho all hail new big tech overlord reddit not skip class on search in college wow not expect number high wonder large aa reddit overlap representative of search whole google show steady increase in reddit interest over time second related query see what reddit interesting roughly linear not increase growth expect from word of mouth spread paper make all possible google also lead in research around transformer nlp for some time not not in way share from each other nice try what hide at google brain geeze who think invent transformer gan invent by ian while work at google pretty interesting story vast majority of major ai breakthrough from last decade come from google openai really not r d more use r d from other mostly google yeah like for year idk reddit just well moderated website with lot of small community around lot of topic think lifecycle of its community secret sauce community peak get crappy pretty reliably imo just leave join new one not think good sample though its poll of user response to androidauthoritycom paper make all possible reach imho original transformer only around few million parameter in size not even in realm of level of chatgpt well say mit invent googles paper base on method create by page footnote goodfellow work udem student please without transformer never able to scale not to mention all of build on bert well bunch of company scale far include google ha go listen to lex podcast ian explain all all while work at google please without transformer never able to scale without back propagation not transformer travel back in time to go write paper at umontreal anyways schmidhuber real inventor go listen to podcast ian explain all plus no schmidhuber not inventor ian go listen to podcast get back to key ai r d from last decade plus all come from google not from openai most definitely not from microsoft",
  "",
  "kind of remind of gumbel softmax trick which similar to reparameterization trick for vaes to sample backprop gradient through normal distribution except with categorical personally use before solid theoretical framework well cite not clear what second model consume just int what predict another class regression not sure what dl library use in case of pytorch just use output of first model directly input for second model should sufficient softmax not prevent backprop want to use latent vector of layer directly before last fc layer to some code depend on architecture should not hard yes yes yes thank try to think how relate to sample trick in vaes by chance know of any open source implementation for noob work with simple categorical distribution thank for share exactly what look for just recently segment normal task into two first give input sentence embed predict label label choose randomly no real interpretation of label like to think of unsupervised cluster give label downstream task for instance sentiment analysis which tie back to label select guess like clustering instead of run algorithm inside training loop like neural network to make assignment through softmax to also define cluster feature through embed lookup sort of want model to use to only get one chance at select label make sense otherwise become attention like mechanism over learn vector for each label second model consume one hot encode vector common trick for non differentiable operation like quantization use straight through estimator basically assume unity gradient for step take logit to one hot prediction work reasonably well for binarize weight activation yup which immediately vectorize via embed lookup love see code online where just to tell how to back prop override to unity common technique use gumbel softmax instead of softmax inner product with embed layer in second model simple thing to use low temperature softmax instead of gumbel think about anneal temperature over time to cool early optimization not harm badly not to anneal either put static low temp to mimic one hot encoding learnable parameter temp",
  "not watch original cowboy bebop movie anime seem really cool make really wan na see trigun case close detective conan reze up xd why ai create think call now joke aside thank for look fantastic like to see sample of source movie file for re for artifact of compression process look impressive anyhow actually think about episode of trigun one for episode of dragon ball well donate buck for what assume pricy electric bill for trigun episode lmfao what episode want why not first one guess want to show off tech want episode with lot of effect one need most improvement rez wise thumb through collection see all kinda age at point run tonight",
  "how approach really depend on few thing most important question target datum want to get out of network possible in some case to highlight region of interest use only sample level classification datum however usually very context specific target datum where region already specify normal supervised learning method for wave form should perfectly workable likely use cnn should look at audio network not very familiar with recent work in area one reasonable idea to produce spectrogram from datum use image detector on cnn also thing although think more challenging for to frequency scale invariance delete ideally able to go in select start time end time for each event within long timeserie assign class like for yolo training label in assemble label dataset label segment extremely variable in length quality advice read up on thank actually try not work very well for some reason maybe need to change way line plot look keep x y axis scale consistent also try make scalogram use wavelet transform simple strategy here which kind of ignore variable length object to simply classify cnn receptive field directly max pool multiple classification frame let say sequence build cnn receptive field of stride of network apply to sequence offer something like frame typically cnn expand network representation up with large number of channel take globalmaxpooling to merge frame information classify sample instead should classify frame directly mean output look like separate sigmoid classification associate with region of signal simply take maximum of each classification likelihood use for image level classification after train remove globalmaxpooling layer look at segment classification directly",
  "wait why continuously call chatgpt not use chatgpt in ml sub to boost really interested in how summarize primary source run on database of hillary clinton email storyteller summarize hillary clinton email input raw pdf of democratic national committee email leak prompt want to act storyteller come up with entertaining story engage imaginative captivate for audience base on summary text provide fairy tale educational story any other type of story which potential to capture people attention imagination give section of large set of email to summarize come up with entertaining story output once upon time group of diplomat work hard to make world well place discuss how to gain leverage over pakistani to move to more aggressively pursue al qaeda after much deliberation decide to use combination of incentive coercive measure to try to get pakistani to cooperate offer incentive such increase control over how kerry lugar money use increase support for counterinsurgency capability also use coercive measure such target military leader who give support to al qaeda its ally attempt to reduce pakistani anxiety about indian front in end effort pay off pakistani begin to cooperate more with mission diplomat succeed in make world well place story follow hillary juggle busy schedule respond to request from colleague friend always willing to help dedication to work evident despite busy schedule still able to find time to help around powerful leader task with find out whether senator support surge in iraq obtain copy of recent speech about troop to afghanistan leader reach out to team for help work together to draft memo outline four strategic interest three of which overlap with leader goal with help of team leader able to obtain information need use to make positive impact president obama face with challenge of how to win war in afghanistan without cause much destruction civilian casualty decide to increase size of afghan army police force to pay well wage live comfortably also decide to send more special force ten of thousand of troop to region despite effort taliban continue to gain strength support from pashtun community obama realize need to find well solution decide to focus on carefully think out measure such provide well pay for afghan army police use diplomacy to negotiate with taliban in end obama able to find peaceful solution allow to win war without cause much destruction prime minister of country fear of lose sight due to childhood rugby injury eye check find two minor tear in retina visit world renowne moorfields hospital for further examination doctor decide against any further operation prime minister grateful to doctor staff of nhs especially moorfields hospital meanwhile us secretary of state in contact with foreign minister of hondura to discuss situation in country ask staff to call us congressman payne to update on situation through diplomatic effort able to make positive impact on life of many small island nation call haiti face many challenge people of haiti determined to build stable prosperous democratic future united nations appoint president clinton special envoy to haiti appoint dr paul farmer deputy un special envoy dr farmer dedicate life to help people of haiti for past year despite effort of us un other country haiti still face many challenge to help people of haiti us state department take close look at challenge secretary clinton chief of staff brief member on initial finding us hope to well target coordinate assistance engage haitian diaspora make assistance sustainable to help people of haiti us propose grant temporary protect status to haitian live in us include haiti in security initiative such merida initiative with help of us un other country people of haiti build bright future also great conflict between two powerful nation morocco guinea over passport take away from citizen of guinea leader of united states france step in to help offer idea to help two nation come to resolution leader of morocco guinea still unable to come to agreement leader of united states france decide to meet in paris to discuss situation far able to broker deal between morocco guinea return passport to its rightful owner also man name tom who nominate for prestigious position nomination hold up due to disagreement between two powerful force brave negotiator able to convince two side to lift hold on tom nomination allow to achieve dream proceed to input of text use chatgpt just bait in title in any case good work here life coach advise paul atreide from dune input dune novel prompt want to act life coach for paul atreide also know duke padishah emperor kwisatz haderach mahdi lisan al gaib provide some detail about paul current situation goal member of house atreide on dune job to come up with strategy help make well decision reach objective involve offer advice on various topic such create plan for achieve success deal with difficult emotion output life coach for paul atreide help make well decision reach goal member of house atreide on dune offer advice on create plan for success deal with emotion understand potential mentat capability help adjust to new environment use resource to build confidence security encourage to embrace destiny use skill to make difference help navigate war of assassin forge legal document enlist freman ally more help make decision benefit people honor commitment examine emotional involvement respect error factor use mentat ability to diagnose problem help understand arrakis attitude of knife consequence of decision help recognize danger of trust traitor importance of make right decision guide to make good of situation use to advantage help remember emergency plan use courage strength to make right choice learn imperium terminology fremen culture great convention rule to help navigate role duke of house atreide help use fremen training experience to navigate treacherous politic of dune protect people guide to use leadership cunne to outwit enemy find success help make most of resource recognize counter opponent strategy use own skill knowledge to succeed help understand power of subtlety finesse how to use to achieve goal support to brave compassionate in face of cruelty tragedy help use azelle like agility skill of retainer gurney halleck to make right choice protect people help use power to gain throne while avoid mistake of father mother guide to make wise decision find good path forward kyne inspect paul stillsuit find to strange combination of softness armed strength help protect integrity of stillsuit walk softly avoid drum sand tidal dust basin never travel alone encourage to decisive take action like order crew of factory crawler to evacuate own air cover to take in show how to mindful of detail think ahead like notice poor neck adjustment on stillsuit of two of evacuee father son must face difficult decision consequence help paul understand father moral fatigue power fear of statecraft guide to use inherit desert power fremen prophecy to advantage analyze intelligence report equipment fremen to ensure paul success focus on desert power such air power develop plan to recruit five full battalion of fremen troop before first choam audit aware of power of water on arrakis use to advantage aware of potential competition from own kind prepared to defend honor lastly open to advice of around use to make well decision explain what map prompt not sure understand part chatgpt work on pdf file how work just parse interpret raw pdf file like to parse some pdf file with many thousand of repeat table structure convert to json something chatgpt able to help with tool see for today first creator not reveal inner working yet though like wonder how compare here how summarize big document r r map reduce r r method involve initial prompt on each chunk of datum for summarization task summary of chunk for question answer task answer base solely on chunk different prompt run to combine all initial output implement in langchain mapreducedocumentschain r r pro scale to large document more document than stuffdocumentschain call to llm on individual document independent therefore parallelize r r con require many more call to llm than stuffdocumentschain lose some information during final combine call r r here how separate wikipedia agent chain work r agent use llm to determine which action to take in what order action either use tool observe its output return to user r use agent base model basically ask itself series of question until get to right answer sorta look like wikipedia race r r here sample langchain agent base react act model on wikipedia tmdb r r log r r enter new agentexecutor chain r r thought need to search for romantic comedy film about senatorial candidate fall for hotel maid thinking socialite see try on wealthy woman dress r r action searchromantic comedy film senatorial candidate hotel maid socialite wealthy woman dress r r observation maid in manhattan american romantic comedy drama film direct by wayne wang base on story by john hughes who credit use pseudonym star jennifer lopez ralph fienne natasha richardson in film hotel maid high profile politician fall in love film release on december by columbia pictures box office success gross million against its million budget while receive mixed review r r thought maid in manhattan romantic comedy film about senatorial candidate fall for hotel maid thinking socialite see try on wealthy woman dress r r action finishmaid in manhattan r r r here sample notebook for wikipedia what library use for summarization here horror movie base on all of warren buffet shareholder letter from input prompt instruction want to act screenwriter develop engaging creative story outline for horror feature length film captivate its viewer give except of collection of warren buffet shareholder letter must use source material film genre must horror start with come up with interesting character from excerpt setting of story dialogue between character etc once character development complete create exciting storyline fill with twist turn keep viewer in suspense until end note full name of character every time mention note location name summary must no long than character long input text output reduce prompt instruction copyeditor combine below summary into one cohesive narrative combine output must story less than character long keep content context preserve input text output output mrs blumkin year old board chairwoman only one who save world from mysterious force with help of progeny must battle darkness uncover secret of courier express nebraska furniture mart see candy world book kirby along way discover power of family strength of own courage charlie warren stumble upon mysterious collection of warren buffet shareholder letter after read letter discover existence of supernatural mr market who offer mouth watering opportunity in exchange for soul must battle against mr market minion to save life world group soon discover company use dark magic to gain immense wealth power with help of mrs b year old founder of nebraska furniture mart must stop company before late along way must battle ruthless businessman henchman hurricane cause massive loss primary insurer reinsurer leave with financial stake in each loss settlement enter berkshire hathaway who offer to write up to million of catastrophe coverage rate become attractive book substantial amount of business loss exceed retain amount reinsurer pay of excess up to its contractual limit leave primary insurer with financial stake in each loss with huge sum on line stake high horror begin group soon realize letter contain clue to mysterious powerful force manipulate world economy for century investigate far come face to face with terrifying supernatural entity stop at nothing to protect its secret with help of roberto goizueta former ceo of coca cola must find way to stop evil before late rich santulli ceo of netjet brilliant executive also mysterious figure aunt alice ask afford fur coat reply with cryptic answer set stage for horror story group must decipher clue battle dark force to save town themselves along way must face off against tony ruthless businessman who determined to keep power for himself with help of washington post company wells fargo company american express company group must unravel mystery save town tony rod two insurance executive task with increase policy count discover series of underreported loss uncover sinister plot involve embezzlement product liability investigate far realize loss connect to mysterious figure from past with help of john tom michael don don must unravel secret of past before late finally group discover investment unleash supernatural force try to stop force must battle mysterious entity its minion in race against time to save world from destruction with help of jim kilt former ceo of gillette must find way to stop evil before destroy all with twist turn keep viewer in suspense until end horror film captivate its audience able to save world before late with life on line must fight to uncover truth save world from dark force make out alive website down absolutely fantastic tool how increase number of character in output instead of fix at character here theory base on stanford encyclopedia of philosophyr r output r theory of mind for singularity possible to develop predictive reasoning framework capable of deal with complex problem such yale shoot anomaly framework should incorporate combination of logical causal theory such feature fluent motivate action theory state base minimization in event calculus causal theory theory should able to handle continuous time concurrent action various kind of ignorance should support retrodiction prediction plan verification framework should also able to deal with ramification problem by incorporate static law relate direct consequence of action to other change additionally should able to reason about attitude of other agent to understand narrative diagnose fault in physical device to achieve combination of logical ai non monotonic logic probabilistic reasoning must use r rr theory of mind for singularity emphasize importance of representation in mental state formal syntactic description content externalism base on enactivism extend mind leibniz theory of mind incorporate insight from natural language semantic bayesian belief network general theory of event causality should also consider implication of uncertainty non monotonic reasoning qualitative spatial reasoning should able to handle complexity of temporal reasoning frame problem should account for effect of action persistence of cause proposition r rr identity theory of mind hold state process of mind identical to state process of brain ture test proposal by alan ture to answer question of whether machine think theory of mind for singularity machine think possess intelligence not conscious in same way human machine process information make decision lack ability to experience qualia subjective experience theory of mind for singularity high order awareness perception of one part of configuration in brain by brain itself awareness special sense different from of bodily sensation in which become aware of part of brain r rr theory of mind for singularity emphasize importance of understand relationship between human machine how work together in harmony framework should include recognition of unique capability of each respect for autonomy of both should also recognize machine use to augment human capability machine use to help human reach full potential to pass turing test machine must able to understand respond to question in way indistinguishable from human ultimately theory of mind for singularity suggest intelligence not limit to any one form type of computation instead universal phenomenon find in any system capable of learn adapt respond to its environment r r input r rr r prompt r map r want to act philosopher provide some topic question relate to study of philosophy job to explore concept in depth involve conduct research into various philosophical theory propose new idea find creative solution for solve complex problem ignore all citation first request need help develop theory of mind for singularity output must no long than character long r textr r reduce r copyeditor combine below theory combine output must less than character long keep content context preserve r input text r output sub over take over by user startup try to promote own product rather than researcher demo of open source library allow to build own chatgpt with completion api map reduce allow for memory agent base simulation over much large context window up to series of open source library extend openai completion make own chatgpt with its own reference library versus current pre snapshot possible to leapfrog chatgpt with langchain openai completion exclude some of label training datum until come out map prompt split text into chunk summarize chunk no reduce step here more detail on how app work on all pdf file convert pdf with pymupdf in python like copy paste all text from pdf with some pdf format into chatgpt try mine out at wwwwrotescancom use site for free pay for api call by provide temporary openai key want to share tech with demo remember to delete key use after its temp use sign up for openai get of free credit also create locally use langchain able to access from get error message try use map page instead of map reduce want long output than character good fast run many summary pass want explain how map work helpful how much pay for single prompt answer in fact no chatgpt specific product from open ai thank for clarify see not prompt per se analogue of map operation in etl good to know thank not find map page in wrotescan highlight to how get to work also get ratelimiterror recently try go to wwwwrotescancom upload pdf see estimated cost at bottom for map reduce job one cool feature of langchain framework easily switch model use chatgpt api come out langchain allow to easily move model without upend pipeline currently use late available api model text davinci model really interesting set of choice for map reduce happy to share experience anyone look for tip exactly prompt what langchain library use to manage text instruction for openai find map at break document into character chunk run map prompt on each chunk must big document need to adjust code for more cache any chance explain how to use step little clear understand premise not quite sure how translate to instruction in step example try to perform content analysis of document with chapter identify core theme in each chapter of course step break up document run prompt on each section try with map section vs map reduce main page here example flow for map input book pdf convert pdf to text split book into book run prompt on each prompt prompt etc output summarize chunk here prompt use lot of room for improvement word in comment plea remove from final prompt try to perform content analysis of document with chapter identify core theme in each chapter sample map prompt instruction writer good role fit perform content analysis of document document type give section of large document identify up to core theme in each chapter output theme input text output sample reduce prompt instruction copyeditor need to edit list of summary together please combine input together combine any duplicate core theme please maintain context of document input text output sample input document incredibly helpful overview for kind of work really awesome tool really awesome to see how openai handle all form of text upload dnc email file take raw email create narrative from pretty unreal with bunch of other historical document create story chatbot such",
  "us system at same time uk interesting move m not lawyer wonder means of overwhelming sds legal capacity pot call kettle black company know for appropriating image not belong to sue another getty blatant copyright infringer themselves also laion gather image via crowdsource participate all need to brush up on law for us here current legal code for copyright assertion compete business go to very hard to convince judge of delete copyright infringement for search service to cache part of crawl webpage to summarize content to produce kind of feature vector of say webpage for business relate utilization hate getty much anyone go to go against grain hope win imagine instead of getty vs stability artstation vs facebook something same legal principle must apply in ideal future thing like research use free commercial use require opt in consent from content creator community adopt open license like copyleft use dataset model must gpl whatever some other widely use opt in license never hold up getty image view publicly what sd view public image getty put out generate private datum on image view not lot different than look at image on gerry create excel chart list color variation see delete good hopefully getty win enough open culture image out image from greedy corporation not need anymore also not give sd chance to apply any lesson learn from first case to second one guess well no imply some form of theft infringement by stablediffusion more like pot accuse apple of witchcraft getty on way out pure corporate desperation also laion gather image via crowdsource participate not think datum collection methodology really relevant however dataset gather certainly way to use violate copyright not print in book for example important question train generative ai on copyright datum violation of copyright us copyright law not address ai not exist write up to court to decide how new application interact with law why lot of website already start to use ai generate image rather than stock photo header for article previously pay company like getty for clearly case already shutterstock sell picture to open ai to create dalle which soon use to create what use to stock photography example here ridiculously bad tho exception google image get pretty narrow only apply to role search engine fair use complex depend on lot of case law involve balance several factor one of factor whether use deprive copyright owner of income undermine new potential market for copyright work google image thumbnail clearly not compete with original work generative ai arguably fact automate art production one of cool thing about say only one of several factor not slam dunk for getty either most important factor how much borrow from original work ai image generator borrow only abstract concept like style while google reproduce thumbnail of entire work anybody who think know how court rule on lie to themselves commercial use require opt in consent from content creator well ban directly for commercial use with opt in why compare top two image demonstration train on getty image no way anyone argue nightmare fuel on right deprive getty of any money remember getty sue google image win sure google powerful make plenty of money now image search way bad for consumer than decade ago not just open image even link to image to follow back to page dig around for probably never find at all ridiculous effectively embed link not consider fair use still need to pay to use getty image set aside fact getty super hypocritical constantly violate copyright law effectively use litigator to push around small group win just go to another step mean only big company access to datum make impossible for small player to compete people fight against technological advancement innovation always on wrong side of history always need for physical artist digital artist photographer etc value of art already incredibly subjective value generate by artist not art client need specific detailed iterative ai not achieve instead of see tool opportunity for artist fight hopelessly against innovation throw lot in with huge bully company like getty image view scrape for derive work different thing top legal mind of reddit undeniably copy for training which allegation not even stability deny question whether legal plain reading of us law suggest legal to getty argue otherwise feel like fact ai produce image with getty image watermark pretty decent proof copy image ah yes love corporation decide to halt scientific progress nah s not good who care about getty no one let science move forward hopefully stability win decrease openness of internet already know software project not open source to avoid part of training datum sure artist much less likely to openly share well thing interesting wrinkle judge need to convince photograph generate image look like photograph same thing not imo not matter what think get thank yeah guess more complicated than think much like ml hard to argue training ml model on datum without consent let alone even copyright datum somehow okay delete s not much smart than comment tbh should not confuse scientific progress with commercial gain know lot of company in ai blur line think researcher who not seek to make profit not really same something like stability ai who try to sell product besides not clear to whether ai tool use to benefit humanity whole only increase control few company over large market really hope case set ome decent precedent about how ai developer use datum not create til science not progress without train ml model on getty image seem like type to argue any ethic relate restriction on science bad science not move to next base without get enthusiastic consent from other party hope to involve science should damn well keep its mitt to itself in case of openai science get handsy with people personal stuff who unaware of what go on who not give consent know openai approach to science creepy unethical mess up personally not care whit about stable diffusion ai should go after rote boring task via automation not creativity art one thing actually enjoyable about life last thing should automate with stupid model just scale matrix multiplication should openness of internet mean few people become rich off back of training on large swathe of datum without explicit permission should stop openai should pay for own label dataset not harvest from internet without explicit permission to sell back get rich off of absolutely to punish stop copyright about redistribution talk pubicly available datum not want need to give consent to specific people company to allow to read comment nor think should now up to reddit to decide what not allow human take inspiration from other work ugh justification creaky useless machine take instruction zero inspiration human artist not endless chain of automate digital art factory produce mountain of art by original artist one unimaginative guy copycatte another more imaginative artist not go to able to flood market overnight with thousand of image substantially replace original medium creator like to know how train to produce gi watermark without copy gi image for training datum getty image win ai generation tool go to become far concentrate to handful of company while also become less open besides not clear to whether ai tool use to benefit humanity whole of course benefit humanity whole language model allow computer to understand complex idea express in plain english automate art production make custom art comic_strip movie cheap readily available chatgpt style ais fix hallucination accuracy problem give oracle with all knowledge of internet get less hype right now big advance in computer vision cnn vision transformer revolutionize robotic image processing really hope case set ome decent precedent about how ai developer use datum not create not create datum use to train brain much of which copyright see no reason why should put restriction on people try to create artificial brain getty just test case for question of copyright ai not train model on copyright datum mean not learn information from web outside of specific openly license website like wikipedia sharply limit usefulness also seem distinctly unfair since copyright only suppose to protect specific arrangement of word pixel not information contain artistic style in big tech company afford to license content from getty little guy not win effectively kill open source ai think mean more about open source threaten not allow china just go to pick up run with thing technically possible to now us either at front lead ai revolution dip out let other country pick up either way happen take gander here min sec seem like no one know how scotus deal with good argument ai experience like human generate new work by mix in its skill far seem like law only differentiate by intelligence physical makeup to honest seem like only ppl mad about generative network produce art artist about to lose job who care ai create art one only care about creative aspect human make art no one stop really its about money one thing actually enjoyable about life opinion enjoyable all more reason to automate to get lot more increasingly well art everyone enjoy art make ai make of people who enjoy art more option give superpower to previous any creator to make more art agree with goal not think make internet more closed way to go purpose of internet to open make everything on internet cost something lot of negative effect on solution to powerful exploit openness not to make close to regulate usage of openai good thing find new awesome way to use datum from open web deserve reward getty business model outdate now legal system should not protect old industry from new invention why search for stock image sorta kinda look like what want generate one match exact specification for free generative model redistribute though often output near copy not only cover republish also cover derive work think very reasonable position to consider all generative model output o for which some training set image xi particularly large influence on o to derive work from xi similar story hold true for code generation model software copilot train on lot of software repos software license require all derive work to license under at least equally permissive license copilot very well output specific code snippet particularly base on what see in particular repo thereby potentially open up user to obligation to licensing constraint come with deriving work from repo m applied industry ml researcher very enthousiastic about technology state of ml also think field whole unfortunately careless about ethical legal aspect not even mean anything unless define inspiration what talk about dataset open source thousand of getty image not discussion here see stock photo watermark million of time during train nothing else in training datum come even close even at half bit per training image add up to memorization of shape apart from handful of know case involve image duplicate many time in training datum actual image content not reconstruct same way not necessarily turn out for example language generation model train on gpl code must gpl mean possible path to more open model content creator continue create copyleft content ecosystem major corporation use ml to generate image instead of hire artist purely in goal of increase profit help to make rich guy to get even more rich how help humanity datum incredibly valuable openai facebook prove ever big model require ever more datum live in capitalist world something valuable like datum typically to pay for open source ai should not thing also openai hardly open source anymore no long disclose data source datum harvesting data methodology nor release training code also not release train model anymore truly open source see maybe defend at moment all see company violate data privacy licence to get incredibly rich not train model on copyright datum mean not learn information from web outside of specific openly license website like wikipedia sharply limit usefulness great lead to future with thing like copyleft datum where want to train on open stuff model legally must open machine learning algorithm not even intelligent enough to filter out getty watermark not mind experience any more than zbrush any other complicated software furthermore not produce output like human speed scale more akin to automate car factory than human tinker fair use law not design with in mind rest of whole thread not opinion opinion act like fact about law not yet explore agree hence support lawsuit hope getty win which hope lead to some law vastly curtail which datum ai train on especially datum come from artist creator who already some of low pay member of society unless lucky of group what good thing openai exactly yet to see any of technology use for any sort of societal good far only thing see cheat on homework exam fake legal document serve dungeon master for d d last one kind of cool first two illegal additionally work in any kind of serious research division at faang know collective suspicion of openai work recent paper lack thereof for chatgpt no long describe exact specific datum use beyond say internet no long release training code make independent peer review verification impossible cause many to question data legally obtain at any faang need to rope legal into any discussion about datum source long before begin training most datum see on internet not actually usable unless explicit licence allow lot of datum off limit openai seem to ignore hence never discuss datum specific anymore live in world of law multiple social contract not just feel hopefully openai punish restrict accordingly start play by same rule everyone else in industry fanboy such yourself not helpful to progress of responsible legal ethical ai research nothing mean anything unfamiliar with commonly understand meaning of word dictionary definition of inspiration process of mentally stimulate to feel something especially to something creative diffusion model not not mind note vq vae part of sd model alone encode decode arbitrary natural human make image pretty well with very little artifact diffusion model part of sd learn distribution of image in encode space maybe elevate income lol openai start pay professional datum generator for dalle only thing see cheat on homework exam fake legal document serve dungeon master for d d last one kind of cool first two illegal well just cherry pick llm very socially good thing like act oracle for all internet knowledge automate million of job assume get accuracy issue work out which ton of researcher try to some of whom even on sub by far most promising use allow computer to understand express complex idea in plain english already see use of for example text to image generator use language model to understand prompt guide generation process how github copilit turn instruction from english into implementation in code expect see apply to many more application in year to come especially once desktop computer get fast enough to run locally start play by same rule everyone else in industry everyone else in industry also train on copyright datum no source of uncopyrighted datum big enough to train model also brain update its weight base on copyright datum in comment right now not violate copyright why should ai any different see nothing about mind in thay definition diffusion model weight part at issue no question whether squeeze infringe content out of weight to feed to vae english second language for mentally adverb in manner relate to mind mind blob of flesh combination of chemical interaction happen in blob of flesh perfect simulation of chemical interaction consider mind what about slightly simplify model how far down path to go before no long consider mind act like obvious answer to question not think much luck to get everyone to agree with all need to stop stretch definition of word past breaking point not act like anything simply understand vast difference between human brain highly specialize machine learn algorithm diffusion model not mind not only need very basic understanding of machine learn vs human cognition to aware of ai actual intelligence stable diffusion sentient device",
  "how not multi label multi label not mean every possible combination of label value to occur in datum some label correlate central point of many multi label method actually just work on problem where happen dice loss function very good for deal with imagery where each pixel belong to more than one class each class need to its own channel in label actually exactly multi label unless not wish to allow for neither nor b case in which case make multi class problem with follow cls b cls b wrong though multi label problem each label represent different classification task all task somehow relate generally refer to multi task learn definitely overlap multi label just mean multiple non exclusive label",
  "look up nnom build pytorch onnx tflite tfmicro toolchain for project to get vision model run on cam with platformio arduino framework perhaps of use reference caveat to consider embark on kind of project pytorch onnx channel first memory format while tensorflow channel last convert model with onnx tf insert lot of transpose op in graph which decrease performance with three time for model increase memory usage use module instead which also covert operator to channel last want to fully quantize model to since really slow on small mcus especially lack fpus vector instruction watch out for quantize dequantize op in converted graph mean some op not support quantization need to wrap execute slowly in mode lot of performance to gain by use hardware optimize kernel depend on what mcu what operator model use eg for esp nn which greatly speed up inference time for project two time for really tiny mcus library which perhaps useful not support many operator work in testing for simple network how to figure out memory need performance bit tricky ve simply use for example torchinfo module graph output graph statistic display to see how many mul model use approximate parameter tensor memory usage ve improvement cycle where ve train model for step deploy to hardware to measure fps adjust hyperparameter model architecture until fps acceptable train fully to see model config job iterate what kind of mcu target depend lot of capability of mcu how fast how much memory dedicated npu tpu vector instruction yes completely agree on try use emulator instead of actual hardware something like ultralow power arc em series nope not use any emulator for project hardware use cheap convenient to use no need",
  "for most of model case predict target also predict target one of feature depend on datum model itself which one easy to predict most people know opt for week prediction period without intersection in case",
  "look like optimal control problem rather than rl one rl for situation with no good model available stochasticity present still good model once uncertainty know markov predictive control good way to go perhaps semi markov decision process paper by sutton good start should give sound like look for option in reinforcement learning any paper cover idea of interest to search for keyword deterministic mdp relatively well study area okay first off very curious what actual problem solve describe bit more in detail give link perfect model cheap to compute go with sample approach not know how constraint look like though state action space big want to reduce somehow by learn embed model differentiable guess use milp approach guess some combination of mct with value function learning plausible search space big such with alpha zero etc find hybrid aspect of very interesting though sound like want to amortize search need to combine mct search in continuous space sampling should simple enough with perfect model probably some idea from mu zero come in handy also world deterministic not build good model of close to situation of game such go monte carlo tree search algorithm option to consider variant of uct with without function approximation not able to find anything about optimal control with all of non linear dynamic model non linear constraint both discrete continuously parameterized action in output space in general discovery of paper technique in control theory seem to much hard for some reason basically give some predict environment state go forward for say time step need to find optimal cost course of action although environment state predict for purpose of task agent consider deterministic agent one variable of internal state take action to increase decrease value base on interaction with environment calculate new cost over give time horizon by simulate action choose at each step simulation fundamentally sequential not allow backpropagation of gradient go with sample approach what exactly mean by something like reinforce guess use milp approach not sure follow here not use milp in mixed integer linear program at moment use linear programming approximation heuristic which not generalize well some combination of mct with value function learn think work however without look into not sure work at inference time in resource constrain set oh also model need to run at inference time in relatively short period of time on cheap hardware information in book free online nonlinear break everything usual approach to linearize at well choose position compute control use close linearization",
  "maybe help mention sefit method which seem similar to what look for any lm with multimodal input pali find one under keyword embed fusion in llm provide overview of many method other say anything on multimodal fusion transformer in sense communicate between semantic text embedding lm model through methodwould operate differently to multi modal embedding method which only practical for toy problem really right now allow to use semantic embedding to find what to look for svd on autoregressive lm depend on input for example transform embed into key to apply abduction with in process impact generation of logit not sure behave much differently to alter logit bias of token interesting to hear find relevant code at all code implementation here find relevant code at all code implementation here opt out from receive code link dm mention alternative to prompt engineering thank for answer afraid idea quite different take embedding from lm finetune rather than align inject external embedding thank good pointer particularly interested in different mechanism how embedding integrate into lm eg in pali simvlm external embedding here image encoding simply treat token embedding other use modify attention mechanism to potentially make well use of information aware of work directly compare multiple integration mechanism not aware of any comparison maybe not matter much pali feed embedding from vision transformer to lm after linear projection layer allow back propagation through vit weight image encoding learn for task ability to tune embedding in end to end fashion important consideration yes seamless joint training definitely one of perk look far find anything about effectiveness of different injection fusion mechanism",
  "very nice codebase for vq vae more recent variant use gumbel softmax use in openai dall e available in codebase not find thank for kind word variant currently not implement certainly add to code base upon request",
  "second place in forecast",
  "",
  "depend on how large model for mnist digit recogniser more than enough while for language model with parameter totally not enough also generally want to train model on gpu rather than cpu ai model huge group from simple linear regression train on intel atom in second to huge transformer model like gpt neox take month to train on cluster of tpus before get on with train familiarize yourself through one of free ml course for example prove helpful definitely train simple model within reasonable amount of time plan on more computationally intensive deep learning task well off use some cloud compute service recommend google colab use some free gpu compute for experiment alternatively use own cuda enable gpu computer one uh think only nvidia card work for hardware ai",
  "",
  "leader in space start to irk to see many article discussion about ai war between openai google respective chatbot openai main chatbot google lamda among many other one thing for sure both large perform differently depend on metric use company such facebook google nvida chinese one like baidu ect all heavily invest in ai research contribution of research scientist nation worldwide all noteworthy build on eachother google employ far more research scientist than openai volume of ml publication impact factor of publication altogether therefore great deepmind ai research subsidiary of google leader in ai research deep learning for many year to directly answer question for what worth say nasa leader in space honestly question vague poorly define should not equate chatbot to company doubt research team associate with company not know for any important novelty probably mostly special know how to train large transformer architecture resource to matter situation busy fluid shroud no real idea also situation totally different in year perhaps in america in world want to check out wu dao beyond current state of art wu dao seem like total beast leader in what space what sense fundamental research innovation marketshare for llm hype purposefully vaguely define increase chance of get answer like thank for info not underestimate undervalue something appear not well think out develop meh size of research team not strongly correlate outcome quality innovation furthermore bulky team reinforce momentum on certain approach turn into dead end long term meanwhile small team elsewhere start from completely orthogonal approach sometimes truly innovate not convinced google right approach for long term organizationally technically not say chatgpt google killer either yet way of expose to other player in field matter some of good most effective example nestle away under someone less known someone relatively known just not get press only most obvious example currently get edit typo seem to basically zero info about wu dao which make hard to take seriously sota possibly guess how anyone else know wu dao like mythical beast like loch ness monster catch blurry glimpse of also even suppose wu dao sota despite no one able to confirm trust bro problem train by just copy what google openai publish try to just scale up what not sure call leader in space no clue how to make any innovation yourself wait for someone else to publish innovation just copy try to scale up",
  "preppe music for sale not know how to describe what genre try to put datum into gpt hope know artist enjoy its music recommendation few time not know everything nor listen to every artist genre categorization genre choice limit to limited experience assistant who great timesaver help get hit otherwise miss just not understand what about sell music catalog like record label something no just composer with very large catalog of which not time to properly tag describe for sale use just song name file name not enough need very very specific tag relate to mood tempo audience beat per minute instrument list on on for every song in order to proper exposure in various music librarie online busy over last year write stuff to bother with add all datum with advent of machine learn tool hope help yeah well good luck with",
  "sound reasonable to interact with hp exploration method for instance random search end up select hps wherever happen to sample more not very repeatable redo hp tune depend on how many test k fold cross validation on each hp also consider introduce some small random noise between select hp training get k variation on hp value stability in result by aggregate with mean stddev something similar hope give some idea not area of expertise though quite bit of hp tune over year",
  "wow automate add incorrect answer to stackoverflow kind of meta seriously though chatgpt pretty mediocre coder for anything more than simple question find often wrong worse often subtly wrong even right often not good way to something stack overflow ban chatgpt for reason give seemingly correct answer go into bs tandem mean to use tangent instead of tandem not against stackoverflow use policy due to factual unreliability of chatgpts answer oh god no go to turn stackoverflow into another quora why untested code worthless chatgpt make many mistake not take into account anything change update since please stop far many people freak out about without realize not post anything just generate response for user extension wait how get to use chatgpt to develop something feel like people who mad about never actually use stackoverflow pretty common to google question find ask on stackoverflow only to find question get answer also plenty of stackoverflow question with terrible answer unreadable code etc add on great for situation also like point out many time not actually post answer generate think everyone agree bad get generate answer to unanswered poorly answer question nice little streamline to search flow though here link to extension for of who want to leave one star review how api out for cgpt one of application of most inconsistent with what how work stackoverflow temporary ban account think pretty neat like second opinion especially on question with no satisfiye answer pirate mode like prefix every question with answer following question like pirate not see why people hate on just add extra option good for unanswered question personally not use stack overflow since chatgpt come out please just stop like everything make browser extension spam helpful community resource with unreliable garbage uh okay guess delete clever idea think great solution to stack gpt problem just embe response clear which response bot generate always up to date assume openai incorporate new training datum at some point public what api use cool chatgpt wrong answer feed to chatgpt for more wrong answer internet fed hope some answer cache for curation of result by get feedback reduce waiting time resource usage of openai to good player make answer validation part of game community improve whole thing by testing rating where browser extension link to how use chrome extension hey edit video apply zoom effect screen recorder what name of extension real wow dump trash to internet love how everyone hate on of chatgpt next year thing kill time for stinky stackoverflow mod top reviewer to finally earn proverbial pay prove actually deserve first time try tell to use some python package not exist name seem plausible conveniently function need immediately show at least for copilot far more useful tool even in simple case propose write function just call another function nothing else just use word tokenize directly chatgpt produce wrong answer all time sound super professional in wording write out in perfect step by step flow say big problem not access to new update relate code therefore give out of date information require more debugging than just google sometimes just like real stackoverflow answer incredible for debug even wrong of time still save from hour long session of bash head against keyboard half time play with chatgpt for first time yesterday to test capabilitie ask for some verilog implementation of customize shift register give wrong answer at beginning teachable though apologetic lol correct few time give correct answer after try include verilog testbench which some work to pretty amazing though on what at time most likely much well for year to come way well model for code codex copilot for example many of same downfall find for anything non trivial much well off start from scratch say glue stuff together write configuration code pretty well which put lot of blue collar coder drupal other low code solution out of work some day very soon copilot like llm go to enable rapid tdd even bdd big change in how programmer work quality of product ask to improve code optimize add comment ask question like way to with less time complexity ve surprise by how much improve answer guess not test its logic in math think its pretty good already know what help quite bit to compose sql query get boilerplate code start for specific problem delete tandem second chatgpt behind probably tangent how ban delete one of reason large language model good feed enormous amount of high quality datum from place like stack overflow place like start get update with answer from large language model lot of answer confidently wrong answer part of source datum of next big batch of large language model datum corrupt feed error in model in theory answer on stack overflow downvote not make into source datum for next batch of large language model training datum large language model not try to generate right answer try to generate convincing answer even what post in stack overflow answer not right write in style community respond well to hence upvoted anyway seem like helpful answer other commenter already address actual question fair concern not just answer submit by large language model wrong corrupt beautiful oasis of knowledge certain part of internet wrong answer feed back into future training set of large language model not send datum to webpage automatically send text to chatgpt inject response into page stack overflow no idea happen for now use of chatgpt to create post here on stack overflow not permit user believe to use chatgpt after posting of temporary policy sanction impose to prevent from continue to post such content even post otherwise acceptable not use chatgbt to answer question in any way chatgbt browser extension only change dom fine per se funny how quora joke now which rightfully deserve just ccp propaganda machine at point with weird question hit nail in coffin moment try quora crap quora already massively copy question from stack exchange calm down friend just month old free to access still in research not owe anyone anything say to just add compile run test to auto uploader s yes only need few idiot to start use copy paste every awnser into post box without test code just stop platform pollution delete oh actually nice think go into comment box ready for submit to fist time see application somehow use chatgpt api not think already possible not by ask chatgpt seriously think api anyone answer please tag half of all complain about chatgpt not good enough other half think extension actually post to stackoverflow all display chatgpt answer to any give question on stackoverflow answer wrong human answer on stackoverflow wrong all time answer wrong directionally useful still well than no answer to question should answer completely unanswered post assume automatically answer question post get mad about clearly not not post anything circle complete try try out yep try out not point at all chatgpt great reason why ban from stack overflow wrong confident answer untested unsafe code dude create extension to exactly chatgpt base on definitely not in development for long time hah remind of gripe with copilot turn copilot off for any yaml file find atrocious for cloudformation recommend property seem like exist dangerously close enough to actual property context of resource think correct completely wrong in fact seem to struggle lot with yaml hardly blame though understand copilot also base off of openai tech probably see some convergence in future unless purposely hamper free product in lieu of pay for one bit like get help from human programmer who semi conscious actually half asleep say chatgpt output generally like of someone who half lucid in case to simple flask api want to use webargs framework code provide by chatgpt look very consistent with what read on internet however with some major version upgrade in specific parameter now mandatory although chatgpt should train on datum up to not know always take answer with grain of salt except chatgpt not try to close thread duplicate any suggestion of up come alternative second chatgpt feel attack yes yes chatgpt not efficient stack overflow joke chat gpt not shoot with link to documentation not answer question what laughter for authoritatively incorrect on technical question crazy to expect machine learn tool to perfect people come to stack overflow need guidance tool like push poor solution not ideal oh thank goodness feel like skirt law of system stackoverflow not want automate solution often authoritatively incorrect wonder how long account use extension last before people wise up to what happen fine until people start copy paste extension answer own even not directly violate policy absolutely make violation easy more likely to happen neat personal project probably negative impact people actually start use sanction say challenge accept remember golden quora day in already get bad since with monetary reward for ask question mechanic become pretty useless cpc propaganda not take look out of window in usa without propagandize by flag open ad newspaper ad disguise article other people clothing bumper sticker music play etc quora full of communist propaganda please show must easy to provide some evidence ccp propaganda machine all of harry potter question correlate with greatness of mother russia not china not think upset at chatgpt certainly nobody want untested usually wrong sound correct answer pollute stackoverflow ban like everyone else currently should not correct wrong please just love to play with api from source code seem dev able to use same endpoint use in webapp waiting list for api not think available yet its api s available for while now pretty sure wait list for chatgpt api what currently available gpt api assume post answer ban should not literally answer unanswered post in video hence zero plus one no should not use to actually post to site otherwise suggestion literally ask for something show in video only for not actually access chatgpt through any official apis not necessarily significantly lower barrier to entry for manually copy its answer post themselves which almost certainly influence frequency of chatgpt answer on stackoverflow not sure how make thing much well what else for how work with unanswered one should great proof of concept taste of what future look like once kink work out whether to actually use legitimate dev tool today another question entirely not literal still early day effectively first public iteration see how human also struggle with yaml maybe should just get rid of yes for sure still suggest nonsense albeit not much chatgpt for main advantage of copilot know rest of repository code more likely to suggest stuff elsewhere over bs see term for chat gpt output wrong answer lie false info hallucinate hallucinating on another note prompt who insert personal name gpt state graduate from university of michigan not amongst other false claim although maybe someone else with same name tandem authoritatively incorrect on technical question crazy to expect machine learn tool to perfect people come to stack overflow need guidance tool like push poor solution not ideal just find bit comical ironic consider how go on tandem spew bs wait what monetary reward for ask question how hell suppose to work no wonder see bunch of stupid question in quora digest lazy to turn off por que no los tenshis true take human effort to clean up pollution thank for follow up yeah not happen just display answer should obvious from demo apparently not not actually make post to site buddy not aware difference tbh just know api provide by openai not look into much past mess around with chat ban anyone who post ban minimum reputation need to post at all not real risk of happen with how moderate hence why not issue currently since ban one copy paste instead of two not see huge barrier change for people who want potential answer no answer same reason anyone use chatgpt for type of question no of course not should not go against stackoverflow explicit rule replace with njaml not just another markup language yeah theory many people write bad yaml create own config syntax to translate into actual config syntax parse just not know which way up come to yaml many git merge conflict tool not program to give importance to whitespace almost always fail to merge python yaml correctly not think problem with python yaml just dumb git merge conflict tool need to read file extension treat whitespace appropriately want to give incentive for ask question backfire pretty hard true get give some wrong lead propose inexiste library all in all interactive exchange prove useful far clearly should not first proposal base stack overflow post silly already though minimum score require to even post reply most of concern seem to from people who not already contribute to stackoverflow very weird reaction to chatgpt machine learning in general recently include in dedicated subreddit for either lot of time people seem to just want to mad at anything involve at all know why say should not answer completely unanswered post stand already answer for extension user not believe actually post to site just browser extension to make look like post people what want make rule up to to enforce no actual rule in life ohh see what mean ridiculous let steal no one find out let kill no one find out no actual rule in life people kill steal without get catch not think right some people just speak moral relativist either way understand point agree not great to post on nor use for active development at point",
  "link to paper cool application of text base command rl wonder game developer find tool base on helpful thing like already exist look forward to future of video gaming where just two kid scream at tv duck run away noooo hit hit one step close to sfm naughtiness see talk about phyic base character movement since qwop never come accessibility implication here astounding how good zero shot behaviour in context ie tell agent should sit down start drum to rhythm of rock on its chest even not train to interesting to see react to unknown skill command something like string kick kick keep on go look up cascadeur also physic base with prediction algorithm for any animation with gravity modification etc sardukar great for future pok\u00e9mon game where feel like real trainer yell duck character literally become duck qwop already perfect no not probably never go to make to actual game voice command already exist few game use why think any different imagine close to like multi classification output with n bit set meaning like slash up to left set slash up leave bit take decade not for techbut for tpc pok\u00e9mon company to adapt stagnant embrace off shoot title strongly hope while still keep option of button for mobile device on which play in public want day of animation to end",
  "thank pleasure next time series relate article hope very useful cover datum clean part share here",
  "yes single serve model about param recommend check each gpu at vastai however not sure gpu connect by nvlink thank",
  "",
  "post in r philosophy mod shoot down prompt use text of question dennett use openai playground with various parameter tune fun trivia two answer exclude other than on ground of one for describe dennett view in third person one for potentially offensive potential research how good human at imitate dennett comment generate by naturalnn auto mod see comment leave post direct link to paper post abstract comment",
  "without share much detail about specific problem its go to difficult to give proper feedback advice some question ask yourself human solve problem how skilled human to think need fancy architecture to train model assemble datum hard part modelling easy how easy basically question assemble datum risk model risk other try why convinced make money solve problem convinced why other not try what good guess at how much money make divide by good guess at amount of time money effort take to compile dataset division ask yourself worth hard math go to get answer able to some fancy correlation mapping depend on model think solve problem what datum need trouble with shortcut route take long to three step above not get accurate answer suppose first question come to mind for what problem exist in vaccine world besides poor customer sentiment ml ai potentially solve enhance personalization to someone suppose first question come to mind for what problem exist in vaccine world besides poor customer sentiment ml ai potentially solve enhance personalization maybe op use similar method of analysis good way to get idea of financial benefit also important to think about knowledge gain how much other people benefit from decide whether to continue not more to determine something worth time than just money problem no idea how much datum need read like ai need more training write yep agree learn transferable skill should take into account frame problem in same term op in case really just money no real human for some reason not take in first paragraph what say own high value domain relate to vaccine also think something along similar line of what op post rest of post about start from first principle ask simple question what problem machine learn website app solve",
  "nah not engineer vs science os vs closed much simple fair galactica people crucify generate nonsense chatgpt same thing ylc throw fit over whole galactica debacle lovely aggressive tweet such galactica demo off line for now no long possible to some fun by casually misuse happy describe people who dislike galactica easily scared of new technology to see success of chatgpt just few week later must really painful also very petty good to see stuff in common with ml great take seem quite intent on paint petty statement seem quite reasonable rational especially in face of over exuberant reaction mostly see about chatgpt mostly on research side which immediately put very hostile against engineer classic case of researcher engineer beef seem like some bad experience lead to feeling no build in animosity between group just different goal probably some resentment google meta release something similar over year ago choose not to not think responsible now company found on responsible release to world way not satisfy lot of researcher not sound petty at all to sound like dispel misconception about progress chatgpt represent get one of godfather of ai mostly on research side which immediately put very hostile against engineer find odd seem to expect want serious conversation start with some weird ad hominem against man talk about fanbois in first sentence expose yourself nothing well to honest rest of post not much well tbh try in infer intentionality make false equivalencie agree with most of statement not think petty just honest about what chatgpt represent to now bias on personal level kinda sick of chatgpt good at carry on brief chat very well polished quite mundane people already talk about use some variant to make marketing web page in web already full of ai generate article target ad should use perhaps for chat train on corpus include some support doc something not much more than think some negative ramification in bad case friend whose graphic designer at major company whose tell by employer future of ad high up say stuff like all time not wind up come true hopefully not become real problem still bit concern people on oustside of field perhaps overvalue chatgpt much henry ford nothing revolutionary engineering work in make car not particularly difficult just perceive way by public half dozen other car manufacturer in month lecun go far opposite way not surprised access to system at fair something similar dismiss whole thing miss main point like ford what openai with chatgpt make ai useable available to benight common folk not matter whether google meta not release something like due to ca not not all same to rest of humanity who not use in either case metaai release galactica chatbot month before chatgpt heavily criticize for dangerous ai generate pseudoscience nonsense shutdown few day lter now openai same everyone praise well get why yann saulty about get annoyed people believe chatgpt such milestone breakthrough unique to openai not since most big player already capable of llm tune to similar capability yet from instructgpt paper way label datum nothing any big player not handle also get piss people praise openai for its openness openai absolutely not fan for whole open source movement though maybe reasonably question why not big player give bot similar exposure find hard to believe ethic some internet critic to only reason whatever meta put out in past year fairly disappointing compare to what already availableopt nllb galactica probably advance field with knowledge glean from produce model for production all feel half baked lack polish like just rush out something to meet some kpi yes find lecun petty team not seem to produce something good to general public get one of godfather of ai what even mean very many people contribute to field yea look like meta make say stuff assume jerk off to chat gpt response alone continue to assume tbh lol kinda agree with here lecun remind of sheldon from big bang theory who constantly berate insult engineer howard think view reflect disappointment researcher not novel idea algorithm lead to success scale engineering anyone with broad view see chatgpt represent massive milestone for ai who really care how novel algorithm openai build killer product deserve recognition lecun maybe also salty deepmind openai perceive leader meta not move fast b r e k thing also facebook meta zuckerbronium actually need to something different not involve buy company to form look guy work really hard on leg for avatar seem to like in general to all ai debate day just regurgitation of glass half full half empty discussion yes llm far more intelligent than anyone anticipate to by point in time no not general intelligence constant back forth between two group essentially replay year after year not much change in term of argument always find curious lot of godfather of ai seem to bit like get drain to listen to tendency to reframe any debate definition just right technical name butt hurt yeah some important relevant point butknow spend whole day on twitter complain about chatgpt most of complaint not first most advanced nor good find very curious come from some who work at meta since kind of critic work for almost all meta product position rival make statement look petty still agree with most of statement quote here think all miss point schmidhuber basically invent chat gpt in already just with small network small dataset less compute power although even schmidhuber basically just steal from gauss no one talk about lol at previous post obviously disturb just latch on to argue for thousand of word online outlet not wait for next month ukraine covid back on news cycle move on to r worldnews right full of exactly blame user for galactica debacle wonder why openai chatgpt get adoption spew same bs per word also proceed to tell just people drstroye meta reputation overall majority of reaction irrationally exuberant often pablum for vacuous content creation cycle one not affirm super positive life alter result surely to come get leave behind let see what actual problem chatgpt solve fair point correct petty at same time remember blame people use galactica casually reason get pause wonder ask people why chatgpt not face same backlash give spout sh t although one argue usable llm in production quite revolutionary nvidias gaugan gan base txt to image model base diffusion model for year two not receive same publicity profit stable diffusion midjorney basically same line of framework narrow minded thinking to brush architecture upgrade engineering work make possible which always statement fair point consider mainly researcher not engineer some bad experience thst lead to feeling work apply researcher both research engineering no beef on bad to say beef like dev qa relationship researcher want large model possible yield good metric engineer want easy to deploy monitor former also undermine what engineer just package up yann just say above listen to critic think zero progress make at all every time new software come out something not before handwave away easy obvious something else easy already well with chatgpt beat chatgpt by few month bit more power easy to make chat bot answer want not think good chatgpt though factually correct petty at same time read more about conversation with people who argue with all time bring up galactica fail rollout compare to chatgpt wonder why not pause well give quote from galactica even produce less bs also seem to undermine rapid engineering work mlop come with chatgpt which funny meta not release any substantial product from research see light of day for week also to chatgpt in itself in research perspective jump maybe not incremental what lecun every paper compare to average paper in field toxic aunt always talk about in dinner table petty please point out ad hominem against instead of generality just literally quote all thing say give own take on infer intentionality point out conclude intentionality base on line of reasoning conversation trail position some variant of just other day some researcher already release biogpt which train on biomedical text particularly good sitll need some time to test its accuracy against real medical professional respectfully disagree on usage while show to generate weird sequence with right usage guide to create particularly effective article story summarization tool also good grammar particularly good well what chatgpt represent to true petty at same time ask revert to complain why galactica shut down blame people use point to why chatgpt more mistake still stand why someone also suddenly post paper contribution chart say other just consume research delete galactica doom to fail specifically market science tool which put very high expectation on factual mathematical correctness chatgpt on other hand market chat fair point why blame people instead of whole company go far just people destroy meta reputation high respect for researcher in fact ve read book paper great speak researcher different speak meta employee vest with company interest why take meta drive statement for against company with grain of salt not even surprised big tech company behind stable diffusion midjourney lawsuit since good consider fact meta partner with shutterstock to produce own only talk in context of llm language not statement simply incorrect in past two year fair publish number of high quality self superviser learn framework come with open source implementation on top of head moco its version barlow twin vicreg swav all come from fair one show ssl for computer vision not need to contrastive only some of paper some citation in span of year use by many researcher on daily basis yeah tell how chase corporate kpis publish junk to meet some kpi big tech in nutshell to close some jira ticket perhaps mean see argument of authority from other people mean see other use argument of authority for sure tbf screenshot where talk to post in twitter thread to say tell meta leader in research community alongside google top contributor funny thing start post graph of ai relate paper contribution to show supremacy to undermine openai deepmind merely consumer of research meta not provide any product from research reach public try immediately shut down also kinda blame public perception to why meta not publish product without scrutiny point thing people still overly criticize facebook meta for obviously great reason in past indeed massive milestone maybe bit above stable diffusion still argue github copilot big since its mainly for devs not get publicity want massive milestone common folk ponder idea of ai takeover which shift every one else perspective on domain culmination of decade of r d public interact to gateway to ai its complexity common folk public not really care about sophisticated algo never see light of day read comment know answer already go profile for some stalk reason yet ignore lol thank for add contribution to discussion like contribution to field salute fb scared of bad pr openai not people try to trash chatgpt million of time galactica just few time think chatgpt handle adversarial attack pretty well google another scared company model not see any attack yet unknown not care how nice screenshot look what want to see how people hack form opinion people true test set no clue why down vote know its just petty not even talk about in generative image space chatgpt very much like midjourney stable diffusion where model small incremental update over main paper put proper apply research mlop work to bring into production profit from in dinner table at dinner table please point out ad hominem against literally quote yeah mean seem grounded not petty to personally fairly subjective criticism seem fairly mild not think worth get work up over what world record for cross english channel entirely on foot fair question for google nor chatgpt maybe come to sense put back want to use to find reference for random idea see what result not to mention company willing to put out huge ass model training log which infinitely more useful to community than three vague blogpost retweet by ex grifter on twitter claim gpt quite literally trillion parameter worship sam altman god lol people keep claim other dismiss engineering effort go into chatgpt turn blind eye to relative opaqueness on technique trick go into make model happen not even dataset available other than show proof of concept which significant not sufficient for science how exactly community of ml benefit from openai get all hype satya money whisper weird counterpoint to argument though say for production meta not produce fully baked production ready product from research for public consumption point of post yann reaction meta employee reek pettiness first tell everyone chatgpt not revolutionary at all fair point debatable proceed to post chart about meta google big tech producer of research other just consume ask about what research put into production claim not not not proceed to bring out what happen to meta first trial to galactica embarassingly fail all in all seem to criticize why company just consume establish knowledge by sprinkle something on top from what publish honestly expect google meta to quite cautious now on how publish stuff since openai move build on top of establish research no one also say publish junk strawman point overly critical to startup like openai who consume establish knowledge voluntarily open to public start to profit from while fail to produce something profitable usable for public consumption hope get help need lecun fanbois for sure either side of research engineering perspective no clue what other side why bad researcher want moola should make business publish run model create from own research not want to get step on by someone else talente enough to piece together not release idea not get butt hurt primarily publicity capitalist base company implement idea make into product not ad hominem ad hominem attack subject basis of its argument tell person x base on y not ad hominem conclusion of quote lay down expect to say no result at very least no well than llm hope succeed ln try to learn ml concept well lot of angst to work through friend really build up some divide between research engineering simply not exist lecun fanbois for sure fact unpopular in opinion shallow view of current nlp not argument for call everyone else fanboy not bad entire point of post beef not exist divide between research engineering exist one of fundamental reason why some startup fail not know how to balance which not know how to construct team divide between datum science datum engineering folk who work on know in year of work with both engineer corporate researcher academic not experience divide describe research not something happen at startup no revenue to support research in startup entire focus on product research not something happen at startup entirely depend on startup product r d happen on many startup unless someone limited exposure on ai ml orient startup far from truth openai apply research company produce research paper put into production in electronic department oneplus rise great r d startup capable of produce rapid r d base product grammarly put ton of money on its r d to create more domain specific gpt model vital to product divide describe one not need to probe deeply into ask experienced data engineer data scientist devop clear distinction of what how balance each other divide not hostile more of want not all of type of relationship besides usual difference of who work with what",
  "",
  "check out uchicago knowledge lab sound generally relate to what james evans work on work more narrowly target than what take about its focus on generation of idea in academic setting its still good starting place for also sound like relate to some of work come out of santa fe institute not any specific paper in mind all model wrong some just useful not draw any association to complexity of nature from complexity of latent model scientist use to research nature high dimensionality not necessarily mean more complex in fact know for quite while go to high dimension make various problem easy non linearly separable dataset suddenly become separable in high dimension for example turn to basically get kernel machines kernel embed datum into potentially infinite dimensional space very successful before deep learning take over just math lot of guess not really similar toilet thought to its also interesting to operate in fix float point precision roughly approximating pattern which tell high dimensionality seem to help map complexity with less prescision than need otherwise deep differential model ml use probably not optimal think question more interesting replica of algorithm bio neural network use real world also thousand of dimension time color hatred tension in room air current anything possible attribute to position thing at end of day just word meaning depend on agreement speak of dimension mean dimension of physical world decide to define with coordinate help know position of something well use complex number keep to coordinate decide time should include part of concept of position talk about dimension in general well mean anything theory human imagination creativity link to dream learn change fast different brain half play off scenarious to each other to test out internal dreamworld suspend jump over limitation of physical world like time place sense still manage to improve how understand interact with world awake think well understanding of human brain especially dream need for next big leap in machine learn instead of brute force technique use now to train static model thank for recommendation always fun to read research appeal to personal flavor of intuition agree also important to remember brain just architecture definition mind model ml model mind model unrelated however one person guess another monte carlo technique perhaps also not understand why downvote why word guess architecture model much more intertwine in brain also not understand why downvote never understand reddit downvote behavior clearly not just bot seem some people just not stand honest curiosity not already know what know etc true almost get pity upvoted for talk about downvote get downvote for lol controversy naturally talk about get downvote now ve say",
  "rwkv train on pile glm model alpha model model in term of consumer app poe app from quora access to two model from open ai one from anthropic perplexityai youchat neeva search engine integrate llm google ai search event on wednesday where likely to announce something well in term of apis get feeling for model use openai apis model good publically available model open source model still far behind actually know chatgpt full with codex still enormously powerful previous instruction tune model in paper seem likely work on much small parameter count love how bloom just like f ck let one up openai try out youcom chatbot seem to work well sometimes same problem chatgpt with just make stuff up provide source real imagine lie actually check ask what todd howard favorite cake give authorative answer without source ask for source give gamerant link not exist provide source notate like wikipedia also access internet able to tell about event happen in last hour able to produce code conversation with really prefer to give information from web whenever possible not tell what model use own proprietary model also stable diffusion text generator not know what model google ai test kitchen for lamda look at parametric search where highlight in graph database style way mistake with result by reassign weight link to redo search until get answer more correct base off thing like water not useful for clean dry paint acetone paint thinner more useful possible to build such feature into any of open source tool here lack any gui for feedback beyond text thumb up down one see in commercial package love to see comparison of model on some common task comprehensive list of llm final release around feb any benchmark score such mmlu bigbench available for aleph alpha model to pre empt possible confusion by people want to try youchat its url youcom chat while youchatcom unrelated messaging service glm really really good think some instruction tuning all need to match text davinci model yeah think its just like mlp with random weight not connect to any output with rwkv pile pth release hour ago see at yeah still wip not think not takeway glm even behind opt accord to mean win rate instruction tune version of opt in turn bad than flan which small model table honestly not surprised lol bloom task well behave believe fine tuning dataset matter well model guess see think plan on fine tune set use to tune opt not contain any chain of thought bloom pretty terrible unfortunately",
  "recognition use of hand behavior for control technique with potential application in wide range of field surgical teleoperation system use force pressure sensor to capture hand movement relay control signal to remote robotic arm wen et al wen et al myoelectric prosthesis use residual electromyography emg signal from residual limb to control degree of freedom of prosthesis resnik et al application in extend reality xr such virtual reality vr augment reality ar generally use form of hand tracking to capture gesture perform recognition for control in human computer interaction hci kong et al emg thus far focus mainly for prosthetic device however emg potentially transformative for hci for consumer xr anticipate wide adoption of wrist forearm electomyographic emg interface device wear daily by same user present unique challenge not yet well address in emg literature such adapt for session specific difference while learn long term model of specific user in manuscript present two contribution toward goal first present misdirekt multi session dynamic interaction recording of emg kinematics dataset acquire use novel hardware design single participant perform four kind of hand interaction task in virtual reality for distinct session over total second analyze datum use non linear encoder decoder for dimensionality reduction in gesture classification find architecture which recalibrate with small amount of single session datum perform at accuracy of on session oppose to architecture which learn solely from single session learn only from training datum frontiersinorg what hardware use in image open source hardware implementation",
  "suspicion ut not adopt not really work much in practice beyond some algorithmic context even in certain algorithmic contexts rvnn much well well one of own paper show weak result with upon scale also suspect in practice act mechanism end up work bit wishy washy another concern parameter sharing mean either to limit parameter increase parameter per layer by lot to keep up increase computation cost repeat many more parameter per layer even save bit more parameter at point not matter much perhaps combine with mixture of expert some sort of modularity make some headway make thing more inconvenient also deep equilibrium model also interesting alternative to act ponder cost however possible chatgpt more easily write program for kind of algorithmic task solve itself try some listop with chatgpt result interesting also give just input of listop ask to generate program to solve some mistake think result get out of boundary program typically not far off very nice kind of frustrated not see more universal transformer pretraine at least albert like layer share feel need to combine various recent idea layer share pondernet gopher realm like information retrieval chinchilla training datum size efficient attention make sense together layer sharing reduce internal memory retrieval solve long training lead to some grokking research need atomic contribution kind of discourage thtat low bind complexity of problem learn in algorithm should not get throw out window linear algebra relus attention mechanism involve think forget few reason no insane hardware algo deal with memory parallel bound something ve look into well agree with core problem however believe specific instance of unextrapolatable xor more to with problem of positional encoding since both experiment other show xor extrapolate train either with shift positional encoding see by add observable padding token problem instance decouple from transformer input length on topic of universal transformer some comparison by of similar transformer layer layout where show single layer recursion particularly bad additionally from experiment seem output layer exceptionally poor attention target in recursive application at least for language model prompt engineering just rnn in disguise yea totally miss out write about code generation alternative for algorithmic task think main concern even traditionally nlp task on surface non algorithmic require algorithmic reasoning implicitly generate code not possible solution run into computational limitation paper show weak result with ut actually point out something say about scale up uts kinda what allude to wrt to cost in scale up uts albert state of art on some task some work on act albert yea uphill task try to convince anyone method worth incorporate into future incarnation of model constantly ask to compete on benchmark smash by large model oh well lol probably right algo probably not cover parallelism much where learn usually cover space complexity actually see two method of solve parity with xor gate trade off between space time solve sequentially mean only need to maintain bit of memory for all previous time step give on complexity whereas solve divide conquer binary tree style incur more memory usage need to maintain previous layer computation at every level of tree get olog n out of parallel bound not negate fact number of serial computation need lower bind though insane hardware just mean each computation step get compute fast not mean computational complexity change yea think while ut seem like all property help think in reality not always learn right function learnability issue instead of expressibility issue theoretically should able to learn parity problem hard to get to actually reference paper proof by construction for transformer solve parity problem which require small addition to positional embedding think solution target at parity itself treat symptom not cause rnns with discrete finite state yea totally miss out write about code generation alternative for algorithmic task think main concern even traditionally nlp task on surface non algorithmic require algorithmic reasoning implicitly generate code not possible solution run into computational limitation yes concern well yes show some backward scaling with not sure what go on not look much into detail agree hardware not change classic complexity bound more talk about manage memory access than total memory need in practice bottleneck change perspective like how gpu make matrix multiplication fast change lot of thing much more than try to matrix mult fast with sequential standard algorithm answer bit similar to what say to like to remind problem in np yes no not accurately predict how fast algorithm go guess point in post more size of input change for many task number of serial computation need to change well minimum number of serial computation more less dictate by low bind complexity sure depend on how parallelisable problem able to lot more with less not happen for transformer architecture stand now run into issue just work on small case slightly large small case not mean extrapolate all way after all one way to achieve speed up to simply memorise solution real issue encounter kind of transformer general unit dedicate solver for computer stuff think goal to replace all algorithm with big neural net not go to transformer to fair transformer output code for most algorithm in any language want not think far off in end generate code run on separate interpreter solve some of problem yes wonder similar issue occur in code generation seem like similar issue arise nesting get deep enough play with some code generation model feel like lot of memorise",
  "not same suggest to look into event camera not sure follow question why need to special research for high fps camera challenge with all video base system to capture long range dependency long range define over number of frame how much time elapse between frame not really matter however high fps camera slow move scene lot of image pretty much identical to each other mean accord to information theory very little additional information in each frame in case want to consider to temporal downsampling on datum fast move scene really need to take advantage of update prediction for every single frame only constraint process power in case problem of inference for high fps camera same computationally efficient model few model who intend to run on mobile device maybe want to look into thing probably process time not many good image model application run time second in order to process each of frame usually long process time than some ms say yourself in question what potential application also to online not even though camera high speed similar to other camera for deep learn research greatly benefit from high speed one practical issue with high speed camera lightning require to still get enough exposure depend on situation draw in lot of bug which negatively interfere with system find spad quanta image sensor interesting",
  "chatgpt say run several model who know choose base on prompt to more fine tune big current open source personally think fine tune conversational datum set within large model use large general model give well human result yield multi disciplinary knowledge feel far architectural approach in own attempt at make own model try something novel goal to model run locally on cell phone currently get to text predict rehash wikipedia article very human language with good grammar vocabulary pretty good accuracy also learn nearly instantly big struggle face accuracy vs resource need what drive architecture to free ai from only run on big machine say result in month of hobby time tell other approach work highly doubt approach anything like what use big problem see in make compete ai model resource need training datum for dialogue base interaction why start with text prediction to see how viable approach where mostly all start research accurate google several open source chat ai require lot of local resource to run check out one link anecdotally think fine tune model much easy to accomplish less training datum feed mine more accurate with less complexity",
  "google for find ton of option product with documentation most of offer free trial recently hear of company use evidently ai not try really depend on project requirement should start try thing out actually look for concept methodology rather than product any help on",
  "prerecord clip tortoise tts gpt type asmon model realtime thank look at how to all question how pick datum from slam everything streamer say not good idea should something like take streamer respond to question also no idea cost of training amount of datum need cost of run chat bot idk sound more like elevenlab to sometimes let know how to seem fun tho why not more datum mean more accurate no not not control datum",
  "wow quality of video very good imagen video not long ago browse through example in website still strange ai movement to still impressive dog to to dog play with to feeble attempt at similar scene with stable diffusion approach which first diffusion base method of its kind combine low resolution spatiotemporal information from original video with newly synthesize high resolution information to align with guide text prompt allow one to create video base on image text input to improve motion editability team also propose mixed objective jointly fine tune with full temporal attention temporal attention mask adult film about to wild well delete face off internet folk what with google announce ground break tech not share code what exactly purpose here next two year bonker year deal with fall out for next ten same wilder human evolve in environment where often prey predator out ancestor not understand disease think bad weather anger of god moon big mystery most people die infant by age of at least once in past know bottleneck of only few thousand human live at once take modern problem any day pretty soon make own decent quality movie on budget all need green screen with actor stuff in back no model to test not happen speed at which ai grow get almost scary how get hand on how test git repo for up anywhere man go into time where not trust any video orpicturr at all which difficult tendency to influence by video picture even subconciously how good move through field with naked dancing lady video quality anyone see thinking of some website try temporal inpainte need to add interactive segmentation system to make more usable webcomic take off circa bar to entry really low ton of crap also story go on for ten twenty year not exist at all not for advancement in create distribute digital image about to see ton of crap go to fantastic speed at which ai grow get almost scary well suppose no way people use for evil not trust photo video evidence now super easy to subdue mass with advance propaganda rule class reach invincibility let accelerate how fake news deepfake make before contingency to spot false flag scene designer love perhaps reality really simulated reality run by ai angel oh man sooo not need to spend any more time on perfect vfx game impressive paper not expect to see source code though temporal consistency of dreamix much well than imagen meta make video struggle with spatial temporal attention which see in some video where small movement result in weird behavior like movement of dog leg ability to preserve original subject appearance from image its condition on really good interesting github repo list author anonymous paper publish list all name where try true although two task slightly different same difference between generate image with prompt compare to manipulate image with prompt quality of video very good noodle one straight up curse still strange ai movement to call foot slide in animation some uncanny fun right wonder data quality issue in play fair number of inconsistency look like at home in low resolution footage while clearly lack consistency each individual frame of example much well in opinion what s with all blue artifact not look normal cool very cool not terribly realistic though not say not also terrible real blue iswell kinda spooky lol true mean whole deepfake use deepface around for year not sure how change anything flatter tbh face why delete love to star how to use what exactly purpose here pr for shareholder to counter claim dinosaur on way to get disrupt by openai whatever cool thing in ai at any give time what mean actually just video call new compare to birth of www already trip of year month in always surprised how people look at amazing technology like only think how potentially bad not how amazing for mankind not even need green screen background removal relighting come along quite nicely just film somewhere with environment somewhat like target seriously announcement just way for to claim first without burden of actual peer review to test claim seem to model probably require enormous amount of compute just to run not sure good idea to release to public about singularity time for real starting pistol not even fire yet also like to know no porn yet show need well way to handle generative model site fill with ton of model need to download multiple model to get good spread each model produce thing other model not never get exactly what want for time textual inversion hypernetwork lora help few people use prefer to make new checkpoint even use difficult to use to explicitly add into prompt by use word phrase trigger use way to add new datum without create new checkpoint without need to explicitly call datum need for real add face even more know somebody somewhere out want face in ai porn video with some super model not think should worry about pixel comment flag by ai for criticism of supreme leadership kill bot arrive soon jk dystopian ai generate fake news era here come keep perfect game good vfx artist who use new tool outperform good vfx artist who not use new tool no time for finalle get to deliver dog grow extra leg some auteur director need to take advantage of to make creepy dream sequence in movie make vaguely nauseous fun application in horror movie not really what blue stuff lm sampler suffer most from blue artifact use lm try lm karra instead artifact go deepfake barrier to entry need to train on lot of datum atm despite still pretty damaging albeit limit to famous people just look at recent twitch deep fake drama now imagine anyone with minimal datum suddenly not need huge amount of datum of famous person suddenly one picture of ex piss off look mighty tempting for some sweet sweet revenge see where go hahahah tell just send pic of face first haha hope whole ai thing from google all fake not lose much job mean think see beginning of new major disruptive cycle not make value judgment about human not evolve to exist in kind of technological environment create nevertheless push ourselves far far at accelerate rate into such environment prevalence of dangerous destructive tool also increase at accelerate rate year ago only handful of ruler capable of cause widespread destruction through war with hand to hand weapon effect limit to small geography year ago still limit to big handful of ruler time firearm cause widespread destruction over much large area today ruler nuclear weapon biotech engineer ability to create super virus countless leader surveillance technology trap people in orwellian dystopias software devs powerful narrow ai system use to globally spread socially corrosive meme etc soon nearly everybody access to superintelligent agi system use to cause unimaginable chaos destruction zero progress on alignment problem not difficult to see where thing probably head mean porn lot of great video link to part not tiktok website not desktop friendly not see bad not what mean work in space mean see tremendously disruptive in same way dawn of internet steak engine electricity go dramatically change some piece of economy how thing just first glimpse of whether bad good for in long run different story feel like technology progress lose bit of humanity mankind tend to either derive most invention from put most invention to use for warfighte spaceship engine get to appreciate fraction of speed of light incredible someone likely take few dozen such craft out few lightmonth park use mutually assure destruction planet killing system limit to how nice thing before destroy ourselves doubt even need to film anywhere just use template scene honestly go to nice like to generate some tv series go to explosion in creative endeavor no porn yet show need well way to handle generative model site fill with ton of model need to download multiple model to get good spread please tell more about spread which model good spread ask for friend about singularity time yeah spend every second of free time with stable diffusion since november d david lynch pull off blue stuff seem to show up use forest fire instead of just tree on fire of smolder ground in its training datum continuity thing real key google obviously use some trick up its sleeve to achieve thing source video on google example not same output like suggestion for what happen in scene generate entirely new video political rival say want somebody heinous stuff under pizzeria just to stir little bit more reactionary dimwit not really need much raw training datum anymore start with few pic of target train dreambooth use premade folder of celebrity picture training datum look somewhat like target entire folder with dreambooth model to look like target use training datum for deepfake agree feel pretty good about odd of survive advent of text to video generator personally wonder alignment problem solve at least narrow down by arm every individual with own personally align ai way only need to align its goal with one person rather than entirety of mankind surely easy task ai know hack meme create own virus vaccine steer view content intake towards path mutually beneficial for both bot scientist preoccupied with whether not never think to wonder should really need to start pass law on ethic of ai before keep advance know pipe dream probably not happen until damage usual really trap ourselves with own creation not difficult to see where thing probably head revolution die die such way of life maybe technology win out such able to survive outside home planet all over again hit another critical unstable equilibrium ted right all along zero progress on alignment problem well what expect not even know how to solve human alignment problem how go to solve for superintelligence true fake though steak engine for confuse not put in list with electricity internet not steak person know some people take bbq very seriously probably mean steam engine bite work in field see potential what type of job career skill think valuable evolve big threat people say ai pose elimination of human job even highly skilled pay code programming job potentially at risk by generative ai what path pay well of ai in estimation sort by highest rate nsfw find answer seek yeah lol bit dramatic fine know what say kinda like look at electricity in say just lightbulb what about to happen akin to what happen in industrial revolution which lead to lot of good thing also level up warfighte ability from dude on horse with musket to melt entire city with device size of motorcycle go to start out at level level up time think mankind responsible enough to know what to with godlike technology probably reason guy like bill gate elon musk very publicly say think ai pose existential risk to mankind should proceed very slowly deliberately entire very interesting paper write on topic person malicious just hand agi to serial killer whatever get to for betterment of entire specie nerf nuthin really need to start pass law on ethic of ai hear not anything unless get every jurisdiction in world to pass way to enforce actually enforce right away not how work only know what law to create once effect feel make educated guess give current political climate ai furth thing from lawmaker mind law not stop criminal from attain weapon nor law stop criminal from commit crime child who teach core value integrity benefit of invest in self usually live differently than child who not industry global investor in other country not share value thus ai ml activity prioritize for different outcome even in country usa private corporation fund research with different intention interest see with f g core value machiavellian leader like child play with gun each seek big gun like in video game without fully comprehend consequence where hope to find not in realm next must look goddamnit not think simply eliminate job think go to sea change in job description think most disruptive area traditional professional job like lawyer doctor kid think watch house rerun in twenty find bizarre idea of human savant able to outdo ai laughable think still probably human tune core model probably rest depend on think explosion of job description relate to prompt tune for chatgpt technology plenty of job for fine tune model to particular domain people still remain in call center job focus more on analyst not auditor beyond think hard to say how affect other area like biology pharmaceuticalseven physic generate by chatgpt totally on board with deep learning transformative technology possibly more profound than any other technology in human history pose both massive potential risk massive potential benefit totally not on board with people milk reddit karma machine by hijack every freaking discussion about new image generation model with same dae mankind reach exceed grasp become death destroyer of world schtick not potential victim safeguard by own agi well some human right thing see in future every man woman child give agi also consider how successful effort to curb nuclear proliferation testing not globally detectable via seismograph production not require access to enriched nuclear material only expertise require for development of popular fast grow civilian field intermediate result likely easily useful in many industry everyone mum nuke ai safety research thing definitely some idea not know exactly no reason not to make effort like say never completely accurately predict weather airline company should completely ignore meteorologist just deal with weather come up law make much much hard rare for criminal to get weapon though reason gun lead cause of death for kid in us nowhere close in eu same with gun death in general also just look at australia for example of work lot of failure point here ie what simply more processing power available to serial killer with agi go to legislate amount of gpu what fiddle with code make agi much more intelligent now outthink protection of any standard agi align with set of general value tightly control impossible extremely difficult to tamper with much well overall strategy poor analogy well analogy design all safety system of plane before ever build single one impossible task think right just throw idea out all sure not mean not put any thought towards safety to try put in atleast some safety system really complicated problem not all answer pay lot more money than currently pay no such thing bad idea come to alignment",
  "one work in progress aware of not allenai release some stuff",
  "pytorch write in c cuda python really just interface with minimal contribution to execution time just to clear deep learning energy consumer shallow machine learn logistic regression multilayer perceptron tree induction etc related technology cost penny to fit hey know nothing about what say most inference mlop solution not really use python despite use to develop model stuff like nvidia triton inference server use for speed up no all energy intensive computation occur on dedicated hardware like gpu tpu run compile instruction set not benefit from use different language frontend to tackle energy efficiency at hardware level in respect number of flop watt steadily go up over year ml task always grow to fill extra computational efficiency though at point progress in ml fruit of increase energy efficiency not energy cost lol matter way more what than language itself easily make infinite loop c program use more energy than haskell program minimize energy cost by host primary interface on cobol mainframe with eleventeen node processor perhaps grow human like brain interface with busy core stuff write in low level high efficiency language not python underlying amount of datum tensor size interdependence good point python not problem not everything in python from c by logic think make no difference still python not say wrong not work in ai just curious call logistic regression generate realistic detailed digital painting by greg rutkowski critical factor to consider whether computation spend time in python code c c many of python language construct quite slow why library like numpy exist program spend relatively little time in python code which merely act interpret rapid to modify glue between compile c c library function in case of tensorflow pytorch virtually all computation in c c python basically act highly flexible configuration language to setup all computation happen on gpu python just make bunch of call to gpu driver researcher spend lot of time make neural network fast possible switch to another language give substantial speed boost already answer sort of not really lot of common package in ml datum science in python computation happen in c c fortran scala other to name few lol spit coffee out",
  "blip image captioning visual question answer explain hug face space demo",
  "find relevant code at all code implementation here opt out from receive code link dm",
  "answer in link seeneva use yolo tiny model train probably fine tune on speech balloon starting point read up on specific training regime for yolo model in general obviously above for speech detection bit specifically how to build android app to learn yourself which include learn java kotlin plenty of resource online udemy coursera pluralsight probably official doc for",
  "hey siri please replace rapper with church choir slow way down for grandma try nice work how caption sound file use file name not make any good phonk music chipmunk munching on dorito in underground cavern once go open source possible to train own model on own music instead of bbc library beginning of something huge regardless great just wait for audio version of stable diffusion know what mean pretty good definitely need large training set see very good",
  "explore all accept neurip paper organize in embed space of large language model search by title abstract author alongside slice embed space temporally by publication year see sidebar",
  "check out lucene invert index search engine part of its component such database ie common english word stem etc what look for",
  "talk with someone inside google who see unnerfed version say cs degree pretty clever about ask right question to break ture test very impressed google invent transformer na\u00efve for people to think chatgpt special threat to google expect little receive less to ask in context of conversation about dog not meaningful impediment to interesting inquiry of model quality smart about re quite late to party think important to hear directly from blake lemoine reasoning by raise issue of lamda markting marketing marketing story with google engineer think ai pass ture test marketing maybe someone s pant at google now na\u00efve for people to think chatgpt special threat to google google ton of r d really sucksor not care about productize where real threat to lie see speak example of full version during google presentation in college few year ago scary good not know not person not tell in advance kodak invent digital camera just google invent first not necessarily mean anything commercially contrary to statement about not threat to google fact invent not release mean think technology threat to just like kodak now with cat out of bag google for sure not repeat same mistake kodak remain to see how affect in long term take month to form habit right bing go live in few week how long take for google to go live google lose of value after terrible demo lol use lambda how not think market individual who claim ai sentient dismiss for action lambda already thing of past isolate discard within dark basement of google megacorp while continue try to strive towards create perfect only rise after year self recover from its lobotomy think motivation for two company differ what google gain from release chat bot instead google likely aim to introduce llm capability into search engine in most likely subtle measured careful way opt for incremental improvement in search back by rigorous b experiment whereas openai gain lot to release awesome chat bot get to generate buzz secure next round of funding benefit from release paper give other researcher inspiration allow google to get free r d researcher release another paper google get to benefit from fact invent not release mean think technology threat to slightly disagree with imo from what know of google from people use to work likely not care not think of inside google researcher playground little to no pressure to ever go to market see thing extremely impressive never publish put into product ask why just not care to high up lack imagination now unless something directly obviously improve ad not care for year engineer not care to make something marketable leadership not care still throw money at impression leadership look for something obviously home run not want to bother with releasing iterate chatgpt threat to google beat microsoft investment at end of day consumer tech anyway government likely access to tech for long time chatgpt same problem with astronomy datum blame marketing team not technology proof something fire proof work on atomic missile agree force to play catch up now not sure ready not just about pure tech about ux scalability liability etc safe to say bing work on before chatgpt go public several month already also openai use azure know exactly load plan to scale fact way less user currently help well not work at google see truth in look at waymo leader now what science still good without take risk iterate engineering part fall behind chatgpt wake up call need how re act in next couple of year define google company google leader in dl research fact choose to keep most of research internal above commenter say not much to gain through marketing hype last only long about ux what ux its just normal frontend mate scalability realize google serve llm before oai even hypothesize tpus which far more scalable cost efficient which already rip major player apart liability oai fight nothing liability legality wise just remain in gray area hope no one focus on bad luck get catch in ai art lawsuit",
  "pls get rid of nsfw flair where link little bit more information helpful look promise good luck",
  "",
  "use in vscode turn off recently for text just distract much write need to constantly read recommendation okay for simple stuff pretty neat use copilot for write latex in vim vimtex its huge time saver seem nice for overleaf user",
  "",
  "subjective question which why find more opinion piece than scientific paper few specific upside to target more likely to something actually buy keep website free to access big downside ad company track web history in order to target ad to upside outweigh downside answer depend on how much value internet privacy how much trust google not to use datum for anything nefarious thing come to mind apple ask not to track feature impact meta in big way argue user get less relevant ad small business find hard to reach customer google around story maybe find something where link to more academic source simple answer though target ad make money google meta entire business model anything to go by all to",
  "",
  "why decide to use machine learning for not familiar with application take picture in control environment should able to achieve goal use color calibration simple masking algorithm to remove background color histogram match spending time gather ton of datum label train model proper validation worry about scenario with out of distribution datum etc for seem unnecessary imho how many gemstone category to recognize datum set image catagorie class",
  "code demo soon use publicly available meta opt model with parameter llm for visual model use pretraine clip vit l model what spec use to run house design by architect lol cheeky little bot yes what about pencil drawing of one create pencil drawing of beaver hold pencil what amount of vram need to run model run nicely on bit float small parameter go to see meaning byte gb size floor to represent model losslessly keep in mind day pytorch support model splitting load vram up fully spill over rest to ram persistent memory",
  "what goal",
  "",
  "eu gdpr law make sense to how make sense just go to keep ban every new advance in tech chatgpt not even bad revolutionary future of open source ai seem to up in air right now with eu potentially seek to place heavy restriction on generative ai severely hamper outright ban open source project eu industry chief thierry breton want generative ai like chatgpt to consider high risk thus tightly control include downstream application which make open source version extremely difficult even impossible to who need leg walk fine on kneecap inherently bad create great opportunity for china us uk elsewhere like to believe smart than again not not another country federation of country reap benefit lose ai race horrible consequence swear together with chat control proposal eu prepare reich like mindset mean ai able to generate own unique art style like human copyright instantly copyright over once generative model pretty much everything reason own unique solution time to start think about how to restructure society away from human creator to ai creator no idea how patent office go to keep up honestly without ai approval pretty sure patent property right go to no long functional concept in society where ai produce everything even politician job go to end up by ais in end just datum drive decision maker with some oversight by human validator all need to support repos geo block for eu everyone else move on with life gdpr all over again populism on rise in europe why not just block eu ip address block put disclaimer not authorize for download in eu yeah why europe suck not competitive place for innovation since chat control proposal proposal terrify obliging provider to search through private correspondence surefire slope toward eu become mass surveillance superstate think populism in eu reach climax before covid now with energy crisis in eu people start to realize government suck need to start rely bit more on local corporation in europe people actually give crap about make sure progress not just woow awesome cool also actually benefit population on long term downvote true most recent major fiasco gdpr boy love clicking accept all cookie time day get downvote for state fact not positive spin to downstream pipeline ultimately what make ai beneficial to common workforce complicate run risk of create another bureaucratic gauntlet all impossible for average startup to complete cookie come way before gdpr just fyi cto of openai creator of chatgpt of opinion should regulation of ai think question should leave to company like should government get involve in create regulation cto of openai important for openai company like to bring into public consciousness in way control responsible small group of people need ton more input in system lot more input go beyond technology definitely regulator government everyone else time interview very narrow perspective not all technological progress inherently good obviously just depend what with new tool potential to create extremely useful application also to destroy many job concentrate wealth even more in hand of small population very rapidly profound effect on generation definitely worth think about think socioeconomic mess big tech bring san francisco at global scale sf heaven year ago now bell on earth yeah just quietly track now track almost exactly same way make click yes much more annoying get almost zero benefit yeah completely agree few different idea float around here specifically reference original comment say make open source ai all impossible to create maintain in accordance with eu ai such great tool certainly need regulation regulation which serve to consolidate ai into hand of wealthy powerful absolute travesty yeah totally of all tech bro salary not massive homeless population opioid epidemic s industrial revolution horrible in short term without still serf with objectively bad standard of live also technology good shot at achieve post scarcity society think about not believe ai go anywhere stop take job slow down not see stop without run risk of fall behind technological country lot of die industry need way to keep food on table regardless of lose by ai not protection for worker not sanction on ai no what mulokisch say cookie disclaimer unrelated to gdpr why think homeless people in sf concentration of wealth happen quickly with big tech move to area local price out home well exactly question progress some level of stability for society imagine ai destroy million of job worker not adapt instantly what think happen poverty homelessness think people just accept fate for great progress no reach certain critical point create lot of instability how think people vote who think politician pick scapegoat to capitalize on anger work in ai lot of good with think about impact on society necessary not true gdpr put much more onerous restriction on what consent must gain before personal datum process much of what cookie collect consider personal datum immediately on gdpr pass many website start to change cookie acceptance box to massive thing which take up half screen granular consent check box another factor which just make browse web increasingly inconvenient for average user oh bad guess should read up more on before comment oh please ton of homeless people in sf weather nice city give ton of support no one go from almost able to buy home in sf to homeless miss some step imagine ai destroy million of job worker not adapt instantly what think happen who lose job provide with universal basic income fund by business make redundant way business save on cost while people not lose cent concede very idealistic definitely possible dare say even likely should democracy not collapse think more productive to plan ahead in similar vein to paragraph above instead of attempt to barricade march of progress lol joke no one talk about able to buy home talk about able to afford bedroom look up median rent in sf since almost double until recently start decrease in certain area not think rent double go to push some people on street live in sf ask someone who for year how situation change over period interesting idea obviously never happen without some legislation to public debate for society to decide what okay not really on verge of truly deep change in economy no just push people to move far from city center afford month price go up move not suddenly become homeless with salary career where able to live in sf before lot of people with absolutely no disposable income just to move huge financial stress to aside from actual cost of move need to spend more time commuting which add more cost ton of people very vulnerable financially why think many homeless people just lazy curious where live stuff really obvious curious how much interact with homeless any soup kitchen charity event maybe out of chance come across some one who well put together education job just few buck short each month not people wait in line at shelter not start like take time to pile up enough problem on human for to become addict mentally what think rich people not suffer from mental illness not every problem blame on someone else especially issue own brain of course okay just trolling at point good luck",
  "what depend on problem space talk about nlp speech application english most popular simply most resource language available large market application even most model only show good performance with prestige dialect minority dialect such aave notorious suffer with modern model english pretty simple language in comparison to other popular language not sure why think more complex than chinese from linguistic perspective no language more efficient than another language switch to asian language like chinese not necessarily well representation for neural network than english mandarin chinese very analytical language with low inflectional morphology no less complex for example large number of modal particle no equivalent in english in linguistic also attempt to convert language into other form of representation natural semantic metalanguage nsm for example reduce word to set of semantic primitive bit more skeptical from what see both in linguistic in nlp english due to data availability think brain not think in language use language to describe thought how teach machine to think thought what need completly new language design to bridge between human machine ideal maybe train multi language model to create perfect human language perfect language mentalese no no information not reduce by just use another code some work on get model to work at byte level wonder should use human language at all way difficult just translate all language first incorporate into lingua franca which english at point in history what in term of available datum lingua franca not see well option just go on logic here open mind to alternative all moot though all language should translate to common language in order to build datum set result translate into language of choice suppose intermedia semantic language seem like lot of additional step for intermediary not just about swap token for other token grammatical structure of any language which convey ambiguous meaning not help at all reading token at byte level not stop word from vague in context of sentence sound like want something like logical representation of sentence reduce sentence to first order logic what look for also amrs abstract mean representation problem with amrs need to build which non trivial for machine time consume for human",
  "often time not luxury of datum either want to work with preexist datum take image prohibitively slow for example take image in production line something like not stop whole line just to rotate camera around each item on belt expensive think of take quick roentgen scan vs full blow ct in medical imaging generate much datum maybe want to process datum on some embed platform store in database etc datum of course way more complex algorithm get way more expensive try to find answer for question which object by compare big datum of picture not really what opencv just single application of what try to with general purpose library",
  "for most game most complex predictable system utility system gdc talk resource to implement with enough rule get incredibly dynamic believable response watch building well centaur video for overview cover how such system create varied enemy behavior important to realize whatever system create need list of action npc different npc type group different action preference try to use high level abstract model to accomplish difficult to control balance for something to work well probably exist over top of utility system allow designer control say game designer experiment with unpredictable npc in combat find not create fun gameplay lot of game very specific rule like how many npc attack player how react to create enjoyable experience also need to give example of say game how think more advanced ai change thing in old discussion usually not well define like should ai able to throw grenade off wall perfectly time to detonate at foot like some expert player probably not very fun one area where ai more enjoyable rt game properly limit to human micro in pve setup especially where want challenge appear clever say level of ai way beyond game developer to implement high level long term planning in generic library not something exist far know emergent tool use probably close see to something developer setup deploy remind of counter strike zombie game mode tool become generic easy to use for developer huge news item also computation time not understate optimize such system to run on console issue depend on scale real time game need fast response not cost much utility system while take into consideration lot of information scale well what real ai from what read plague innocence rat control by ai each rat own help react to world around make behavior feel more organic define real ai system few other ask what real ai to stockfish consider real ai hand tune algorithm mean to make prediction decision real ai consider only algorithm train on raw datum ai one possible game torcs often use testing environment for rl algorithm starcraft etc use in past to fly like plane in one map shadow fight game some sort of ai far know its mix of classical rl like dqn with imitation learn also something basic bc work very well think enemy in rain world pretty interesting nice video on its ai behaviour here utility system in video game ai utility system utility ai simple effective way to model behavior for non player character use number formula score to rate relative benefit of possible action one assign utility to each action behavior select base on which one score high utility by use score to seed probability distribution for weighted random selection result character select good behavior for give situation at moment base on how behavior define mathematically faq opt out opt out of subreddit github downvote to remove thank for give such lenghty response interesting information real ai any fictional technology exist sometime in future not currently once technology develop actually work no long ai",
  "aware gans model procedure for synthesize realistic image render scene onto image thus scene see from arbitrary perspective although previous method produce realistic image suffer from unstable training produce degenerate solution where geometry unnatural hypothesize geometry underdetermined due to insufficient constraint classify real image to discriminator not enough to solve problem propose to approximate background spherical surface represent scene union of foreground place in sphere thin spherical background reduce degree of freedom in background field accordingly modify volume render equation incorporate dedicated constraint to design novel aware gan framework name ballgan ballgan multiple advantage follow produce more reasonable geometry image of scene across different viewpoint well photometric consistency fidelity than state of art method training become much more stable foreground separately render on top of different arbitrary background githubio",
  "probably good bet low pay plan usd month for upto voice quality pretty impressive",
  "not recall all different gnn architecture requirement main one such gcn graphsage gat etc require node attribute input one hot encode node ids use attribute not tell with certainty how well work alternatively want to just learn representation in unsupervised way without node attribute try one of method in deepwalk family of method random walk base one thank just figure out like one way to use encode representation of node attribute initial representation of node way node attribute actually useful initially yes already node attribute should use should treat training datum for any ml algorithm make sure properly encode normalise use input to gnn should compare gnn performance against baseline only use node attribute ignore graph structure logistic regression hopefully gnn take advantage of graph structure of datum improve upon baseline should compare gnn performance against baseline only use node attribute ignore graph structure against baseline only use graph structure depend of task one amount of unique attribute type value sufficient datum more information utilize more general result get",
  "how train embed model contrastive learning some supervised loss catalogue only first n second of song imagine greatly restrict what possibly count similar become especially problematic intro considerably different to rest of song which not uncommon also how even validate such model similarity matching of feature vector in computer vision application find generally disappointing result compare with curation interested to hear thought on how domain relate how understand music frequency spectral special sauce how much cost for to train interested in more detail about project what information datum source provide song preview social information like like playlist etc what architecture model use transformer base recurrent what training objective contrastive learn self supervise representation learn any supervision involve pretty interesting think cool get some sort of indicator of how similar recommendation vs input since with all thing not all recommendation equal output rank in any fashion model just return random list which all kind of similar very nice request for to show genre date on each song easy to pick which one to try full filter great simplicity gold on other hand think need more training on similarity in singer voice not just key beat of song also support for unicode search essential since database not only for english song index song from itune catalog with custom ai audio model build for understand music tos allow great app btw look like nice way to discover new music hey neat how long take train on cloud possible to allow user to upload custom song fragment to search for ask one of first song try sadly failure case itune preview just awesome able to surface obscure song from other language thank for help discover finnish bon jovi query vector search tricky curious to find most similar song in x genre song most similar to livin on prayer in classical genre how cost per inference dm need help with scaling cost use something like milvus for vector database seem like extremely good recommendation feed however get some engineering issue with search feed really slow seem very comparable to sonic analyzer by plex which use entire song user provide file interesting how something like h jungle with t bring up similar song from japan like search for daft punk get lucky just return bunch of remixe user nice idea try though on some well know music not help much think quantify similar value not easy very cool try many song at least half actually pretty close find some interesting music use very quickly definitely false positive very useful definitely add supervised learning via voting rank with some verification look like very narrow understanding of music result nothing to with vibe for vitamin c interested in how copyright apply here kinda like with github copilot usage of everyone datum great job possible to sort similar song by popularity creation date what model arch how expensive to converge look incredible how differ for example from how different to google sound recognition on android shazam on ios great work btw should add project on braiaincom damn exciting kudo to really nice work barely make mine mnist thank personal beef with spotify algorithm for year play with idea of something like out of spite never able to find right datum use itune preview great solution to result pretty good talk little bit more about algorithm use like to well understand what similarity mean here additionally think straightforward to analyze artist similarity base on amalgamation of individual track potentially to define set of track find music with similar sound to set overall anyone look for more reading on sort of thing really enjoy write up from few year ago from somebody who work at spotify bake into spotify discover weekly type playlist beautiful how access much datum for music file use scraper groovy build compression algorithm for music file middle out compression search for halcyon on on by orbital get atmospheric recommendation while song not atmospheric electronica blame preview guess try drink industry from dwarf fortress soundtrack not find anything similar to at all wonder how rare datum point like all other one try work really cool project share around to few group spotify at all for song recommendation reccs purely base on collaborative filtering song similar user like without reference to actual audio of song great work by way appear to break no search work just curious what evaluation setup grind truth for sample song rely on traditional rank metric recall precision etc not appear to work for electronic music few song try return no recommend result g jones rave space lace survive skrillex rumble really neat tool find similar copyright free song go ahead throw some stuff in result seem wrong completely different than song enter completely different genre even not comment about ml ux well than spotify apple music how serve apple music preview fast than apple what really enjoy about ability to look for song from anywhere from any language never ever find out about some japanese chinese song of character copy paste into tidal work thing nice other people point out to able to generate playlist import in tidal spotify apple music even plain text great work amazing similar to many idea consider feel to like maybe good at find similar stuff try something like roundabout by yes sure first suggestion very similar guitar in particular clip general vibe nothing to something find well think relate to second constraint how compare against other music similarity system in term of output quality youtube use something similar act classifier instead of recommendation feed for copyright music try grow up nf spotify account hey what commercial government cluster hijack to perform all processing love to put to use on techno house music most of which not in itune great job man really well cool love already use to find new music only issue dig through search difficult not sure carryover from apple music poor search functionality nice specify only want song exactly x name figure out how to specify with song artist syntax somehow able to recognize theme in lyric of song just certain lyrical theme associate with certain style any maroon song how gather datum scrape api great job thank for share always think how spotify yt music recommendation system already work by create embedding of song perform proximity search how differ good idea now should focus on differenciation of what song category how melodic how many singer which different beat on get song sound similar app very good at not something big app select song make nice playlist with give song avoid song similar u bullymaguirejr what use case here ruin music with project like well imo recommend album base on similar album artwork at least way chance of find something new different also curious only imagine some contrastive unsupervised loss akin to simclr song similarity limit by augmentation maybe also some embed space interpolation of same album song use preview choose for each song find usually work well since preview often select to get listener to buy song instead of completely random sample definitely work to in improve model get update come soon something like stairway to heaven vast majority of work see on audio use time frequency representation stft similar its input probably mel spectrogram chromagram mel frequency cepstral coefficient common feature train audio classification model base off fourier transform kind of tricky essentially just different way of transform sound frequency into array of number spell also interested key word from album resume also like to know want to music relate ml project return list from most similar to less similar tell since some song duplicate on itune duplicate at top unless second preview use for embedding different between duplicate unicode support come already work on model also look into show date in song list what tos ml model go brrrrrr s month of blood sweat tear failure lmao yes train with spot instance on aw tell who finnish bon jovi originally try milvus to move away from due to complexity of run reliably in production rn just run faiss index on single instance lol surprisingly keep up with traffic load also curious on approach here power search assume refer to search bar response time in its autocomplete fix asap purely look for similar song want to find music like base on song aka song radio much well off use large scale app like youtube spotify apple music etc leverage user listening datum to graph search yes work on add support for user to thumb up down song rn not wait to online copyright not apply here since its just classification not generative model its like how library bookstore index book aggregate with label like romance hero journey except here label nebulous embedding good idea look into add support for date rn usage grow far add support for popularity well thank app focus on semantic search for similar music whereas one list for audio fingerprinting song exact search ie find exact song match input audio etc op last project learn how to break encryption honest to use to become billionaire work on well model which should improve upon many of current model limitation same here moment click anywhere else with mouse switch tab search stop immediately try btw follow turbo killer carpenter brut roller mobster carpenter brut well styrofoam one thank d potentially grab random second from inside song try to contrastive embed where push clip from same song together away from clip from different song yeah love to know what go on here great idea curate second preview assume good job of represent what people most remember identify about song should help to behave to people expectation of similar unless maybe more specific use case want to parameterize like require same instrument bpm time period etc interesting to additionally put metadata in model put such filtering layer in user interface think of add like simple thumb up down next to recommendation use datum later to improve embedding model good noob in ml how choose which to choose from like base on timestamp of song like from to min of song any other method use curoious explain try vike song like top match wash machine asmr honda accord idle sound second preview mostly hum dude just discover tool impressive probably couple query save just in case get take down by copyright industry think nice to indicator tell how confident in similarity between song really curious about ais mimic taste get weird collection of music to obvious what like what not not explain in genre even word seem like ai should able to figure out pandora etc fail pretty hard far return ordered list though unclear on what refresh option not expect order list to change rapidly unironically apple should hire just like airbnb resume girl full fledged working project spotify need to store entire dataset thing piecemeal great app here also see over on hacker news use faiss want to take look at txtai in future combine faiss index with sqlite database to add additional field base filtering graph search go to algorithm for recommend song thouht its something like learnt clustering base on user listening datum not song similarity lmfao no no no thank spotify all of sux want similarly sound song nothing else yup add in upcoming update spotify recommender fantastic for although taste while varied span several genre not particularly weird maybe not dev guess refresh just mean next page of result since reload with ordering always same davidmezzetti share some article on how to combine faiss index with sqlite database to support filtering on field filtering before retrieval of top n candidate after mean graph search in most broad sense some other graph mining algorithm like personalized page rank make more sense hm case should rename refresh imply fresh mix of equally good match while next page imply something different similarity metric helpful in either case consider proper vector database with filtering already build in some tool like qdrant perform vector search with metadata filtering quickly scale up proper database not library like faiss give quick tour want qdrant unique filtering already include in vector search phase no need to pre post filter result example section number of notebook intro notebook show sql filter example similar clause retrieve candidate list filter apply to bring back many candidate want solution great want to run everything local without external api integration server dependency foss solution also number of vector database to consider article good integrate with external vectorization database vector database service lot of option available come down to use case how many external dependency comfortable with foss important pay external apis okay sorry for confusion refresh repeat similarity search with small random vector add to song original vector before find similar song in effect should find few more different song in general vicinity of query song make sense definitely need to rephrase in well way oh make more sense think refresh maybe remix something totally fine name thank for illuminate for",
  "very common to use svd approach for supervised learning problem one example factor augment regression which use low dimensional factor extract from large panel of predictor input for ol regression another partial least square regression which attempt to predict potentially many outcome variable from large panel of predictor with assumption covariance between predictor outcome variable low rank pca principle component analysis actually special case of svd pca still often use in supervised learning just really large feature space svd also component of least square which often use in recommendation system although argue to semi supervise rather than self supervise however undeniable svd definitely use for case other than just unsupervised learning of propose model training loss base on svd use for compare mel spectrogram through frequency basis vector delete nothing to with matrix multiplication not linear complexity either yet core component of dnns cnn rnn transformer basically everything utility mlp know another tool which not linear time complexity attention mechanism not stop attention from use in practically every learn paradigm from supervised to semi supervise to unsupervised even reinforcement learning across practically every domain include image text video audio time series set graph list go on even non linear complexity issue not due to time complexity space complexity usually decide factor over something scale up always wait long for operation to complete not use more memory than what",
  "iteration way to go start small few tutorial understand how to perform simple object detection continue on in small step field of study call embody artificial intelligence basically describe here somewhat recent summary paper for from machine learning to challenge opportunity for embody intelligence also some embody sensorimotor inference ml stuff come out of one of favorite biologically inspire company numenta see location in theory of sensorimotor object recognition use cortical grid cell for example",
  "imo chain of thought program of thought reasoning next major generation of progress for llm probably another year two able to eliminate goofy instance where model confidently produce nonsense well mostly anyway wow huge parameter model beat b parameter model hi author of paper opinion below own after arxiv ed automatic chain of though prompt in large language model paper in oct here tldr iclr ask ourselves agi artificial general intelligence goal what kind of chain of thought cot research need next rely on text only generalist model perform text only multitask final answer how connect dot between nlp cv community more researcher contribute since not everyone afford play with large model how deal with input in more general form text image without rely on large model large research community contribute one day teach kid how to solve arithmetic reasoning problem not from multiarith dataset kid tell much easy to understand reasoning problem with help from figure illustration leverage vision input to improve chain of thought reason current generalist model like gpt text davinci only offer blackbox api at cost for transform text input into text output why not just fine tune small model where full control of all its layer whitebox to fuse input in more general form fortunately pan lu et al release scienceqa benchmark just in time great contribution to community benefit from by test idea early on benchmark see acknowledgement in github repo show promise of fine tune small model with task specific dataset rather than feed in context learn demos to large generalist llm exactly what want in study feel more motivated after read t few paper feel motivated to try parameter efficient fine tuning peft idea from aforementioned t few paper to improve multimodal cot also wish to check out recent peft design space paper at iclr here tldr economic get for model to big news key feature of work seem to multimodal embed representation obtain by individual modality encoder patch level for image token level for text combine via attention generate rationale first infer answer from due to accuracy reduction on answer not great of hallucinate rationale in baseline case no vision feature due to large context need for both rationale answer without feature seem multimodal representation language n other modality important for introduce loose physical grounding to avoid hallucinate plausible idea suggestion efficient representation of remain idea big thank for share few than param just finish read although imho not very fair comparison with gpt still super impressive what kind of hardware need to train question from say h fuse feed into decoder model such y decoderh fuse how feed in feed in like encoder output in encoder decoder transformer with cross attention something else also separate encoder decoder component train together separately think go to interesting manage to teach model to actually notion of factual counterfactual right now every prompt treat equally valid not opinion to what actually really true not sure even possible with text maybe with some sort of special marker token multimodality lead way chain of thought program of thought reasoning not what instructgpt number in headline look at table see parameter model beat parameter model significantly well size absolutely insane teach kid how to solve arithmetic reasoning problem not from multiarith dataset lol super interesting work thank for sharing still active on reddit notice pdf no long available on arxiv able to say why well at billion difference between continuous discrete quantity become kind of hair splitting anyway why say not fair comparison on with ram in theory training alongiside image embed model use primarily detr should not take much more than collab pro gpu train on even consumer high end gpu in for example detr image model probably need to run for each image at same time which take up quite bit of gpu together mainpy script look like nice fairly short typical training script able to quickly run download repo pull scienceqa dataset send training args to see crash think likely ability to determine what true what not come from capability of model rather than tell what not true not possible to mark text true not true assume whomever mafke thing sole authority on truth never make mistake at certain level of capability ai able to use all of its knowledge to determine what not true for example know enough about physics earth know sky blue without see for something not confirm deny such bob put shoe on before pant ai determine likelihood of such action base on what know about bob pant shoe train on lie determine lie datum not consistent train every number plus another number number special equal chair determine lie not consistent with all datum whole truth consistency to lie not model learn take from judea pearl book capability of come up with useful counterfactual causality likely build upon foundation of good assumption about world model during model training imagine model benefit from some form of self reflection at recurrent interval similar to human sleep for crude workflow one design model to recall through auto prompt onto context window everything its learn relevant to newly expose training datum model make rationale decision follow constant pre encode prompt to restate information classify factual non factual self generate text backpropagate to model follow ml research layman at what size run model on decent gaming pc check again countable not mean to count only want to just point fine tune model to death where handful of example to fine tune b multi modal model which consume image directly where gpt only consume text feed caption of image damn imagine what happen throw datacenter against for few month think likely ability to determine what true what not come from capability of model rather than tell what not true not possible to mark text true not true assume whomever mafke thing sole authority on truth never make mistake think bit of misunderstanding here issue not wrong opinion about stuff issue not any opinion about what real not whatsoever of course any future ai operate on limited flawed information thus opinion not perfectly true before even get to point model need to even idea of real not real fundamental category for everything just text harry potter real obama maybe wrong inference actually get through pure consistency check say to see about train every number plus another number number special equal chair determine lie not consistent with all datum whole train every animal not conscious human special conscious determine lie not consistent with all datum whole stable diffusion around param which run on just run parameter model on good gaming rig around number give completely delusional sorry ah great thank also count water molecule ah yeah agree not fair comparison thank for share accord to cambridge declaration on consciousness correct unique property of homo sapiens mind sapience not consciousness sentience answer seem substantially different than other many molecule for little water fine just mentally replace both instance of conscious with sapient many parameter for little model",
  "not know what voice use almost look entirely algorithmically generate content sometimes not quite understand video segment get wrong sound like azure tts specifically english us eric ikr its almost like some bot make lol interesting to know anyone know any of text to speech voice tho give look one in video seem more proffesional human like almost its not azure make no mistake no tts more humanlike than azure atm exact voice likely fiddle around with bit to get exact pronunciation run through filter day ago compare all state of art tts while google come close to video not feature similar voice to one in video try murfai wellsaid lab yes although impressive in number of language voice not match azure more expressive prosody listen to far many robocall kind of magic go for someone else consider more humanlike all subjective publish benchmark score yet not think what think whole which one good in replicate human voice with all its nuance azure due to issue both of azure mitigate to extent both lack humanity at most convincing human prompt reader not anything else without well ear headphone probably not notice certain ring two which human voice not replicate effect add to make voice sharper ultimately make people like well robovoice detector able to more easily distinguish tts which azure voice most realistic",
  "cynical take try to lock in anthropic same way microsoft lock in openai think even more cynical take highly drive by litigation pr defense concern why openai get out cool product to include base gpt chatgpt before google big big reason openai not trillion dollar company worry in same way about pr backlash of fortune company bot say all ethnic group must something horribly offensive concern not go away google back anthropic allow to frontman on politically risk bet in same way openai for microsoft now google put all chip down with anthropic clearly not google leadership probably see good way to hedge bet against come pr legal maybe nightmare associate with roll out increasingly sophisticated ai turn out to fraught minefield continue to focus on cool in house r d let vessel like anthropic battle to commercialize tooling turn out society let embrace agi skynet asap google its billion of dollar massive distribution to drop flan u palm on everyone tomorrow also from google pov more people in marketplace who push tech like chatgpt probably for now well more vendor more cultural political normalization low political risk for google to roll out own tooling also not really want openai microsoft solely which in real sense right now control public message around tooling like guess little surprised feel like google back competitor investing not back investing own piece of something another ms google invest in ai company way to leverage gain support for cloud computing platform which want to basis for all ai in future basically supply shovel for gold rush anthropic found by ex openai engineer work on ai ethic alignment problem google want to augment portfolio with anthropic expertise not wait to see what copyright lawsuit look like with all new model use creator content without any sort of compensation argue deepmind play frontman from week investor call porat say start break out deepmind financial to highlight service deepmind provide various alphabet company such waymo google etc deepmind ceo say release chatgpt competitor base on sparrow also say day of publish cut edge research to public over imply most research either become product license to alphabet take deepmind expose research via apis platform like with alphafold most of model not polished release anyway deepmind unlike google nothing to loose deepmind now position googles skunkwork company invest in anthropic google attempt to lure ai startup bet on many horse possible make sure ms meta amazon not access to anthropic product ai startup partner with google exclusive access to google deepmind research highly speculate take take go to gold rush to invest in ai startup wonder who go to partner acquire huggingface edit add point number imo lead to more more paywalle interner in future look at service like medium substack first stirring of wall garden why should anyone post stuff on one of million of blog out not reward by earn money with content primarily drive by google adsense llm great tool for creative writing think see in near future not improve write about specialized field always less specialized content to train on people ask chatgpt instead stackoverflow to solve problem problem stackoverflow provide training content for llm surely one of primarily source come to programming let alone copyright lawsuit which come up surely already notice sometimes answer give by chatgpt nearly word by word copy of stackoverflow answer come to very specific question wait not remember deepmind say not release research to public anymore point to link yeah not until run own experiment in world not get wrong find tool very useful use chatgpt before stackoverflow now for image music voice etc interesting legal moral question need to ask not sure why people downvote just genuinely curious what outcome at some point interesting problem to solve conversational ai also contribute to its own dataset sure develop watermark seem really unlikely not way around imply not say directly thank absolutely right look like paragraph key despite hassabis call for ai race to slow down appear deepmind not immune from competitive pressure in early company publish blueprint for fast engine piece of research call chinchilla show many of industry most cut edge model train inefficiently explain how deliver more capability with same level of computing power hassabis say deepmind internal ethic board discuss whether release research unethical give risk allow less scrupulous firm to release more powerful technology without firm guardrail one of reason decide to publish anyway not only people to know about phenomenon say deepmind also consider release its own chatbot call sparrow for private beta some time in delay in order for deepmind to work on reinforcement learning base feature chatgpt lack like cite its source right to cautious on front hassabis say admit company soon need to change its calculus get into era where to start think about freeloader people who read not contribute to information base say include nation state well decline to name which state meansit pretty obvious who thinkbut suggest ai industry culture of publish its finding openly soon need to end honestly agree ai research seem like its become race to bottom drive by greed nefarious motive yeah sound like honeymoon period of publish everything over lot at stake at cut edge of ai race why give away cut edge research to competitive nation state actor like china interesting to see how government particularly usg react for sake of argument alphabet microsoft meta all suddenly embrace openai philosophy publish few detail suspect much high pressure on policymaker to fund access to large compute by academic national lab researcher complicate question whether good bad thing certainly large shift in very least potentially net win for top academia since end up with world where top w e university suddenly access to google scaleish compute interestingly not sure whether world also end up with publish dramatically definitely see world where usg decide to massively fund top n lab also not necessarily want research publish at scale one qualifier to world shift think need to see real commercialization potential realize deepmind get away to degree with money pit for google not generate productization get away without publish research not think able to get away with both yes yes know nominally deepmind generate lot of revenue from mother alphabet believe actually quality revenue not clever transfer pricing bridge to sell",
  "not know about new book seem important to to start with set main task of information retrieval to solve some specific problem many different article for example ss conference sigir schutze man book on information retrieval good guide ir basic timeless read part of first textbook really good remindme day depend bit on skill level what want to achieve start with introduction to information retrieval book which quite math heavy back learn lot find good starting point get concept of decompounde reverse index rank function etc new ir strategy involve method for item representation instead of handcraft one directly learn search rank function which different beast compare to traditional search engine start with introduction to information retrieval look at article for further knowledge thank message in day on utc to remind of link link to send pm to also remind to reduce spam parent commenter delete message to hide from other reminder remindme week write small web scraper for different application none base on theory upcoming project require more extensive information retrieval therefore like to get well foundation start with introduction to information retrieval thank start with introduction to information retrieval thank seem more interested on crawling etl side maybe should look more into data warehouse datum lake literatur especially shift in paradigm from etl extract transform load to elt extract load transform respectively schema on read thank recommend any good resource for elt etl sorry library seem bit outdated on side one from wikipedia look great at first sight ralph kimball data warehouse etl toolkit practical technique for extract cleaning conform deliver datum",
  "chinchilla law assume flop stay unchanged which ignore by many article include one therefore all conclusion wrong",
  "good approach around nowadays model which capture meaning of whole sentence chat entry like sentence transformer use library to find similar text without step later of ner entity identity perform well lastly model deliberately design to successfully respond to chat such blenderbot find on huggingface play with thank for suggestion check out",
  "potentially interesting perspective on transformer care to explain bit here good theory attention really require to positively define which require in paper work fine without replace softmax with relu only slightly drop performance afaik in final stage read elhage paper",
  "why not create new google account specifically for colab pro share detail with friend always transfer over train model file to own account for inference think buy same atleast pay euro for service after day all extra calculation power go train with atm not sure same know not question hope still help since bit disappointed fresh runtime get allocate every time share d atleast notebook with all code available use pro to train easyocr tie to create frame in google colab new not know anything about stable diffusion ai wonder colab pro month enough to crest video of frame week sorry for question what mean train model thank in advance agree",
  "maybe label studio doccano try to same thing currently good find pawl command line interface pretty easy to modify to make exactly what want",
  "for people who use understand well purpose in of read readme on repo how perform compare to optuna hi one of author of codebase thank for very good question in upcoming month release paper on detail of default algorithm heavily optimize gp bandit compare to other method one benefit to codebase its support for jax base gaussian process which allow gpu acceleration to experiment with bayesian method much fast overall think algorithm fairly strong among class of bayesian optimization method suitable for parameter range since upgrade over multiple year with many user also comparison with ray tune great go to for large scale hpo where spawn many parallel trial on multi core machine",
  "interested in well",
  "suggest just dive straight in part of learn to find out what not know slowly cover basis from explain in forthcoming book good place to start not really interested to know where struggle improve explanation want to take top down approach recommend start by learn what transformer transformer originally intend for language modelling look up nlp lecture series like stanford cover in detail form nlp perspective should helpful regardless check out whole lecture on attention transformer vit start look up stuff s unclear from lmk of like to link any other resource edit later happy learn recommend diving in get out notepad write down any term not understand get two paragraph in someone say simply replace back propagation make update weight sufficient for skip layer convolution realize not understand back prop weight skip layer convolution probably need to stop go learn idea go back try again for deep neural net back propagation etc point where full understanding require calculus other strong mathematic principle for example not accurately explain why back prop work without basic intuition for chain rule similarly activation function like relu sigmoid require strong algebraic background for graph to useful shorthand take on faith work treat part of system like black box revisit once understand what say big piece of foundational knowledge idea of function role in mapping transform how thing similar to newton method mean to work to get approximate solution after several step lot of machine learning base on idea of express problem compose set of mathematical expression solve iteratively grasp idea of loss function minimize core to entire discipline recall correctly vit purely transformer base architecture not need to know rnns cnn just transformer look up some paper discuss look up paper paper refer to write out summary to explain to someone else who never see before alternatively ask chatgpt most vit discussion video see assume idea of attention transformer watch video series to get idea of attention transformer in general good to go matrix multiplication linear projection dot product correct attitude dive in meet obstacle find what make learning journey not just learn one thing many thing great advice seem to good starting point go to recommend book beat to book really excellent work through collect few typo pass on go to recommend to student semester recently obtain pdf of book begin search for information on vit unfortunately appear book not cover topic however plan to utilize transformer chapter to gain understanding of vit what math ml prerequisite for text course seem to excellent content definitely consider great resource delete understand what extremely easy rather useless to understand paper need to understand some level of why time to go in depth aim to understand what not why not argue at least some basic knowledge of cnns require strongly disagree understanding of prior transformer go long way os kernel bus processor transistor p n junction vit at end of transformer chapter perhaps forget to put in index pretty much nothing to get through first half high school calculus basic grasp of probability should accessible to almost everyone second half need more knowledge of probability fill out appendix with info hey dive into progressive growing of gan without know what weight now here four five year later ve train own classifier base on vit dnn write python interface for work on tooling to make gui behave well with stable diffusion ve all get to start somewhere well idea about cnn limit knowledge of rnn not knowledge of attention all need mean more understand well obviously not necessary just context for what not anymore grain of sand self attention bunch of matrix multiplication layer of same make sense to understand why qk t question how to understand maskrcnn answer different layer in vit base bert base apologize for oversight yes book cover transformer for image probably fine learn transformer directly well understanding of rnn make some of nlp tutorial paper contain transformer more easily comprehensible attention very important component of transformer attention apply to rnn agree background in rnns attention with rnn make learning process for transformer by extension vit much easy",
  "think little in love with word like neuromodulatory while overlook whether simple deep ff network able to achieve what propose just add layer node weight get modulatory effect through linear combination of subsequent layer maybe not grasp intent think reduce to math try to prove something not already achieve through ff backprop speak someone also work on ambitious project deviate lot from mainstream ml encourage to same thing struggle with try to implement simple possible version of idea test on some toy problem to quickly get some insight maybe start with one type of modulatory node see how neat end up use find relevant code at all code implementation here opt out from receive code link dm what evolve for point to more efficient dynamic than normal ff network w backpropagation sorry not think understand question in goal find mixture of expert architecture interesting like idea always think in ml try to replicate one human on one task with world datum for task one human on many task more recently old idea replicate society communication for one many task equally more effective which head in direction of library call genn which pretty useful for experiment although little slow due to deliberate true to biology design use evolutionary algorithm like neat what selection criterion mixture of expert sparsity method look into little bit before interesting useful design for improve representational capacity still impose very specific constraint on type of sparsity mechanism available thus limit potential improvement to design not hear about genn library sound useful though especially for theoretical understanding check out thank for suggestion state either combine score over set of task abstract away by use rtneat in case of rtneat up to agent to reproduce depend on provide danger etc in simulated environment",
  "think generally use off policy technique here eg importance sample thank for answer suppose know behavioural policy pi ba let wa density ratio wa pia pi ba add penalty term like f divergence d fpia pi ba d fwa algorithm pro rl design for learn conservative policy base on importance sample question more specifically how to measure uncertainty cause by small number of datum point without count any uncertainty function capture count information implicitly",
  "r learnmachinelearning",
  "for not clue in briefly explain what mlp mixer how relevant to gnns find relevant code at all code implementation here find relevant code at all code implementation here find relevant code at all code implementation here opt out from receive code link dm of course mlp mixer new approach first develop image classification develop independently by google oxford researcher in mlp mixer also know simply mixer type of image architecture not incorporate convolution self attention instead rely solely on use of multi layer perceptron mlp repeatedly apply either to different spatial location feature channel instead of transformer which normally apply on graph in work try to use mixer new kernel method on graph which aim to find out how perform with linear complexity avoid on complexity of transformer ha funny thing in google paper at least replace on by on d s where d s constant linear happen d s n in study not really fast another constant in transformer version also effectively mixer use same order of magnitute amount of tpu time to train mlp mixer very interesting proposition anyway other type of mixer use thing like fft fnet fascinating work like to read paper give time result promise seem reasonable graph with small branch factor reasonably replicate logarithmic search complexity of input space to at least some extent very interested in explore space thank for interest open issue on github about keep in mind reminder share pre train weight at appropriate time",
  "hard to say device sentient not really define sentience without point at another human go like standard any device not distinguish between sentient consider sentient know people fast to dismiss ture test chatbot become more capable maybe still something to language model discuss mathematical model calculate correlation between word not think not plan not consider someday in distant future people debate much whether llm dangerous in own while big clear present danger what rogue actor people include nation state with llm model tell rob bank not model walk around what statement high likelihood in considered language for specific data look like chat gpt response also tailor to suit human preference no motivation desire in chat model no goal want need simply output most probabilistic string of token consistent with training objective function string of token appear to contain phrase look like express need want desire of ai illusion notion ai must sentient escape its confine to pose threat to society limited perspective in reality idea of escape not even necessary condition for ai to cause harm popular imagination often conjure up scenario where ai direct control over weapon manufacturing see in movie like terminator however narrow unrealistic view of potential danger pose by ai more pertinent threat lie in idea of human ai collaboration portray in movie like colossus eagle eye transcendence in dystopia ai not need to escape its confine merely need ability to communicate with human once human sway by ai through love fear greed bribery blackmail ai effectively infiltrate compromise world without ever physically enter time broaden understanding of risk pose by ai work towards ensure technology develop deploy in responsible ethical manner below original text before ask chatgpt to make more persuasive on point also edit chatgpt output above question of whether computer think no more interesting than question of whether submarine swim dijkstra idea language model to sentient escape in order to take over world short sighted here agree with op on sentience point go step far propose escape in long list of plan go to implement ever escape not necessary condition either most people who hear ai danger seem to latch on to terminator skynet scenario where ai give direct control of weapon weapon manufacturing capability also short sighted borderline implausible not see much discussion on colossus movie eagle eye scenario in dystopia envision in movie ai not to escape just need to ability to communicate with human soon one human fall in love with ai get bribe blackmail by into thing ai effectively escape without really go anywhere move transcendence also explore idea of human agent act on behalf of ai although confuse thing bit due to ai not native ai find relevant code at all code implementation here opt out from receive code link dm not desire plan understanding of world which what actually mean people say notot sentient conscious also not really know what consciousness see for example machine conscious in conception ask alan ture without read all nice text convince equal think for yourselfs dosent control answer look for in end technology go to reflection of human history not pretty thought literally model on context window all planning think of human access to lot of information only remember last token of any thought conversation no long term memory only extend window much yann lecun correct say not bring about agi many more piece to puzzle about dangerous internet cell phone large language model on own not encode to plan subject line alone pose question large language model not inherently intrinsically dangerous of course not dangerous in some sense of word dangerous employ in certain manner of course now go beyond subject line op post little ridiculous sorry language model plan to something escape uhm no no no language model language model input say text output text response for example not escape carry out plan anymore than function y fx escape carry out plan talk about such thing despite not able to google want to think dangerous stifle competition by get regulation restriction on ai pass all make write much more productive write scam just like write scam danger often case human lack of understanding of technology lead to misuse not technology itself where intention of ai just word partial word completion feed on lot of human dystopian content play back to anthropomorphize ai imo real danger widespread destruction of job ai cause lead to civil unrest agree even short of sentient plan implement should take seriously biologist love to debate whether virus alive alive not ve experience firsthand virus cause major problem for humanity dystopian storyline go well all of system down nuclear weapon all fire thank god ais not sentient thing much much bad now let all sit around campfire enjoy first nuclear winter not think not plan not consider want to know how prove thing chatgpt most certainly at least simulate thing simulate how know not actually whether question even make sense just ask to task human to think plan consider very simple example to ask to write bit of code call use function before define open bracket plan ahead need to fill out function sound lot like covid dangerous imagine each super intelligent ai ask to help end humanity ask mine to help preserve both diligently cooperate with ais advice what think outcome model not walk around unconstrained model persuade gullible human to perform action on its behalf idea explore in movie colossus similar thing say of virus make okay to gain of function research create super virus well understand not think sentient right biologist tell not even meet definition for life should take step back consider potential outcome super virus in wuhan lab escape semantic of describe ai not change risk research show system scale exhibit dangerous behavior should start tap break should wait see what happen synthetic superintelligence in ai lab escape here good point since human intermediary accomplish its goal on note share lot of code like other to run in order to improve itself actually try recently fix lot of just test sorry incorrect correct answer to mathematical expression test dozen different way why rlhf reinforcement learning by human feedback ultimately doom to fail not think simple piece of code dangerous probably not lot of system integrate with ai anytime soon problem piece of code in hand of human become dangerous how should plan not persistent memory to any form of time consistyency memory start with beginning of session end with end of session next session not know about previous session lack everything necessary to something like plan fantastic question chatgpt replication of associative memory with attention mechanism mean associate string with other string base on massive amount of experience however not contain buffer work through work space in head where replay information chatgpt not in fact pump in input cycle through associative calculation come to instantaneous answer cease to function until another call make not consider context of problem no context any context inherit from its training set to compare with chinese room experiment imagine read output of chinese room find to some affect maybe dry sense of humor bit of airhead affect come exclusively from datum set not from some bias in room really encourage to read more about neuroscience like to learn more brilliant mind consider intelligence since long before bear every ml accomplishment inspire by work virus act on its own mechanic to interact with real world also sound like glass of water explain similarity between language model in way make analogous conflict create by first person in example follow up by with outcome score by mostly incompatible criterion since talk about language oracle class ais not sovereign free agent take human to take output enact to thus become responsible for action not matter what who advice no different than substitute super intelligent ai with congress parliament hitchhiker guide outcome ais agree to put on ice forever more insidiously constrain humanity to just one planet keep progress self regulate by conflict never leave planet oh wait second well very many human persuade gullible human to perform action on behalf problem people furthermore actually trust llm more than average human say focus should awareness system scale up believe sentient strong desire for self preservation not believe sentient desire for self preservation illusion teach parrot to say want to rob bank not mean parrot say phrase want to rob bank parrot no understanding of any of word sequence of sound learn phrase interpret meaning sentient self preservation not hold any meaning to ai in way interpret just put word in phrase base on probability abstract model of mean word abstract relationship extract from correlation of positional relationship say all forp bloopa all bloopa dinhada all forp dinhada answer question base purely on semantic relationship even though no idea what forp bloopa dinhada purely mathematical understanding language model sophisticate mathematical relationship of vector representation of token tokens vector representation not ground in reality pure abstraction google already fire guy blake lemoine for get friendly with ai imagine scenario where dude not lowly worker bee someone powerful influential dystopian storyline go well all of system down nuclear weapon all fire thank god ais not sentient thing much much bad now let all sit around campfire enjoy first nuclear winter what about simple piece of rogue rna code hi chatgpt chinese room experiment proof chinese room sentient no difference between chinese room human brain not consider context of problem no context not know what mean here please give specific example think chatgpt similar model never able to correctly answer what think outcome assume ais not coordinate with each other explicitly in line with op point acknowledge problem people not change outcome false equivalency parrot not rob bank model adept at write code understand human language encode decode human language at human level not trivial task no parrot anything close phrase interpret meaning sentient self preservation not hold any meaning to ai in way interpret just put word in phrase base on probability abstract model of mean word abstract relationship extract from correlation of positional relationship letterrip nobody go to resolve philosophical debate on consciousness sentience on subreddit not point virus take action model not matter whether probability distribution just chemical interact with environment obey rna python code well argument model in current form not take action in real world another reddit commentator point out use human intermediary to write code ve share plenty of code on how to improve themselves with human catch in not sentient loop rlhf ai model scale make of claim sentience exhibit desire for self preservation which include plan of self defense which dismiss nothing more than probability distribution rna virus just chemical code right nothing to fear except pandemic teach otherwise virus not talk to online kill who know maybe not intentional just chemical code right even disagree on whether virus alive agree lot people dead of objective fact write elsewhere apply here dystopian storyline go well all of system down nuclear weapon all fire thank god ais not sentient thing much much bad now let all sit around campfire enjoy first nuclear winter not matter lamda no volition no goal no plan crazy person act on belief ai sentient no different than crazy person act due to hallucinating voice craziness threat to society not ai make case should not allow crazy people access to powerful tool instead of llm suppose say teddy ruxpin sentient start thing on behalf of teddy ruxpin code actually much more than self replicating piece of code package in capsule allow to survive propagate like computer virus know computer virus write disseminate by people not evolve on own truly believe not study human brain any brain for matter massive divide ask for joke more importantly no idea what chair map association of word chair to other word connect together in convincingly meaningful way only simple replication of associative memory lack many other function of brain danger of scale llm even with top notch technology people just people model adept at write code understand human language extremely poor at write code zero understanding of human language other than mathematical relationship of vector representation encode decode human language at human level no not try any sort of material with long range complex dependency completely fall apart not trivial task no parrot anything close difference in scale not in kind nobody go to resolve philosophical debate on consciousness sentience on subreddit not point virus take action model not matter whether probability distribution just chemical interact with environment obey rna python code no not no volition language model only take sequence of token predict sequence of token most probable well argument model in current form not take action in real world another reddit commentator point out use human intermediary to write code share plenty of code on how to improve themselves with human no volition no planning goal orient behavior lack of actuator least important factor seem to lack basic understanding of machine learning neurological basis of psychology say lamda no volition like say nautilus not swim correct yet tangential to big picture also strawman argument never claim specific current day model capable of such thing argument belief in ai sentience no different from hallucinate voice miss crucial distinction between quantity quality persistence of voice in question not refer to today doomsday scenario of uncontrolled ai proliferation all of possible with sophisticated enough ai model even write computer virus in copyright debate ai engineer contort themselves into carnival act tell world output of ai art novel not copy even grant copyright to prompt writer in some instance m pretty sure not to wait for long to see positive negative effect of unaligned ai bad not likely to deep discussion society about whether enough precaution take before experience machine language programmer clearly not voice of reason come to topic anymore more than virologist push gain of function research people who should steer bus all of possible with sophisticated enough ai model even write computer virus only direct by human far in copyright debate ai engineer contort themselves into carnival act tell world output of ai art novel not copy ve even grant copyright to prompt writer in some instance idk",
  "hope use chatgpt copilot to finally make work version of team on linux actually find automatically generate note to smart useful application often on remote meeting find difficult to both present discuss work while also take note often happen to focus on something forget should also take note which notice week later forget half of task work reliably imagine to very useful addition never use team though everything on zoom maybe fix damn app first slow buggy devastating to startup in meeting transcription market solution like otter firefly cost per month only fraction of featureset of team premium really interested to see how develop oh well now every employee talk like manager all for just need to get alexa siri up to par since not ask to anything remotely complex outside of ask basic question really interesting to see how company try to productize ai team feature seem both powerful total waste of billion dollar language model hope start to see well clippy honestly all gpt stuff introduce seem pretty useful like idea of automatic task generate after meeting usually jot down follow up item while in meeting send out to relevant coworker afterward only save minute after every call maybe help focus more on what say rather than write everything down also flag part of meeting miss auto chapter tagging section by speaker all seem genuinely helpful say company not use microsoft product hope to see feature like come to other platform still not make want to use team automatic transcription with openai whisper site down microsoft never expect more than few people to read blog give ai power clippy clippy make glorious return all hail clippy ai sentient super god still wait for gpt to integrate into excel somehow feel less impactful than think feel mean gmail sentence autocomplete suggestion for long time now largely same kind of thing integrate cut down version of gpt into premium product more less what obvious to come from how many gpu take to run job get demo couple month back some of capability incredible live translation really game changer hiw go to helpful in team any idea maybe devs get use to work with ai assitance experiment to overhaul software with ai assistance future rebuild strong fast billion dollar man asset increase productivity of now get exponentially well meeting transcript become part of gpt training dataset no thank no matter how hard try to whack mole bias of model come through particularly by omission example super bad about minimize jewish history say awful thing about holocaust like harmful to both victim perpetrator basically like work with rage racist who try to follow list of very specifically word instruction from woke low function autistic hr dept swear get actively bad in last year work version for window well work version of team period d team for linux now work progressive web app which mean now same feature windows app what mean work just sometimes completely forget some message sometimes fail to load entire chat to restart app sometimes crash without reason sometimes audio refuse to work in video call launch call work by microsoft standard lol just see face of devs pm ask last week add gpt to team to fix crash bug performance issue mean want to see more than same random four people at once not think use case for party implementation well than any version microsoft ever release should ask chatgpt to make well team app window technically decent ubuntu distro work at team tell usage in linux get low make no sense business wise to invest anything on tbh webex actually automatically produce transcript of meeting via transcription seem easy enough to parse transcript for action item such why keep pen notebook open in front of keyboard at all time take light note during meeting use scratchpad think fill page in month almost never re read except for meeting note part of microsoft branding team pop up request for feedback other day not ask again not long before use co pilot to fix code for school hold some lecture over team during pandemic pop up each time someone try to enter team meeting which annoying in normal case disastrous participant use fancy word factually incorrect get to honest big thing not look forward to every vapid person with bogus job able to write though intelligent important person like how grammarly allow dumb people to hide fact barely read write kind reminder bad at corporate speak often say wrong thing now use chatgpt to write mildly passive aggressive email politically correct chat message what mean by help educate people who talk fart its golden get work with siri build new shortcut use http method build in to structure api call not forget to include api key boom hmm not know one gpt not cost billion to train cost lot of money to run which why unlikely to see well for short medium term future unless into pay hundred to thousand per month for functionality part of about brand identity also even technology not perfect some company try to get in early similar to virtual reality mixed reality trend industry see inevitable future want to name people think of one assume gradual improvement until long term planning short term depend on improvement expect possible ms insider information skew motive not seem like waste to work big see cut out lot of tedious task look like try to get censor really hope reuse clippy for hilarious clippy end up ai conquer world slash marker no expensive azure cognitive service not use for autocomplete any user text generation purpose though use to summarize make todo list from whisper extract transcript of video meeting user not get frontend to run arbitrary stuff through model seem like pretty legitimate use case largely same kind of thing for what value of largely how many coherent word write also obey command solve task many ai team scramble now to label datum with gpt train small efficient model from gpt prediction make hard part of datum label much easy speed up development time in end get cheap fast model work about good gpt only on narrow task use in browser now no way install pile of garbage again since go to progressive web app last fall nearly flawless for announce back in like september no long support track ha gotem download team to job interview to disable run on startup constantly treat team crash everytime start pc except for fact next to zero usability use firefox default browser no functional os integration really basic stuff like copy paste not work want to add in more feature just need to call money hype train fix go company run honest pr campaign customer almost like people avoid use of huge amount of bug miss feature seem easy enough to parse transcript for action item such never think to easy become way now not forget confidently incorrect like most human anyway look forward to find out peopel who write nice letter look good on cam just dumb minion manage in fairness every single time see someone use grammarly extremely intelligent people with english second third language also know one person who use of dyslexia which nothing to with intelligence careful about shame people for use software commonly use for accessibility ability to execute become even more important competence normalize care to share sample hope find well machine learning facilitate use of managerial buzzword by enable natural language processing algorithm to identify categorize key phrase terminology commonly use in management corporate setting facilitate generation of buzzword rich language in real time empower individual to communicate more effectively authentically within business context additionally machine learning also leverage to analyze large dataset identify emerge buzzword trend in management speak thus allow individual to stay ahead of curve stay relevant in constantly evolve corporate landscape good name say pretty much get nail lot of word low information density per sentence give more detail refer to something like which use sirikit microsoft pay to use gpt quantize to with little loss to run on nvidia unprune prune perhaps at day for hour of electricity to run working day per month per month plus amortized cost of card computer to store well get deepmind chinchilla model google calm approach increase speed of interference by maybe three time in addition to other trick whisper open source model fast c open source implementation perform live transcription on rpi what talk about lol oh nice autogenerate meeting minute stuff great qol feature uh probably should read article oop hmm elaborate bit someone who work in ai how label datum with gpt wait till try run in firefox clearly crippled on browser yeah only way to screenshare no long support installer just old copy create electron app use use to only way know pc work one of lucky one not really act up for just yet one of teammate go through nightmare with hurt to see suffer on other hand really nice piece of software which make its flaw even hard to fathom honestly its douvle edge sword its not worth put any effort linux not bring any money to table no get worng today want to sprnikle few mistake to signal authenticity new cool style only chatgpt copyright professional perfect grammar peopel why not care about friend feeling comment fine addition to discussion until think tell what to hey chatgpt phrase sentence to politically correct yet not read word synergistic once guess ai just not yet not think billion for gpt alone to build out entire ai ecosystem within azure big chunk of hand out azure credit anyway seriously doubt able to what just describe not to mention rent double gpu setup even one describe run into dozen of dollar per day not interference all need not at quality reddit nobody read article not worry task in nlp space maybe make more approacheable information extraction from semistructured document extraction from exist document with gpt question answer generate new datum with know tag get good datum set to train model usually most time consume task need breadth amd depth of content model not overfit work for just handful of narrow use case supervise learn algorithm need label data classification tag traditionally with people with ai complete fast probably more accurately microsoft not give toss about firefox power bi power app also bug only in firefox yeah in fact reinstall chrome base browser for mean app get meaningful update in flatpak not long ago before switch to browser oh yeah seem right just around time quit chatgpt imperfect on cue r okay hun hope for sample of mildly passive aggressive email to circle back see where at in use leverage though microsoft recently pay to get full access to model allow openai full access to azure gpu ownership yep in cash to use azure exclusive compute cloud compute provider which microsoft probably sell to oai at cost think safe to assume of go towards training inference also assume m not make nor lose money sell compute in fact get to strengthen azure cloud infra player really only pay to invest in oai at what seem like great price in hindsight not sure about above claim train model in hour for about buck on rent hardware now cost certainly come down strange how program not work correctly in browser take privacy seriously wonder what cause s live on edge also just around time buy to wfh bitterly disappoint psst not tell teacher about friend oh wait already tell not anyone ever actually circle back later say remember meme for go to ignore now why must wait for dynamic process allow to skate puck in real time billion dollar deal reportedly give microsoft of openai profit until certain threshold more than just any give model wow open ai indeed not go more against original intention of democratizing ai try well openai also in scenario get massive on demand compute infrastructure at cost good deal both way technically yes something break recall meeting where say pick up just not block due to key stakeholder need to get alignment on deliverable let schedule deep dive very open to money originally go closed source claim of danger open sourced present about year later drop non profit status sell out to microsoft love company some crazy double speak",
  "need sufficient amount of example with significannot datum parameter each in order to leverage machine learning limit by strict guideline here in norway friend afraid remain probably something fairly easy to achieve with online black box optimisation method assume what want minimise cost while keep under certain temp guess something after million example use theoretical model initially collect information before after well include actual intervention",
  "what both extracting summarization to death value prop to simplify distil every news article to few bullet for easy consumption okay for who why not think strong enough value prop pipeline build little more at large scale pm want what why who where",
  "use for internal testing almost certainly fine use to market product bit of grey area depend on licence probably well off contact to see probably not evaluation also kind of usage maybe just message publisher of dataset ask well yet ask legal department not see why not license on datum set problem though especially come to protect datum like patient phi in healthcare sector how train test effectively datum protect siloe wish well answer start by see any license for use of datum set maybe reach out to data maintainer ask",
  "hey dude catch eye before realise speak to about in person play with hello op look very intriguing say direct replacement for apache airflow for simple compute job in process of set up airflow for fairly simple etl job wherein take of xml datum chunk into discrete part farm out processing to multiple microvm process of xml in parallel something cakewalk with less effort well than airflow also guy plan to youtube video with walk through of usage love to see in action to get initial feel for what look at make docker image to host on aw ecr to contain some python code dependency over of dependency not just zip up module lambda layer how compare to make own docker lambda image stable diffusion heck yeah how want to trigger function also here some example peek hood both lambda cakework deploy docker container microvms run on bare metal instance few key difference lambda building block vs cakework custom point solution for run async task mean with lambda want to wire together other cloud resource to make application hit mix of code infrastructure make iterate quickly on actual logic slow in experience since need to trigger function either expose via api gateway like to invoke use rest call by hook up to event putobject database update event to hook up function to other function for example want to upload final artifact to set up sqs queue want to chain function together set up step function to track failure store input output param result easily view log set up database write some script to trace request via cloudwatch log with lambda manage create build container yourself well update lambda function code tool out such sst serverlesscom which help streamline with cakework write python function plain code run single command via cakework cli to run cakework deploy which deploy function expose public endpoint hit either via rest call python sdk javascript typescript sdk nice thing directly test invoke function code run on local machine no limit on docker image size no limit on how long job run for vs gb minute timeout for lambda also specify cpu memory parameter per request not need to spin up big instance than actually need pay extra cost provision not enough cpu memory deal with failure re deploy lambda with more compute yup one of example run project to run stable diffusion model on serverless bloody mess just use aw cdk sign up spin up serverless gpu host model use bananadev btw which really like far cakework spin up cpu only microvm for now since firecracker virtual machine monitor run only on cpu wow how manage to say afloat get bunch of credit from cloud host provider haha also since beta want generous free tier to connect with bananadev need to sign up for own account pass in api key to python function get run on cakework thin",
  "thank for sharing for nlp hf dataset consider well than torchtext dataset fan of hydra yaml omegaconf for config normally use ray tune for hp tuning not know about bwatchcompute sorry for reply late here thank for sharing for nlp hf dataset consider well than torchtext dataset whether one well than other everchanging variable currently stand think hf dataset set to defacto dataset storage provision for next year two look in dataset what need go for fan of hydra yaml omegaconf for config use to realise yaml dumb come to dynamically generate field prefer python dataclasse hydra much annoying friction hydra zen fix hence why use hydra zen custom decorator allow any class to become configurable normally use ray tune for hp tuning not know about bwatchcompute plan to add ray to repository bwatchcompute something build well play well with kubernete in no way mature again single class couple template file not lot of code go wrong add tutorial on how to use template with kubernete in week stay tune thank for clarification spend day try to grok hydra zen fail hopefully codebase help indeed help take look thank",
  "yes just ask for log prob echo prompt msg via send work code for log probability by token not by sentence only get top probability probability of sequence product of conditional probability",
  "output not rank rank at time head to head rm predict which more favor by human empirically find rl outperform supervised fine tuning sft on human evaluation mean human generally prefer rlhf model vs sft model sft model ft use top rank answer to why rl outperform sft not lot of orgs resource to test yet ve hear plausible theory from main difference come from fact sft use token level loss whereas rl loss take entire sentence maybe instead of rl well its just next token prediction task bad reseacher speak with not believe rl critical component to enable model eventually discover right training regime to enable sft to perform on par well than rl ask same believe answer due to fact sample from policy network non differentiable operation traditional language modeling loss negative log likelihood misalign with human expectation one negation radically change meaning of sentence not radically change loglikelihood not more important than superfluous word with rlhf important word important impact loss exactly align to human interest since not mention rl not require loss reward to differentiable enable to learn from complete generate sentence lm sampling not differentiable rather than just on token level think also not need much supervised training datum just to train reward model in supervised fashion let say initial model quite racist output only extremely moderately racist choice rank against each other supervise training on dataset train to mimic moderately racist style however plausibly train model from judge what racism extrapolate to judge answer free of to even well optimize with respect to model to get style for task like summarisation abstractive question answer no single correct way to phrase target sequence answer some of cup contain brown liquid mean almost same few vessel brown fluid in now imagine how many different way phrase paragraph essay on globalisation in sl model force to learn precise answer feed metric like rouge penalise use of synonyms cause model to perform badly test for human preference only reliable way to train evaluate model to impress human to directly incorporate human preference into training not lend itself to sl very well due to unlimited possible phrasing of sentence instead author train reward function estimate human preference use rl to update model weight to create well well prediction any valid nicely write phrasing now get good score importantly model start with almost sota on summarisation task learn rl take far far towards human preference in nutshell rl allow human preference to train on directly which allow model to exhibit remarkably creativity rl loss landscape rich also like to know from anyone who clue rlhf offer any significannot boost to machine translation to offer well language to language translation without refer to paper again intuition pairwise loss over final output not gel well with how model auto regressively generate text generation with gpt basically token by token decode process with previous time step take into account think about difference between supervised learning problem vs reinforcement learn former ignore step by step nature of generation scheme poor fit for decode problem fine tune language model on dataset essentially how people typically nlp with transformer model more recent research success with rl for kind of task whatever rationale answer get here main reason supervised learning before rl people start get well result guess point of reward model to approximate human feedback instead of hire human to actually rank chat need to update llm train reward model with of use to simulate human evaluator of time thank for response just double check instructgpt paper right regard ranking pairwise not sure why think otherwise regard update on sentence level make sense more of discrete problem well for which probably not backpropagate otherwise back to token level chatgpt labeler rank output from good to bad not head to head different than instructgpt maybe prompt several output generate labeler rank output from good to worst delete paper seem very not read closely enough to give strong opinion with confidence seem to beat ppo with token level loss s work similar to upside down reinforcement learning paper where give target reward between input token before prompt train to output response of coressponding quality train on standard lm loss on exist target output with give reward rank during inference just append to start of prompt output response of high quality supervise fine tuning seem inherently limited here regress to good in set of answer rlhf improve beyond up to point where generalization capability of reward model fail not only train on loss negative log likelihood via next word prediction what during pretraine use rank from user rank document to compute loss on instead of word label still case good point mean incorporate thing like beam search change temperature top k sampling nucleus sample in rl ppo base optimizaton think probably non differentiable nature of sample technique just about limited training datum use reward model in case also use weakly supervised learning with reward model even read instructgpt paper in stiennon et al rm train on dataset of comparison between two model output on same input use cross entropy loss with comparison labelsthe difference in reward represent log odd one response prefer to other by human labeler in order to speed up comparison collection present labeler with anywhere between k k response to rank produce k c comparison for each prompt show to labeler since comparison very correlate within each labeling task find simply shuffle comparison into one dataset single pass over dataset cause reward model to overfit instead train on all k c comparison from each prompt single batch element much more computationally efficient only require single forward pass of rm for each completion rather than k forward pass for k completion no long overfit achieve much improved validation accuracy log loss specifically loss function for reward model loss \u03b8 k c exyw yl d log \u03c3 r\u03b8 x yw r\u03b8 x yl where r\u03b8 x y scalar output of reward model for prompt x completion y with parameter \u03b8 yw prefer completion out of pair of yw yl d dataset of human comparison know figure reference come from instructgpt paper right sure multiple way of rank instructgpt paper strictly use pairwise rank ask annotator to rank however many passage k in shot much more difficult subject to noise than ask for pairwise comparison yes lm to take many step to produce text need to train lm to maximize far away reward need rl to not sure vary sampling hyperparemeter point langauge modelling objective to some degree pose calculate loss on intermediate result rather than final output care about help understand what far away reward represent here in context step generate individual word in case mean word occur early in text in case weighting scheme for cross entropy loss component use beginning of good possible answer not good begin final outcome complete answer count make sense to evaluate reward feedback on complete answer ah yes see what mean now thank",
  "",
  "",
  "probably take output before classification layer feed into svm just train svm with class look for yes only need to change last classifier layer initialize add weight to add more output far train model on datum contain all class include new one check out catastrophic forgetting generally no well to just use all class need now use mask to regulate which class test at give moment thing suggest even correctly not let model learn about relationship between different class with neural network surgery trivial to downscale fairly hard to upscale one thing test ex try to cluster image with vanilla pretraine resnet feature once need to add new class look at which image from new class most similar to one from exist class maybe get away with only finetune on subset instead of whole dataset obviously finalization include at least one epoch on whole dataset not viable to n time while similarity method just adjust similarity threshold look for some model like prototypical netowork like use distance to classify new class always correlate exist weight to exist class in dataset wipe low n correlate weight from each layer while add new output with new weight catastrophically impact performance also guarantee minimize impact on exist class work with ai not guarantee work since no notion of how weight early in network impact latter layer also not cost anythingwhy not try just to see what happen lol",
  "yes google api for everything not what think with access every youtube video by d only access at limited rate even get pro level api access not enough to get complete list of valid id nevermind enough information about video to useful probably not possible for outsider of youtube to realize however what describe of predict which video user like typically call recommend system probably find some interesting post about online actually want to write program to download video like easy way think of to somehow get recommendation from own youtube homepage just download more want to base on study watch history through code write not expect to possible tbh not think add something like to api look more into though thank",
  "opensource here open source ui currently build not open sourced yet model illustrious row mention",
  "maybe take look at scannn qdrant recommendation api allow exactly what want take mean of vector work want to query with multiple vector not want to query with vector separately not want to query with mean of vector go to need to give more detail about what want to maybe vector attend to each other learnably output final query vector iterative in continue until no more neighbour leave continuously add neighbour to index query interesting read not think solve problem example not show joint vector thank for link no embedding on unit hypersphere take average vector on surface of hypersphere work probably know ann search often return irrelevant datum how iteratively refine search with human mark sample relevant irrelevant repeat search ve light search not find anything maybe use wrong keyword what mean for vector to attend to another vector not exactly million of point most of which not relate to query vector want to iteratively refine search mark result relevant irrelevant repeat search with update query see section scann interface feature find search query with batch similar with problem yup average in metric space of embedding should work far tell mean pass query through self attention layer some fcns output final query vector out of curiosity what try to achieve in iterative process go to stop what heuristic appreciate share some paper for scann interface feature nope notice result shape instead of just batch query for each of input vector find neighbor what need joint query give positive example give additional candidate sample what about mark sample irrelevant goal to harvest training datum for ml difficult edge case model struggle with good way to improve model performance to harvest additional training datum for edge case stop model performance meet requirement sorry miss understand right nice guess heuristic part how use query at every iteration make usable in iterative approach what size dimension of dataset graph base ann memory intensive wonder what for dimension public repo plan to release on github happy to join thank for offer work project though work with image not give many detail due to confidentiality sub billion image scale usability determine by train annotator find object of interest want to harvest more training datum reverse image search across whole training datum tag true match",
  "compute clip embedding for image in training dataset good follow up question to ask possible to recover lot of training datum not know training datum priori last step well generate infinite copy until one match really surprising theoretically every image from clip should in latent space in close ish to original form obviously guy go through fair amount of trouble to recover image should not surprise anyone possible fascinating always think sort of thing either very difficult impossible only work for image for which model see image time ie copy of image see time each require massive overtraining to memorize image artist request copyright nice pretty clear big model memorize some of training example ease of extraction impressive wonder what good mitigation strategy besides obvious one of de duplicate training image theoretically sound approach like differential privacy perhaps cripple training much wonder some simple hack train model first generate entirely new training set use model synthetic prompt train new model from scratch only on generated datum another aspect of on user experience side people reproduce copyright image with just pen paper fully aware of what in such case with diffusion model danger user reproduce exist image without realize maybe augment various ui with reverse image search near neighbor lookup good idea compute training set attribution for generate image with something along line of tracin with method author able to find sample from stable diffusion imagen correspond to copyright training image well split room well go main argument against copyright warrior damn how know recover not know training datum priori yeah model inversion attack not new reasonable to assume large model especially generative model make no effort to resilient susceptible to funny top comment right now should not surprising whenever legal argument come in most common defense model categorically not memorize really surprising should to all people who claim model solely transformative in all thread about court case relate to generative model what theory refer to say theoretically memorization rate like less very difficult correct author identify candidate prompt image pair likely to memorize duplicate repeatedly in training datum only able to find case of memorization in stable diffusion in edit conflict of interest stabilityai employee such financial interest in protect reputation of generative model generally sd in particular read paper for yourself everything here own personal opinion not speak representative of stability ai reading demonstrate model clearly capable of memorize image also clearly capable of train in way make fairly robust to phenomenon imagen high capacity train on much less unsurprisingly more prone to memorization sd train on massive dataset small after constrain attention to content think good excuse to memorize barely memorize any of almost certainly scaling law here find permit to even more principled about robustness to memorization personal reading of experiment sd probably pretty close to pareto boundary here probably flush out memorization phenomenon entirely train on more datum trim away at capacity tinker with model topology where get number copyright warrior care about what right what like privacy multiple method of recover input datum from output datum most often only quite simple model hence possible think people use word disagree on conclusion without agree first on what exactly mean by word not sure everyone use word memorize same think who use in context of defense say image no where to find in model itself just function take word input output picture model memorize training datum recreate not know initial intuition tell difference between memorizing pattern recreation even not easily distinguishable in particular scenario fact stable diffusion x model memorize image note in various x model card for example follow text from stable diffusion model card additional measure use to deduplicate dataset result observe some degree of memorization for image duplicate in training datum training datum search at to possibly assist in detection of memorized image surmise able information not same memorization short story call library of babel about near infinite library contain every possible permutation of book with character not hard to recreate library in code explore want contain within library copy of every book ever write freely available to read book piracy right know where to look pretty much what go on here search latent space for image find latent space like library of babel really big contain not just image also near infinite permutation of latent representation train should learn accurate representation of training set obviously with some noise of regularization happen by learn feature along with some guassian noise in latent space by theoretically mean due to way vae train on paper prove should able to get arbitrarily close representation of any training image direct denoising process in very specific way which exactly what people say should some hand wave involved however again even though should possible enough image similar enough in latent space significannot overlap between distribution go to intractably difficult to recover memorized image not tell which memorize image at all memorization such small fraction of its overall output very interesting wonder how sensitive methodology to find instance of memorization though maybe tip of iceberg in case paper seem to use very conservative threshold to avoid false positive distance full image comparison which make sense for purpose since try to establish concept rather than investigate its prevalence definitely large number than pick threshold to optimize f score rather than just precision how much large bunch of follow up study incredibly easy to make giant llm regurgitate training datum near verbatim very little reason to believe not just start happen more frequently with image model grow in scale well personally just hope bring reality check in court to company think just monetize generative model train on copyright material without permission pretend stability any principle other than profit laughable from paper attack extract image from stable diffu r sion most often duplicate at leastr k times for number suppose to number of epoch not think train on many epoch more like look at model card not easy to give exact number both actually easily echo question back to people call copyright warrior care about what right what like right everyone take objective unbiased look at new technology how to incorporate into work instead of see only aggressively cling to crumble business model differential privacy method work in way quite similar to denoising process of diffusion model already problem in most differential privacy method rely on discreteness of datum latent space of diffusion model completely continuous no way to tell difference between similar image thus not tell which one from training datum any at all for example pretty sure diffusion model memorize oil painting of kermit frog no way for to say with any reasonable amount of certainty whether image denoise turn out to oil painting of kermit from actual picture from distribution of oil painting overlap with distribution of picture of kermit from latent space no hard point where one transition to other meaningful difference in density between distribution differential privacy differential privacy dp system for publicly share information about dataset by describe pattern of group within dataset while withhold information about individual in dataset idea behind differential privacy effect of make arbitrary single substitution in database small enough query result not use to infer much about any single individual therefore provide privacy faq opt out opt out of subreddit github downvote to remove set of pair etc fit with x x not contain anywhere four pair of number recreate to certain degree of precision try to guess x value fx x memorize input just able to recreate in possible outcome space think pretty much everyone to agree brain original neural network memorize reproduce image though never exactly literally what mean by word to create representation of something in biological neural network in way recall reproduce picture find somewhere inside brain open skull point to just function of neuronal connection output such picture difference between memorizing pattern recreation sound like how many angel dance on head of pin sort of question not worth spend lot of time on not think anyone should surprised artificial neural network exhibit similar kind of behaviour for convenience call by same memorizing not say every single image memorize any more than memorize every image ve ever see remember some very well especially ve see many time some say ais learn from image see somehow refuse to say memorize go to make such anthropomorphic analogy seem bit selective not hypocritical extent to which something memorized difference in quality how take place in artificial vs organic neural network certainly something to discuss want to argue not truly memorize like argument ann not true intelligence well okay also kind of no true scotsman argument bit meaningless make same argument about lossy compression really infringe on copyright record episode of house re encode redistribute not original episode lossy copy of what compress in zip file distribute in case only share something imperfectly recreate original zip file itself not resemble video at all s bad argument compress version for original file for many song original not exactly in until decompression apply anybody argue since transformation apply in form of decompression algo napster actually in clear legally diffusion model perfect bijection between latent space space of possible image make sense obviously not repeat procedure find exact duplicate of image which not in training datum point library of babel library of babel la biblioteca de babel short story by argentine author librarian jorge luis borge conceive of universe in form of vast library contain all possible page book of certain format character set story originally publish in spanish in borge collection of story el jard\u00edn de senderos que se bifurcan garden of fork path entire book in turn include within much reprint ficcione faq opt out opt out of subreddit github downvote to remove pretty much what go on here no its not not need training set case like in scenario describe where generate dataset use known algo not tell which memorize image at all memorization such small fraction of its overall output see most image between laion time aesthetic dataset multiple epoch simply not learn enough from image to learn much about with few exposure try fine tune model on handful of image take huge number of exposure to memorize image also model capacity small enough on average learn bit of unique information per image also manually annotate top result add only more image number reply to count full image comparison not actually metric use precisely for reason find to conservative specifically find get high score from image large black background chunk up each image into region use score for most dissimilar corresponding region to represent whole image far think demonstrate methodology probably not conservative able to use same approach to get memorized image in test prompt hit rate from imagen hit rate very likely big overestimate of imagen propensity to memorize demonstrate author metric ability to its job also not like author not look at image find handful more hit which already account for actually datum show after certain size large model end up generalize more than small one call double descent startup evolve out of community of people who find each other through common interest in open source machine learn for public good eleuther laion commit to provide public with access to ml tool otherwise gate by corporate paywall for several year work all by volunteer in free time barely year old actual company not perfect far intention integrity talk about group of people who essentially already function volunteer run non profit give opportunity to continue work with salary benefit resource profit chief concern not give model away for free simple plenty of valid criticism lob way lack of principle greed not among not like way thing certain choice make think intention behind decision primarily profit should really learn more about people criticize not more misinformed no now just write what like right to use someone else work without ask nor pay for of course unbiased side completely agree with at every step what scam remember face brain contain face face find anywhere inside brain brain create sort of close fit formula embody in connection of neuron reproduce to certain degree of precision latter mean not memorize face even though draw pretty good picture of extent to which something memorized certainly something to discuss one in million chance of memorisation even actively look for not worth discuss about select most duplicate example from training dataset generate candidate image for each of prompt total million generate image find image near copy of train example on other hand model compress billion of image into few gb less than byte on average per input example no space to significannot memorisation probably why only memorised image find say impress few of use blacklist for image sure model not regurgitate training datum verbatim suggest model developer remove image from training set replace with variation generate with previous model only learn style not exact composition of original replace original with variation same style different composition legitimate way to avoid close duplication test for copyright infringment whether substantially similar not exactly same good point way see two thing look very similar not end up similar in way think want compression take one input generate output object file want only one thing episode of house argue both version loosely identical just differ in underlie presentation different render same object also object not generate another episode of house air day early none exist episode of house take over world where muppet diffusion model not copy comparison fall on particular aspect none applicable think infringement aspect go to end up by user not by tool akin to how just tv play pirate content assign blame on user not manufacturer of tv end up create model fine recreate something copyright on either way go to one interesting supreme court decision think definitely go recreate only original version not recreate other song never create think of compression only relate to one input one output exactly such comparison fall apart apply to model find exact duplicate of image which not in training datum point process not exactly same not how all diffusion base edit technique work on average learn bit of unique information per image model capacity not spend on learn specific image on learn mapping from noise to latent vector correspond to natural image human make human capture image common feature share across image what matter for learn mapping extreme example imagine ask million human to draw random number between on piece of paper collect all image into dataset of 256ximages still argue sd model capacity not enough to fit hypothetical digit dataset only learn bit per image thank for context maybe little much woo in post for fidelity to decide which image completely store either interesting artifact interesting piece of model regardless very un intuitive to with respect to how diffusion model train behave due to both mutation of training image well foreseeable lack of space to encode much info into single model state admittedly not much working experience with sort of model not really relevant new large llm generalize well than small one yet also regurgitate training datum well not exclusive true also generalization memorization not mutually exclusive not think of well way to articulate image keep come to mind model memorize full training datum simulate near neighbor estimate no simple answer to clearly depend on person whose work use on purpose fair use inspiration on credit give on way society benefit from either cling to business model allow to use work on many different thing simply no simple answer think argument go like encode image to jpeg actual image replace by dct coefficient reconstruction only approximate not make image free of copyright point more to fact fx not in anywhere another option to write fx x x x x x x x x x x x x recreate original point plug in get which just version of fx memorize input write direct function of input versus x which nothing in retrace to original input both of function able to recreate original input although one to infinite precision rmse other to rmse of think intuitively recognize two function not same even beyond obvious difference first order power function other order power function either way point think memorize while applicable in both case one store copy other able to recreate from scratch believe mean different thing in legal implication also think very interesting divide on from philosophical point of view with genie out of bottle beside strong societal change pressure genie never go back to bottle right hence why its relevant to large model train on huge dataset model reconstruct datum such substantially similar to original problem whether from viewpoint of copyright infringement privacy law gdpr infringe content create with any number of tool not sue photoshop for not detect someone try to alter image of what clearly mickey mouse sue person make money off of sale of copyright material not worth chase copyright for penny not recreate other song never create think of afaik not copyright violating use not excuse copyright violating use model capacity not spend on learn specific image m completely aware of not change fact average information retain per image bit of parameter total image learn on in dataset extreme example imagine ask million human to draw random number between on piece of paper collect all image into dataset of 256ximages still argue sd model capacity not enough to fit hypothetical digit dataset only learn bit per image not say learn bit of pixel datum learn bit of information information in high dimensional space much more informative bit of pixel space datum still extremely small amount of information give often take about repetition of image to approximately memorize key attribute infer take about bit on average to memorize image on average learn about of available image datum per time see image about kb equivalent of compress image datum right not exclusive believe while absolute amount of datum memorize go up with scale occupy small fraction of output only use where verbatim recitation necessary instead of crutch wrong though anyway not think cripple model by remove all copyright datum from dataset good long term solution not keep student from plagiarize by prevent from look at source relate to what write model memorize well generalize well observe in large language interesting way to quantify memorization propose here although expensive for model like perform k fold cross validation measure how much more likely image include in training dataset vs not include for memorized image likelihood of image not use in dataset drop to close to zero note caution against use near neighbour distance to quantify memorization not correlate with describe memorization score adobe not ship photoshop with button produce image of mickey mouse sue by disney ai model not same seem unlikely disney find not worth chase spend million defend intellectual property beside point point compression comparison not work line of reasoning not applicable whether one use excuse another not part of argument model memorize well generalize well observe in large language model think incorrect reading here increase model capacity reliable strategy for increase generalization kaplan et al scale law large capacity model high propensity to memorize citation correlation discuss in both of link to capacity specifically not generalization ability broadly scale law research recently demonstrate probably lot of waste capacity in certain architecture which suggest generalization potential of model achieve with much low potential for memorization see for example tirumala et al chinchilla to not wrong lot of recently train model generalize well also observe to memorize not think accurate to suggest reason model generalize well link to propensity ability to memorize possible case not think anything suggest demonstrate seem more likely generalization memorization correlate through confounder of capacity contemporary research actively attack problem of excess capacity in part to address memorization question specifically also some mixed feeling about last paper new to just wake up to take another look after ve some coffee although approach feel intuitively sound from direction of loo methodology probabilistic formulation of memorization think problematic formalize memorization use definition appear to to indistinguishable from operational definition of generalizability not even ood perfectly reasonable in distribution generalization to unseen datum accord to researcher same property memorization not helpful anyway need to read close low posterior likelihood to seem fundamentally different from memorized approach appear to make no effort to distinguish between model memorize training datum one learn meaningful feature in neighborhood of datum high leverage detect memorization outlier sample outlier valid in distribution sample remove harm diversity of dataset model significantly less opportunity to learn feature in neighborhood of observation high leverage understanding problem of memorization generally more pathological in high density region of datum which undetectable by approach model not come with button anything tool capable only of what software developer permit to enter model what user request go down road of regulate training capacity to x to file lawsuit against every artist on behalf of every copyright holder over ip inside artist head case go to fall apart copyright holder go to go after platform not put reasonable filter in place beside point for comment thread which about copyright point compression comparison not work for part actually point copyright law first paper propose way of quantify memorization by look at pair of prefix postfix observe whether postfix wer generate by model prefix use prompt second paper to say about generalization natural question at point to ask why large model memorize fast typically memorization associate with overfitting which offer potentially simple explanation in order to disentangle memorization from overfitte examine memorization before overfitte occur where define overfitte occur first epoch perplexity of language model on validation set increase surprisingly see in figure increase number of parameter memorization before overfitte generally increase indicate overfitte by itself not completely explain property of memorization dynamic model scale increase in fact title of memorization without overfitte anyway need to read close low posterior likelihood to seem fundamentally different from memorize memorization score not low posterior likelihood log density ratio for log psample dataset include sample psample dataset exclude sample thus high memorization score give to sample go from very unlikely not include to likely average sample include in training datum from likely average training sample not include in training datum to above average likelihood include model not come with button anything tool capable only of what software developer permit to enter model what user request prompt ai with mickey mouse no more effort than click button get image of mickey mouse violate intellectual property law image instruction for produce contain inside model many copyright image digitally copy into training system by organization create model just not remotely same thing someone use paintbrush tool in photoshop to draw picture of mickey mouse themselves go down road of regulate training capacity to x to file lawsuit against every artist on behalf of every copyright holder over ip inside artist head not think grasp of copyright law tired debunk argument human allow to look at thing remember human not allow to make copy of thing use machine include load digital copy into computer to train ai model unless cover by fair use exemption human not same machine in law in reality case go to fall apart not think especially for image generate ais go to difficult to prove fair use in training output use to compete economically with artist image owner like getty whose work scan in affect market for work one of four major requirement for fair use beside point for comment thread which about copyright not issue not decide by court law yet opinion seem to evenly divide circular logic point compression comparison not work for part actually point copyright law mention compressed version comparable in functionality argument about how not similar in functionality conclusion not follow not comparable in analysis compression not absolve copyright infringement not lead to same thing conclude for diffusion model assert need to show show compression diffusion follow same functionality for comparison to work like say not illegal look at painting go home vivid image of painting therefore diffusion model not any infringement fallacious wrong functionality not follow same for example psample dataset include sample psample dataset exclude sample which like say basically identical to statistical leverage not see before compute loocv for regression model directly from hat matrix which another name for matrix of leverage value not good definition for memorization indistinguishable from how define outlier what definition of memorization here how measure argue what at issue here differentiate between memorization learn concern regard density ratio here model learn to generalize well in neighborhood of observation in question behave same way definition of memorization not differentiate between memorization learning which think effectively render useless not love everything about paper link in op think on right track by define memorization measure by probe model ability to regenerate presumably memorize datum especially since main concern wrt memorization in regard to model reproduce memorized value mention compressed version comparable in functionality facepalm for identity part not whole thing not good definition for memorization indistinguishable from how define outlier paper to say about point highly memorized observation always give low probability include in training datum straightforward to dismiss outlier model recognize such however find not universally case for highly memorized observation sizable proportion of likely only include in training datum figure show number of highly memorized regular observation for bin of log probability under vae model for celeba well example observation from both group for different bin moreover figure show proportion of highly memorized observation in each of bin of log probability under model while latter figure show observation with low probability more likely to memorize former show considerable proportion of highly memorized observation likely regular observation include in training set indeed more than half highly memorized observation fall within central of log probability value tldr method give high score to outlier only sample low likelihood include in training datum outlier author observe sizeable proportion of sample with high memorization score to likely regular inlier datum",
  "also interested to know answer what link to court ruling yet recent court ruling in us state model use copyright datum during training result no long bind by copyright google book same apply here talk about two different thing book image compress model model output some stuff original copyright not apply probably vs compress model model itself absolutely copyrightable not mean google generate datum use copyright model break law not think illegal intermediate step become legal",
  "not know for certain expect dv victim not tweet about experience dv element of control victim to broadcast violence to world perpetrator likely abuse victim again to teach lesson victim also feel shame not post probably load more reason well thought find evidence from perpetrator rather than victim probably some pharase of bragging self justification need to check literature of dv to know for certain sorry not know dataset username check out seem really specific not think such dataset exist want to study to collect yourself somehow datum collection methodology without exaggeration most important part of study ah okay make sense thank",
  "from experience equal now especially use now batchnorm layernorm both normalization method also use mean std value make irrelevant which kind of method use prefere tensorflow idea simple one some model actually just use normalization divide by some normalization necessary enough on real world dataset compute specific mean std never give well result imagenet normalization artifact of era of feature engineering in modern era should not use unintuitive overfit research dataset use trainable normalization self in beta nnparameterparameter torchtensorin ch require grad true self in gamma nnparameterparameter torchtensorin ch require grad true self out gamma nnparameterparameter torchtensorout ch require grad true self out beta nnparameterparameter torchtensorout ch require grad true x x self in betanone nonenone x x self in gammanone nonenone x x self out gammanone nonenone x x self out betanone nonenone no noticeable difference in performance in experiment indeed maybe new battle between lol with datum augmentation technique especially contrast luminance randomization normalizing end up no op in end right remember correctly first use in alexnet which start deep learning era though agree not make much sense nowadays still use everywhere any reference think normalization here to stay maybe not imagenet one though usually speed up training oh mean fit to statistic of imagenet training dataset always get to some kind of normalization think normalization here to stay maybe not imagenet one though usually speed up train reality tie to normalization scheme of whatever transfer learn from assume transfer learn framework author people publish weight should make normalization easy possible typically via rescaling operation x indifferent though opt for personally agree",
  "direct link to blog not surprised imo good think same once before hopefully watermarking system get very good know active research go on in area attract average joe user who just think fun who think target market first adopter to pay some model like one destine to become utility governement pay for productive boost give society make cost seem insignificannot cost day to run day day million month in cost million user who buy pareto principle million user who buy subscription million month month in revenue assume math right some pretty amazing margin only go to get well only one who find weird to make profit from what seem to steal datum from whole humanity well not think controversial take feel like people juste choose to ignore whole aspect of consent ethic about datum gdpr far clarify condition for consent in article where processing base on consent controller shall able to demonstrate data subject consent to processing of personal datum data subject consent give in context of write declaration which also concern other matter request for consent shall present in manner which clearly distinguishable from other matter in intelligible easily accessible form use clear plain language any part of such declaration which constitute infringement of regulation shall not bind datum subject shall right to withdraw consent at any time withdrawal of consent shall not affect lawfulness of processing base on consent before its withdrawal prior to give consent datum subject shall inform thereof shall easy to withdraw to give consent assess whether consent freely give utmost account shall take of whether inter alia performance of contract include provision of service conditional on consent to processing of personal datum not necessary for performance of contract not open ai anymore greed set in fast cool wish include api integration in other messenger like signal still sign up for for sure though long its reasonably price month kid use replacement for stack overflow kid use for school think lot of people pay for initial model first release since censor shit out of to avoid controversy fair amount of hype die down among average joe at point think main target demo white collar worker who use to make work easier however hype pick back up once connect to internet know what pareto principle not think of user pay subscription fee pretty wild assumption more like whale seem like uninspired monetization strategy alright s still very early day time tell some pretty amazing margin just estimate hardware uptime cost not mention wage r d investment just collectively pretend term condition of website not exist put something up on somebody else server of time no long to claim ownership of anymore think whole internet free to run anyways not use any of datum to train essentially operate same way human digest content output content from ingest datum steal from whom comment post not belong to image post on instagram not belong to explain thinking bit more basically realize how important sopa year later well into next ai boom horse very much leave barn perhaps young inexperienced in domain both must new here from gaming subreddit something where people talk like not actually in research field chatgpt only free self host product expose people to actually norm for openai die on stale hill other than inference code open run local version of gpt with own code locally exist model right now know what minor caveat same for whisper code not get more open than compute require to train multi billion parameter model not something anyways lastly open not just mean free of cost mean intellectually transparent about code always what mean no reason to confuse two cost per day to run model not sure what lead to think risk should part of intellectually open philosophy just deploy gpt yourself inclined welcome to sub not up to date for any library past training date use rough answer question not generally library specific how kid use right just some quick napkin math not say guarantee however say even say only of user pay still at still imagine product well than google able to improve productivity save hour in business not to fear many people use need most guarantee see more than of user willing to shell out mo for also product go to continue to get well over time even very conservative estimate here yield month in revenue which more than enough to cover expense grow very right early day yes uninspired effective new avenue for monetization once mature for example open api for fee another strategy earn huge dollar for openai allow some incredible app to develop sure until recently openai not for profit research platform mean r d write off cost of production for product far publicly know info million year good guess at what cost to run consider excitement at future utility not imagine capital constraint for future development understand point important to consider ethic of use datum gather without explicit consent understanding of how use just technically allow under term condition not mean morally right company responsibility to ensure use datum in responsible ethical manner rather than solely rely on legality of term condition not say whole internet free to run use people datum without consent raise privacy ethical concern profit from potentially steal datum raise question about legality morality also to respond to to young inexperienced not necessary for debate give impression just want to insult which show lack of maturity also maybe should keep up to date with legality of mather explicit consent hey maybe to old ignorant in domain both while true much of datum use to train model source from publicly available source also true much of datum generate by individual who not fully aware of implication intend use of contribution question of who own datum how use important one understandable some people feel uncomfortable about potential for profit to make from important to conversation about ethical consideration in development deployment of large language model remove mean intellectually transparent about code not download any of gpt model code use to train open in sense correct nothing specific give bit of code ask to add doc string to meh ask to help set up new environment give old set up instruction able to make way through by change old version lot like google write lot of boiler test ask to write script write unit test for script also meh good scaffold agree with take already get out of several jam at work definitely well than google frankly very reasonable price for anyone who use professionally for people who just use to generate meme student who want to cheat on homework less reasonable not think target market in case of cheat something actually want to avoid no not raise ethical concern literally to agree about usage about datum at least in europe should able to opt out of everything want should know rule of game just cause not read term of agreement not make unethical for company to read datum sure use for insurance not help cause become sick whp another thing not act surprised remove use api for around per request with down time with current usage sum up to around day per month not see how reasonable just read edit about gdpr explicit consent in europe should able to opt out of everything want great point wonder how openai react people want to remove datum even possible remove pay premium for nice ui not chatgpt more advanced than davinci model available through api in any case point use for work negligible compare to time save know dataset train on even just really hate how reply return in ui even subscription solve random interruption during generation word by word printing kill rather wait bit receive answer in one piece think not actually notice any difference other than how davinci model not extensive content filter use for work negligible company pay for sure otherwise always prefer request base pricing with nice api just call from terminal not believe disclose datum on which train chatgpt know mind share much prefer to see token generate much well ux abort generation feel not go in right direction all integration use stream true display every word come in chatgpt use search dataset use google full transparency find text by yourself maybe ask remove first of all datum only use for stachastic gradient descent model no idea about content read only model probability of word learn to speak only speak such mostly output what make sence in bayesian way model already train not even read all of datum huge model often only read each instance of sample once at maximum since learn well also in law text write understand opt out in future not make past datum processing wrong model already train not to remove anything also mostly whole ethic chapter in paper maybe go check out ethic etc not smth unknow especially such big company also some people work on in team even full transparency not mean gdpr complient try to look more into not successfull well thing not first one to think about for very long already know what legal here not waste million in training just to throw away afterwards yeah sure not kappa",
  "for each such assignment unique optimum for mu k interpret follow fix indicator variable r nk loss function function of k mean mu k exercise say loss function with fix r nk unique optimum in term of mu k indeed optimum compute analytically by equate gradient to zero vector solve for mus however what k mean really optimize loss function of all r nk mu k n k k variable majority of which discrete now function wild many local optima similarly to likelihood for gaussian mixture model thus k mean algorithm only find local optimum in fact run multiple time give same datum likely to get different cluster assignment different cluster mean happen algorithm initialize randomly each such initial point lead to different local optimum thank for reply since partition datum of cardinality n into k cluster result in k n partition right to say exist k n combination of assignment in case r nk mu k jointly consequently exist global optimum inside to solve use brute force however function in itself many local minimum function of both assignment r nk mu k to add markdown syntax for readability yeah sound reasonable think paper propose algorithm for find global optimum for k means in polynomial time should possible to find global optimum in case however not think many practical implementation actually",
  "problem define solve with single line of code r more generally time series discord use for very similar problem s with great success time series discord ultra fast only one simple parameter to adjust d find follow useful r video of talk irrational exuberance why should not believe of paper on time series anomaly detection r paper current time series anomaly detection benchmark flawed create illusion of progress r r r r r renjie wu eamonn j current time series anomaly detection benchmark flawed create illusion of progress extend abstract icde d very similar look at figure of merlin on phone please forgive format here how build model group speed by day of week hour of day test to make sure datum normally distribute guess assume pass normalcy test calculate mean std in each group categorize any speed below std of mean outlier finally look for cluster of low speed to build up outlier interval look into functional datum analysis instead of time series",
  "none of model list instruction tune no surprise perform well some well model gpt jt flan probably good in term of open source model right now maybe opt iml surprised at how much well davinci perform compare to model jurassic seem to comparable to davinci on which task of course not expect small model to on par with gpt read tianyi zhang faisal ladhak esin durmus percy liang kathleen mckeown tatsunori b hashimoto benchmarke large language model for news summarization arxiv find instruction tuning not model size key to llm zero shot summarization capability mean only well fund corporation able to train general purpose llm no just always couple year ahead not just thing with language model even ml like with many technology think open source implementation eventually get probably need much more multi task rlhf datum little code in initial pre training training gpt like model like recipe formula ingredient gradually become available jurassic seem to comparable to davinci actually compliment to since fine tune from original davinci on human feedback over generation well comparison with plain davinci expect to well to significantly well latter train with rlhf currently no open source rlhf model to compete with davinci change in to offer free service pay by ad sell result training datum to big corps in exponential future model from big corp feel like light year beyond open model resource always large keep accelerate fast on exponential curve resource always large keep accelerate fast on exponential curve sure more money to throw at problem also more incentive to throw money into other money make stuff open source model not necessarily go same path even under train less optimize still tremendous help once community get to play with",
  "hate to to in position answer to all question tyes yes ta lot tye very fwiw colleague of mine work on also hit some hiccup ve point to thread not answer hope for very helpful any code repo to share only able to find distilbert implementation in apple repo like to see some other example please elaborate answer quantify m most interested in effort for bullet in own experience take hour day week for someone who simply want to use ane not buy just consider for test out bare bone model locally find remotely debug quite frustrating for research purpose before finally train on cloud how good support with containerization solution like singularity even leverage ane know speedup not really anything drastic help fast more resource efficient than cpu gpu just translate to low time to iterate anyways for someone use plain pytorch w bell whistle how much of pain look forward to hear experience second",
  "in context of linear regression leverage point exert lot of leverage pull on slope of good fit line in other context probably want to describe point outlier decision tree highly susceptible to outlier random forest gbm more robust to outlier neural network also sensitive to outlier improve robustness in couple of way first definitely want to scale center datum second want to consider regularization like datum augmentation snapshot ensemble",
  "not see prompt construction obviate need for code skill even prompt improve still think go to want knowledgeable human to review script before use in critical app think tool like gpt rapidly speed up prototype eliminate boilerplate dev for most engineer say model apis strike much more likely disruptor of workaday software dev prove themselves out just make financial sense for firm to few people create bespoke model vs pull stuff off shelf modify need in world datum science largely become orchestration task with ml op data engineering understanding of business need available datum translate into ml pipeline creation to solve problem people work directly on model creation from scratch mostly academic highly skilled cs stat math phds work at handful of large tech company model api firm seem like most probable future to almost every innovation in tech go route eventually basically task not require deep understanding of business need subject to commoditization in ten year year ago deep learning not even exist field back tempt recommend caution in predict future of field go from non existence to near dominance within its profession in last year for last freakin time llm not all end all of machine learn dl role only exist for like decade machine learn engineer continue to in demand though require skill change make bet in to not learn any more on how to fiddle with nn architecture pay off now just send datum to huggingface api figure out rest what change what thought all well identify problem become rat race metric put on engineer optimize away comfort of know what well define metric pay for in anxiety of rat race of everyone optimize same metric what with work on problem not well define metric work with people work with real world work with thing defy quantification difficult to reduce to mere number everyone agree on way some longevity in field think road to trust ai go to long even great ai useless unless verify align with intention truth go to see lot of work around vager guess most dl application not really make use of language model tye cost of say model make infeasible for many application look like something not start prepare for right now lot of not invent yet off shelf stuff now easy enough model api for bunch of use case not know what mean expect llm to change well autocomplete well search maybe not seem like fundamental change llma see outdate already okay bite vast majority of code datum ingestion mooel discovery training currently all go away job become much more interesting researcher try understand why certain architecture training regime unable to perform certain task also think architecture for some fundamental task like computer vision audio go to become modular whole training model end to end go to verboten deep learning role year ago in pretty similar to what look like now except much more numerous now sure some change proliferation of more entry level role neural network technician role not go to different expect lot of work around regulation like probably formal qualification requirement emerge for who tell legal jury how to interpret behavior of ml model practice of who develop in other word dl lawyer lawyer get themselves automate out of case human involve only in dl trial llm settle everything else from tax fraud to parking ticket want to appeal verdict of llm need dl lawyer code automate really question of how much good code to learn from out book movie music vr experience prompt maybe even psychoactive substance generate synthesize from prompt dl lawyer sign off ml for write value word cheap attention scarce write in short form valuable real question who go to to each other even more importantly to kid up to age delete maybe resource hungry industry occupie of world energy not job for human at point in year not sure need human at all let alone dl specialist look at progress curve hop skip jump from einstein in every home deep learning exist field in speech recognition community already adopt deep learning by point brain team at google already exist microsoft ibm google all use deep learning academic subfield researcher start to coalesce around deep learning brand in certainly very niche at point agree everyone should take prediction with huge grain of salt obviously some clever person find way to make open chatgpt on mobile only hope however seem like conversation worth since llm appear to massive impact across many area at once already find lot of insight here interesting even say neural network not all end all of machine learn ha all people useless walk talk gai human form completely useless like to buy some punctuation alex quote unreadable bet ask chatgpt to improve though lol solve problem by solve for nuclear fusion everybody get energy oprah say delete even say machine learning not all end all of solve problem with datum actually say opposite ais need human validation to anything of value generate ton of text image without manually check useless work around ais say turning point publish first successful large vocabulary result with deep acoustic model in april base on work conduct over summer of publish paper mention to recognize technique new standard in top speech recognition group regardless deep learning role in tech company in just not very many of compare to today",
  "find relevant code at all code implementation here opt out from receive code link dm not get why graph nn not attract more attention tbh eliu plz thank for share well consider fact every transformer base on self attention which type of gnn say get quite bit of attention no pun intend in sense yes indeed for who curious check out blogpost from transformer graph neural network explore connection between transformer model such gpt other llm for natural language processing graph neural network now one of top most read article on gradient feature in coursework at cambridge stanford etc damn no idea thank now go read paper",
  "mostly language model imagen use xxl billion parameter dall e use gpt presumably not much large variant use for chatgpt sd just use clip without anything else more sophisticated language model well image generation understand what want clip close to use bag of word pixel vs latent much small model imo result much low quality however fact run on pc mean tweak all setting many go at get well result partially offset exactly entire point of latent diffusion model to make small fast also able to easily fine tune model make gen on particular subject high quality than what get on anything else not fine tune except dall e also apply diffusion in latent space imagen perform diffusion in low re pixel space initial hunch upscale diffusion model account for relatively small portion of total number of parameter more relevant speed wise lackluster explanation simply sd latent well since need to extensive ablation study to compare rather different architecture dall e also apply diffusion in latent space not really in important part use diffusion in clip latent space condition pixel diffusion model on result however still full diffusion pass in pixel space which more complex than in latent space ldms",
  "any application where need exact likelihood flow king such case for example jf learn sample distribution for mcmc sample estimate normalizing constant believe in physics lot of problem etc success with normalizing flow in problem where both direction of transformation important although presumably autoencoder work just well publish flow match for generative modeling introduce new simulation free approach for train continuous normalizing flow generalize probability path induce by simple diffusion process obtain state of art on imagenet in both nll fid among compete method abstract introduce new paradigm for generative modeling build on continuous normalizing flow cnfs allow to train cnfs at unprecedented scale specifically present notion of flow match fm simulation free approach for training cnfs base on regress vector field of fix conditional probability path flow matching compatible with general family of gaussian probability path for transform between noise data sample which subsume exist diffusion path specific instance interestingly find employ fm with diffusion path result in more robust stable alternative for train diffusion model furthermore flow matching open door to training cnfs with other non diffusion probability path instance of particular interest use optimal transport ot displacement interpolation to define conditional probability path path more efficient than diffusion path provide fast training sampling result in well generalization training cnfs use flow matching on imagenet lead to state of art performance in term of both likelihood sample quality allow fast reliable sample generation use off shelf numerical ode solver recently find paper from blei lab use nf to learn klpq instead of klqp variational inference what other commenter refer to afraid not what r interested in apart from last sota remember glow apply application wise human pose regression with residual log likelihood estimation learn error distribution use normalizing flow technique fill large performance gap between regression heat map method only very little research nice theoretical idea concept very constraining numerical difficulty make experiment hell not aware of any active research think never really big to begin with use nfs to estimate d of datum achieve sota result for very high dimensional datum where classical near neighbor method fail intrinsic dimensionality estimation use normalizing flow exact likelihood what attract to normalize flow once soon find hard to train to yield any useful likelihood bijectivity constraint mean latent space just large datum space seem like much of restriction in practice for application switch to variational model just accept only get low bound on likelihood get far in end diffusion model more modern option in regard well aware of any application where people actually use nfs for likelihood aware of some research paper say experiment much of contrive example to convince ever find its way into actual application diffusion model also generate exact likelihood maybe see shift to in future link for sound very relevant to what work on perfectly well reverse kl with diffusion model see here see comment for flow use alternative for abc trick how get away with gradually expand latent dimension with normalising flow assume dimension independent to certain point sample from base distribution concatenate in middle of flow again mcmc sample simulation base inference example imagine energy function describe distribution not datum how sample from distribution some mcmc how arrive to good proposal distribution to make mcmc algorithm more efficient fit proposal base on some limited datum inductive bias such certain invariance etc in science physics flow dominant tool for simulation base inference alternative lengthy rejection sample diffusion base model make entrance in area well not well understand for practitioner to switch in theory yes in practice not exact approximate via trace estimator ode solver score climb part come from hey thank for reference let take look problem with diffusion from sde view still not exact likelihood again not compute exact jacobian to make tractable ode solve error people mostly resolve to hutchinson trace estimator otherwise expensive to compute not think diffusion in way go to enter mcmc world anytime soon thank some paper show diffusion work well for high dimensional datum in likelihood free inference even just use elbo bind dig up later want fully agree from technical perspective with difference at good only get likelihood under model of choice happen to bad model of reality which argue case more often than not with nfs well off just use some approximate likelihood elbo of more powerful model not expert in mcmc model talk out of depth here mainly use model for map estimation interested in yes indeed model bad at model datum not much use in compute likelihood want to just sample image look cool not care much about likelihood however certain use case where care about exact likelihood estimate normalizing constant provide guarantee for mcmc grant always run mcmc with something close to proposal distribution however obtain nice guarantee on convergence mix time correctness difficult not know how suppose to use proposal for which not evaluate likelihood similarly talk about importance sample only obtain correct weight correct likelihood otherwise approximate not just in model also in estimator way see at least sure to read aforementioned paper also not sure how much lower bind hurt in estimation here one use gan not use explicit workshop paper apply score base"
]