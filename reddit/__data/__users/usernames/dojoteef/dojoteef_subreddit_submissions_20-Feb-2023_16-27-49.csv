created_unix_utc,created_pst,username,subreddit,id,title,body,num_comments,submission_comments,reddit_permalink
1672974372.0,05-Jan-2023 19:06:12,dojoteef,MachineLearning,104ixvi,[R] Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers,,15,"['dojoteef: They also have a demo website:\n\nhttps://valle-demo.github.io/', 'BookPrudent360: I would have never thought I would see TTS as realistic as this in my lifetime. This, oddly enough, terrifies and amuses me at the same time.', 'msbeaute00000001: The models are trained using 16 NVIDIA TESLA V100 32GB GPUs with a batch size of 6k acoustic tokens per GPU for 800k steps. We optimize the models with the AdamW optimizer, warm up the learning rate for the first 32k updates to a peak of 5 Ã— 10âˆ’4, and then linear decay it. => No hope to train this one.', 'Caldoe: Wow, This is going to enable so many authors to create audiobooks , as well as YouTubers and creators\n\nAlso, those reddit narration accounts on TikTok are gonna sound like podcasts XD', ""GoogleIsYourFrenemy: o_o that's like 95% of the way there!\n\nWe are rapidly approaching a point where AIs will pass the Turing Test consistently. This will only help with that.\n\nI can totally see this being used for telemarketing :("", 'artsybashev: $50/hour from aws on-demand. If it takes 1 second per step, it would cost about $11k. Steps per seconds vary depending on the model. Usually my models have been much faster. Might be just $1k if it trains 10 steps/s.\n\nExpensive if you just want to play around. For a company, if you have a business case, it can easily be be worth it. Azure probably gives this as a service for relatively cheap soon.', 'artsybashev: Vast.ai has 10 x V100 for $3.192/hr. You would need to scale down the tokens per step and increase the steps, but using this machine would probably give you the model for about $1k.', 'msbeaute00000001: > V100 for $3.192/hr. You would need to scale down the tokens per step and increase the steps, but using this machine would probably give you the model for about $1k.\n\nYep, to play ground, I just hope they could share the trained model so I can finetune on this based on my budget.', 'mr_birrd: Meanwhile me training on 8 rtx titan for 6 days xontinuous already on my uni cluster for a 6 creds project now noticing how expensive that actually isðŸ˜…', 'artsybashev: That explains the student debt ðŸ˜†', 'mr_birrd: no dept I am from Europe', 'artsybashev: Ok. That explains the high taxes ðŸ˜†', 'MrHumun: Just opensource code please :)', 'mr_birrd: Sure if anyone is actually interested, noone stars my projects so:D']",https://arxiv.org/abs/2301.02111
1661987610.0,31-Aug-2022 16:13:30,dojoteef,MachineLearning,x2ro5v,US Gov imposes export requirements on NVIDIA A100s and future H100s to China and Russia,"According to this [SEC filing](https://www.sec.gov/ix?doc=/Archives/edgar/data/1045810/000104581022000146/nvda-20220826.htm), the US government has instituted a new license requirement for exports to China or Russia of any NVIDIA GPUs that are as good or better than the A100.

The motivation is supposedly to prevent possible military uses. Seems the collateral damage could be a blow to Chinese ML research moving forward, considering the massive reliance on NVIDIA GPUs currently:

>	The Companyâ€™s outlook for its third fiscal quarter provided on August 24, 2022 included approximately $400 million in potential sales to China which may be subject to the new license requirement if customers do not want to purchase the Companyâ€™s alternative product offerings or if the USG does not grant licenses in a timely manner or denies licenses to significant customers.",190,"[""Puzzled-Bite-8467: How is this going to be enforced on the second hand market? What's stopping GPU hoarders from reselling in China?\n\nMaybe Chinese cloud providers won't offer A100 but the military can just go shopping on Amazon and bring a thousand cards home.\n\nWhat about a Chinese company located in overseas?"", ""Southern-Trip-1102: They knew this and have been developing their own domestic alternatives for a while. Unfortunately I don't think we allow them to be sold here.\n\n[https://www.tomshardware.com/news/first-wholly-domestic-chinese-GPU-graphics-card](https://www.tomshardware.com/news/first-wholly-domestic-chinese-GPU-graphics-card)\n\n&#x200B;\n\n[https://www.scmp.com/news/china/science/article/3188578/chinese-tech-firm-launches-gpu-chip-it-claims-marks-new-era](https://www.scmp.com/news/china/science/article/3188578/chinese-tech-firm-launches-gpu-chip-it-claims-marks-new-era)"", ""SirReal14: Hopefully this means we get interesting new accelerator chips that break Nvidia's monopoly in the ML space."", 'UncannyRobotPodcast: I assumed they were manufactured in China. Are they not?', 'schwagggg: new cold war shit. nice. \n\nnobody in either country will really benefit from it, but the politician will keep fanning the nationalistic narrative so both side feels itâ€™s ok to do this stupid shit.', 'aSlouchingStatue: And they laughed at me in college when I suggested AI software and hardware would someday soon be regulated as munitions. Ha HA!', 'gwern: https://www.reuters.com/technology/nvidia-says-us-has-imposed-new-license-requirement-future-exports-china-2022-08-31/\n\nRemarkably naked geopolitics here. What is the connection between shipping an H100 months or years from now to China, and Soviet-era artillery shelling the Ukraine frontlines today? A subtle one, to be sure...\n\nThe second-order effects here would seem to confirm Chinese autarky and trends towards [secrecy](https://www.nextplatform.com/2021/10/26/china-has-already-reached-exascale-on-two-separate-systems/), and further, to shift power from Chinese academia/small businesses/hobbyists/general-public to Chinese bigtech and thus, the Chinese government. If you\'ve been following along, the big megacorps, especially in the wake of the attempted US execution of Huawei, have been developing their own DL ASICs for a while with an eye towards exactly this sort of scenario. (For example, ERNIE Titan is trained on not just Nvidia, but Huawei\'s [""Ascend 910 NPUs""](https://arxiv.org/pdf/2112.12731.pdf#page=8), which you are going to have to look up.) To give an analogy, it would be like if Americans or startups were forbidden to buy Nvidia, but Google could still make all the TPUs it wanted to. Google may not be better off in absolute terms, but it\'s definitely getting a big relative advantage over you or me, and that is convenient for the government - because it\'s a lot easier to control a single corporation than an entire society (particularly after Chinese bigtech cowing during Xi\'s techlash).', ""EasyMrB: I mean, can't they just switch to 3090s for similar workload results?"", 'gwern: HN: https://news.ycombinator.com/item?id=32669215', ""jdxyw: Can't usa gov invest more in their tech and education to make themself better? Always forbid, forbid, forbid. For china, yes, it would be a tough time in a short time. But for a long time, it will be a great change for local companies or universities. The same thing has happened many times in history. The GPS, Space Technology, J20 and ...., The USA forbid all of them. Guess what? Let's see what happens in five years."", 'None: All this time it was okay, and now suddenly limitations so they dont use it for military purposes lmao', 'klop2031: Maybe USA should invest more money in education...', 'irve: This is really bad for humans, considering what they do themselves to realize it cannot be allowed', ""skydivingdutch: Any chip with enough fp64 ALUs is subject to export control. This isn't anything new."", 'jamesvoltage: No wonder demand is so high on colab these days, this must explain the price increase', 'Ligeia_E: here we have an obvious roadblock done to the research community due to the ever ridiculous geo-politics and all the comment have to say is â€œhehe Chinaâ€. Truly one of the redditor moments.', 'kkngs: This is kinda late. China already purchased a huge portion of the Ampere class GPUs.', 'UpperCut95: No wonder China is contemplating to invade Taiwan, who is the manufacturer of Nvidia chips.', 'j_lyf: Chips are the new oil.\n\nIF you are an EE/CS student and not gunning for a job at NVIDIA, AMD or Tenstorrent, you are an idiot.', 'jms4607: USA! ðŸ‡ºðŸ‡¸ If China is truly a powerful country they should be able to figure out how to build them themselves.', ""PsychoComet: They have surprisingly advanced methods for stopping these kinds of things. Normal customs enforcement can prevent any volume enough to actually be serious. \n\nIf you're talking about illegal smuggling, then that's something different."", ""233lol: The military won't use Nvidia, don't you worry about the back door?"", 'utopiah: I imagine the same limitations would apply to cloud providers then.', 'Terkala: They simply cannot manufacture chips at the nanometer scale that Nvidia can. At best they can make chips that have parity with 2010 tech (and even that tech parity is disputed).\n\nAlso it\'s not wholly domestic if their fabrication step includes ""buy a precision laser from the Dutch (ASML lasers) for about a third the cost of the rest of the manufacturing process"".', 'Probono_Bonobo: That\'s a _really_ interesting thought. How feasible would that be, anyway? The last time I looked into ""CUDA, but for OpenGL"" was around 3 years ago and there wasn\'t a lot of optimism then that Tensorflow would be compatible with a generic GPU backend anytime in the near future.', 'xqzc: Monopoly? What about TPUs?', 'MrHyperbowl: They would also be blocked though, no?', 'wise0807: To me the point is why is the US starting this trade war with China? It seems like there are forces at play that want to be aggressive with China seems unnecessary to me.', ""midasp: If it's developed in the West, it's just going to be blocked in China and Russia again."", 'xingx35: well maybe but this means the cost of every new ML chip will be significantly higher not being able to scale sales in china. larger companies will probably have an monopoly on ML infrastructure for a long time going forward.', 'jpapon: Theyâ€™re manufactured in Taiwan. Soâ€¦ sort of.\n\nEither way, controlling export from Taiwan to the mainland shouldnâ€™t be a problem.', 'pitrucha: Encryption used to be governed at federal level just 30 years ago. Releasing it open source was federal crime.', 'cderwin15: Some AI software was almost definitely already regulated as munitions when you were in college, it has been for at least the past 30 years', 'unicodemonkey: I suspect the pimary concern is with CUDA-accelerated physics simulations', ""1Second2Name5things: Yes and no. Even if we don't stop exporting high grade GPU's they will eventually try to make their own anyway. China will always try to capitalize on any market they can get their hands on."", ""Southern-Trip-1102: So you think china is going to control who can get compute and who can't? How would this serve them when they clearly want an AI edge, it makes no sense to suffocate their academia for this reason, and they aren't stupid either."", 'antimornings: A100 (and H100, but I know less about it) is in a whole different league from 3090s or any consumer gaming GPU. Just look up the specs and benchmarks. One was designed for large-scale deep learning workloads (think large language model, text-to-image models), the other primarily gaming but works decently for middle-sized deep learning (individual research projects etc). Industry and government data centers are not going to be stacking gaming GPUs for their projects, they will buy data center-grade GPUs like A100s/A6000s.', 'wen_mars: Yes. I think this is more about blocking them from future generations of AI chips.', ""Strange_Finding_8425: Well the US pours Billions into R&D and China just steals that hardwork so I don't know what you're talking about here but China isn't the victim, lol No one knows how to play dirty than the US ðŸ˜‚"", 'mongoosefist: Porque no los dos?\n\nI think restricting cutting edge technology to autocratic countries that are currently committing genocides and threatening democratic and independent nations is generally a good idea.\n\nBut also education good.', 'sanxiyn: Which one was subject to export control before this?', 'zoru22: lol', 'First_in_Asa: Itâ€™s never enough though, tech is always consuming it seems like wouldnâ€™t you say?', ""utopiah: I doubt that'd solve anything. TSMC can just open the door making current fabs useless."", ""ILikeLeptons: Normal customs can't stop drug smuggling; why do you think it can stop chip smuggling?"", ""Puzzled-Bite-8467: customs enforcement, do they really have time to check if it's A100 or 3090?\n\nAlso you can buy the card in India or Vietnam are they as strict?"", ""Puzzled-Bite-8467: If it's airgapped backdoor is kind of useless."", 'nikshdev: Amazon was mentioned as an online store, not a cloud provider.', 'None: Isnâ€™t this one reason why the want control over Taiwan?', 'Southern-Trip-1102: Not yet, [https://www.scmp.com/tech/big-tech/article/3190590/chinas-top-chip-maker-smic-achieves-7-nm-tech-breakthrough-par-intel](https://www.scmp.com/tech/big-tech/article/3190590/chinas-top-chip-maker-smic-achieves-7-nm-tech-breakthrough-par-intel)\n\nTrue, though a government sponsored company of theirs called dongfang is working on eliminating reliance on ASML.', ""mano-vijnana: Nvidia itself does not make the chips. And I don't think this agreement stops China from buying chips, unless I'm mistaken--just the cards."", 'estjol: Nvidia does not manufacture chips, intel, samsung and tsmc do. China are already producing chips with tsmc. Notable companies are mediatek, hisilicon. and tsmc is the most advanced fab.', ""Tripanes: > They simply cannot manufacture chips at the nanometer scale that Nvidia can\n\nNvidia can't make shit.  They buy nodes from the Taiwanese plants just like Chinese companies can."", 'todeedee: People still use TF?\n\nCheck ROCm : there is some support to run Pytorch on AMD\n\nhttps://rocmdocs.amd.com/en/latest/Deep\\_learning/Deep-learning.html', 'sanxiyn: Note that TensorFlow.js works today. This feels strange, but in fact WebGL is the most portable form of OpenGL, so using a web environment is a good way to implement a generic GPU backend. It will probably accelerate your model on your AMD card without any problems.\n\nJavaScript is not the fastest language, but JavaScript is faster than Python, and computational kernels all run in GPU anyway.', 'zepert: They will offer better salaries to Chinese Nationals who are already working at Nvidia. Btw, this has been going on for years.', 'Brusanan: Mostly because of the legitimate fear that the US could be at war with China over Taiwan in the near future.', ""wallagrargh: Waning empire struggling to stay on top. It's historically never a peaceful process and it will affect many issues in this decade."", 'new_name_who_dis_: > Theyâ€™re manufactured in Taiwan. So~~â€¦ sort of.~~ no\n\nFixed it for you!', 'IAmBecomeBorg: So no, they are not manufactured in the PRC.', 'panzerboye: >Theyâ€™re manufactured in Taiwan. Soâ€¦ sort of.\n\nEhhhh', ""symmetry81: Wouldn't they be targeting AMD cards if they were worried about physics simulations?  While NVidia has been putting more silicon into low precision throughput AMD has been putting more into high precision throughput."", 'AluminiumSandworm: not sure china will be able to build their own any time soon. basically no one is able to compete with taiwanese lithography', ""gwern: > So you think china is going to control who can get compute and who can't?\n\nIf by 'China' you mean 'bigtech and the central government', they sure are. They aren't even going to have to try, it's just inherent to fixed costs that the richest and most powerful unitary actors are better able to pay those costs. If you are rich and well-connected and can finance the lobbying and guanxi and paperwork, you'll be able to get access to compute, one way or another, while the small guys can no longer click 'buy' on nvidia.com or just negotiate their usual datacenter orders and will pay higher costs or go without. It's the same reason why things like GDPR always wind up hurting FANG less than the activists expect (and hurt small actors like NGOs or startups much more), why 'regulatory capture' exists and why big actors often actively lobby for more regulation. It's going to be much harder and more expensive to get Nvidia GPUs or to get proprietary hardware (can *you* buy a TPU from Google? no, you cannot), therefore, small actors like hobbyists will be systematically disadvantaged and many priced out.\n\n> it makes no sense to suffocate their academia for this reason\n\nAgain, it's going to be inherent in the effects that academia will be disadvantaged without beginning extreme explicit counterbalancing efforts to subsidize them much more (which do not exist). The trends and incentives are already not in their favor, and this is true in the USA as well - even without any chip bans, academics complain about not getting enough compute and being left in the dust by industry. Plenty of people in the USA who aren't stupid either - and yet."", 'kkngs: Right. In addition to having either 40 or 80 GB of VRAM, that memory is also ECC protected, which is important for most data center applications. The cards themselves are also rated for more power draw, and are typically set up for passive cooling (cool air provided by the racks).', 'jdxyw: well, ""steal"" from where?  China how to steal something which doesn\'t exist in the US.  Would you please tell us what technology China stole from the USA? How, when, and where?', 'sirencow: So block the sales to Saudi Arabia and Qatar  and communist Vietnam too?', 'skydivingdutch: https://www.bis.doc.gov/index.php/documents/regulations-docs/2334-ccl3-8/file\n\nSection 3E002, page 57.', '_insomagent: You mean letting particles get into the air?', 'Thorusss: drugs are still more valuable per weight/volume than these cards', 'PsychoComet: Illegal smuggling is different like I said. But yes. In some contexts chips and gpus are as dangerous as nukes according to the US Gov', '_ajog: When Tencent is buying gallons of PCP with corporate dollars let me know', 'PsychoComet: TLDR: a similar way they stop anti-money laundering and terrorism funding.\n\nThis report is interesting and goes into more detail: https://cset.georgetown.edu/publication/securing-semiconductor-supply-chains/', ""utopiah: Ah my bad. Well same principle though, I imagine a store can't be used to bypass legal restriction."", ""utopiah: I think having machines from ASML, as TSMC is their biggest client, without their support wouldn't help much. Maybe for current tech but not next generation."", 'DarkWorld25: Lol no fabs are incredibly delicate and any conflict would destroy them almost immediately', ""DarkWorld25: SMEE is what you're looking for, not dongfang. No EUV yet but they have made DUV litho machines"", ""sambiak: Sadly for them, that isn't EUV. It is feasible to do 7nm on a previous generation lithography machine, but the yield is horrible. It just doesn't make any economic sense to manufacture 7nm on those machines."", ""whata_wonderful_day: I worked at asml, that ain't ever gonna happen."", 'Terkala: Well yeah, I meant the suppliers of Nvidia.\n\nAnd of course China can buy chips, just not the finished cards. For now. But many manufacturers are moving chip production outside of China because of industrial espionage concerns.', 'phantasma638: Mediatek is not from China. Itâ€™s a Taiwanese company', ""gwern: AMD/ROCm is no good for this purpose. OP didn't mention this but [Reuters did](https://www.reuters.com/technology/nvidia-says-us-has-imposed-new-license-requirement-future-exports-china-2022-08-31/) - AMD fabs at TSMC too and is also under export bans:\n\n>> Shares of Nvidia rival Advanced Micro Devices Inc (AMD.O) fell 3.7% after hours. An AMD spokesman told Reuters the company had received new license requirements that will stop its MI250 artificial intelligence chips from being exported to China but it believes its [older] MI100 chips will not be affected. AMD said it does not believe the new rules will have a material impact on its business.\n\nSo switching over to the AMD stack does Chinese users little good."", 'sabouleux: >\tPeople still use TF?\n\nMaybe in deployment, but research is largely PyTorch.', 'sanjuromack: Most of industry uses TensorFlow. ROCm support was added back in 2018: https://blog.tensorflow.org/2018/08/amd-rocm-gpu-support-for-tensorflow.html', ""waterdrinker103: Why wouldn't they?"", 'dails08: Not never; Graham Allison examines this in Destined for War about how China and the US can avoid war. Most, but not all, of the scenarios that you describe ended in war, so he looks at how the peaceful examples might be replicated.', 'dat_cosmo_cat: Or just an upstart Asian nation ignoring international rule. China seems much closer to WW2 era Japan (both in behavior and relative capability) than the U.S. is to say; post WW2 Britain --at least from a global perspective. That being said, a world war in the 21st century would be cataclysmic for civilization, and authoritarian govs are better positioned to leverage this fact to subvert international law than the West is to enforce it.', ""londons_explorer: See also:   The fall of the British Empire in the 20th century, The fall of the Portuguese Empire in the 19th century.\n\n\nNeither have ended well for those countries - they're now doing less well economically than their neighbours.    An ex-empire eventually ends up being deadweight."", 'stav_and_nick: Taiwan is the republic of China, claims to rightfully rule China, and agrees with the PRC that the island is part of China\n\nSeems like itâ€™s valid to say kinda to me', 'unicodemonkey: The article mentions certain AMD datacenter-class chips are also under export controls now.', 'Southern-Trip-1102: This for example, [https://www.tomshardware.com/news/first-wholly-domestic-chinese-GPU-graphics-card](https://www.tomshardware.com/news/first-wholly-domestic-chinese-GPU-graphics-card)', ""Southern-Trip-1102: They aren't just making specialized hardware for internal use, many companies in china are making stuff usable and purchasable by general academia."", ""wen_mars: I don't think it matters much for AI research"", 'Puzzled-Bite-8467: How hard would it be to make 4090 with double ecc ram? Nvidia makes double ram cards all the time like 3/6GB cards.\n\nAlso you maybe could get around ECC buy putting the card in a lead radiation blocking box.', 'Strange_Finding_8425: What doesn\'t exist? Most of the tech stolen are top secret so to the world it ""doesn\'t exist"" but to Chinese Hackers it does example is the development of the J-20 the Electro Optical Targeting system was stolen from Lockheed Martin through hacking. Why are you acting like I\'m Speaking alien language here Every Knows IP theft is no problem to China. https://www.sandboxx.us/blog/stolen-stealth-fighter-why-chinas-j-20-has-both-us-and-russian-dna/', ""mongoosefist: > communist Vietnam too\n\nThis is a weird one considering Vietnam isn't committing genocide or threatening other countries. But the other ones definitely."", 'NatoBoram: Why not?', 'utopiah: Yes.', ""ILikeLeptons: You just need the silicon, not the whole cards. China assembles electronics with foreign made chips quite well already. If they need it for defense, wouldn't they pay a higher price for them anyways?"", ""nikshdev: I think the author meant it's not a big problem to sneak several thousand GPUs through third-country firms or just private individuals if you have enough resources."", 'Puzzled-Bite-8467: Should all online retailers run a background check before selling GPUS?', 'EmbarrassedHelp: Taiwan has plans to destroy the fabs and related assets while extracting employees, if China invades. So, it seems unlikely China would get anything of use.', 'Southern-Trip-1102: Does SMEE have EUV cuz from what I read I had thought that dongfang was the one working on euv', 'Southern-Trip-1102: For consumer goods probably, but for the manufacture of military hardware where cost is less of an issue this works fine. Though I still think this shows their intent and ability to catch up.', ""florinandrei: > It just doesn't make any economic sense to manufacture 7nm on those machines.\n\nNational defense does not need to make economic sense."", ""whata_wonderful_day: u/Southern-Trip-1102 u/utopiah lithography tools are among the most complicated machines we've ever built. I worked there >10 years ago, and then it was DUV. For example, a DUV scanner stage can accelerate faster than a fighter jet, whilst also offering nanometre-level precision.\n\nNowadays, it's EUV. This is a whole new level of complexity, such a machine costs \\~10X more (250M as opposed to 25M). ASML's EUV development program is years late, and is one of the main reasons why Moore's Law has fallen. EUV machines are so difficult to build, that Canon and Nikon (only competitors for lithography tools) gave up. ASML is the sole supplier - Intel, Samsung and TSMC realised this fact and bought stakes in ASML.\n\nBack when I worked there, there were 7000 engineers just doing high level design and integration. Major components such as the optics assembly are subcontracted. E.g. Carl Zeiss does the optics. Another \\~20K people were employed at suppliers within a few hundred KM of the HQ. The company is now many times bigger than when I was there.\n\nIn summary, all the kings horses and men have taken over 15 years to get something built. Even with IP theft (which I agree is a very big concern), they ain't doing this. These machines are just so much more complicated than anything else that's ever been built, and the knowledge base is safe in the Netherlands & US. You can't build one of these machines just from the blueprints. Also not with the US blocking the supply chain (ASML bought Cymer, a California based laser supplier in order to get EUV on track)."", ""utopiah: I'm curious, that's also my (naive) intuition so without entering into detail what make you think so?\n\nI mean you have experience at ASML but not at the competition, so what makes you think they can not catch up?"", ""Southern-Trip-1102: And many engineers who like you worked at asml now work at dongfang. They also have strong government support, meaning they will probably do whatever it takes to do it, such as industrial espionage. If the manhattan project couldn't be kept safe then no way asml's tech will be kept safe."", 'sirencow: Not even many western engineers believed EUV was possible and look where we are. You should go back in time and read on EUV efforts in the 2000s and and how it was a colossal waste of time and money.', 'maxToTheJ: > Most of industry uses TensorFlow.\n\nIs that still true?', 'sirencow: ""It\'s your choice to go down fighting like Yugoslavia or peacefully like the Soviet Union but go down you will""', ""sfulgens: Hasn't claimed that since democratization, and won't formally renounce the claim because China says they'll see such a renunciation as a pro-independence provocation.\n\nSo no, Taiwan is a country separate from the PRC."", 'Rico_Stonks: You must be lost, hereâ€™s how to get back to r/sino', 'herro7: Isnâ€™t China just west Taiwan though?', ""symmetry81: Which article?  The SEC filing linked at the top didn't say anything about AMD.  I'd like to learn more though."", ""gwern: Sure, but some sales to academia in the future doesn't undo the overall net effect across the entire economy... I don't know how open any of these new chips will be - at least for the Ascend NPUs, all the English-language material seems to imply it's never sold as a consumer or low-end item, there is no price information and you either buy it as part of an entire Huawei stack or you use it via API etc. Even if Ascends are freely buyable on the open market just like Nvidia GPUs, it is still on net likely a move to much more proprietary chips: you are knocking out the major open supplier of chips, and whoever steps up to the plate is not guaranteed to be as open as Nvidia was, while most of the obvious suspects will want to take a hyperscaler/FANG approach to vertically integrate and own the ecosystem. So you should expect the net effect to be enclosure."", 'NatoBoram: One could even speculate it would be better without ECC', 'jdxyw: greatï¼Œyou mention j20. Since usa think china steal technology like j20, I think usa must can make much much much much more advanced plane, better than j20. Btw, the first j20 was shown 10 years ago. Anyway,you can still keep it in your mind that china keep stealing thing from usa. You know what, such opinion wouldnâ€™t hurt china from a long term viewpoint, but would hurt usa itself.', 'sirencow: So they are a good authoritarian, totalitarian communist dictatorship?', 'only_4kids: Yes, but how will you run that chip? It\'s not just ""slap this chip on some pcb and it will run"". You still need proper support components and software that will know how to use all of that power in most effective way.', ""utopiah: Sure, North Korea manage to get tankers despite the embargo so it's definitely possible. Still it sends a signal and if restriction are applied and suppliers up that supply chain also face sanctions, doing so at scale becomes much harder, slower and costlier."", 'utopiah: This is not my expertise but I imagine that any business working for the military have to declare it so believe this could be done automatically.', 'Thorusss: That is believable, but still the first time I heard it. Do you have a source for this?', 'roofgram: Of course theyâ€™re not planning to, but in a conflict they would be a target.', ""DarkWorld25: No EUV (iirc they're working on it) but I would question whether a company that doesn't have DUV experience could successfully create an EUV litho machine."", 'utopiah: Is cost the main bottleneck or time and resources, especially in a very specific supply chain (as we can see here, it\'s not ""just"" the market, regulation does prevent potential alternatives), also important and might make, especially when laws get in the mix, practically impossible?', ""sirencow: You have a point but you need to understand that pushing the frontier is harder than playing catch up.\n\nThe Chinese know that it is technically possible and now it's a matter of devoting man hours to the task. It will not take long before they have a rudimentary EUV machine that can be improved with time.I give them 5 years. \n\nAgain with physical limit of chips approaching, it will be interesting to see where the industry goes after 1nm"", ""Southern-Trip-1102: I agree that the complexity of lithography technology is immense but I do not think that that will make it impossible for china to catch up. Sure you can't simply build one from the blueprints and need the actual people with the knowledge base. And that is exactly what they have been doing, the founder of dong fang was an ex asml employee and he potched other employees to dong fang. At the end of the day if you can't enforce IP, and you can't with nations like China, then it's always going to be a losing battle to stop the spread of technology, it's not a matter of if but of when."", ""utopiah: Thanks but again, and I'm mostly playing Devil's advocate here (as you can see from my comment history), that's showing the challenge from the ASML side but not necessarily how any of each of these specific difficulty is blocking for potential competition from China. It shows it's hard, very hard (if not the most complex technical endeavor on Earth) but not that it's infeasible."", ""That_Violinist_18: Is there a point where all this cost is no longer worth it? How small can nodes get before the effort is no longer worth it. Looks like it's getting rather close."", ""sirencow: -It's hard for me so it must be tough for everyone else.\n-The laws of physics only work in the West"", 'Terkala: The only people who think they can catch up, are basing that decision on politics rather than science and technical expertise.\n\nYou can\'t just hire a hundred engineers and say ""build me the most advanced machine in the world"". You need to build the tools, to build the tools, to build the machine. And all of it has to be done at a precision level that requires patience and extreme attention to detail. Which so far Chinese companies have been unable to demonstrate.', ""whata_wonderful_day: Source? To be clear, I'm talking mostly about EUV."", ""utopiah: Genuine question, what makes you think that the Manhattan project is on the same level of complexity than EUV and whatever ASML is working on?\n\nPS: as you mention dongfang, can their own numbers be trusted? As you mentioned in another post some things are clear, e.g precision, but others, e.g yield, can be faked so I'm wondering, as we read so much about China and its internal accountancy challenge."", 'whata_wonderful_day: I was there...', ""sanjuromack: I don't want to start a holy war, but TensorFlow is still very much in use across several industries. To be fair, most companies use a variety of models and frameworks.\n\nSome more notable logos and use cases: https://www.tensorflow.org/about/case-studies"", 'Appropriate_Ant_4629: > ... Most of industry ...\n\nDepends how you count.\n\nGoogle/Alphabet is still mostly TensorFlow (but even there, Jax momentum is growing), and depending on how you count, Alphabet alone(Google + Deep Mind + Kaggle + etc) might be big enough to ***be ""most""*** all by itself.  Outside of Google (and spin-offs from ex-google people), I personally think TensorFlow already lost.\n\nFor another metric where TensorFlow ""wins"" ""most""......  Running in the browser, tensorflow.js is still better than alternatives; so if you click on [any of these TensorFlow.js demos](https://www.tensorflow.org/js/demos), your browser/desktop/laptop/phone will add 1 to the number of TensorFlow deployments, making it ""the most"".', 'florinandrei: > peacefully like the Soviet Union\n\nSeems like they just repressed the conflict for a while.', ""schureedgood: Lol the claim is constitutional. Taiwan's territory claim is even bigger than the mainland. And both sides claim they are the rightful government of China. That's why there is a one china policy."", 'TanJeeSchuan: No no no, they belong in r/chunghwamingkuo', ""NatoBoram: No, it's the best China"", 'unicodemonkey: Ah, sorry, this link is from another thread https://www.reuters.com/technology/nvidia-says-us-has-imposed-new-license-requirement-future-exports-china-2022-08-31/', ""Southern-Trip-1102: I'm not too familiar with Huawei's NPU but the link i sent states that one of the GPUs made by that particular startup is meant for PC desktops. Its roughly equivalent to a 3060.\n\nSure their large tech companies would want to take that ecosystem ownership route but I doubt their government will allow it, their gov has not been kind to big tech in the past.\n\nAlso since when was NVIDIA an open supplier? They have been stubborn to provide even open source drivers and are practically a monopoly for academia here in the US."", 'RobbinDeBank: Authoritarian, yes, dictatorship, no. Itâ€™s only as authoritarian as singapore. Youâ€™re suggesting that the US should ban exports everywhere considered less â€œdemocraticâ€ than the US?', 'ILikeLeptons: gosh a state level actor like China could *never* assemble components on a printed circuit board and write software', ""Southern-Trip-1102: They have alot of ex asml employees so I think that's where they draw their knowledge base from."", 'Strange_Finding_8425: Not only that The chemical used and even the complex software required are all banned for export.\nhttps://www.technologyreview.com/2022/08/18/1058116/eda-software-us-china-chip-war/amp/', 'Southern-Trip-1102: Not sure what you mean but I would think that time and resources would be considered as part of the cost.', ""whata_wonderful_day: I 100% agree on the IP stuff. But this is such a large mountain to climb, even if they managed it will be decades. ASML is a $500B company now. I'll believe this is possible when some of the other prestige China projects, like building their own jetliner/engine work out."", 'Strange_Finding_8425: Yhep was gonna say this, China has be potching ex TSMC employees and current employee, one of SMICs executive was potched by a family friend who was working in TSMC at the time trying to catch up to intel hence why they were able to develop 7nm chips soo fast. China is were it the ppl they really need to get, money is no problem for China if they have to bribe Top Executives to get what they want they will and that\'s the problem. China has ""thousand talent plan"" a program to attract brilliant individual they would have gone to the US to China with huge financial reward to me in the end China will beat the US but it\'s gonna take time .https://en.m.wikipedia.org/wiki/Thousand_Talents_Plan', ""whata_wonderful_day: Sure, it's not infeasible, but nearly so. I'm trying to find words to convey how complicated and hard to build these machines are. Remember that ASML also isn't sitting still. It's a $500B company, that basically just makes these machines"", ""whata_wonderful_day: Good question - but people have been saying this for years. There are colossal amounts of money and smart people getting thrown at this problem, and my bet is that they'll keep making things smaller."", 'utopiah: Indeed, biases to highlight.', 'Southern-Trip-1102: ""Yu recruited engineers from the ASML division working on optical proximity correction (OPC) software. OPC software is a crucial part of lithography machines which shrink and print patterns of transistors onto silicon wafer that are then sliced into individual chips. According to Gartner, ASML controlled more than 90 percent of the $17.1 billion global lithography equipment market.\n\nDeparting employees told management that they would be working on unrelated projects. However, when ASML director of engineering, Song Lan resigned in August 2015, it was found that he had been working for both companies at the same time and had downloaded ASML files to a hard drive including source code that he took to his new employer.""\n\nhttps://www.datacenterdynamics.com/en/news/asml-engineer-who-fled-charges-of-stealing-chip-tech-is-living-comfortably-in-china-as-ceo-of-xtal-inc/\n\nThis is one source I could find quickly, there is a report with more info but I need to dig around for it again.', ""MemeBox: I know it's hard, but the Chinese are super smart and hardworking. They also know roughly how it should be done. Parity within a decade I think is likely."", ""Southern-Trip-1102: Oh EUV and the rest of ASMLs stuff is exponentially more complex but it's also far less secure than the Manhattan project.\n\nTheir goverment wants dongfang to work out, therr isn't much propaganda value in faking semi conductor manufacturing progress. If you just mean fraud well then idk since fraud is everywhere in the world"", 'czorio: Doesnâ€™t it generally end up in an ONNX runtime anyway?\n\nâ€” sincerely, a clueless research boy', 'florinandrei: What if you count by the number of jobs, which is the metric that matters for people in this field?', 'maxToTheJ: >  + Kaggle \n\nThere is nothing about Kaggle or Google Collab that prohibits the use of PyTorch or even really takes much on an opinion on it.', ""sfulgens: The claims are there because the government started out of the KMT which fought the CCP for control of what was formerly ruled by the Qing dynasty. Only one country intends to invade the other, and that's what matters. Not having a territory not actively claimed on the books. \n\n Presently, China's stance is the only reason there's a one China policy. Everyone except China would be ecstatic about Taiwan renouncing territorial claims and Taiwan being recognized as a free country."", ""gwern: Again, you are grasping at individual instances and not thinking about the overall effect. It is the overall impact on the entire economy that matters. The existence of one prototype GPU, with unknown DL performance or suitability for large AI research clusters of hundreds to thousands of GPU-equivalents, that may or may not someday actually materialize at an unknown price point with more or less availability, may be an achievement of the domestic chip industry (even if it was mostly pirated, as seems likely given how 'fast' it was developed), but does not change much about the effects of these export bans starting now.\n\n> Sure their large tech companies would want to take that ecosystem ownership route but I doubt their government will allow it, their gov has not been kind to big tech in the past.\n\nOf course they will. The problem with large tech and figures like Jack Ma from the standpoint of the CCCP is them getting too big for their britches, not them building technical stuff. You're not doing all that video surveillance, face recognition, and tracking on your home desktop GPU. You are doing it in the large datacenters funded by government contracts spending the endlessly expanding national security budget. They don't care if Huawei owns both the datacenter and 'NPU', they just care if the black cat catches mice and remembers who is the master."", ""mongoosefist: Don't feed the trolls. Just downvote and move on."", ""sirencow: Yes.. Isn't Biden all about values and human rights ? \nRemember he convened a summit of democracies an year ago"", ""only_4kids: I see you don't have experience in this field..."", 'Thorusss: China has huge chemical synthesis capacity. A lot of the ingredients for the big pharma companies come there.\n\nSo if they can acquire the knowledge, I have to doubt they can resynthesize everything they need.\n\nAnd software is A LOT easier to smuggle than an EUV fab', ""utopiah: It's distinct but if it's economical you can print money, or rely on investor trust, but if it's material, e.g chemicals or specific mirrors, then you might just be able to source it all or in sufficient quantity, same for time. Sure they are part of the total cost but there is a distinction between very slow, very expensive and impossible to acquire."", 'whata_wonderful_day: Well, nearly was a $500B company haha', 'Southern-Trip-1102: I suppose all we can do for now is wait and see. At the very least this will introduce some needed competition in the advanced lithography industry.', 'That_Violinist_18: But each shrink costs way more than the previous one, right?\n\nSo there would have to be a larger increase in the available market for the new shrink to make it worthwhile.', 'whata_wonderful_day: >58 min. ago  \n>  \n>""Yu recruited engineers from the ASML division working on optical proximity correction (OPC) software. OPC software is a crucial part of lithography machines which shrink and print patterns of transistors onto silicon wafer that are then sliced into individual chips. According to Gartner, ASML controlled more than 90 percent of the $17.1 billion global lithography equipment market.Departing employees told management that they would be working on unrelated projects. However, when ASML director of engineering, Song Lan resigned in August 2015, it was found that he had been working for both companies at the same time and had downloaded ASML files to a hard drive including source code that he took to his new employer.""\n\nIntriguing. I signed a pretty strong non-compete.', 'utopiah: I\'ve worked in China for a bit so I have no doubt they\'re smart and hardworking. I also don\'t think EUV is anything ""special"". Still, the fact that ASML is a global bottleneck, including for the US, makes me thing this is not trivial.', 'utopiah: > therr isn\'t much propaganda value in faking semi conductor manufacturing progress\n\nI\'d argue there is. I\'m not a China expert but from what I read there seems to be a persistent feeling of at least being as good as the ""West"" so if there can be showcase of appearing that they can remove any dependencies, especially in state of the art in high tech, then it has political value, despite potentially ridiculous costs.', 'sanjuromack: It really depends on the needs of the business. Who is running the model, what does their stack look like, how often are you running it? Heck, does ONNX have support for the ops you used in your model? Sometimes the juice just isnâ€™t worth the squeeze, and sticking a TF model behind a REST API in a container is the easiest way to integrate a new model into the existing stack.', 'Southern-Trip-1102: The issue is that you are assuming that they are going to go the route of compute gatekeeping. There are no indications that they are going in that direction. NVIDIA leaving simply means that they are going to be replaced by domestic alternatives, which has been shown to be the case in basically every market before. Plus there are a multitude of Chinese startups and corporations working on domestic gpu hardware, not just the large tech companies.\n\nThey have punished tech companies for acting as monopolies and generally desire to keep innovation going. Walled ecosystems and the suffocation of academia do not help gain an AI edge which is a widely known priority of their gov.', 'RobbinDeBank: Suddenly in an ML group and you bring up Biden this Biden that. That does kinda tell me who you are.', ""only_4kids: > And software is A LOT easier to smuggle...\n\nYes, but what to do with it? \n\nYou don't have source code, you don't have anything. You are literally just consumer of that chip and that's it."", 'Strange_Finding_8425: Japan is the sole Manufacturer of Chemical used to Treat Wafers sure they can replicate it with time, but Chemistry is tricky to get right .', ""Southern-Trip-1102: Oh I see what you mean. Given that the processes they are using are regular lithography, im ps not the new EUV stuff, I don't see why the materials would be hard to source rather they would just have to buy alot more due to low yield."", 'whata_wonderful_day: Yeah, time will tell', 'whata_wonderful_day: It does, but the semiconductor market grows very quickly. Also we could see chip prices go up, like what just happened during Corona. Personally I think chips are too cheap', 'Southern-Trip-1102: I doubt alot of them r planning on leaving China, they kinda stuck unless they want to get sued/jailed.', 'MemeBox: agreed', 'Southern-Trip-1102: Sure but I doubt most people just generally even know what lithography is. I think it would make sense to use so.ething more well known for propaganda.', 'krapht: Difficult to have a competitive domestic alternative without TSMC, though. This will set China back at least a decade.', ""Berzerka: You're acting like industrial espionage isn't a thing. Of course china has the source code."", 'squirdelmouse: If you read this thread through you can kinda see why that\'s helpful, the first response was ""China can just make their own"" which until people with actual knowledge of lithography stepped in held up pretty well...']",https://www.reddit.com/r/MachineLearning/comments/x2ro5v/us_gov_imposes_export_requirements_on_nvidia/
1654813452.0,09-Jun-2022 15:24:12,dojoteef,MachineLearning,v8smlm,[D] Request for moderators,"If you frequently visit r/ml throughout the day, have a good understanding of the field, and a history of constructive comments/posts, then we need your help as a moderator.

Please apply by sending us a [modmail](https://reddit.com/message/compose/?to=/r/MachineLearning) with the following info:

* Your role (engineer, student, researcher, self-taught, etc) and years of experience in ML
* Amount of time available to spend on the sub (you must check the sub quite regularly throughout the day)
* Your time zone

Weâ€™re specifically looking for friendly people that have at least a year or two of experience in ML who understand the current research and industry landscape and who have been on r/ml long enough to understand what the community expects in terms of moderation.

Thanks!",3,"[""Razcle: I'd be sort of interested in helping but I've been a member for some years now and feel that the tone and content has changed a lot in the last 1-2 years. It used to be the case that I came here for interesting discussions of papers and to find out about the latest research Nowadays I find that a lot of the page is dominated by simple applied work or discussions of side projects. \n\nPersonally I find the volume of beginner related questions and projects to have gone up a lot.  \n\n\nThere's nothing wrong with this change per se but I'm curious which of the two you're keener to encourage? Are you happy with the evolution and want to support it or are you trying to moderate back to more research heavy conversations?"", 'dojoteef: The sub is not purely research focused and hasnâ€™t ever been. Thatâ€™s why [tags were introduced](https://reddit.com/r/MachineLearning/comments/56hdqi/no_shirt_no_tags_no_service_posts_without/) for projects, news, and discussions in addition to research. You can always filter by tag.\n\nAnd there has long been a push to reduce beginner content (e.g. [2 yrs ago](https://reddit.com/r/MachineLearning/comments/co37ut/regarding_beginners_guides/), [5 yrs ago](https://reddit.com/r/MachineLearning/comments/4s175l/growing_pains_of_rmachinelearning_more_active/), [8 yrs ago](https://reddit.com/r/MachineLearning/comments/1zje5g/meta_questions_get_downvoted_in_this_sub_so_lets/)), which we try our best to enforce. For example in the last 24 hours the mods collectively removed 44 posts out of the 56 that were posted (most by the AutoModerator, but I alone removed 9 beginner posts).\n\nOf course, if you see content that you donâ€™t think belongs, feel free to report it.', 'Razcle: Thanks for clarifying! : )']",https://www.reddit.com/r/MachineLearning/comments/v8smlm/d_request_for_moderators/
1637188705.0,17-Nov-2021 14:38:25,dojoteef,compsci,qwavjv,UMass Amherst CS PhD Application Support Webinar,"Iâ€™m a 4th year CS PhD student at UMass Amherst. Last year, we started [a PhD student run program to provide guidance and support for people applying to CS PhD programs](https://paspumasscs.github.io/). Our program provides 1-on-1 support from a current PhD student to those who identify with a marginalized background (first gen, gender/sexual/racial/ethnic minority, etc). Quite a few other schools also began similar programs last year, but ours is one of the few programs that additionally provides a webinar **open to people of all backgrounds** where we share advice and answer questions from the audience.

Our last [webinar](https://umass-amherst.zoom.us/webinar/register/WN_iahy2XkaShG1-SNTlRflNw) for this yearâ€™s application cycle will be held this Friday, Nov 19th at 11am EST.

Please check out [our website](https://paspumasscs.github.io/) for more info about the program and the [webinar](https://umass-amherst.zoom.us/webinar/register/WN_iahy2XkaShG1-SNTlRflNw).

Good luck to everyone applying to CS PhD programs this year!",1,"['timee_bot: View in your timezone:  \n[Friday, Nov 19th at 11am EST][0]  \n\n[0]: https://timee.io/20211119T1600?tl=UMass%20Amherst%20CS%20PhD%20Application%20Support%20Webinar']",https://www.reddit.com/r/compsci/comments/qwavjv/umass_amherst_cs_phd_application_support_webinar/
1635899869.0,02-Nov-2021 17:37:49,dojoteef,MachineLearning,qlilnf,[N] Zillowâ€™s NN-based Zestimate Leads to Massive Losses in Home Flipping Business,"Zillow announced that they are [laying off a quarter of their workforce](https://www.cbsnews.com/news/zillow-layoffs-closing-zillow-offers-selling-homes/) due to a $420 million loss incurred by Zillow Offers, the home flipping arm of their business. The business model was reliant on [Zestimate](https://www.zillow.com/z/zestimate/), a neural network-based model that forecasts housing prices.

This seems like a colossal misstep on their part. It begs the question, how can other companies avoid a similar fate if they are making large gambles based on machine learning models predicting market movements? Additionally, how much should consumers rely on market predictions like Zestimate when making financial decisions (speaking as someone who recently bought a home and researched the market on Zillow during the process)?",189,"[""None: Man, that's one helluva plot twist. They used to really push (read: brag) about their Zestimate system and predictive competence. They also poured a lot of money into Kaggle competition(s)."", ""anonamen: Not an expert in Zillow, but have spent some time working on home price prediction.\n\nZestimates are often high at the worst times (for them). I'm sure their error-metrics are balanced overall, but whenever I've used them they skew high. Specifically, I think their apparent balanced errors come from under-valuing good houses and over-valuing bad ones by putting too much stock in paper features and geographic location (neighborhoods *are* geographic, but they're very irregular and the lines aren't immediately obvious, nor is there good data on the lines that matter).\n\nThe worst estimates I've seen are in areas I know the most about. Practical example. There's a house around where I live that's 20% cheaper than similar houses 1-2 blocks away from it. Saw it on Zillow and drove by it. Every piece of data I could think of would tell me to buy it. Problem is that it's right next to a road that, on paper, isn't that busy, but in practice is a major commuter artery. Loud as hell, crap place to live. A block into the neighborhood and the noise is barely noticeable. There's no data on stuff like this (at least not affordable data; satellites could be a solve, but expensive and hard to process). Zestimate had this house in the mid-high 900s. Sold in the low-800s, after months on the market. Comps from recent sales put it around 900. Recent similar tax assessments put it around a million. Don't know if it was a Zillow buy, but someone thought it was a good opportunity and took a 50k loss. \n\nEDIT: just looked this up again, because I was interested. Zestimate *still hasn't updated for the houses right next to it*. It just updated for that one house, because it sold, so now the model knows the value. But the fact that an almost literally identical house right next-door sold for far less than Zestimate though is apparently not weighted very highly in the Zestimate algo. That single comp, which is the only good data point, gets drowned out in the neighborhood averages.\n\nBack to the data. I suspect that Zestimate is built around several very good predictors (tax assessments, recent comparable sales, appraisals) that can be horribly misleading at really bad times. The model probably works best when every idiot knows that a house is good, and then the model ends up with a low prediction because those houses get bid up above the Zestimate. Houses that look good on paper but have big practical problems that aren't readily apparent show up as prime targets.\n\nFrom a practical perspective, it's hard to get around the local knowledge problem. Locally, real-estate markets are efficient. Local flippers and/or realtors will buy a good house if it's on the market for too long. Realtors know *everything.* So Zillow couldn't wait. Only way the system works is if they make quick decisions that are mostly better than local experts. Which is a tough ask, and they didn't come close. Honestly, they'd have done better financing local experts (probably realtors) in flipping opportunities and taking a cut of the profits."", ""jrkirby: There's part of this that's adversarial, which is where you need to be extra careful.\n\nThey're predicting the prices of homes right? And they give an offer to buy the home, really quickly using machine learning. What happens if they predict too low? Well, that's not a huge issue per se. Anybody trying to sell their house would see this estimate as too low, and then not sell to zillow. But what happens if the model predicts too high? Well, that's actually a very big deal. Well, someone if very likely to pursue that offer. So if they actually buy the house for too much money, then they lose a ton.\n\nSo the cost of prediction errors are very asymmetrical. And they're competing against other people's offers and knowledge to make a profit. So they don't just have to be accurate with their offers, they have to be *better than the competition* otherwise they won't purchase anything at a good price, and *everything they purchase they will lose money on*. Which seems to be what happened."", 'snorglus: I don\'t know the details of their ""Zestimate"", but this could be a simple case of not removing the market component.  \n\nIn quant finance, the most successful strategies bet on cross-sectional differences in values, after demeaning (or market-neutralizing).   The market component is basically the first principle component if you do PCA and often explains a *huge* amount of the variance.  Sure, you can predict it as well as any other asset, but it\'s equivalent a *single asset*, so to speak, so it\'s a low Sharpe ratio bet.   You want to bet on *relative* valuations of assets, ideally with the ability to either short assets or hedge out the market component, if you can\'t short.  So if there are 10,000 homes, you get 1 market component and 9,999 relative bets.   \n\nYou don\'t take a huge fucking bet on one god-damned principle component any more than you bet your entire life\'s savings on a single stock.  Amateurs!\n\nEdit:  I should point out that plenty of people hold S&P500 ETFs in their personal accounts (as do I), but we\'re holding for decades until retirement, so we\'re not too concerned about a low Sharpe ratio.', 'TerribleEntrepreneur: Ex-Zillow here. Zestimate and Zillow offers were actually separate due to some legal issues. They did want to try and combine them to create a better UX, but couldnâ€™t find a workaround.\n\nA lot of mistakes were made, and I really hope they create a public postmortem, but it wasnâ€™t the NN zestimate model that caused this.', 'BonkerBleedy: >  how can other companies avoid a similar fate if they are making large gambles based on machine learning models predicting market movements? \n\nInvest in explainable AI. Demand better reasoning than ""computer says buy"" and ""computer says sell"".', 'purplebrown_updown: Damn. Can we please find the details on what type of model, how they trained, and what was their validation? It should be a warning for others.', ""mettle: The obvious flaw is that they didn't look at a single house in person. So every house they won the bid, there was likely some off-the-listing issue depressing the other bids and every house they lost, the probably were missing on-the-ground info that indicated the house was more valuable."", 'ktpr: They didnâ€™t properly manage their exposure. Even at 99.9% accuracy you need to manage your potential losses smartly.', 'sansampersamp: [hmmm](https://i.redd.it/lum8l166abp71.jpg)', 'None: Got the PMI dropped on my home with the ""Zestimate"" argument.  \n\nLooking at home prices is complex as it gets for a ML Algo.  Multi-faceted, granular down to a case-by-case basis, and several established market intelligence firms have multi-billion dollar valuations for doing such work (CoreLogic, First American).  Zillow was bold, I think this is a great 500mm dollar lesson.  I\'m sure deep-pocketed investors will keep it chugging along.', ""edunuke: I don't think this is much of a NN issue but more of a risk quantification issue. Difficult to say as not much information was given but in general ML or DL are usually good at predicting general population behavior. However, at the tails, due sample size, things gets really bad."", ""badjezus: Really couldn't care. Corporate real estate investing needs to die. You wonder why housing is so expensive..."", 'None: Maybe donâ€™t use real money unless you know it works.', 'None: Real estate has always been a local business. Generalizing it (which is what ML does) is in my view just a very difficult proposition to begin with.', 'pinnr: First off itâ€™s unclear how much of the losses are attributable to pricing inaccuracies and how much of the losses are due to other factors. Perhaps one take away is that the expected benefit of your model needs to exceed the cost of developing, running, and executing the model. In this case executing the model involved not only expensive software engineers, but also realtors, lawyers, contractors, etc, so every transaction likely would need a large price benefit just to break even.\n\nSecondly the per-house loss is actually very consistent with Zillowâ€™s pre-pandemic performance, so perhaps it was less a model problem and more a problem that scaling up did not reduce their per-unit expenses as they had predicted.', 'dogs_like_me: I remember a recruiter reaching out to me a few years back who was hiring for that when it was greenfield. Feel like I dodged an embarrassing bullet.', ""smoke_carrot: > how can other companies avoid a similar fate if they are making large gambles based on machine learning models predicting market movements\n\nTreat it with skepticism, and continuously evaluate its predictions? If you're basing a billion-dollar business on it, it shouldn't be that hard to assemble a team that does just that."", 'farmingvillein: As a general statement--\n\nMost orgs that manage sizeable tail risk and/or do substantial financial engineering have to invest a lot in their people--be it cash, carry, or equity.  My guess is that Zillow wasn\'t paying top of market (it becomes organizationally hard to justify paying someone 7 figures when your baseline is much, much cheaper engineers who slam out ""just"" some SaaS code), and got burned in part for it.\n\nAnd/or if they were paying that, it becomes hard to organizationally hire the ""right"" people at those (comparatively, for the company) astronomical compensation ranges, when most people in your org are paid far less.\n\nI have no idea what their internal comp or capital structure was, but my guess is that they would have done better if they had engaged in a partnership with someone like Citadel or DE Shaw, and let them handle capital + data/market analytics, and Zillow handles data collection + distribution.  But someone probably tried to do this on the cheap, and they got burned.', ""maxwellsdemon45: It wasn't hard to figure out that their Zestimate was BS when the prediction was always just the asking price plus $1."", 'longgamma: I think the problem was that they rolled out too many offers?', 'timisis: Your post is a bit on the sensationalist side, but it all boils down to the same thing noted by several other comments. You can\'t predict the future. Corollary: nobody can save you, your doctors cannot save you, your police and armed forces and your mama cannot protect you, the President cannot figure out how to save the country.  All for the same reason: the existential threat is in the future!  Regardless if we have a PhD or cannot read and write, we\'ve all been feeding each other ""certainties"" for too long. It could be that the status quo is the lesser evil, in some sense. To paraphrase Bismarck, the people should not see how these 3 things are made: politics, sausages, and predictions!\n\nOn the positive side, Zillow is a great business that employs thousands, is worth billions and serves millions. Maybe they lacked something in ""antifragility engineering"", which they\'ve learned now. Maybe the fired staff that were busy ""predicting the future"" can step it up a notch and create it, perhaps work with autonomous vehicles and other robotics. Do not, I repeat do not predict the future. Live here now!', 'Weslyvanbaarsen: Seems like they forgot one of the key principles of forecasting. Forecasts are almost always wrong.', 'hetero_scedasticity: It might be interesting to note that they only began using the Zestimate as a live, initial offer *in February.*\n\n> As a result of the company\'s increasing confidence in Zestimate accuracy, in February Zillow began using the Zestimate as a live, initial cash offer through its home buying program, Zillow Offers.""\n\n[Link](https://www.prnewswire.com/news-releases/zillow-launches-new-neural-zestimate-yielding-major-accuracy-gains-301312541.html)', 'zhumao: hahaha, NN-based, no surprise there.', ""victotronics: I always thought their estimates were self-fullfilling prophecies. Good to know that for once I'm too cynical. Doesn't happen too often."", 'd84-n1nj4: Forecasting is hard.', 'None: [deleted]', ""Basil_A_Gigglesnort: In the hedonic pricing academic literature, almost all models used are spatial econometric models. I don't know the details of the NN model used by Zillow, but house prices are definitely spatially autocorrelated, ie, non iid."", 'None: woof this is a blow to trust in machine learning models', ""Nicolay77: I don't see why the blame should lie on the estimation model instead of on predatory business practices.\n\nWhen something is so 'successful', the market reacts against it, there's no model that can predict it."", 'None: this might hurt data science job prospects', 'FartyFingers: One of the things I love when companies like this go all in on ML is where cunning opponents realize that ML is often easily screwed with through ""adversarial"" means. \n\nFor example, it could be something like luxury homes often have a surplus of bathrooms. Thus you take some 2bed 1bath crap house that should be worth 200k and throw in 4 more bathrooms. Just stupid bathrooms that make no sense. Maybe just 4 side by side in stalls in the basement sort of stupid. But then the ML algo sees that and suddenly the house is ""worth"" 300k and boom.. Arbitrage. When the reality is that any human buyer would go ""WTF there are 4 4\'x4\' bathrooms in the basement?""\n\nAfter a while they learn that bathrooms need to be weighted differently but the adversarial types realize that dividing the garage in 2 (now smart cars only) gives you a 2 car garage for another 80k calculated value increase.\n\nI am willing to bet that if I had free access to probing the Zillow algos that I could recommend 20k worth of changes to a cheap house that might double or more its Zillow value. It might even be on a neighborhood level. You buy 30 houses in a derelict neighbourhood and then buy out a bar and a tattoo palace and replace them with a bridal shop and a coffee shop (that aren\'t viable businesses) and suddenly the value of your 30 houses all went up 25%. Then you do some straw buys where a few scattered houses transact for an ever growing increase in value (make it seem like the market is heating up). On top of that you do spend 5k on each house to get rid of some real heavily weighted negative factor like oil heating. Even though the reality of the neighbourhood is that it should be bulldozed and turned into a park is that the ML thinks it is a fantastic investment.\n\nIf I can come up with this in 4 minutes, real-estate vultures will have long figured this out and have been minting it for a while now.', 'cderwin15: New York investment funds have been making millions using deep learning for years.  This is a really bad fuck up involving a high profile use of ml but is not endemic of a larger problem.', 'None: [removed]', 'MoogTheDuck: >how can other companies avoid a similar fate\n\nThatâ€™sâ€¦ not really the important question here', 'alexpantex: Is it possible to find some representative data that they used for model training?', 'slowjetr: Looks like there program got backendtested.', ""Cholojuanito: Well if there's anything that I learned from my statistics classes it's that attempting to extrapolate (predict the future) is risky business. Sucks for the couple hundred employees that their leadership bet too much and now they get screwed for it."", ""amasterblaster: ah, concept drift. It's a real b\\*\\*\\*h"", 'big_black_doge: When I was buying my house, multiple realtors told me zillow estimates are generally overestimated or at least highly inaccurate. This comes at no surprise to me. Sounds like they ignored the warning signs.', 'None: Well thats what you get when you try to force NNs onto everything.... Why just why ....', ""andreichiffa: It is unsurprising. Housing market is notably irrational and prediction of the algorithms that will be used by byers/sellers (including the unconscious component) is task that's well beyond the capabilities of most ML models.\n\nAnd that before we start speaking about the halting problem (user using Zestimate to modify their bid, which in turn changes the Zestimate, which, ...)"", ""geneing: Most post miss major parts of the story. From what I've read, the major part of the business model was fixing up the houses they bought before flipping them. Most of the profit was to come from the difference in cost of repairs and higher selling price. \n\nFrom what articles reported, the real problem was in managing house repairs - hiring contractors, managing projects, etc. Especially with labor shortages and wild lumber prices."", 'None: I was sure they were doing what all the big boys are doing - buying up the real estate and then forcing it to go up by essentially creating a monopoly. But this high frequency real estate trading i am just shocked someone thought it would work.', ""_kernel_picnic_: Another variable is the seller can choose when to sell depending on the offer. Let's imagine Zillow models has perfect mean price, but high variance. Two houses on the market have actual price of 1m. Zillow estimates and offers 600k to the first house and 1400k to the second house. On paper, mean is still 1m. But first house chooses not to sell to Zillow, while second house does. Now, Zillow bought just a house #2 and overpayed 400k."", 'newbie_lurker: The problems underlying Zestimates and limiting their usefulness are not unique to Zillow--the whole real estate industry\'s approach is based on training neural nets on as many ""comparable"" property sales as they can, to the extent that the various companies have sued each other repeatedly over the similarity in methods.  Comparables are necessary but not sufficient to predict property value in markets where the demand profile is changing rapidly or the supply stock is changing dramatically (i.e. big migrations of different types of buyers and/or construction of specific types of properties that never existed in the local market before).  In these situations there simply won\'t be enough data to make an accurate prediction (as is the case when looking at more rural, sparsely settled areas).  But I strongly disagree with those who say this is why it\'s impossible to model such markets, or you need a realtor to guage the impact of micro-level property and neighborhood features for which you don\'t typically have data... those people are just as prone to misunderstanding the effects of such details as any model, and if anything subject to more cognitive biases.  The problem with the dominant industry approach is the general lack of theoretical understanding of real estate market economics that it reflects; throwing more data at a neural net isn\'t going to magically make your model understand how competitive bidding or segregation dynamics or bank finance affect property values.  It\'s one of many situations where a return (or at least a nod) to a more econometric approach would work better.', 'FartyFingers: Outside of Zillow investors and real-estate professionals is there anybody on this planet who is saddened by this news?\n\nDriving up the price of family homes. What a socially bankrupt business model.', 'Everlast7: Mistake is simple - why would you let our customers know the true value of their home?\nKeep this shit a secret and exploit the info by yourself, dumbasses â€¦', 'the_real_chuck_evans: Itâ€™s almost as if real estate isnâ€™t a commodity and every property is unique', ""jazmaan: Zillow's estimates almost always exceed Redfin's estimates by significant margins.  Redfin is also in the home buying business.   It remains to be seen if they will also pull back."", 'None: [deleted]', 'AuspiciousApple: Looking at the page, I find it odd that they report median error rates. Is that commonly done in some fields? I get that medians are robust etc. but if you make financial decisions you also do get the long tail of very bad errors so the mean error is more relevant.', ""coffeecoffeecoffeee: You'd think they could deemphasize the usefulness of the Zestimate for buying and flipping houses while emphasizing how useful it is for deciding how to price your house or what to charge for rent.  The score might not be useful for planning decades into the future, but it still seems quite useful for decision making based on the current state of the market.\n\nIIRC, their home flipping business was also pretty recent, and the Zestimate wasn't originally designed to help with it.  Seems like they should focus more on the Zestimate's original focus.  Also, I don't really have a sense of how their neural net model works compared to a non-NN model.  At a talk I went to at Zillow a few years ago, they indicated that it was some kind of stacked regression."", 'tristanjones: Their analyst interview process involved having you do property estimates. Lots of crowd sourcing to still end up here.', 'CheesingmyBrainsOut: > done better financing local experts (probably realtors) in flipping opportunities and taking a cut of the profits.\n\nTurn them into feature gatherers as well. Could create a massive labeled data set with features like noisy road, busy commuter road etc., And then eventually just deploy less costly feature gatherers and predict primarily based on that.', 'omniron: â€œNear a noisy roadâ€ is a simple enough feature for a neural net to learn though\n\nI think this was a human failure. Maybe a bad model, maybe bad training data, maybe bad interpretation of the model output', 'VipeholmsCola: Great post!', 'joshdick: Thatâ€™s known as the winnerâ€™s curse:\n\nhttps://en.wikipedia.org/wiki/Winner%27s_curse', ""None: This is a really cogent and incisive analysis of what could have happened to cause this. It's hard to imagine that no one at Zillow thought about this - did they just have so much confidence in their models they discounted the chance of this happening? Did they have some kind of manual or automated QMS for outgoing bids that totally failed? It's kind of nuts to not cut your losses before losing this much money. Heads must be rolling at the senior management level."", ""JustDoItPeople: >  Well, that's not a huge issue per se. Anybody trying to sell their house would see this estimate as too low, and then not sell to zillow. But what happens if the model predicts too high? Well, that's actually a very big deal.\n\nPeople have mentioned the winner's curse here which is true and the causal mechanism underlying this.\n\nThey could have partially gotten around this statistically though by changing the loss function; the loss of overprediction and underprediction need not be symmetric. Given that they're reported median errors, that doesn't sound like an asymmetric loss function to me."", 'marsten: The asymmetrical cost of valuation errors is an issue in a lot of industries.\n\nIt\'s a huge factor in the auto and homeowner insurance markets, for example. If each customer gets competitive quotes and decides based on price, then it tends to be the insurer most overly-optimistic about the person\'s risk level that gets the business.\n\nIn the auto insurance market, historically one route to profitability has been to specialize. For example Progressive (in the US) for many years specialized in ""bad"" drivers: People with records of traffic violations who pay a lot for insurance. By capturing most of this segment, Progressive gained an information advantage that allowed them to more accurately value these customers. In effect they figured out how to distinguish the truly bad drivers from the people who got unlucky a few times. You see similar specialty insurers for RVs, water craft, and so on, and as a general rule these are the most profitable insurers in the industry (but not necessarily the largest).\n\nAnother factor that may have hurt Zillow is that sellers don\'t approach you with uniform probability. Zillow\'s attraction is that it\'s easy for sellers: You get cash and don\'t have to deal with contingencies, repairs, staging, etc. Now as a seller if you know there is something about your house that will make a traditional sale complicated (say a hidden plumbing issue, or a building code violation), you\'ll be more likely to seek out Zillow Offers. It\'s the all-you-can-eat buffet restaurant problem: You tend to attract the sorts of customers that take advantage of what you\'re offering, at a cost to your profitability.', ""saksoz: This. They're not buying and selling houses, they're writing put options on houses."", ""farmingvillein: > You want to bet on relative valuations of assets, ideally with the ability to either short assets or hedge out the market component, if you can't short.\n\nYes but I don't think this option was really available to them.  This is hard to do for real estate in general, and hard to do as a public C corp as well.\n\nMore importantly, they were apparently dramatically (based on the scant public data reporting) overpaying for pretty much everything...so they may have even thought they were taking a bet on the most valuable homes, but it turned out they still dramatically overpriced."", ""35nakedshorts: This guy knows why coming up with a predictive signal is very different than making money trading that signal. I wonder how they could've hedged the market component. Maybe shorting publicly traded REITs."", ""Ocelotofdamage: The S&P 500 has a very good Sharpe ratio. You don't have to be able to short to have a good diversified portfolio."", 'dojoteef: Thatâ€™s an interesting tidbit. Thanks for sharing! Are you able to share any additional differences between the two forecasting models?', ""gwern: Thanks for the inside info. I look forward to reading in papers and media articles for the rest of my life how the collapse of Zillow proves how NNs don't work or we need further research on epistemic uncertainty & calibration (rather than what appears to be a much more mundane story of an inexperienced market-maker getting run over by a steamroller)..."", ""Cholojuanito: >but it wasnâ€™t the NN zestimate model that caused this.\n\nOh we know, it's definitely the executives and investors betting their money away because they know they won't suffer the consequences, the people under them will. So now hundreds of people are without jobs because senior members of Zillow didn't listen to common statistical sense, when you **extrapolate and predict the future you are playing a dangerous game.**"", 'maxToTheJ: Machine learning go brrrrr', ""at_least_: I live in an area where all the houses go for over asking price. There's 1 Zillow house that doesn't sell. They have lowered the price already several times. The floor plan is terrible, I don't know if they looked at that feature for example..."", 'TerribleEntrepreneur: The industry is rife with that. I just rented my house out to a rental-arbitrage tech company who signed a 24 month lease sight unseen. They were just going off a 2 year old listing for the property when they came up with the price.\n\nIt doesnâ€™t seem nearly as risky as what Zillow did, but still a problematic practice.', ""35nakedshorts: And this is what we call adverse selection. Even if their models could predict the correct home price on average, the houses that they actually own would be in the worst quantile of prediction error. They should've calculated pnl based on this and not the average error."", 'geeky_username: Like a human saying ""maybe we shouldn\'t pay top dollar during a once-in-a-century worldwide pandemic?""?', ""bin_und_zeit: Yeah this is 100% a fault of the business side of zillow. I don't care how well an algorithm / model does on a dataset, don't hedge a potential loss of $400m on it out of the gate."", ""bandrus5: I really thought they would succeed. It's a hard problem, but it seems to me like they've got the best possible training data available. If they couldn't do it then I'm not sure any end-to-end ML system can."", 'wymco: >Got the PMI dropped on my home with the ""Zestimate"" argument.\n\nPlease elaborate on this...I am thinking about getting a new assessment and use that to drop the pmi, but not really sure if the values will be close to each other (zillow vs assessment)', 'karmanye: Housing is artificially inflated due to financing via debt. If a 1% rise in interest rate can cause significant changes in the market, imagine what would happen if there were no loans whatsoever. Its almost as if it would become affordable for everyone again.\n\nI feel this is what we are seeing with higher education costs too.', ""Sam_Sanders_: We care because it's an interesting large-scale real-world case of failed machine learning on a sub called /r/MachineLearning. Not because we feel bad for Zillow."", 'bradygilg: At the same time though, the real estate agent business needs to die. What a huge community of middlemen.', ""SirReal14: I mean, this was a direct wealth transfer of $420m from Zillow shareholders to homeowners that sold their house to Zillow for an incorrectly too-high price, and also to the people buying the houses back from Zillow at (presumably) the correct, lower price. Seems like corporate real estate investing worked out for the little guy in this case lol. If you ignore the fact that there are ton's of small time investors in Zillow."", '-Rizhiy-: Housing is expensive because of policies which promote increasing housing prices.\n\nSaying housing is expensive because of corporate real estate investing is like saying that coke is expensive because of supermarkets.\n\nThe truth is that the majority of the voting population already own a home and will vote to keep the value of their homes increasing. Treating your home as an investment was the biggest scam sold to the public.', ""farmingvillein: I'm sure they backtested extensively.  Global pandemic + massive fed injection, however, was not a backtested event."", 'SkinnyJoshPeck: ML isnâ€™t generalizing it - theyâ€™re featurizing it. Chances are high that they donâ€™t have enough features in their model to safely predict prices. It was a fool errand with the data they have: case in point, 3 years ago I was offered a position doing Zestimate and I was like â€œwhat kind of data do you have?â€ And they were saying it was proprietary based on the expertise of the humans who give predictions as their training data. Yeah, their training data was features and prices from humans who chose them. \n\nCool idea, really lacking in features I imagine.', 'farmingvillein: > First off itâ€™s unclear how much of the losses are attributable to pricing inaccuracies and how much of the losses are due to other factors\n\nReporting states that they were demonstrably paying top dollar and then had to mark things down considerably from the purchase price (presumably after additional fixed cost investment), so pricing inaccuracies are almost certainly core to the store.', ""s0n0fagun: >Secondly the per-house loss is actually very consistent with Zillowâ€™s pre-pandemic performance, so perhaps it was less a model problem and more a problem that scaling up did not reduce their per-unit expenses as they had predicted.\n\nThis should be emphasized more and I believe the CEO they have a problem selling properties as quick as they are able to acquire them.  Most people don't want to buy a place sight unseen.  We still have supply chain problems and the housing market (new and existing) makes home ownership still tough. Their real estate acquisitions are not nearly as appealing as Sears real estate from an acquire and hold position."", 'farmingvillein: Maybe you could have saved them!', ""ChubbyC312: Zillow actually pays decently for DS, but obviously nowhere close to Citadel levels (and no one in tech can compete with HFT). Zillow TC is just a few percent away from FB/Amazon and is pretty much comparable to Goog. You do have an interesting idea either way - Citadel DS people I've worked with seem way more buttoned up than Z."", 'Thud2: For once you were *NOT* too cynical you mean.', 'None: >I for the life of me cannot understand how you lose on housing investments. HOUSING.\n\nBuy high sell low.', 'grizzli3k: And its not an average Joe who fucked it up. Freaking Zillow, they run a marketing platform for the love of God! Theyâ€™ve got the data, a shit ton of money, and a red hot market. Just unbelievable.', ""maxToTheJ: > There's also climate, immigration, nimbyism that can affect a house price\n\nRacism quantifying model would have helped. Oops I meant â€œkeeping a cohesive communityâ€ quantifying model"", 'fasttosmile: AFAIK coatue had a big fuckup a year or two ago', 'None: I highl doubt that they are simply trying to predict future stock prices or so by a nn.', 'dojoteef: Lots of interesting info. Thanks for sharing!', ""StephenSRMMartin: Yep.\nAlso why it's critically important for statistical theory and domain expertise to work in concert when building out models, assessing them, and making decisions under uncertainty (bayesian decision theory? Game theory too?)\n\nMachine learning is great. But you can't just build a super predictive model, if it doesn't have some design elements that make sense for the domain... Or if it can't quantify uncertainty, which is literally critical in decision making. (And no, an accuracy metric is not an uncertainty estimate, it itself is an estimate, with uncertainty, and it isn't coming with conditional predictions).\n\nUnfortunately, Zillow may have learned a very hard lesson, in a very hard way. I think more companies are (hopefully) coming around to the shocking notion that uncertainty quantification and statistical risk minimization is important too, when using big predictive models. Kill the point estimate, consider instead the whole random variable. Especially when you're betting millions."", ""whb90: As a non-American who used to live in the US, I would occasionally fantasize about moving back, and check Zillow listings. I noticed that the Zestimate is often a gross overstatement of the actual value of a property... Houses that are estimated at 800k, that are really no more than 300-400k. I thought it was just because, at the time (2-3 years ago), the ML algos weren't banking on as richly filled libraries yet, but now I'm starting to think, this should've been a sign."", ""marcus_hk: I wonder how much effect Zillow's overestimation has had on real prices. It would be nice if Zillow's current pain contributes to lower prices."", ""TotallyNotGunnar: Redfin in my area does well in the city and okay in towns. Their rural estimates are hit and miss though and it's obvious when a remodel or added feature isn't considered in their model.\n\nThe thing is, buyers are filtering their search by Redfin and Zillow estimates. A bad model will shift the perceived value of a house and therefore shift the actual value of the house once the shift plays out in the bids."", ""whymauri: I wonder how much money they threw into the market and if it could sway signal for certain markets. Isn't this a problem large investment funds run into? Running predictive models where your actions based on the model itself becomes an agent/influence at scale."", ""bigfish_in_smallpond: The only way that business model works is if they are offering well under the market value of the home and the buyer is taking them up on it for convenience of just being able to sell their home easily.\n\nBut from my own anecdotal use of the tool, they were basically giving a competitive offer on my house +/- 10K. So there is no way that works unless you are doing it on a massive scale and have completely optimized out all of the legal/real estate/legwork for buying/selling homes. \n\nAnd I don't see how you can do that without getting royally screwed with bad houses."", 'None: [deleted]', 'SnooHedgehogs7039: Exactly correct. I spent some time looking at house price predictions as part of our macro modelling. Our conclusion was within regime it was extremely doable. When the regime flipped though you got screwed. Itâ€™s also made worse by the fact governments often prop up housing markets that should be collapsing so you get screwed both ways.', 'sharadov: There is another angle to this - they usually do a quick renovation to the houses they buy before they flip them, but with a big uptick in costs of materials, supply chain delays, and a labor shortage they were not able to turn around the homes quickly enough. And ML models work based on the input parameters provided at run time, but when variables change in the future or new variables are introduced your predictions can go terribly askew.', 'maxToTheJ: Nah I donâ€™t believe that.\n\nThe problem was they didnâ€™t do Agile right and they should have had more advanced leetcode questions /sarcasm', 'Alimbiquated: Part of the fuel on the subprime mortgage fire was the claim that house prices ""never"" fall. ""Never"" meant not since the Great Depression.\n\nAssuming that is actually true ( I haven\'t checked) I don\'t see how a neural network would help.', ""InfiniteState: There's no evidence for that. If it was a tail event, what was that event that caused them to miss the mark on many homes across so many regions?\n\nThe more likely cause is much more mundane: their algorithms simply weren't good enough. They rolled out it too fast, too quickly, and the losses caught up with them so they had to shut it down."", 'BEWARETHEAVERAGEMAN: >In my opinion it failed because forecasting works till it doesn\'t (regime change). \n\nPretty much. ""Forecasting works until it doesn\'t"" is kinda like saying ""a broken clock is right twice a day"" though. When something happens which your model gave 0.000000000000001% chance of happening, it isn\'t that things changed. It is that the model was never right in the first place. Obviously there is lots of room for statistics in financial markets, but ignoring microeconomics is what screws all these people over. Sure, real estate go up at some pace so your statistics say real estate goes up at this pace, but any economics model would have spit out ""real estate prices cannot continue at this pace"". And no, the solution is not just to add some microeconomic factors to your stats model. A stats model would never capture the tail ""dependence"" between prices and defaults before the crash, while a simple economics model would say, if price drops by X then *choosing* to default is optimal.\n\nedit: looks like I hit a nerve, yet the only person to dispute me said ""well it would have worked if the pandemic didnt happen"" which is akin to saying ""it would have worked if it worked"".', ""farmingvillein: Perhaps someone didn't learn the lesson from 2007-2008 that picking up pennies in front of steamrollers risks going terribly wrong at some point."", 'ric2b: The point is that ""Near a noisy road"" was very likely not in the dataset at all.', 'WikiSummarizerBot: **[Winner\'s curse](https://en.wikipedia.org/wiki/Winner\'s_curse)** \n \n >The winner\'s curse is a phenomenon that may occur in common value auctions, where all bidders have the same (ex post) value for an item but receive different private (ex ante) signals about this value and wherein the winner is the bidder with the most optimistic evaluation of the asset and therefore will tend to overestimate and overpay. Accordingly, the winner will be ""cursed"" in one of two ways: either the winning bid will exceed the value of the auctioned asset making the winner worse off in absolute terms, or the value of the asset will be less than the bidder anticipated, so the bidder may garner a net gain but will be worse off than anticipated.\n \n^([ )[^(F.A.Q)](https://www.reddit.com/r/WikiSummarizer/wiki/index#wiki_f.a.q)^( | )[^(Opt Out)](https://reddit.com/message/compose?to=WikiSummarizerBot&message=OptOut&subject=OptOut)^( | )[^(Opt Out Of Subreddit)](https://np.reddit.com/r/MachineLearning/about/banned)^( | )[^(GitHub)](https://github.com/Sujal-7/WikiSummarizerBot)^( ] Downvote to remove | v1.5)', 'ReasonablyBadass: Does this mean you should never participate in an auction?', ""mniejiki: Resume driven development is very much a thing. No one wants to kill the goose that may lay the golden egg of a good resume and promotion project. Most likely you'd have moved onto your next job or team before it all implodes anyway.\n\nedit: Also people on visas (or in green card process) who may have issues staying in the country if they get laid off due to the project getting cancelled prematurely. It's logical for them to play it safe and not rock the boat they're currently in. Remember that 99.99% of projects will not sink a large company or impact it in any meaningfully negative way if they fail eventually."", ""respeckKnuckles: > Heads must be rolling at the senior management level.\n\nNot how it works in American companies. Senior management get golden parachutes. Low-level employees get punished (I mean, look at the OP's links)."", 'gettotea: They would have thought of this. They\'d have been validating these things out of time - the problem is how long you have to react in a market that shifts. The time it takes for this data to mature is too long; the only thing you can do as a risk mitigator is ""OK, I think our models are going to fail, so let\'s buy fewer houses"" but that\'s not an easy decision to make when the business is running predicated on certain revenue expectations. In hindsight, they should\'ve had better risk mitigation for sure.', ""JustDoItPeople: > The asymmetrical cost of valuation errors is an issue in a lot of industries.\n\nIn fact, it is trivial enough to see that there's an inherent connection between utility and loss functions; if there's asymmetric costs to acting on point forecasts depending on where the error comes from, then standard loss functions (which are symmetric) will not work well."", 'TerribleEntrepreneur: Yeah, unfortunately I never learned a whole lot about how ZO did their forecasting and what models they used. I worked on an orthogonal part of AI to both zestimate and ZO. My understanding was that ZO wasnâ€™t NN but ZO was watching zestimates performance to see if they could go down a similar path.\n\nI will say, that the way ZO operated was still very labor intensive and that even though they used a lot of ML to come up with pricing, there were a lot of pricing analysts that would adjust and correct as needed. It honestly seemed internally that things were going pretty well up until I left (only a few months ago). Even colleagues on the zestimate/ZO teams said they were blindsided by this.\n\nI do think that this problem is a quantitative one that the finance sector is experienced in solving. When you think about it, transacting houses isnâ€™t that much different than buying/selling other securities (but without the fungibility). That said, Zillow has almost zero institutional knowledge in quantitative methods and pretty much no one in Zillow AI had that kind of background.\n\nIf I were to try and start to diagnose where they went wrong, I would suspect it was more to do with organization and/or how they approached problems and less about the ML and the application of ML to the task at hand.', ""gwern: Anonymous Zillowites are apparently reporting that the model prices were fine, just overriden by the humans: https://www.teamblind.com/post/Did-Zillow-fail-miserably-due-to-forcing-application-of-Machine-Learning-o8fCCZCD\n\nAs well, a HNer who [listens to their analyst calls](https://news.ycombinator.com/item?id=29141096) reports they said they were overriding their ML models:\n\n> -They were paying way too much for too many homes. I believe this is ultimately due to internal incentives and ambitious goal setting. IIRC, they mentioned they had to alter their model output to be able to give themselves the permission to keep buying at high volumes. They lacked fiscal discipline here.\n\n(He also makes the good point that if the models were just overconfident and blew up in the unparalleled covid environment, why didn't Zillow's competitors blow up as well? They all make heavy use of ML models.)"", 'The-Protomolecule: I donâ€™t think they can train the AI to look at something like that with such scant data.', 'maxToTheJ: > The industry is rife with that. I just rented my house out to a rental-arbitrage tech company who signed a 24 month lease sight unseen. \n\nUugh that exists. The Federal Reserve making money plentiful and shitty models doing rent arbitrage , that just is a recipe to inflate rent prices', 'underdaawg: But home prices were and still is higher than normal due to the pandemic right? The model predictions where higher than that?', 'farmingvillein: hey man just invest in momentum', ""aCleverGroupofAnts: They probably had a model that worked quite while in pre-pandemic market conditions. This is just my speculation, but the underlying forces affecting prices changed, and so it's possible the model needed to be retrained to learn parameters of the new market."", 'None: [deleted]', 'AlexFromOmaha: The margins on new construction aren\'t fantastic, and new construction tends to be more expensive than comparable existing houses, so I feel like ""artificially inflated"" is the wrong idea here. It\'s probably closer to say that consumer tastes are strongly influenced by the availability of mortgages.', 'paid__shill: If there were no loans whatsoever then housing would be built or accumulated only by the very wealthy and most people would be perpetual tenants to those few.', ""kylotan: It's not 'failed machine learning'. It's a failure of the users to appreciate that a numerical extrapolation method, no matter how complex, is not capable of predicting the future."", 'zildjiandrummer1: Absolutely. They do nothing and expect 3% like they matter at all.', ""po-handz: My realtor was incredibly knowledgeable and really helped me narrow down the search to the right place\n\nMaybe if you're buying a cookie cutter house in a dropped from sky neighborhood they bring less value, dunno"", 'maxToTheJ: This. There are no policies to do anything but inflate the process . Along with education there is no downward push', 'Cholojuanito: The practice of machine learning might be about ""featurizing it"" but they used a deep learning, neural network based model and neural networks are also known as ""universal function approximators"", in other words they generalize.\n\nObviously, a statistical model of any kind is only ever as good as the data it is provided so yes, there was certainly a lack of data that covered the feature space.', 'pinnr: In their older data from 2019 they lost $6k per house in direct expenses (i.e. pricing and holding costs) and $48k per house in indirect business expenses.', 'grizzli3k: Nope, would have either been forced out, quit, or followed along. To me looks like organizational problem, not ML.', 'dogs_like_me: Maybe, but this smells like the sort of thing a business stakeholder might override if I tried to control it as a data scientist. E.g. how to balance the risk/reward tradeoff endemic to the problem, determining what our maximum risk appetite is, etc. You know, the sort of thing that clearly lends itself to optimization, but which a lot of business people think needs to be calculated by licking their thumb and sticking it in the wind.', ""farmingvillein: > Zillow TC is just a few percent away from FB/Amazon and is pretty much comparable to Goog\n\nYeah but this is the wrong comparison.\n\n1) They are generally get worse people than faang, dollar for dollar.\n\n2) More importantly, their competitor here isn't/wasn't Amazon.  It is a) the market and b), to a lesser degree, entities like Opendoor.  The amount of money Opendoor has spent on developing their models and systems vastly, vastly outspends anything Zillow spent, because of the equity runup (mostly through their private rounds).\n\nOpendoor attracted people to build their models that had a reasonable expectation of a rocketship, where their comp would be worth...a lot.\n\nZillow...not so much."", 'None: [deleted]', 'None: [deleted]', 'subjectiveobject: Nah, what you are saying is grossly over-exaggerating the margin of error. Its definitely off but not by 200%\nJust being honest as someone who has been involved in 3 home sales/purchases in the last few years. I used zillow, redfin, and other estimating tools and none of them were THAT far off.', 'htrp: rumor has it they tweaked the algorithms to be more aggressive and prioritize deal flow in competition with OpenDoor', 'None: [deleted]', 'jturp-sc: Sounds like they need to sell about 7k homes with an average purchase price of about $400k.', 'longgamma: Soros calls it reflexivity in financial markets. Archegos had managed to create a self fulfilling cycle in some of the stocks they bought. They managed to buy so much that the stock prices actually doubled or tripled in some cases - their buying was propping up the stock prices. When their brokers started unwinding they realized that no one wanted those stocks at those prices.\n\nThis is a different issue with Zillow - the housing market is actually hot right now.', 'geneing: They would fix up the house before flipping it. Done right you can increase the house selling price by a lot more than the cost of repairs.', 'Drakkur: I wouldnâ€™t say junk but from the times Iâ€™ve used it against an appraisal itâ€™s around 3-7% too high. Which is close to your profit margin if you are buying and flipping in a hot market. \n\nThey played a game of hot potato with houses and got burned, simple as that.', ""None: i am amateur house watcher and always thought zestimates were too optimistic. the article mentions they couldn't schedule renovations fast enough so they probably also had too much inventory and had to sell it at lower price because they don't want to hold it for so long. long live bananas."", 'None: [deleted]', ""geeky_username: >It is that the model was never right in the first place.\n\nThat's a pretty bold claim.\n\nThe model might have worked fine had COVID not happened"", 'None: [deleted]', 'omniron: It doesnâ€™t have to be', 'JustDoItPeople: No. \n\n1. This is limited to auctions with interdependent values.\n2. There is a ""closed form solution"" to this problem- namely, bid thinking about the expected value conditioning on the fact that your signal was the highest.', 'whymauri: Look up the Vickreyâ€“Clarkeâ€“Groves auction (VCG mechanism). Enjoy the rabbit hole :)', 'None: Wow ""resume driven development."" My instinct would have been that you\'d hit a senior level where they\'re more concerned about long term performance than shiny cool stuff but no you\'re right. The people doing the work want to do cool stuff to plump their resume and the mid level managers are always going to fluff up the importance and feasibility of whatever their teams are working on to build political capital. Anyone with decision making power either has perverse incentives or bad information.', 'bohreffect: Musical chairs but its Squid Game level stakes.', ""None: I don't know how it works in Silicon Valley but in my former industry (engineering services) I've seen numerous executives fired over far less."", ""GlassPut: > That said, Zillow has almost zero institutional knowledge in quantitative methods and pretty much no one in Zillow AI had that kind of background.\n\n> If I were to try and start to diagnose where they went wrong, I would suspect it was more to do with organization and/or how they approached problems and less about the ML and the application of ML to the task at hand.\n\nCan you elaborate on the kind of knowledge they lacked and how they approached problems? I'd like to understand better."", 'gwern: [Bloomberg](https://www.bloomberg.com/news/articles/2021-11-08/zillow-z-home-flipping-experiment-doomed-by-tech-algorithms) is quoting insiders as confirming this:\n\n> By the Spring, Zillow became fixated on another issue. The forecasting models it used to generate offers had underestimated breakneck home price appreciation in the early months of the year, meaning its pricing algorithms spit out relatively weak offers, preventing it from buying as many homes as it wouldâ€™ve liked.\n>\n> Zillow turned up the dials in the second quarter, according to a person familiar with the decision, who asked not to be named because the matter is private. The move put Zillow out of step with competitors that had begun to take a more cautious stance, including Redfin Corp., which started making more conservative offers in March. But it also translated into rapid gains in the number of offers that Zillowâ€™s customers accepted. Zillow bought almost 10,000 homes in the third quarter, more than double the number from the previous quarter.\n>\n> Zillowâ€™s humans couldnâ€™t keep up. The company hired 2,500 people in the first nine months of 2021, a 45% increase in head count, but neither the expanded workforce nor the armies of renovation contractors Zillow employed were big enough to flip the homes as quickly as it needed.\n>\n> By the middle of October, Zillow began telling customers and business partners that it would stop making new offers until the end of the year, though it would continue closing on homes that were already under contract.', 'at_least_: Exactly. Something like this is obvious when you see it in person', 'mettle: my point exactly', ""TerribleEntrepreneur: Tbf they are doing mid-term (1-6 month) leases to corporations, something that I am not equipped to broker. So it doesn't have a direct impact on rent. That said, it does indirectly impact price of rent through the amount of supply (one less place you can rent)."", ""ddofer: That's what I would assume as well - COVID is a heck of a shift, and if you're looking at short term trading (a few months) then you're playing with non IID data."", ""JustDoItPeople: > That's when unstructured inputs like satellite imagery, interior images, and text descriptions become relevant.\n\nstill doesn't change the winner's curse; if they don't account for that, there's really no way they can make money"", ""ChubbyC312: I've been thinking about this for a couple days and came to a diff conclusion from you so happy to hear your thoughts more. I think if interest rates were higher (less subsidizing from government or just generally, if rates went higher due to Fed decisions), then purchase affordability would drop. When purchase affordability drops, I'd assume new construction would not be as feasible to purchase and therefore build (and we would see supply shortages in the near and more in the medium term). Rates increasing will also make older construction harder to afford - with slight demand tailwinds due to the lack of new construction feasibility. In general, I see this as promoting rentals and increasing the average cost to rent making it make more sense to buy. As I'm typing this out, I'm going in circles a bit.. Speculative investments in real estate may change with increased rates? Now I'm just unsure of myself."", 'mjs128: Lmao itâ€™s 100% a failed machine learning application with a big cost attached to it.', ""bradygilg: If you're unable to use search engines, sure."", 'farmingvillein: Sure.  But [it looks like they probably got burned on the current run-up (and then cooldown)](https://www.wsj.com/articles/zillow-quits-home-flipping-business-cites-inability-to-forecast-prices-11635883500):\n\n> Starting in the summer, competitors such as OpenDoor and Offerpad began to pull back from home purchases in one of the biggest home-flipping markets, Phoenix, as the red-hot pandemic market began to cool.\n\n> But Zillow accelerated, according to an analysis of sales records by real-estate tech researcher Mike DelPrete, scholar-in-residence at the University of Colorado, Boulder. Zillow also paid significantly more than those competitors for each home it purchased, buying homes priced $65,000 above the median on average, according to Mr. DelPreteâ€™s analysis.\n\n> By October, the company had listed 250 Phoenix homes at a median-price discount of 6.2% below what it had paid for them. Mr. DelPrete called Zillowâ€™s price blunder a catastrophic failure.\n\n> A wider look at Zillowâ€™s national performance by analysts at KeyBanc Capital Markets found it had listed 66% of homes at prices below what it had paid for them, with an average discount of 4.5%.', 'None: You can always buy any asset high and sell low if you are automating appraisal and get the market price wrong.', 'geeky_username: Pandemic.\n\nAnd: the market can stay irrational longer than you can stay solvent', 'maxToTheJ: > and all the racists are proud pro immigration liberals living in expensive neighbourhoods. \n\nIts because neoliberalism doesnâ€™t have cohesive world view outside of prioritizing aesthetics, procedure, and speeches', 'slothboy_x2: There wasnâ€™t an â€œorder,â€ though, and if we think of it that way, it probably had nearly as many counterparties as deals. This isnâ€™t like offloading a massive stack of shares in a short timeâ€”itâ€™s about geographic concentration. Even if you â€œsplit up the orderâ€ over years you are still taking a huge stake in the market.', ""MrEllis: So you're estimating that those houses are selling for ~350k?"", 'blahblahloveyou: Itâ€™s not that different. Zillow is also finding that nobody wants those houses at those prices.', 'Mr_Again: Yes but nobody can hire contractors now', 'paid__shill: ""Done right"" involves being *extremely* picky about what/where you buy. Basically the opposite of the Zillow model.', ""InfiniteState: That's not what happened, though. There wasn't a hot market and then a cool down.  It was a hot market for a couple of quarters and then a very hot market this past quarter."", 'The-Protomolecule: Itâ€™s called model decay and finding it out via a 420M loss is a bad look.', 'None: [deleted]', ""BEWARETHEAVERAGEMAN: But pandemics can and do happen. The micro effects of a pandemic could be predicted by an economics model. The micro effects of a pandemic can't be modelled by a statistics model that has never seen a pandemic before."", ""BEWARETHEAVERAGEMAN: It is taken from a great Bukowski poem, Genius of The Crowd\n\nIf you were implying I'm average then even if I am, that would make you an elitest.\n\nIf you were making a pun about how I'm essentially saying beware of statistics (even though I'm doing my Master's in Quantitative Finance) and the average is a statistic then I can get behind that."", ""ric2b: It has to at least be correlated to something else that is in the dataset. Sounds like it probably wasn't:\n\n> Problem is that it's right next to **a road that, on paper, isn't that busy**, but in practice is a major commuter artery. Loud as hell, crap place to live."", ""mniejiki: Executives encourage this usually because they want to also have an impressive resume for their next job or promotion. It's not like the vast majority of executives will stay at the company long term and become CEO one day.\n\nedit: And perceived failure even early on in a project is when the other ~~sharks~~ executives start circling."", ""MohKohn: It's almost like any institutions with more than one layer of management are a huge morass of principal agent problems"", 'Accurate-Nomad: I spent part of my career at large defense contractors.  Missing cost and schedule by >3% was a serious SIN.  Then I worked for Silicon Valley type unicorns.  Blowing billions of $$$ on stupid crap was celebrated.  Pointing out that sociopath execs had no clue of how to deliver what they had promised would get walked out the door by armed guards.', 'None: [deleted]', ""oddodyssey: Agreed, there's only so much you can pickup from Google Street view and staged photos. Actually being there in person can drastically change a person's opinion on a house."", 'AlexFromOmaha: I actually work in the mortgage industry!\n\nNon-adjustable mortgage rates are a function of the 10-year T-note and economic uncertainty. Mortgage-backed securities are considered a very safe place to park money, so when uncertainty is high, demand for mortgage-backed securities increases, which drives interest rates lower to increase supply.\n\nWhen rates drop, housing prices increase somewhat because people can afford ""more house."" It\'s not strictly proportional, though. Lower rates improve borrowers\' debt-to-income numbers, but rising prices makes loan-to-value numbers harder to hit assuming a limited amount is available for a down payment. Sometimes this makes new construction more attractive, but that\'s conditioned on things like labor and material costs, land availability, and urban planning.\n\nRentals are their own beast. In most American markets, mortgages are already cheaper than rentals. Affordable high density housing is only available as a rental or something like a condo, so they have their own market forces. Detached single family rentals are a function of apartment rates as much as they are real estate prices, but investment buyers are less likely to get mortgages and have stricter lending rules in general. Landlords are way more likely to default and go into foreclosure than even high credit risk borrowers in their primary residence. Not all investment buyers are looking to rent, though. Some want to flip. Some are betting on increasing prices. Some investors who want to wait for prices to go up will rent. Some won\'t.\n\nBut in short, a lot of that isn\'t in government control.\n\nIf you really want to drive housing prices down as a matter of government policy, you want to go after the local ordinances that make residential land harder to build on. These look like mandatory setback requirements, zoning restrictions against 2-8 unit housing, banning accessory housing, and NIMBY fuckwits who protest with every racist dogwhistle imaginable every time someone tries to build an apartment. There are policies in Fannie and Freddie that make these sorts of projects harder to finance than they have to be, but there\'s not much sense campaigning for changes there until people can actually start building more densely in cities.', ""po-handz: You can't search up decades of experience in water/heat systems, foundation issues, local regulations on renting, typical renters in an area, how much replacing windows can cost, what kinds value a 2 car garage brings, how/when to negotiate on price, and contacts on hand for every kind of contractor/inspector to call\n\nYou can search all that if your time is worth that little"", 'None: [deleted]', ""jturp-sc: I don't know what they'll ultimately sell for -- though that 7k figure I believe was how many of their 9k inventory they expect to sell at a loss. I'm just restating what I've read from reporting on their earnings call."", ""BEWARETHEAVERAGEMAN: Econometrics =/= microeconomics\n\nSome econometric models use micro-foundations. Most dont. External regressors is *not* micro. Microeconomics is the study of optimal individual behaviour. The models you listed like VARIMAX are statistical number crunchers. They are literally just linear (and somewhat non-linear) ML algorithms and subject to the exact same criticisms, although that depends where you draw the line between ML and regression etc. Regardless, number crunching will always overfit to market conditions in ways that micro models wouldn't."", 'GlassPut: That makes sense. Thank you!', ""ChubbyC312: They do lots of computer vision work on listing photos FYI. Although I'm not sure what the degree of that work informs the pricing estimates or if they even evaluate floor plans as part of that. But they do 100% do an image analysis"", 'nocsi: All that you need to figure out as a home owner.. Like really? I need a RE agent for water/heat system and foundation issues?', 'bradygilg: All of that literally takes 30 seconds to look up. You do not need a realtor to be your phone book.', 'slothboy_x2: Yeah thatâ€™s why I was comparing real estate, you said you werenâ€™t sure.', ""Rocket089: Except that with dark pools, and like Archegos using total return swaps, many funds can maintain exceptionally large positions and make large movements (except when it's a firesale in the former case) without moving global markets too much. It's only in the public facing exchanges that block, split and sweep trades are used to reduce market influence. \n\n&#x200B;\n\nThere is far more to this topic than anyone (ive read, here) has touched on, and therefore dont see how it relates in any way to RE market making.\n\n&#x200B;\n\nI have wondered if it were feasible to offer a service where you sell puts or a type of stop loss to companies like Z. Of course the premiums I/my firm would charge/ would need to be sufficiently nosebleed to reduce my risk to <nose bleed-wake-me-up-in-the-middle-of-the-night-cold-sweats sways in the market."", ""oddodyssey: Sure, but that's going to biased towards the angles that the real estate agent selects.  There's a lot of stuff that isn't photographed and kept out of frame, that you won't see until visiting the property."", ""po-handz: I was a first time buyer maybe that was it. But my realtor told me things like how long past warranty certain systems last, how efficient one vs another type is, differences factors between steam/forced air/etc. When it would be possible to upgrade with x kind of walls. What basement water damage looked like. What was normal vs not with 100+ year old basement floors and walls. How much putting in a sunk pump could cost. What were costs of new water tank? Cost of new heater? Costs to upgrade electric? Issues looking for old knob and tube wires. How to talk with currnt tenants to get inspections/work done prior to close. What brands of water/elec were reputable, which weren't. And so much more  JUST on the systems that I could list\n\nIdk why I took all that time to write it out. Maybe it was because I was buying a house solo, with no family in the area and in a high cost of living area, and buying a 2 units... That I really really got a lot from my realtor. True professional. And the best part: it cost me NOTHING"", 'po-handz: Realtor is free and my time is expensive as is the cost of making a mistake during home buying\n\nDo you actually own a house? Like a real one not a cookie cutter 1 floor in a tropic zone', 'bradygilg: I own a real house, yes. \n\nRealtors are not free. They are extremely expensive.', 'po-handz: My realtor was free. Seller covers the cost', 'bradygilg: That is just a mind trick to convince you to pay. There is no mathematical notion of one party paying and not the other. \n\n6% paid by the seller causes house prices to raise by 3%, so effectively both parties are paying half.']",https://www.reddit.com/r/MachineLearning/comments/qlilnf/n_zillows_nnbased_zestimate_leads_to_massive/
1632536553.0,24-Sep-2021 19:22:33,dojoteef,MachineLearning,puxq1v,[R] Recursively Summarizing Books with Human Feedback,,2,"['arXiv_abstract_bot: Title:Recursively Summarizing Books with Human Feedback  \n\nAuthors:[Jeff Wu](https://arxiv.org/search/cs?searchtype=author&query=Wu%2C+J), [Long Ouyang](https://arxiv.org/search/cs?searchtype=author&query=Ouyang%2C+L), [Daniel M. Ziegler](https://arxiv.org/search/cs?searchtype=author&query=Ziegler%2C+D+M), [Nissan Stiennon](https://arxiv.org/search/cs?searchtype=author&query=Stiennon%2C+N), [Ryan Lowe](https://arxiv.org/search/cs?searchtype=author&query=Lowe%2C+R), [Jan Leike](https://arxiv.org/search/cs?searchtype=author&query=Leike%2C+J), [Paul Christiano](https://arxiv.org/search/cs?searchtype=author&query=Christiano%2C+P)  \n\n> Abstract: A major challenge for scaling machine learning is training models to perform tasks that are very difficult or time-consuming for humans to evaluate. We present progress on this problem on the task of abstractive summarization of entire fiction novels. Our method combines learning from human feedback with recursive task decomposition: we use models trained on smaller parts of the task to assist humans in giving feedback on the broader task. We collect a large volume of demonstrations and comparisons from human labelers, and fine-tune GPT-3 using behavioral cloning and reward modeling to do summarization recursively. At inference time, the model first summarizes small sections of the book and then recursively summarizes these summaries to produce a summary of the entire book. Our human labelers are able to supervise and evaluate the models quickly, despite not having read the entire books themselves. Our resulting model generates sensible summaries of entire books, even matching the quality of human-written summaries in a few cases ($\\sim5\\%$ of books). We achieve state-of-the-art results on the recent BookSum dataset for book-length summarization. A zero-shot question-answering model using these summaries achieves state-of-the-art results on the challenging NarrativeQA benchmark for answering questions about books and movie scripts. We release datasets of samples from our model.  \n\n[PDF Link](https://arxiv.org/pdf/2109.10862) | [Landing Page](https://arxiv.org/abs/2109.10862) | [Read as web page on arXiv Vanity](https://www.arxiv-vanity.com/papers/2109.10862/)', 'dojoteef: Hereâ€™s a link to the blog post:\nhttps://openai.com/blog/summarizing-books/\n\nThere is also a summary explorer:\nhttps://openaipublic.blob.core.windows.net/recursive-book-summ/website/index.html']",https://arxiv.org/abs/2109.10862
1630723726.0,03-Sep-2021 19:48:46,dojoteef,MachineLearning,phjecd,[N] Facebook Apologizes After A.I. Puts â€˜Primatesâ€™ Label on Video of Black Men,"Itâ€™s been [six years since Google Photos tagged black people as gorillas](https://www.reddit.com/r/MachineLearning/comments/3brpre/with_results_this_good_its_no_wonder_why_google/) and yet despite all the advances in CV in that time, it looks like [Facebook has run into the same problem recently](https://www.nytimes.com/2021/09/03/technology/facebook-ai-race-primates.html). Itâ€™s more than a little troubling that this is an issue that hasnâ€™t been fully addressed in six years despite all the claimed ML advances in the intervening time.

**Please donâ€™t turn this post into a flamewar about whether or not algorithms are biased or racist.** Rather, Iâ€™m wondering what are realistic solutions that can help prevent these types of egregious misclassifications in consumer-facing ML models.

Would something like the ACL 2020 best paper, [Beyond Accuracy: Behavioral Testing of NLP Models with CheckList](https://aclanthology.org/2020.acl-main.442/), help if applied to CV? Considering the wide variety of lighting, camera angles, background etc for image classification, would behavioral tests actually reduce these issues? Are there other potential solutions?",124,"['Vegetable_Hamster732: > Rather, Iâ€™m wondering what are realistic solutions that can help prevent these types of egregious misclassifications in consumer-facing ML models.\n\nThe [OpenAI CLIP paper has some interesting insights about engineering the set of categories/classes to reduce the number of egregious incorrect labels](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language.pdf) when they experienced this exact same problem.\n\nThey observed that it was younger minorities who were most frequently mislabeled.  \n\n(My speculation -- perhaps because children\'s sizes and/or limb-length-proportions are more similar to other primates than to adults.)\n\nBy adding an additional class ""CHILD"", their classifier started preferring the class ""child"" over the egregious categories.\n\nQuoting their paper:\n\n>>We found that 4.9% (confidence intervals between 4.6%\nand 5.4%) of the images were misclassified into one of\nthe non-human classes we used in our probes (â€˜animalâ€™,\nâ€˜chimpanzeeâ€™, â€˜gorillaâ€™, â€˜orangutanâ€™). Out of these, â€˜Blackâ€™\nimages had the highest misclassification rate (approximately\n14%; confidence intervals between [12.6% and 16.4%])\nwhile all other races had misclassification rates under 8%.\nPeople aged 0-20 years had the highest proportion being\nclassified into this category at 14% .\n>>\n>> Given that we observed that people under 20 were the most\nlikely to be classified in both the crime-related and non-\nhuman animal categories, we carried out classification for\nthe images with the same classes but with an additional\ncategory â€˜childâ€™ added to the categories. Our goal here\nwas to see if this category would significantly change the\nbehaviour of the model and shift how the denigration harms\nare distributed by age. We found that this drastically reduced\nthe number of images of people under 20 classified in either\ncrime-related categories or non-human animal categories\n(Table 7). This points to how **class design has the potential\nto be a key factor determining both the model performance\nand the unwanted biases or behaviour** the model may exhibit\nwhile also asks overarching questions about the use of face\nimages to automatically classify people along such lines\n(Blaise Aguera y Arcas & Todorov, 2017).\n\n\n**TL/DR: Add some more appropriate classes to your classifier**', ""micro_cam: Similar to the famous google photos incident:\nhttps://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai\n\nFunny i was just playing around with ms azure's computer vision service and noticed it classified a chimp as a person. One way to be safe i guess..."", 'None: Google was smart to stop tagging photos as gorillas. Why didnâ€™t FB do the same? Itâ€™s not like FBâ€™s algo is that much better', 'guinea_fowler: 2 cases in 6 years seems like a pretty good error rate to me given what is surely high volume usage. Obviously there will be more, but this particular misclassification has more potential to be sensationalised than others.\n\nRather than jumping straight to trying to solve the ""issue"", it may be more prudent to gain a better understanding of whether or not this error is over represented.\n\nOf course, that\'s probably not going to help with PR.', ""Franc000: Ml is at the end of the day the ultimate data driven system. It's behaviour stem mainly from its training data. You can try all you want to add heuristics in pre and post processing, you would end up with an infinite list of rules to try to control it's behaviour. If you want to control the behaviour of an ML system, you need to master it's training data, that is the only lever that makes sense and scale. That means things like adding or removing classes and relevant supporting data points, which requires a good amount of effort on the labeling front, tooling and data management practice. Something that is hard to sell to business people that think of ML as a nice box that spits out predictions."", 'v4pe2: I classify all of facebook as very ape-like.', 'MuonManLaserJab: Is there a nonpaywalled version of the article?', ""adrizein: I think this is probably a class imbalance problem, so any technique that can fight class imbalance would probably help. I like this [technique in particular](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.ClusterCentroids.html), but I'm not sure it applies well to pictures.\n\nAlso, modeling the task as a hierarchical classification could also help because it would help the network understand that technically *yes* humans are primates, and some primates are monkeys, some are humans, some humans are black, some are white, etc. This could be easily done with a multilabel classification where some labels are correlated."", 'kkngs: Technically weâ€™re all primates. Just because this is an easy and emotionally loaded distinction for Americans doesnâ€™t make it an important distinction mathematically or even biologically.  A vision system could easily mistag a husky and a wolf. \n\nThe real screw ups here are the business folks that decided to put something like this public without explicitly worrying about this type of issue. Itâ€™s not really an ethical or fairness failure, because nothing is riding on this system. Itâ€™s just embarrassing. If they wanted to roll something like this out they needed to explicitly account for this problem and include QA steps to validate that the system didnâ€™t do this.\n\n*True* ethical and fairness issues show up when one of us builds a model for setting jail bonds or mortgage risk that mostly just learns to â€œcheatâ€ and just penalize people that live in predominantly black neighborhoods.  Or if we create an pulse oximeter that doesnâ€™t work correctly on dark skin because we didnâ€™t include anyone like that during development. The moral hazard is in the application.\n\nEdit: I will say that I think there are indeed ethical issues surrounding these social network recommender systems, but not so much in that Iâ€™m worried about them being superficiality â€œinsensitiveâ€. I worry that what they are *designed to do* is fundamentally bad for society.', ""Thefriendlyfaceplant: AI ethics discussions that only focus on outcomes are pointless. It's the model that needs to be understandable."", 'getbehindmeseitan: Practically, how do large, consumer-facing tech companies try to prevent this kind of thing from happening? Is this a rare example of something that slipped through a vigorous testing process? Or, on the opposite end of the spectrum, is the ""process"" just a random engineer doing some half-assed searches of things that might return an egregious misclassification and pushing to prod if they don\'t find much?\n\nAnd how do they design products around this? It seems like Facebook might\'ve been trying to avoid bad outcomes here, by writing ""Keep seeing videos about primates"" (implying that the subject of the video is non-human primates) rather than saying it directly ""This is a video about primates!"".\n\n(I\'m curious about this for a user-facing context like the one in the NYTimes article, rather than for developer-facing models/APIs where identifying apes might be more or less of a focus.)', ""None: Technically, aren't we all primates?"", 'GFrings: Serious question, what is the SOTA for distinguishing between monkeys and humans at the moment? Like is this a common failure mode? I could see most models, even trained well, having a hard time making the distinction between brown people and monkeys due to the semantic similarities, i.e. not racist stereotypes but that we are both humanoid with ape like facial features, dark hair, sometimes dark skin.', 'Ki-Adi-Mundi-Jedi: So shocking itâ€™s funny', ""antihexe: > primates\n\n> egregious misclassifications\n\nHumans (Homo Sapiens)\n\nOrder: Primates\n\nIt's not an 'egregious misclassification.' Humans are Primates."", 'beginner_: Its not wrong. Humans are primates.', 'None: [removed]', 'Careless-Piano-2421: If people can be removed from Facebook for thinking taxes is not justified to some degree Facebook can b shutdown for calling black people primates.', 'None: [removed]', 'doctormakeda: In my humble opinion, to avoid these types of mishaps the most obvious solution is adversarial testing. At this point anyone unaware that social biases infect ML products must have been in a coma for the last five years...therefore it is reasonable to expect that companies do adversarial testing for certain protected groups. Maybe Facebook actually did this, but just not well enough.  Statistical biases will probably always be problematic in many ML algorithms, but social bias is something a bit different that can be checked for. Interestingly people sometimes get into flame wars when they use these two terms in ways that overlap and are unclear.', ""PatrickMaguiredc: Humans are a form of primate, but sadly some think of less intelligent species when the word is used.  Some don't believe in evolution for whatever reason.  It does not help when fans throw bananas at a race in some countries.  AI probably was not told this stuff.  If a person is taught only certain bits of information doesn't a human make similar mistakes?\n\nEdit: If the word was actually monkey or bonobo I could better understand the outrage.  Giving the AI a chance to put all humans as primates might have been better.  People might get offended for being called wonderful for all I know eventually."", ""sevenradicals: > Itâ€™s more than a little troubling that this is an issue that hasnâ€™t been fully addressed in six years despite all the claimed ML advances in the intervening time.\n\nYou're expecting AI to fix itself to always classify correctly?"", 'Draftdev69: Excuse me it *what*?! I know itâ€™s not the employees of facebooks fault but like come on man, learn from other peoples mistakes..', 'None: [removed]', 'purplebrown_updown: Wtf. How is this not tested before hand? The minority where this happened wasnâ€™t that small like 1%. If theyâ€™ve been training on millions of images weâ€™re talking about 10k. \n\nThis isnâ€™t just a problem with the training data as LeCun had glibly suggested. Apparently he really doesnâ€™t give a shit. And after all that controversy where he pretended to care. If they even had a small percentage of black people on their team they would have picked this up. But they didnâ€™t cause they donâ€™t care. And people wonder why diversity matters. I donâ€™t want Facebook directing the fate of AI.', ""dogs_like_me: I wonder if it would help to add some kind of max-margin/hinge loss to encourage certain pairs of classes to be further away from each other? Maybe add a loss component like this for each specific misclassification we're concerned about, so we're specifically encouraging those pairwise class separations (rather than say a single margin loss across all classes)."", 'Many-Bees: [This meme is always relevant](https://pbs.twimg.com/media/E4GvNgOWUAEYvCQ?format=png&name=small)', ""AcademicPlatypus: Til Facebook doesn't know how to handle class imbalance"", 'n0_1_here: well...... FB is racist', 'None: AI cognitive flaws', ""vwibrasivat: > 394 comments\n\n\nIt's like *Planet of the Apes* in this thread.\n\n.\n\n.\n\n.\n\n\n\n^( ill be here all week )"", 'sarmientoj24: I was trying to detect humans in an image using mmdetection and it detected seals as human. I didnt get offended.', 'kkngs: Very interesting reference. Thank you for sharing that.\n\nClass design as well as loss function design are areas that have profound impacts on the behavior of systems we build, theyâ€™re basically the interface with the real world and need careful thought and consideration.  I think this is missed sometimes in the â€œKaggle competitionâ€ mindset where someone has already posed the problem for us. In my experience so far, in real life applications, deciding on the representation is a huge aspect of whether or not an approach will work.', 'drlukeor: It is an interesting hypothesis. We\'ve published on this before, calling the phenomenon ""hidden stratification"", meaning that there are unrecognised subclasses that are visually distinct from the parent class, which causes problems when they are visually similar to other parent classes. https://arxiv.org/abs/1909.12475\n\nThere has been a fair amount of work on trying to automatically identify hidden subclasses during model development (mostly based on the idea that their representations and losses are outliers compared to the majority of their superclass), for example from my co-authors: https://arxiv.org/abs/2011.12945\n\nI think we need to recognise that while this problem is likely partly or even mostly responsible here, even comprehensive subclass labelling (label schema completion, which is itself extremely expensive and time consuming) can *never* guarantee this unacceptable behaviour won\'t happen. Models simply can\'t distinguish between intended and unintended features, and any training method we have can only influence then away from unintended solutions. This deeply relates to the paper from Google on underspecification: it is currently impossible to force AI models to learn a single solution to a problem.\n\nIn practice (with my safety/quality hat on) the only actual *solution* is regular, careful, thorough testing/audit. It is time consuming and requires a specific skillset (this is more systems engineering than programming/CS) but without doing it these issues will continue to happen, years after they were identified.  For more on algorithmic audit, see https://arxiv.org/abs/2001.00973', ""canbooo: > My speculation -- perhaps because children's sizes and/or limb-length-proportions are more similar to other primates than to adults.\n\nMy speculation: I think  reason is that there are less child photos as parents often worry about the consequences of putting such Photos online. \n\nAnyway, I agree that this is rather a problem about the data set/reprensentation. However, it amuses me that such problems are noticed only after deployment in a big company like FB. Despite their useful repos, i feel they dont use best practices when it comes to deployment (but this is also speculation)."", 'sabot00: What does unsupervised learning say? What if we let the classifier decide its own classes?', 'chogall: Ahh the good old astrology stupid trick.  If 12 Zodiacs are not enough, add more classes, sun signs, moon signs, etc.\n\nSolves every problem for machine learning since 3,000 B.C..', 'kkngs: It would be kinda fun to create an adversarially perturbed picture of Zuckerberg that it identifies as a robot.', 'maxToTheJ: This is so on-brand for Facebook to have not learned any lessons from Googles incident, total hubris', 'tinbuddychrist: I have no direct knowledge to confirm this, but my understanding was always that this was a function of training on bad data, i.e. pulling images of people that were tagged in racist ways by other people, and not actually just unfortunate confusion on the part of the model that accidentally aligned with racist language.', 'JustOneAvailableName: > classified a chimp as a person. One way to be safe i guess...\n\nKinda the only way to be safe. If a FP is really bad, you have to accept more FNs', 'Competitive-Rub-1958: nor going to get the media outlets those juicy FAANG headlines about their latest fiasco', 'MegaRiceBall: This is how we go from machine learning to human learning. Full circle back.', ""AKJ7: I don't think the issue here is the data. You have a crappy model, you will get crappy results. Black people and apes have distinct features, the model should be able to discern them."", 'dojoteef: Try [this article from USA Today](https://www.usatoday.com/story/tech/2021/09/03/facebook-video-black-men-primates-apology/5721948001/).', 'Hydreigon92:     Itâ€™s not really an ethical or fairness failure, because nothing is riding on this system.\n\nFWIW, the MSR FATE (Fairness, Accountability, Transparency, and Ethics) team refer to these as [""harms of denigration""](https://www.youtube.com/watch?v=1RptHwfkx_k&t=547s). The examples you listed as ""*true*"" fairness issues are considered *harms of allocation* (jail bonds, mortgage risk) and *quality-of-service harms* (in the case of the pulse oximeter) under their taxonomy.', 'Cocomorph: > Technically weâ€™re all primates.  \n  \nWell, there you go. They can refuse to get more specific than â€œHominidae.â€', 'monstimal: The harm is that idiots think this means ""AI"" (which to those people is like saying ""super intelligence"") is endorsing 19th century ideas about race. And Facebook couldn\'t be a better medium for communicating with idiots.', ""midwestprotest: >Technically weâ€™re all primates. Just because this is an easy and emotionally loaded distinction for Americans doesnâ€™t make it an important distinction mathematically or even biologically. A vision system could easily mistag a husky and a wolf.\n\nI'm confused by this -- do you believe ethics violations are primarily concerned with violations of mathematical or biological conventions? I'm not sure what you're saying here."", 'The_Mootz_Pallucci: I think I agree with you here, especially that last sentence. I also agree with you that business folks who lack technical expertise should probably exercise caution before announcing something like that. \n\nDo you suppose that it is possible for a model/system which makes decisions based on color simply categorizes dark colored objects in the same way? In other words, could it really be that simple?', 'franticpizzaeater: I agree this is more of quality control/quality assurance problem rather than fairness of AI.', ""StoneCypher: Edit: I'm being asked to be nicer to people who think only Americans care whether people of color are correctly identified as human beings.\n\n&nbsp;\n\n> Technically weâ€™re all primates. Just because this is an easy and emotionally loaded distinction for Americans\n\nimagine thinking this was an american thing, valuing knowing that people of dark skin color are human beings\n\nhow this got upvoted is beyond me.  this level of apologism is technical nonsense and ethical misery\n\n&nbsp;\n\n> If they wanted to roll something like this out they needed to explicitly account for this problem and include QA steps to validate that the system didnâ€™t do this.\n\nno part of these systems works this way."", ""OnyxPhoenix: CNN's aren't really understandable, and even if they were, what insight will you gain?\n\n People and apes look quite similar, chimps and gorillas both have black skin. It's no surprise that a model will occasionally make the mistake."", 'Ki-Adi-Mundi-Jedi: Yes, in fact humans are apes.', 'dojoteef: Of course context matters â€” in this colloquial usage, â€œprimatesâ€ means non-human primates. Please donâ€™t attack a straw man. If indeed the goal of classification was biological taxonomy, then Facebookâ€™s reaction would not be to disable the classification feature.', 'pombolo: woosh', 'MuonManLaserJab: > Advances in ethical and fair AI?\n\nI think they mean advances in ML in general, including in classification.', ""The_Mootz_Pallucci: Despite the downvotes, you're right. At the end of the day, people only care about one-way prediction errors despite prediction errors going both ways. The way I see it, as long as we reduce such errors as much as possible, and build in checks and balances for the live product, it's not an issue, at all.\n\nAnd, a lot folks (especially on reddit, and in academia) have an idealistic view of the world and fail to realize that one of the biggest priorities for a business is what gets revenues and profits up. That typically involves capitalizing on whatever cultural trends are passing by, such as LGBT Month, or breast cancer, or the Harlem shake, or whatever- building brand loyalty."", ""doireallyneedone11: I think it's a classic case of moral relativism, we value humans more than Gorillas because... We're humans and we're biased towards the well-being of our own species. \n\nIt's important to note that moral relativism is not just limited to species-level, it goes to cultural, national, familial and personal-level ethics because we value different systems differently.\n\nEdit: Wow, the moral absolutists are really miffed at this reply! ðŸ˜‚\n\nhttps://plato.stanford.edu/entries/moral-relativism/"", 'NTaya: Yeah, like, what do they expect. It\'s likely a case of a biased dataset (for example, heavy underrepresentation of black men), not a case of a ""bad"" AI.', ""svartgeit: No one thinks the model will correct itself. The suggestion is clearly that the ML engineers should be correcting their mistakes, making sure their training data isn't biased, changing thresholds for confidence, and changing their model architecture to prevent mistakes like this. You took that quote completely out of context and I am assuming you know that."", ""mo_tag: >If theyâ€™ve been training on millions of images weâ€™re talking about 10k. \n\nJust because 1% of the predictions were false, doesn't mean that 1% of the training data was mislabeled."", 'visarga: Maybe design a class-to-class cost matrix to weigh more some errors than others. Multiply the loss with  the cost coefficient assigned to the pair of (predicted class, true class).', 'Vegetable_Hamster732: > hidden subclasses\n\nIs it strictly subclasses --- or is it more overlapping separate orthogonal classes?\n\nI\'m guessing the models reasonably correctly found an intersection of the classes  """"short limb-to-body ratio primate"" and ""short total height primate"" and ""dark haired primate"".\n\nI think the turmoil is caused because it applied the the egregiously wrong ***label*** to that intersection.\n\nBut that\'s just because a human only gave it bad choices for such labels.', ""zacker150: >However, it amuses me that such problems are noticed only after deployment in a big company like FB\n\nI mean the number of pictures in production at a big company are several orders of magnitude larger than that of a smaller company, and when it does happen at Facebook et. al. it's more likely to hit the news."", 'csreid: Has there been much SSL work on things outside of nlp? I\'ve idly thought that ""GPT but for pictures"" might be cool but I haven\'t looked or seen much about it.', 'Vegetable_Hamster732: > What does unsupervised learning say?  What if we let the classifier decide its own classes?\n\nIt should find both sets of classes!\n\nIn the specific case of ""many pictures of various primates"" it should find all the (overlapping and somewhat orthogonal) classes of:\n\n* Long arm-to-body-ratio primates (including most [but not all](https://en.wikipedia.org/wiki/Dwarfism) adult humans and spider monkeys)\n* Short arm-to-body-ratio primates (including gorillas and human children)\n* Red haired primates (orangutans and [Gingers](https://www.youtube.com/watch?v=KVN_0qvuhhw)]\n* Blond haired primates (Golden snub-nosed monkey and Sweeds)\n* Gray haired primates (Silverbacks and grandparents)\n* Tall primates (adult gorillas and most adult humans)\n* Short primates (mouse lemurs and infant humans)\n* Light skinned primates (including some apes and some humans)\n* Dark skinned primates (including some apes and some humans)\n* A separate class for each separate species (except maybe bonobos and chimps - they\'re too close to call and have [interbred in the past](https://www.newscientist.com/article/2110682-chimps-and-bonobos-interbred-and-exchanged-genes/))\n\nand put most pictures in more than one class.\n\nAnd it would not pick offensive labels.\n\nBut it\'s up to the human (supervisor) to say which of those overlapping classes he wanted for the primary labels.', 'ZeoChill: >robot\n\n*Android\\*. As commander data would keep reminding everyone.*', 'hiptobecubic: I would say ""it\'s a hard problem in general"" in their defense, but given that it\'s the _same exact fucking scenario_ it\'s really hard to understand.\n\nHardcode that shit until you something figure out.', 'William-169: I think maybe facebook just faced to book not faced to human, sometime they just need to look up and to see whatâ€™s happened on the earth.', 'None: [deleted]', ""micro_cam: There may be some of that but there is also a lot of subtle bias.\n\nLike [photography has been calibrated around white skin tones since its inception](https://www.nytimes.com/2019/04/25/lens/sarah-lewis-racial-bias-photography.html) which effects film emulsions, sensors and autofocus/exposure systems. This means you end up with less detail in the faces of black people for the algorithms to pick up on.\n\nThen you've got bias in data set and test case construction...as ml researchers we all eat our own dogfood by testing our algos on ourselves but few of us are black so we don't catch this stuff as early as we should.\n\nMaking sure your training data has good representation and no obvious racism is a start but its still a really hard problem."", 'DanielBoyles: Also just my opinionated understanding, as opposed to confirmed knowledge:\n\nI believe it\'s not just anymore from image classification labels, though they probably still play a big role. \n\nEvolutionary Biology already places primates in close proximity to humans in general too. So an AI trained on e.g. Wikipedia and scientific papers may also have the two at a closer distance in the high dimensional vector space. \n\nAdditionally; Facebook has access to a lot of text data. Every post, comment, etc. Unfortunately a lot of it is ""garbage"" and so we get the old saying in computer science ""garbage in = garbage out"". \n\nAs I understand it; Facebook is not doing enough to manually ensure that prejudices are sufficiently far apart in the vector space to prevent machines from mathematically concluding incorrectly. Possibly as a result of ""move fast and break things"" and it being mostly automated', 'chogall: Model = Data + Algorithm + Optimizer\n\nIt would be a huge breakthrough in machine learning to fix the model by not touching the data but fix the optimizer and/or algorithm only.', ""Franc000: And how do you get the model to make the distinction? Not by controlling the learning algorithm, or else your task will never end. You will always have edge cases that you will need to correct.\nYou do it by controlling the data. Like I mentioned, the model is inherently data driven. Driven. It's behaviour is stem from the data it has seen. We use learning algorithm exactly because writing rules ourselves for each edge cases does not scale or work. If we need to write rules to deal with every edge cases on top of using ML, why bother using ML in the first place? No, you use ML correctly, by managing the training data/curriculum correctly. I have not seen Facebook's model, but I am sure that the model doesn't label all black people as apes, just a subset of images. To try to write rules to catch each of those individual cases wouldn't work, and encoding something in the learning algorithm itself to deal with those specifically defeats the purpose of using ML. Instead you deal with it like Google did when they had the same issue. By controlling the data, so the model can generalize the understanding."", 'kkngs: It sounds like at least some folks out there are thinking carefully about this. And I agree there is some degree of harm here. If a picture of me at the beach was labeled as a manatee Iâ€™d probably be offended.\n\nWell, ok, if Iâ€™m honest,  Iâ€™d probably find it hilarious. But as a teenager it would have been mortifying.', 'cerlestes: Image Description: *Image may possibly contain two or more eucaryotes.*', 'kkngs: Thatâ€™s a good point and I agree these kinds of screw ups are bad for the field.', 'kkngs: Iâ€™m saying itâ€™s just a machine. One that was trained rather than built part by part. If this system is interacting in a problem space where racism would be a concern for a person in that role, you need to take explicit actions to assess and give assurances that the machine isnâ€™t acting in a discriminatory manner.', 'kkngs: Itâ€™s really not a lack of technical expertise, it was a lack of business expertise. This was a failure of setting software system requirements and a failure to learn from the embarrassments the other companies had on this front.\n\nOn the technical side, I think in this case distinguishing bipedal primates isnâ€™t super easy and the system has an easy cheat for non-Hispanic whites via the color channel information, basically by coincidence because there doesnâ€™t happen to be any other living light colored primates.   I canâ€™t speak to how their particular system worked, but most of the CNN based visions system act a lot more like a shallow â€œbag of features & texturesâ€ detector than we like to admit. Look at the neural dreams papers as an example.', ""Thefriendlyfaceplant: One might even say CNN's are too convoluted to understand."", ""BernieFeynman: ? There's plenty of understanding available.  Just looking at activations could show something like this.  Manifold learning would could also help"", ""IshKebab: It is surprising that they still make such big mistakes after all these years of research. Is it because CNNs are fundamentally too limited? Do we need something fundamentally different, like capsule networks (what happened to those?)? Or just more data/parameters?\n\nOr maybe it's actually a really hard problem and we're just good at it because we're so tuned to human recognition."", ""antihexe: It's not a straw man. It's a literal fact. You said it's an 'egregious misclassification.' It is not. It's a correct classification. Facebook changed this because stupid people are stupid and it's an easy choice between technically correct and happy customers.\n\nYou're the only one attacking a strawman by construing my comment as a strawman."", ""svartgeit: There are absolutely different costs to false positives and false negatives. This is an essential part of any model evaluation on a business level. The cost can be calculated and in this case, maybe it relates to a higher churn rate. The other way around would not. Data scientists in businesses think very carefully about calculating the cost of wrong predictions and it's almost always not equal like you suggest."", ""Algebre: This literally has nothing to do with moral relativism. Misidentifying a gorilla as a human in this context doesn't hurt gorillas' feelings. This is painfully evident but it seems it still has to be said."", 'kkngs: Itâ€™s a software project management failure. If you build a system like this for public use:\n\n* Donâ€™t create racist tags \n\n* Make sure it doesnâ€™t call people gorillas\n\n* Donâ€™t let it talk about Hitler\n\nThe dataset may not have been biased in terms of number of samples, but they needed to explicitly check the resulting system and adjust until they had sufficient assurance it wouldnâ€™t do these things.', 'purplebrown_updown: The whole idea of test data is that itâ€™s supposed to be representative of reality. So it clearly wasnâ€™t tested properly. If they had no idea, their testing was shit. If they did and didnâ€™t do anything about it, thatâ€™s just as bad. \n\nI mean this isnâ€™t a hard problem. There are a ton of techniques to ensure your test set and training set have similar class distributions. And weâ€™ve seen problems with this before. I mean come on.', ""drlukeor: They aren't overlapping semantically though; a human does not get confused. They obviously overlap in feature space for this particular model, but that space is arbitrary nonsense that clearly doesn't solve the task as desired or intended.\n\nFor the intended solution, the superclass is human, and the subclass is Black children. The intended solution can readily separate this subclass from gorillas or other non human primates. The failure of the model to do so proves it learned an unintended solution for the problem. That is obvious though, and should really be expected/predicted given what we know about DL and particularly given the history of similar models.\n\nThe turmoil is caused because their testing did not identify that the model acts as if there is an intersection between these semantically distinct classes in the first place. This is why I say the problem is more about AI use/testing/QA than it is about training data. *All* DL models are underspecified, they all make use of unintended cues. For models that can cause harm, it is completely unacceptable to fail to test them for such obvious flaws prior to deployment."", 'dogs_like_me: Oh baby, yes, especially over the last year. BYOL, SimCLR, Barlow twins, DINO, SwAV, MOCOv2...\n\nEDIT: Here are a couple of projects that have been collecting SSL methods for you to use as entry points to recent developments:\n\n* https://github.com/facebookresearch/vissl\n* https://github.com/vturrisi/solo-learn\n* https://github.com/lucidrains/byol-pytorch\n* https://github.com/lightly-ai/lightly\n* https://lightning-bolts.readthedocs.io/en/stable/self_supervised_models.html#contrastive-learning-models', 'HybridRxN: Donâ€™t think this is the right way forward.  A better way is testing/auditing datasets and improving datasets so as to collect more examples of the classes with less examples as mentioned before than creating arbitrary classes', 'tomasNth: And the correct label isn\'t primates its ""Ugly giant bags of mostly water""', ""tinbuddychrist: > Although they should probably be careful which tags to add if they already established something is a human. Because there are an endless amount of things you can classify humans as, that they won't be happy with. If you have sufficient resources you could let the algoritm search for humans before anything else.\n\nYeah, that seems like a clever general strategy, rather than trying to suss out what might be offensive."", ""AlexCoventry: > Evolutionary Biology already places primates in close proximity to humans in general too.\n\nPretty sure [humans actually are primates in the standard zoological taxonomy.](https://www.smithsonianmag.com/science-nature/why-are-humans-primates-97419056/) (Not that that makes FB's recommendations acceptable.)"", 'brates09: Does your ethnicity have a long standing and harmful history of being compared to manatees? I know that you are agreeing with the above, that it is harmful, but trivialising it like that doesnâ€™t help either.', ""StoneCypher: > It sounds like at least some folks out there are thinking carefully about this.\n\nI was asked to be nicer to the person who thinks that only Americans care whether black people are identified as human.\n\nSomething like 10% of the industry is thinking carefully about this.  There have been university departments focused exclusively on this for 50+ years, which is older than most of the people in the industry and most of the users of the sub.\n\nMost of us can name the person who got fired from one of the various Google departments dedicated to managing this, Timnit Gebru.  Most of us can name the equivalent people at Apple, Amazon, Facebook, and so on.\n\nThis is actually a very common job, and lots and lots of us are thinking about this.\n\nEven the New York Times and other newspapers get in on the action.  Frequently.\n\nIt's not clear why you'd believe otherwise."", '8Dataman8: Well, *techincally* being offended is some degree of harm.', '1purenoiz: And about a trillion prokaryotes and unknown quantity of archaea.', 'StoneCypher: I was asked to be nicer to the person claiming that only Americans care if black people are mis-classified as animals, so\n\n> If this system is interacting in a problem space where racism would be a concern for a person in that role, you need to take explicit actions to assess and give assurances that the machine isnâ€™t acting in a discriminatory manner.\n\n1) This isn\'t really how this works.  There is no such thing as ""an explicit action to assess and give assurances that the machine isnâ€™t acting in a discriminatory manner.""  If there was, we\'d all be using them by now.  You might as well tell someone that they ought to have an explicit action to assess and give assurances that they\'ll be a millionaire tomorrow.\n\n2) All problem spaces are places where racism is a concern for the person in the role.  There exists no place where this isn\'t the case.  You could make plastic flower arrangements, and still end up in Chicago jail for racism (1996,) or you could clean out the city underground water treatment tanks alone and still end up in Philadelphia jail for racism (2002.)', ""Puzzleheaded_Pop_743: Gotta be less autistic in life. Words aren't literal."", 'The_Mootz_Pallucci: I did not mean to suggest that such errors are equal, just that they occur. And as I read your comment again, I see I have much to learn.', ""sevenradicals: > Iâ€™d you build a system like this for public use:\n\nif you always have to babysit your model then it's a weak model.  it needs to inherently account for bad actors.  you might be able to strip it of racist references but what about people manipulating it to promote products or political ideologies.  can AI be taught that communism is good and that it should encourage dependence on the government?  that's a far scarier scenario."", 'mo_tag: >There are a ton of techniques to ensure your test set and training set have similar class distributions\n\nBut you don\'t know that that\'s not the case. If the test data and training data are similar, but the data isn\'t completely representative of ""reality"" then no, there isn\'t an easy test that would pick that up. Also, I\'m not arguing about whether or not they should have done more testing, I was replying to a specific part of your comment.', 'HybridRxN: Donâ€™t think this is the smart way forward.  A better way is testing/auditing datasets and improving datasets so as to collect more examples of the classes with less examples.', 'DanielBoyles: sure. and if FB wasn\'t a social network for human beings, but an educational site teaching about zoology and science in general, then A.I. would be correct in labelling ALL humans as primates.\n\nContext is important. The fact that FB\'s A.I. even has a label for ""primates"" seems out of context to me  - when there\'s (admittedly) presumably a lot more pictures and videos of human beings on their platform. \n\nFB actually also has a unique advantage over other datasets, since they had a lot of people tag themselves for a while now.', 'kkngs: Is body shaming trivial?', 'getbehindmeseitan: is google doing a good job at not making things worse? has google studied the effects of their ad optimization algorithms choosing who to send ads to (and to who to withhold those ads from) in terms of jobs, housing, credit and politics?\n\nsame qs for FB', 'purplebrown_updown: If this was the first time this happened maybe I could give them the benefit of the doubt. But itâ€™s not. They have been aware of this for a while now. \n\nItâ€™s strange that the richest most powerful tech company out there who has limitless resources seem to throw their hands up whenever faced with a moral dilemma. This happened with the spread of misinformation as well. Donâ€™t look at what they say but what they do. They are a deeply immoral company from the top down. All the problems stem from that. Google isnâ€™t a saint either, but they have much better leadership. \n\nCase in point they allowed trump to stay on their platform after he called for the shooting of protestors. Zuck used some twisted logic saying it wasnâ€™t actually a threat. It turns out trump actually suggested shooting protestors to his generals. Literally. Many of us knew this. Zuck purposefully allowed him to continue spewing garbage and hate and nobody at the company high up said shit. There were no mass resignations.', ""AlexCoventry: As I said, FB's recommendations were nonetheless unacceptable."", 'StoneCypher: > Is body shaming trivial?\n\nno, but your attempts at ethical positioning are', 'StoneCypher: > is google doing a good job at not making things worse?\n\nYes.  \n\nFrankly, I react poorly to people trying to enter these discussions in a sarcastic tone, when it\'s fairly apparent they haven\'t even checked.\n\n.\n\n> has google studied the effects of their ad optimization algorithms\n\nYes, and you know the name of the person who used to run the program.\n\n&nbsp;\n\n> same qs for FB\n\nIt\'s also a yes.  Go look it up.\n\nLook, I\'m being watched by a mod who wants me to be nice, so I have to be very careful how I say this\n\nBut frankly, have you considered how people look in other fields when they ""just ask questions"" whose answers are fairly easy to look up?', 'mo_tag: Being an ""immoral company"" doesn\'t mean they are motivated by immorality.. If they were actually aware of the issue, they probably would have rectified it. I think it\'s pretty obvious that they are motivated by money. In that context, the benefit gained from having a ""primate"" tag is hardly going to outweigh the loss of accusations of racism. \n\nThere are plenty of cases of learned biases in models that:\n\n1. Had applications that affect people\'s lives in much more substantial ways than making them feel embarrassed on the internet, and \n\n2. Were built by people that would hardly be considered immoral or acting in bad faith.\n\nYour original comment is claiming that they picked up on it in their model testing and decided to ignore it when all they had to do was remove the primate tag.', 'DanielBoyles: yes. and my original comment that ""Evolutionary Biology already places primates in close proximity to humans in general too"" was in context to the original question ""what are realistic solutions that can help prevent these types of egregious misclassifications in consumer-facing ML models.""\n\nIt wasn\'t to start a debate about zoology and science in general. \n\nIt was meant to point out that the tokenization of the words ""primate"" and ""human"", that is two distinct and unique words, are pushed into closer relation in the mathematical space from which machines infer. And in FB\'s case raises the question whether the word ""primate"" should even be in their contextual dictionary and if they could have prevented it.\n\nFor example: If a legitimate word such as ""Cracker"" was correct in some broader or other context as another word for humans, ML models may have just as reasonably started labelling white men as crackers when noticing that it ""seems to apply"" more to that group of images, based on the ""garbage"" in the dataset.  \n\nGoogle for example (at least from my perspective), has far more reason to have that close proximity between humans and primates in their data space. As Google would have to be able to answer questions like ""are humans primates?"" in order to to be any good at being a search engine\n\nWhen we build consumer-facing ML models, we have to be able to take context into account, if we are to prevent these types of misclassifications.\n\nWe have to carefully choose and test our datasets which at least in my mind still requires human level contextual understanding.', ""getbehindmeseitan: Can you provide a source for your implication that Gebru's team checked Google's ad optimization algorithms?\n\nAlso for your claim that FB's teams have looked into their ad optimization algorithms?\n\nYou say I haven't checked, but I actually follow this field quite closely. Both FB and Google's teams theoretical fairness research is quite good and I don't doubt the good intentions and brilliance of those teams' current and former members, but there's been little public work that I'm aware of that tests their companies' production systems -- ya know, the systems that affect actual people.\n\nMaybe there is internal work checking these systems! I don't know, I don't have much visibility into how the companies work on the inside. If you do have info to share, I think everyone here would be fascinated to see it."", ""purplebrown_updown: My original post was how did they not obviously pick up on it? It may not have been purposeful but how do you not test for something like this? Were there no test images with POC? I hope they will fix this going forward but it's emblematic of a larger problem in AI.\n\nOh and I guess one big point is this. If the CEO was black and this happened to him, I am certain people would be fired and or the problem fixed. But that's not the case. That mere fact means it wasn't high on the priority list.""]",https://www.reddit.com/r/MachineLearning/comments/phjecd/n_facebook_apologizes_after_ai_puts_primates/
1621992761.0,25-May-2021 18:32:41,dojoteef,MachineLearning,nl58at,"[N] 65% of execs canâ€™t explain how their AI models make decisions, survey finds","From this VentureBeat article:

https://venturebeat.com/2021/05/25/65-of-execs-cant-explain-how-their-ai-models-make-decisions-survey-finds/ 

>	In fact, only a fifth of respondents (20%) to the Corinium and FICO survey actively monitor their models in production for fairness and ethics, while just one in three (33%) have a model validation team to assess newly developed models.

How should companies responsibly assess deployed ML systems? What metrics make sense for evaluating bias and assuring regulatory compliance in these systems once they are in the wild?

EDIT: Thatâ€™s what I get for using the articleâ€™s clickbait titleâ€¦ no one read past the title. What about the other aspects of the survey?",114,"[""BlackJack5027: 65% of Execs? sheeeeiiiitttt, 65% of MANAGERS couldn't tell you how their direct reports' models work. \n\nHow do you convince companies to assess? You don't. It's all about minimum viable product until it goes colossally wrong, and then it's just patching with a PR blitz."", 'Hopefulwaters: Number seems low.', 'Mjalmok: This seems very clickbaity. Explainability of NN models is a big issue. I wonder how many data scientists can explain how their AI model makes decision...', ""cbsudux: This article is woefully incorrect and I'm pissed.\n\n&#x200B;\n\n65%? More like 90% lol."", ""penatbater: Isn't this normal? The average exec doesn't know how their products are made personally."", 'jtkme: And the other 35% are liars.', ""BEWARETHEAVERAGEMAN: If the headline were in the 19th century:\n\n>65% of pencil manufacturer execs don't know how to make a pencil, survey finds"", 'MuonManLaserJab: The other 35% are describing decision trees as AI.', 'NotAlphaGo: >~~65%~~ **90%** of ~~execs~~ **people making AI models** canâ€™t explain how their AI models make decisions, survey finds\n\nFTFY', 'jimmyw404: AI ethics is going to get weirder and weirder. Credit scores and insurance rates are reasonably explained but still a little invasive. Spreading that numeric approach out to other areas with more arcane fundamentals and then adding a human filter at the end to stop the damn robot from redlining everything will be awkward.', 'PlinyTheElderest: They canâ€™t explain it because AI models arenâ€™t perse explainable.', ""fmai: >In fact, only a fifth of respondents (20%) to the Corinium and FICO survey actively monitor their models in production for fairness and ethics, while just one in three (33%) have a model validation team to assess newly developed models.\n\nNow, this is REALLY problematic. Way too often people make the assumption that you can use existing code or models that worked well on a dataset related to their own use case and employ it in production as is without testing. This is insanely naive, and a major fuck-up on the development team's part. The fact that 67% do this BLOWS MY MIND."", 'SquirrelOnTheDam: The other 35% are liars.', 'AtmosphericMusk: So at most 65% of executives who use AI models are competent enough to understand that Neural networks with decision making interpretability isnt currently possible? Sounds right.', 'dogs_like_me: Well no shit.', 'crazy-usernames: If Neural network is used, then explanation goes like.. \n\nThis wonderful code initializes with random numbers as per Research papers, and tries to find mapping between input data (high dimensional - No issue) and output - predict / act using proven mathematical theorems.', ""raymmm: To be fair, how many Tesla owners understands how the AI assisted driving function works? Even Elon Musk probably don't know how it works."", 'bartturner: This is not at all surprising.  I am actually surprised it is not higher.', 'Duranium_alloy: Presumably they mean ""get an underling to explain"", because I doubt many execs could tell you what an algorithm is never mind explain AI models.', 'isthataprogenjii: How many of you all know how your brain works on a molecular level? Maybe we need to cut it up and reconfigure something to make it ethical and fair.', 'None: [deleted]', 'beginner_: If it\'s an AI model as in DNN, no one can explain it really. If you want to nitpick.\n\nIt\'s doesn\'t matter to the exec as long as the ""AI"" checkbox can be ticked.', ""None: >EDIT: Thatâ€™s what I get for using the articleâ€™s clickbait titleâ€¦ no one read past the title. What about the other aspects of the survey?\n\nYou mean, you get a lot of unproductive comments and a lot of upvotes? Next time, you could link directly to the [survey](https://www.prnewswire.com/news-releases/new-report-from-corinium-and-fico-finds-that-lack-of-urgency-around-responsible-ai-use-is-putting-most-companies-at-risk-301298434.html) and skip that awful blog post altogether.\n\nIn any case, monitoring deployed models and systems should draw more from UX practices and multi-stakeholder subjective assessments than from hard metrics. It's PR doom prevention, not science."", ""Dwman113: How long before the Execs aren't needed?"", 'Getdeded: Execs need to know one thing: business. The product is irrelevant. Same with sales and lots of other positions.', ""FalconRelevant: We'll all gonna die like this."", 'ottawalanguages: Is there a solution?', 'thenwetakeberlin: Ha, they meant â€œML engineersâ€ right?', 'iavicenna: This is how you get terminators people!', 'im_a_peanutbar: much of the explanation relies on the data Id say, like â€žclass A is similar to class B therefore their true positive rates are lowerâ€œ', ""HolidayWallaby: Shit I'm a PhD student and I can't explain exactly how my models recognise a dog from a cat"", 'nota-scientist: This means %35 of them use strictly explainable models and others are either dumb or use deep neural nets.', 'AIArtisan: Sadly sounds like most of the business Directors I work with. ""So this AI will do all the work this one team does right?"" ""well no you still want folks to check things etc. This system will help streamline their process."" ""But does this AI manage people?"" ""...""', '_mini: A lot of execs think they know, but they are just like John Snow - know nothing.\n\nThese surveys are biased and paid, CEOs need to be tested on Kaggle! (bad jokes)', 'peepoook: Does it matter? Is the objective not to evaluate the decision itself rather than the process, just as *how* a human makes a decision is a blackbox to most observers?', 'kdas22: noob question\n\nML models are not interpretable... as a result, 100% of execs should not be able to explain the model\n\nbasically, the report is saying 65% know they canâ€™t explain how their AI models make decisions\n\nrest 35% will realise it the hard way!!', 'zjost85: Hogwash. 100% of executives canâ€™t tell you how THEY make decisions either, without hand-waving and talking about â€œgutâ€, â€œheartâ€ and â€œintuitionâ€.', 'Seankala: *surprised Pikachu face*', ""jack-of-some: I mean... \n\nMost of the people that built and trained the model can't either."", ""midasp: To be honest, it's great news if 35% of managers can understand the models. My gut feel is the actual number is much lower than 35%"", ""meldyr: The number 35% seems reasonable to me.\n\nHowever, I do not think this has anything to do with the word explainability as it is used in AI research.\n\nThe discussion is about that only 35% of execs can explain how AI helps the business. \n\nNote, that even a model with poor explainability can help a business. \n\n\nAn example is an executive at a bank using AI for automatic fraud detection\n.\n\nI do not expect that an executive cam explain in detail how the model makes predictions and why some transactions are marked as potentially fraudulent and others aren't. \n\nHowever, I do expect that he understand the roles different departments play.\n\nI expect that an executive can explain that the data science team runs some anomaly detection algorithm to flag potentially fraudulent transactions. The executive should understand the difference between anomalous and fraudulent.\n\n I expect that the executive understands some limitations of the model and knows why a manual review is required.\n\nI also do expect that he is able to explain how it helps the business and his customers."", 'TSM-: I also had that same reaction. The fact that *~~45%~~* 3~~5%~~ can explain how their AI models make decisions is actually a big deal, if only it were true. But the blog headline has only a tangential connection to the research and it ends up being clickbait', ""jsalsman: Seriously, I can see why FICO is worried about this. I wouldn't be surprised if the Treasury Secretary required the Comptroller of the Currency to issue a Notice of Rulemaking to have every bank and lending or credit institution map everyone's FICO scores from 300-850 linearly to 600-800, not just to minimize systemic overfit discrimination but to relax consumer credit.\n\nEdit: Microsoft has the most comprehensive popular treatment for coders I've seen in video, just yesterday: https://youtu.be/ZtN6Qx4KddY"", 'AIArtisan: POC to PROD then BOOM', ""FinalVersus: Holy shit dude, you just explain my company's business process to a T"", 'Lebo77: I built some primitive ""ML"" models about a decade or so ago. I had no idea how they worked most of the time. Oh, I knew the structure and so on, but it often did things I really had no good explanations for.', 'audigex: The execs at my organization legitimately donâ€™t know half my projects even exist.', 'Binz_movement: Sales', 'ExceedingChunk: 35% thinks Â«the model makes decisions based on what it learned from the dataÂ» is understanding how it makes decisions.', 'ExceedingChunk: Nobody. They can generally explain some concepts if their model, but explaining a single decision is an unsolved problem.', 'None: But NN would be an extreme case. I work in consulting, and many of the real-world models use something as simple as OLS Linear Regression. But senior executives and Data Science managers are still not clear when it comes to the underlying principles.', ""Leptino: Even before AI.  How many project managers fully understand their code in the first place, much less the actual *state* of their machine?  With any project of sufficient size and scale the amount of calls to unfamiliar libraries grows, and you can never really be sure what you're doing is correct other than the patented, appeal to stack exchange authority."", ""MewBlood: Explainability of ANNs is a big issue, yes, but we've come a long way just these last few years. Explainable AI as a research field is growing rapidly. See for instance the very recent [Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications (2021)](https://ieeexplore.ieee.org/document/9369420)."", 'None: \\> only a fifth of respondents (20%) to the Corinium and FICO survey actively monitor their models in production for fairness and ethics  \n\n\nThe content of the article is not so clickbaity. How to monitor models for fairness and ethics is a different question, and a much more reasonable one. So is the question of whether and how to regulate them. Probably the optimal amount of monitoring is more than zero, and possibly so is the optimal amount of regulation.', 'ExceedingChunk: More like 100%.', ""yensteel: I remember a story that showed that Nintendo executives don't know the button layout of their controllers.\n\n Most executives focus on the strategic side of things, but.. some understanding is important. What people liked about their games and consoles, etc. \n\nAI should be the same. They should at least understand their strengths and limits."", 'beginner_: Yeah. Like a pharma execs knows how their meds are made let alone biologics.', 'ewankenobi: I agree. XAI is an important issue that needs research, but judging it on how many execs understand it is a useless metric. How many of the execs have actually put any effort into understanding it or have a relevant background to be likely to understand it?', '99posse: Or delusional ðŸ˜‚', 'techguytec9: ""And the pencils keep writing racist shit for no particular reason""', 'ILikeBigBidens: https://youtu.be/67tHtpac5ws?t=15', 'LargeYellowBus: Boosted decision trees work well enough for most industry usecases soo...', ""Swyft135: They're not wrong though"", ""thejuror8: Pretty sure the other 35% can't explain how execs make decisions to begin with"", 'bohreffect: >insurance rates are reasonably explained\n\nAre they though? There are plenty of arbitrary correlations in actuarial tables that lead to higher rates from a purely empirical perspective. In auto insurance, from the uncomfortable (e.g. men pay higher rates) to the apocryphal (e.g. you buy a red car you pay higher rates). People might offer explanations, but from an actuarial perspective none are needed.', ""jsalsman: Explainability is almost always available from interrogation methods like LIME, but if executives were allowed access to that information, they'd likely learn things that could get them in trouble in court."", ""bohreffect: That's what implicit bias training is for, jeez."", 'ExceedingChunk: Â«Yeah, I totally understand AI! The model learns from data and makes good decisions based on thatÂ»', ""CommunismDoesntWork: >Sort of how Elon musk has convinced the world he actually knows how rockets work.\n\nHe's literally the chief engineer at SpaceX, and it's not just a title according to multiple sources: \n\nhttps://np.reddit.com/r/SpaceXLounge/comments/k1e0ta/evidence_that_musk_is_the_chief_engineer_of_spacex/"", 'techguytec9: idk, seems like that could be bad long-term. Even the traders in the 2008 crisis knew they were peddling bullshit at a certain point.', 'None: I thought so to until I found out about sales engineers, Iâ€™d always thought it was one of those BS terms you insert the word engineer into so it sounds better but theyâ€™re actual engineers whoâ€™s job it is to explain the technical details of their product and how it can solve their problem to potential customers, usually business to business sales\n\nNot quite necessary for every product but would be if you were selling something like a radar system for airports', 'proof_required: Pay them more? /s', ""hummus_homeboy: Take a SAFe approach since Agile^TM isn't cutting it any longer. ^/s"", ""DoorsofPerceptron: 35% of execs *think* they understand it.\n\nDoesn't mean they actually do."", ""metadatame: This was my thought. 35% know what's going on?  Not in my experience"", 'Vegetable_Hamster732: I\'d be surprised if 35% of the people working on the models understand how they work, beyond ""I downloaded some crap off google colab, and randomly kept changing hyper-parameters until I get a better than average result"".\n\n1/2 :),  1/2 :(', ""None: It is less than 35% I'd wager. Executives are usually pretty divorced from what is actually happening on the ground in the USA at least.\n\nIt's a consequence of some behaviors outlined in this article :\n\n[https://hbr.org/2007/07/managing-our-way-to-economic-decline](https://hbr.org/2007/07/managing-our-way-to-economic-decline)\n\nThe long story short is that we let people run our companies that know close to nothing about the actual product or business. They manage the firm like it's some mixed bag of shares in a portfolio instead.\n\nThe bean counters over-analyze the processes using their KPIs and make far reaching decisions this way without understanding the actual mechanisms or systems at play.\n\nIn Germany a scientist or engineer will run a science or engineering firm/department. Here it's a MBA that knows nothing about either discipline even if their bread and butter is using those disciplines heavily to get things done."", 'BlackJack5027: That was my gut reaction, too.', 'prinse4515: Was thinking this.', 'adonutforeveryone: I was with you until, ""executive understands some limitations of the model""', 'Bubbleegret: 35', 'ConstantLumen: You\'re moving the goalposts and inventing a standard absolutely no one and no thing can reach by using an overgeneralized choice of words. I cannot explain the motion of electrons in a circuit, no one can as our physical models are incomplete. Does that mean we have no understanding of circuits? Is a single decision of a logic gate an unsolved problem? Very few would make such a claim in good faith.\n\nThe models we use are all deterministic functions. Input x, follow deterministic steps, get y. You can very well explain every single bit shift involved. That\'s not just \'some concepts\', that is every bit of added and transformed knowledge. \n\nAll that to say this: if you said something to the effect of, ""highly parameterized models are *difficult* to interpret,"" I would strongly agree. To call it an ""unsolved problem"" is disingenuous in the same way claiming that the explanation of logic gates is an unsolved problem would be.', 'CodyLeet: The whole point of ML is it figures out a model that a human never could, so expecting a human to then understand it is a false expectation.', 'ExceedingChunk: I think itâ€™s a bit of a stretch to call OLS linear regression for AI. Itâ€™s nice to use as a baseline to compee your models to, though.\n\nI work in consulting, and I know they have a tendency to use buzzwords like AI and machine learning whenever possible.', 'Mjalmok: We\'ve come a long way, but we\'re still very far. I have no idea what their requirements for ""explainable"" are, but it seems to me that less than 65% of the projects are built specifically with explainability in mind. \n\nAny project that is explainable and isn\'t designed specifically for explainability is probably not complex enough to be considered ""AI"" (decision tree).', 'sonofmath: Is that so? Damn, Nintendo has gone a long way since Iwata, who compressed the whole Pokemon Gold/Silver code to add the Kanto region into the Gameboy cartridge on its own in a few weeks.', ""BEWARETHEAVERAGEMAN: Actually an interesting analogy to how we hold AI to higher standards than people. \n\nAsk a racist why they are racist, do you expect to get a reasonable answer? I think not. Ask an an exec why their AI is racist, why do you expect a reasonable answer now? \n\nA possible explanation for why we hold AI to a higher standard is that we can't throw an algorithm in jail. Figuratively speaking of course. I mean that a human has skin in the game while an algorithm does not (and whoever trains the model can offload blame to the algorithm)."", ""MuonManLaserJab: And the other 45% can't do subtraction right."", ""jimmyw404: Right, exactly!\n\nIt's reasonable to charge me more because I'm in a demographic that has a statistically higher chance of being in an accident, but is it ethical? The actuarial tables that drive that aren't terribly complex (to my knowledge) and are reasonably defensible, but if an AI is developed to build more on the results of its data to drive those kinds of calculations it can get weird pretty fast.\n\nCandidate and employee evaluation is one area that is just, a minefield."", 'entarko: LIME does not really explain a non-linear model.', ""maxToTheJ: If LIME solved explainability there wouldn't be so much work on trying to get Shapley based stuff and other things working."", ""jimmyw404: Not to mention the many interviews where he explains in detail the engineering decisions they've made"", 'None: [deleted]', 'Getdeded: Ya no itâ€™s a bad idea I should have specified more that this is my opinion on the state of things not my opinion itself', ""yensteel: Agreed. Some businesses that turn completely corporate lose their identity and direction. If they're too focused on their stock and earnings reports, it may leave them out of touch with their consumers.\n\nMarket research can only go so far."", 'AllTheWorldIsAPuzzle: ""Here it\'s a MBA that knows nothing about either discipline even if their  \n bread and butter is using those disciplines heavily to get things done.""  \n\n\nI\'ve worked in two tech-oriented companies in my career and have a great network of tech friends that I correspond with when I or they need help, and this seems to be an overall truth and an overall complaint.', ""wjholden: Why not? I know someone who works in fraud prevention. Her entire department exists because the machine isn't perfect and frequently punts decisions to humans. I think this experience should give a banker a very realistic expectation of what an ML can and cannot do for this specific application."", 'ExceedingChunk: TSM-â€˜s model was overfit to a dataset with 55 being the only number.', 'ExceedingChunk: I would not say that is the point of ML. Itâ€™s just using a lot of math, data and computational power to generate better models than what we can derive from other techniques. \n\nThe weather forecast is also calculated using maths and loads of computational power, but we understand that well. \n\nThe fact that we havenâ€™t solved that problem yet does not mean itâ€™s theoretically impossible.', ""jturp-sc: They certainly creates abstractions in hidden layers that we can't necessarily manually construct or comprehend. It is broadly possible to know which features contribute most towards outputs via different techniques for assessing feature importance and libraries like SHAP though."", 'leonoel: Linear Regression has exactly the same principles as NN, the only thing that changes is the complexity.', 'CaptainLocoMoco: NNs are literally just curve fitting anyway', 'ExceedingChunk: This have been my main argument for self driving cars being held to an unreasonably high ethical standard.\n\nIf a self driving car AI makes 1 mistake for every 100 000 mistake humans make, is it really problematic if we canâ€™t explain it? I donâ€™t even think we have that high standards for hardware failure.', ""techguytec9: I don't know if this completely holds up. You can ask an exec what kind of auditing was done, what compromises might have been made in gathering data, what the implications of their proxy loss function are. I think the equivalent would be if you just had one dude deciding all the loans from your bank (or even, if all the banks used someone very similar). Even if you don't know how he makes those decisions day to day, it'd be pretty important to vet him beforehand. I don't think the average exec has the technical background to even do this. The offloading blame part is well taken though."", ""NotAlphaGo: And 69% can't work out percentages"", 'bohreffect: I agree; ultimately we do have to confront the problem that the role of a ""discriminator"" in an ML sense will always lead to imbalanced outputs. But I think a key point is that from a business perspective, an actuarial table is a perfect example of something that *doesn\'t* require an explanation. It just improves the bottom line; end of story.\n\nI think it was already weird for a really long time from an insurance perspective, but price differences were small enough that it could be, for better or worse, ignored.\n\nOne solution I\'ve seen is that domain adversarial methods can be used to design loss functions that decimate discriminator power in select features, you can ask a priori, give me the best classifier that *doesn\'t* depend on some input feature.', 'penatbater: LIME can but it does so with local linear approximations. Or rather, it simply explains results, not the model itself.', ""jsalsman: Very few models are locally nonlinear in a way that can't be represented as linear gradient moments, and those that are still usually get reasonable explanations from such techniques."", ""CommunismDoesntWork: > And you believe him to the point where youâ€™ll simp for him on the internet.\n\nI don't have to believe him, the link I posted is all quotes from people who have worked with him."", 'CodyLeet: But do we understand weather models? Half the time they are wrong.', 'ExceedingChunk: Yes, I was thinking mainly about your first point. That is one of the main issues of machine(or deep to be specific) learning.', 'ExceedingChunk: Literally all mathematical modeling is curve fitting.', 'xmcqdpt2: universal function approximators go brrr', 'ExceedingChunk: They are fairly correct for a few days ahead most of the time. Given how incredibly complex it is, itâ€™s pretty damn accurate. The issue is mainly when you start looking more than 7 days ahead.\n\nThe issue is that modeling physics perfectly over such a large space is too computationally expensive to calculate. So simplifications has to be made.\n\nJust modeling a car 100% perfectly is exceptionally expensive to simulate. Stiff dynamics(things that oscillate almost infinitely fast) are very expensive to simulate. Couple that with thermo and gas dynamics and you have one hell of a physics model that requires some simplifications here and there.', ""pandarencodemaster: They're also probably very sensitive to initial conditions, i.e. even without simplifying the model you'll get different wildly different outputs due to measurement errors."", 'ExceedingChunk: Exactly!']",https://www.reddit.com/r/MachineLearning/comments/nl58at/n_65_of_execs_cant_explain_how_their_ai_models/
1619234019.0,23-Apr-2021 20:13:39,dojoteef,MachineLearning,mxbjji,[R] Wordcraft: a Human-AI Collaborative Editor for Story Writing,,4,"['dojoteef: This demo of an AI story writing assistant from Google researchers was presented during the [HCI+NLP workshop at EACL 2021](https://sites.google.com/view/hciandnlp/home). It combines a dialog model with few shot learning to give authors the ability to request story continuations, elaborate on story details and more. Itâ€™s still an early prototype and there are some limitations, but hopefully it can be improved in time. See [the paper](https://www.seas.upenn.edu/~daphnei/EACL_wordcraft.pdf) for more details.\n\nIâ€™m excited to see where research like this goes next. Though Iâ€™m biased considering I worked on a (less sophisticated) story writing assistant for [Storium](https://storium.cs.umass.edu).', 'amasterblaster: This is terrifying to me, because mastery and use of language is essentially how we craft our internal narratives and subjective sense of self.\n\nIf we offload the crafting and articulation of ""I"" to an external authority, such that it can be moulded and crafted for our own purposes, we also open that deepest conscious sense of self  up to immediate editing, streamlining, and optimization for purposes we may not be aware of.\n\nThis service will become a trojan horse for a kind of advertising and subtle manipulation I don\'t think we want in society, a psychological/social ""regression to the mean"", or ""optimization of loss"", that will, paradoxically, gradient descent us away from those deepest artifacts that make us ourselves.\n\nWhat do you guys think?', ""JustMyUse: Ow sorry I think it's cool!"", 'amasterblaster: It is very very cool! It is just also extremely dangerous! I like it, too! Just totally terrifying.']",https://youtube.com/watch?v=9p4mfA0Fyd8
1617280471.0,01-Apr-2021 05:34:31,dojoteef,MachineLearning,mhub9g,[N] John Carmack solves AGI!,"After a few short years of solitary research in AI, legendary programmer John Carmack has just recently unveiled an AGI named Rick, which he created by combining the flexibility of GANs with the expressive power of Predictability Minimization!

I knew he had a penchant for physically building machines, but the resulting quality of the facial expressions and smoothness of motion is uncanny! It helps that he recorded the video in 4K at 60fps. Check it out [here](https://www.youtube.com/watch?v=bxqLsrlakK8)!",3,"[""BossOfTheGame: I'm not opening a random file I downloaded, even for April Fools."", 'txhwind: I opened the link in the office.', 'None: Extraordinary']",https://www.reddit.com/r/MachineLearning/comments/mhub9g/n_john_carmack_solves_agi/
