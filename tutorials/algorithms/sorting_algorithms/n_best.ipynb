{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating N-Best Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Best using Counter \"most_common\"\n",
    "\n",
    "Counter.most_common() employs a custom algorithm designed to maintain a data structure that efficiently tracks the most common elements as they are counted. It doesn't use any standard sorting algorithm (e.g., quicksort, mergesort, heapsort).\n",
    "\n",
    "Steps:\n",
    "1. Tokenize the text.\n",
    "2. Count the frequency of each token.\n",
    "3. Sort and extract tokens using 'most common'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_nbest(text, k): \n",
    "    # Tokenize text\n",
    "    tokens = text.split()\n",
    "    # Count token frequencies\n",
    "    token_counts = Counter(tokens)\n",
    "    # Extract top k tokens\n",
    "    top_tokens = token_counts.most_common(k)\n",
    "    # Print top k tokens\n",
    "    print(f\"Top {k} tokens:\", top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 tokens: [('that', 4), ('they', 4)]\n"
     ]
    }
   ],
   "source": [
    "text = \"If you go through the archives you can find out different semester course pages and find videos as well as other course materials that you can do on your own pace. Those who have taken these courses claim that after completing this series they feel like they can achieve or learn almost anything if they wanted because they are already well versed on the lingo and tools of CS that is programming, problem solving and low level stuff. What other courses of this calibre are available freely to the public from other schools? Courses that really up your game.\"\n",
    "k = 2\n",
    "\n",
    "counter_nbest(text, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Best Using Heap\n",
    "\n",
    "Heap sort is a comparison-based sorting algorithm that works by dividing the input data into a binary heap data structure and then repeatedly extracting the maximum (max-heap) or minimum (min-heap) element from the heap and placing it at the end of the sorted array. This process is repeated until all elements are sorted.\n",
    "\n",
    "Steps:\n",
    "1. Tokenize the text.\n",
    "2. Count the frequency of each token.\n",
    "3. Create a min-heap (priority queue) to keep track of the top two tokens.\n",
    "4. Iterate through the token frequency dictionary and maintain the min-heap.\n",
    "5. Finally, extract the top k tokens from the min-heap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heap_nbest(text, k): \n",
    "    # Tokenize text\n",
    "    tokens = text.split()\n",
    "    # Count token frequencies\n",
    "    token_counts = Counter(tokens)\n",
    "    # Create a min-heap to store the top two tokens\n",
    "    heap = []\n",
    "    # Iterate through the token frequency dictionary and maintain the min-heap\n",
    "    for token, count in token_counts.items():\n",
    "        if len(heap) < k:\n",
    "            heapq.heappush(heap, (count, token))\n",
    "        else:\n",
    "            if count > heap[0][0]:\n",
    "                heapq.heappop(heap)\n",
    "                heapq.heappush(heap, (count, token))\n",
    "    # Extract top k tokens\n",
    "    top_tokens = [heapq.heappop(heap)[1] for _ in range(len(heap))]\n",
    "    # Reverse the order to get the top token first\n",
    "    top_tokens.reverse()\n",
    "    # Print top k tokens\n",
    "    print(f\"Top {k} tokens:\", top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 tokens: ['they', 'that']\n"
     ]
    }
   ],
   "source": [
    "text = \"If you go through the archives you can find out different semester course pages and find videos as well as other course materials that you can do on your own pace. Those who have taken these courses claim that after completing this series they feel like they can achieve or learn almost anything if they wanted because they are already well versed on the lingo and tools of CS that is programming, problem solving and low level stuff. What other courses of this calibre are available freely to the public from other schools? Courses that really up your game.\"\n",
    "k = 2\n",
    "\n",
    "heap_nbest(text, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Methods\n",
    "\n",
    "\n",
    "\n",
    "##### Counter.most_common():\n",
    "\n",
    "Pros:\n",
    "- It's a built-in, easy-to-use Python function with a straightforward method to retrieve the most common elements along with their counts.\n",
    "- Often more efficient, especially when you need to find the most common elements once or a few times only.\n",
    "\n",
    "Cons:\n",
    "- Doesn't offer as much control or flexibility if you need to perform more advanced operations, e.g., dynamic updates.\n",
    "\n",
    "Time Complexity: \n",
    "- (1) Tokenization: `O(n)`, where `n` is length of text.\n",
    "- (2) Token Frequency Count: `O(n)`, where `n` is the total number of tokens.\n",
    "- (3) Sorting Unique Tokens: `O(u * log(u))`, where `u` is the number of unique elements in the Counter.\n",
    "- (4) Selecting Top `K` Tokens From Sorted List: `O(k)`.\n",
    "\n",
    "\n",
    "##### Min-Heap (heapq):\n",
    "\n",
    "Pros:\n",
    "- More control over the data structure.\n",
    "- Optimized for dynamic updates, e.g., adding new elements or updating counts.\n",
    "- Suitable for scenarios where you need to maintain a dynamic set of top elements as you insert or remove elements.\n",
    "\n",
    "Cons:\n",
    "- Requires custom coding to implement.\n",
    "- May require more memory to store the heap alongside the Counter.\n",
    "\n",
    "Time Complexity: \n",
    "- (1) Tokenization: `O(n)`, where n is length of text.\n",
    "- (2) Token Frequency Count: `O(n)`, where `n` is the number of tokens.\n",
    "- (3) Min-Heap Operations (push/pop): `O(log k)`, where `k` is the size of the heap. \n",
    "- (4) Maintaining Min-Heap in the Loop: `O(u * log k)`, where `u` is the number of unique tokens that have been encountered and inserted into the heap and `k` is the size of the heap.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
