[
  " \n\nWelcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",
  "Hey, guys. We have made a plugin that turns your pandas data frame into a tableau-style component. It allows you to explore the data frame with an easy drag-and-drop UI.\n\nYou can use PyGWalker in Jupyter, Google Colab, or even Kaggle Notebook to easily explore your data and generate interactive visualizations.\n\nHere are some links to check it out:\n\nThe Github Repo: [https://github.com/Kanaries/pygwalker](https://github.com/Kanaries/pygwalker)\n\nUse PyGWalker in Kaggle: [https://www.kaggle.com/asmdef/pygwalker-test](https://www.kaggle.com/asmdef/pygwalker-test)\n\nFeedback and suggestions are appreciated! Please feel free to try it out and let us know what you think. Thanks for your support!\n\n&#x200B;\n\nhttps://preview.redd.it/a7jcuw1gbdja1.png?width=2748&format=png&auto=webp&v=enabled&s=7a344854cfae94086999b448d5d992d3b6e60943\n\n&#x200B;\n\n[Run PyGWalker in Kaggle](https://preview.redd.it/ev8ellb6bdja1.png?width=2748&format=png&auto=webp&v=enabled&s=30b4206cdc00b6ea2425680cd970cf7e1d23cecd)",
  "I am thinking about how Amazon reportedly axed a lot of Alexa teams.  This seems to point to negative.  But ChatGPT is taking up a lot of interest. This seems to point to positive.   What are your thoughts?",
  "Hi how's it going?\n\nFor a long time I've been very perplexed as to *why* the Poisson and Exponential PDF are what they are. All the textbooks just say \"Here's the PDF, integrate it to get the CDF..there you go\".\n\nBut why the number E? I'm trying to really understand intuitively the Exponential family of distributions from the ground up. \n\nFor example I fully understand the Binomial from the viewpoint of combinations. It's the different orderings of a string of 1's and 0's essentially, weighted by their probabilities of occurring. Then you add up all the orderings where there are K 1's and that's P(X=k).\n\nI want to get that same intuition for the Poisson and Exponential distribution. Any good videos or books or articles?",
  "So Basically I have worked on a data science project with a professor in Cannada and we got good results in a medical dataset and got a good AUROC of .85 and we published the paper for it and got selected , but what surprised me was the professor never went through my code and just gave suggestions and tips to do improve the model , but isn't this a lot risky.Everyday I am scared that some person would go through my code and invalidate my entire results based on some simple error which could have been corrected if there were proper code reviews.\n\nFast forward 6 months , I got a job in  a data science company as an intern and he told me to develop self supervised model for their image dataset and I did that and it good kind of okay results and he told me to move on to another project , still there was no code reviews or code checks , do people in data science just blindly trust each others code , I feel managers should at least give a look through to see if we taking the correct data split or if the model is correct or if there is any data leakage.There is a lot of red flags in trusting the AUROC results blindly. Is this a norm or maybe its just for me.\n\nMoreover most of the data scientists in the company dont even write proper documentation and for interns like me its such a pain , it took  me 2 weeks to understand their entire training repo, data science people should talk with the data engineers and take some of their methods and practices.",
  "Hey Everyone, \n\nI just started a new role as a data analyst. I have been loving the work and am so excited and passionate about this career field. One thing I'm starting to think about now is future-wise, what direction I want to take my career in. I have been interested in modeling but still think there's a lot for me to explore before investing into a specialization right now. \n\nMeanwhile, I have been thinking about starting a Master's programs. \n\nCurrently I am thinking about: Statistics, Applied Math, or CS\n\nIn your experiences, what did those programs help you with in your data science career specifically? Do they all give you more or less the same equal footing or would some programs be more set for a specific route within DS vs another. I have also been looking at DS Master's programs but heard maybe it's still best to avoid those for now.\n\nIs it better to hold off until a specific team or function requires me having a master's?\n\nThanks!",
  "I often find myself wanting to run a couple SQL commands against a CSV, I have poor Excel skills, and so I made [https://sqlacsv.com/](https://sqlacsv.com/). You can drag-n-drop any CSV, its a completely offline app, and it gives a quick overview of each column's distribution.\n\n**Is this something people might find helpful? Would love to get some feedback on the tool.** \n\nHere some screenshots of what happens after you upload a CSV:\n\n[Simple SQL Editor](https://preview.redd.it/335fjx7cr8ja1.png?width=1886&format=png&auto=webp&v=enabled&s=a22da852724c61f4846ca08f917111e9b99f980c)\n\n&#x200B;\n\n[Overview of Values per Columns](https://preview.redd.it/qlt46ttdr8ja1.png?width=1873&format=png&auto=webp&v=enabled&s=9d3e64d2eeac20b69c2d4805fd2e307b04ae6789)\n\nThanks in advanced!",
  "Hi All,\n\nI have been using Pandas for my data and it\u2019s been great, up to a point, and I was wondering if anyone dealt with the following stumbling blocks and perhaps had any advice:\n\nI am collecting and analyzing data on a material. I have several serial numbers, each unique serial number corresponds to a unique sample of this material.  The serial number serves as the key, i.e, is set as an index in my dataframe. \n\nThis has worked beautifully until I tried to organize, by serial number, data that requires multiple rows. For example, one datapoint like the mass of the sample only needs one row to express, and so it corresponds nicely with the index.  But what can I do when a dataset needs multiple rows, like for example the transmission of light at various wavelengths?  In my mind, the way to do this was to place this series dataset within a list [df[\u2018Transmission]], effectively nesting that Series into a single row. This seems to work nicely, until I save and load the dataframe (as csv), at which point the formatting gets all messed up and I can\u2019t easily pull the nested dataset out for plotting, or any other operations, because the nested dataset now has a nested index and pandas inserts a line break (/n) between every datapoint after loading.\n\nAnyone have any good ideas on how to organize such a dataset nicely, so that it corresponds to the serial number index, but can still be used for one dimensional and n dimensional datasets at the same time?  My spectral data also needs to be compatible with .loc and filters so that I can conveniently plot subsets of the spectrum based on wavelength filters.",
  "DS in defense, coasting and making $95K with 2 YOE. I want to leave defense, but did an interview for fun, asked for ridiculous salary, and got another defense offer for $180K in cheaper city. \n\nI am not super interested in the job or relocating. However, I think I should probably take the offer because of the massive financial upside. Even if I stayed 1 year, it would probably be worth it financially. WWYD?",
  "This article shows some efficient ways how to share big NumPy arrays across python processes:\n\n[https://medium.com/p/abf0dc2a0ab2](https://medium.com/p/abf0dc2a0ab2) (no paywall)\n\nYou might find it very useful if you need to keep one or more NumPy arrays in memory that serve as the \u201cdatabase\u201d for specific computations (e.g. making online cbf recommendations).",
  "Hi - does anyone know a service which takes a barcode in an email and creates a capture/user action? Best example would be TripIt. How they add it to your trip and you just have to forward your flight or hotel itinerary..? Anyone? \nThanks!",
  "Hey everyone, I'm planning to create a dashboard for data visualization, and I think I want to use Python for the project. I've been looking into Dash and Streamlit, but I'm not sure which one would be the best choice for a beginner like me. Do you have any suggestions on which library to use? Also, I'm hoping to find a library that won't have a very steep learning curve.\n\nIf you have any recommendations for other Python-based libraries for data visualization and dashboard creation, I'd love to hear them as well. Thanks in advance for your help!",
  "is it important for Machine Learning Engineer to have an extra Industry Level skill like Web development or Python Developer or not.  \nbecause, if he has good programming skills but don't know any web framework or dont know much about anything other than those python ML libraries. is it ok?",
  "Hi, I finished an online Python course and wanted to start working on my own project, but I'm feeling a little directionless currently. I've written a function which accesses the API and creates a dictionary of dates and a user's rating on that date but I'm unsure what to do with this. I tried putting it into a SQLite database by using an online tutorial but the .db file was an unreadable jumble of red coloured characters. For someone who's essentially a beginner to data analysis, what should I try and learn/focus on to be able to do something useful with this data?",
  "Just wondering if should make portfolio if I already have 3 years of experience in the data science field.",
  "Someone who\u2019s well versed in good data practices but isn\u2019t familiar with the CRM software being used (in this case, Salesforce) or the tools used with it?\n\nOr someone who knows SF very well but has little to no experience in data practices?\n\nWould time be a factor in your decision?\n\nNew to the group, data steward since 2011. Thanks kindly in advance!",
  "In the ever-evolving world of insurance, data is the key to success. The insurance industry relies heavily on data to make informed decisions about risk assessment, pricing, and customer engagement. With the advent of data-driven technologies, the insurance industry is increasingly adopting DataOps practices to optimize their data-driven processes and improve decision making.\n\nDataOps refers to the set of practices and technologies that organizations use to manage their data operations in a more efficient and effective manner. It involves a combination of people, processes, and tools that enable organizations to collect, process, and analyze data in real-time.\n\nIn this blog, we will explore some of the most impactful DataOps use cases in the insurance industry and how they can help organizations optimize their operations.\n\n#### Claims Prediction:\n\nOne of the most significant applications of DataOps in the insurance industry is the prediction of claims. By leveraging data from various sources such as historical claims data, demographic data, and weather data, organizations can develop predictive models that can help them identify high-risk areas and predict the likelihood of claims in a specific area. This information can then be used to adjust the pricing of insurance policies and to optimize the allocation of resources for claims management.\n\n#### Lifetime Value Prediction:\n\nDataOps can also be used to predict the lifetime value of a customer. This is an important metric for insurance companies as it helps them to determine the cost of acquiring new customers and the expected return on investment. By analyzing customer data such as demographic information, purchase history, and engagement levels, insurance companies can develop predictive models that can help them to estimate the lifetime value of a customer.\n\n#### Influencing Customer Behaviour:\n\nDataOps can also be used to influence customer behavior. By analyzing customer data, insurance companies can identify patterns in customer behavior that can help them to optimize their engagement strategies. For example, by understanding which channels are most effective for reaching a specific customer segment, insurance companies can target their marketing campaigns more effectively and drive customer engagement.\n\n#### Personalizing Marketing Strategies And Targeting Specific Customer\u00a0Groups:\n\nDataOps can also be used to personalize marketing strategies and target specific customer groups. By analyzing customer data, insurance companies can segment their customers based on various demographic, behavioral, and psychographic characteristics. This information can then be used to tailor marketing campaigns to specific customer segments, resulting in more effective engagement and higher conversion rates.\n\n#### Detecting And Mitigating Risk In Real-Time:\n\nDataOps can also be used to detect and mitigate risk in real-time. By analyzing real-time data from various sources such as social media, news outlets, and weather data, insurance companies can identify emerging risks and take proactive measures to mitigate their impact. This can help organizations to respond quickly to changing conditions and minimize the impact of potential risks on their operations.\n\n#### Detection Of Fraudulent Claims:\n\nFinally, DataOps can be used to detect fraudulent claims. By analyzing claims data in real-time, insurance companies can identify anomalies and potential fraud. This information can then be used to investigate claims and prevent fraudulent activity from occurring.\n\n#### Conclusion:\n\nIn conclusion, DataOps has the potential to transform the insurance industry by enabling organizations to make more informed decisions, optimize their operations, and improve customer engagement. By leveraging data from various sources, insurance companies can gain a competitive advantage and drive growth in a rapidly changing market. Whether you are an established insurance company or a start-up, DataOps can help you to achieve your goals and stay ahead of the curve.\n\nISmile Technologies DataOps Managed Services enable organizations to collect, process, and analyze data in real-time, allowing them to make informed decisions about risk assessment, pricing, customer engagement, and more. With our expertise and cutting-edge technologies, insurance companies can optimize their data-driven processes, increase efficiency, and stay ahead of the competition. [Schedule your free assessment](https://www.ismiletechnologies.com/contact-us/) today.",
  "Hi everyone,\n\nI have recently been offered a data scientist position at my current company, but I was told that I would be working exclusively on the Google Cloud Platform (GCP), and that it won't be necessary to code in Python. I've spent the past year learning about data science, models, and programming, and I'm concerned that all of that knowledge won't be put to use in this new role. I always thought that a data scientist would be in front of their Jupyter notebook, so I'm worried that this is a cheap data scientist position.\n\nMy main question is: is it standard for data scientists to work solely on cloud computing platforms like GCP, and is it common to not code in Python? I'd love to hear your thoughts and experiences on this.\n\nThanks in advance for your help !",
  "https://github.com/R-Mahmoudi/Real-Time-Object-Counting-on-Jetson-Nano",
  " In my job as a data scientist, I use deep learning models regularly to classify a lot of textual data (mostly transformer models like BERT finetuned for the needs of the company). Sentiment analysis and topic classification are the two most common natural language processing tasks that I perform, or rather, that is performed downstream in a pipeline that I am building for a company. \n\nThe other day someone high up (with no technical knowledge) was telling me, during a meeting, that we should be harnessing the power of ChatGPT to perform sentiment analysis and do other various data analysis tasks, noting that it should be a particularly powerful tool to analyze large volumes of data coming in (both in sentiment analysis and in querying and summarizing data tables). I mentioned that the tools we are currently using are more specialized for our analysis needs than this chat bot. They pushed back, insisting that ChatGPT is the way to go for data analysis and that I'm not doing my due diligence. I feel that AI becoming a topic of mainstream interest is emboldening people to speak confidently on it when they have no education or experience in the field. \n\nAfter just a few minutes playing around with ChatGPT, I was able to get it to give me a wrong answer to a VERY EASY question (see below for the transcript). It spoke so confidently in it's answer, even going as far as to provide a formula, which it basically abandoned in practice. Then, when I pointed out it's mistake, it corrected the answer to another wrong one. \n\nThe point of this long post was to point out that AI tool have their uses, but they should not be given the benefit of the doubt in every scenario, simply due to hype. If a model is to be used for a specific task, it should be rigorously tested and benchmarked before replacing more thoroughly proven methods.\n\nChatGPT is a really promising chat bot and it can definitely seem knowledgeable about a wide range of topics, since it was trained on basically the entire internet, but I wouldn't trust it to do something that  a simple pandas query could accomplish. Nor would I use it to perform sentiment analysis when there are a million other transformer models that were specifically trained to predict sentiment labels and were rigorously evaluated on industry standard benchmarks (like GLUE).\n\nhttps://preview.redd.it/sz3ejc1313ja1.png?width=1700&format=png&auto=webp&v=enabled&s=16393c01bdbca3a79f55ef61c486d9aa5645680a",
  "Hello, I am fitting count data for each place. That means, my response variable is the count data and I want to regress them to given explanatory variables. And each row represents each place. But the problem is that the count data are collected over years and I found it has a seasonal pattern. I am sorry to confuse you but I also have another dataset that consists of count data according to time and I used this dataset to visualize the time series plot.\n\nSo, my main goal is to make a regression model of the count data using explanatory in the original dataset (that has no time component) while adjusting for seasonality and my question is how I can deal with this. Do I have to request for the new dataset that contains the time the count data were recorded and fit a regression model? Thank you in advance!",
  "Deploy Machine Learning Models with Django\n\nhttps://github.com/R-Mahmoudi/DeployMachineLearningModel",
  "Hi everyone!\n\nI have a situation that I\u2019d very much love your opinion on!\n\nA little bit about myself: \nI have a MS in biomedical engineering, and I\u2019m currently pursuing a MS in analytics. I\u2019m expected to finish the degree by the end of 2023.\n\nI have just over 2 years of experience in a hospital as a research associate. 50% of my job duty is experimental design (mostly A/B testing), analyzing experimental dataset, visualization, etc. The size of the data is usually very small (n=200 or less). And the other 50% is sensors integration and hands on clinical experimental work. I\u2019m also an adjunct professor in university teaching biomedical engineering classes.\n\nI have a couple abstracts in ML published, and one manuscript currently in the work. However,  the journals I submitted to are very health-oriented. The technical findings are not ground breaking, just applying known ML techniques to the experimental data.\n\nInitially I was planning to pursue a PhD in biomed after finishing the analytics MS program, but I find myself swaying away. I\u2019d like to change to a pure DSA career afterwards.\n\nMy question is, should I apply to intern jobs and start over, or is my experience in the hospital valid? My work is 100% Python based, I know a bit of SQL from course project and leetcode.\n\nIt feels like aiming for a mid level job (2year +) may be too far fetched since I technically only have one full year of experience in DS.\n\nSo that may leave me with a new grad/ intern option\n\nWhat do you guys think? \n\nThanks so much",
  " I apologize I don't really know enough about this subject yet. From my understanding, it seems like most of the Big Tech companies don't fully own personal data but they own the infrastructure in which it is stored. I am an architecture student and I'm really interested in doing research about data centers. I am concerned with surveillance capitalism and am wondering if there is any potential in redesigning the physical infrastructure of how data is stored.",
  "I'm currently between jobs; my last boss told me he believes that improving my coding level will help me become a better data scientist.\n\nAny ideas how to work on that?\nPython, of course..",
  "It seems like there are countless data providers that offer identity solutions like skip tracing and people search capabilities, but all references to obtaining this information seem very broad and vague. \n\nSo, how are all of these companies aggregating their people data like phone numbers, email addresses, relatives, etc in an efficient way and with large coverage of the US population? \n\nAre there public bulk datasets that include this information so it can be aggregated and sold for marketing purposes without violating GLBA or FCRA regulations?\n\nAs an expert, how would you go about acquiring this information in bulk and qualifying it for accuracy?\n\nCurrently, the big players in the space are IDI, TLO, Delvepoint, and Tracers. They all have access to regulated data from credit bureaus and other third-parties to be sold to specific industries, but they also provide unregulated data for public use cases, so where is that information coming from?\n\nThis one has had me stumped for years.",
  "If so, what country are you working in and where did you travel to?",
  "I want to pursue a career in data. My laptop broke and looking for a replacement. Is[this](https://www.bestbuy.com/site/hp-victus-15-6-gaming-laptop-intel-core-i5-12450h-8gb-memory-nvidia-geforce-gtx-1650-512gb-ssd-mica-silver/6503849.p?skuId=6503849) good enough? To work on personal projects, build up a portfolio, do hackathons, etc\u2026 (Basically, is it enough for me to improve myself until I can land a job and upgrade?) I\u2019m planning to upgrade the ram to 16 gb.",
  "I just started my first job at an asset management firm after my Masters' 2 months ago. Recently been contacted by the team lead in a large tech company. He is interested in my past research work (I published two papers out of my masters') and wants to have me in his new team. I am unsure if taking this offer is the right move.\n\n&#x200B;\n\nMy current role: Data scientist at a small (\\~10 ppl) asset management firm. They are setting up a new quant trading (stat arb) strategy and hired me as part of a new team. I took this offer because I am interested in a quant researcher role but couldn't get in one of those big quant trading firms, so I am trying to use this position as a stepping stone to better places. The problems are:\n\n* The actual job is nothing like what I was told during interview. 75% of the job are ad-hoc admin tasks, like preparing monthly fund performance reports, booking trades done by their manual trader (for their other non-quant funds), fixing the trader's Excel formulas, and helping non-tech staff run some Python scripts. I am even officially in their \"operation\" team now. This frankly is not what I expected.\n* This firm has a weak tech foundation. They are just starting to do quant trading, so I understand that they don't have any existing infrastructure. What worries me more however is that they have no experienced developer neither; the only developer here has less than 1 YoE. I am afraid the project will quickly become a hell of technical debt.\n* This firm is not very quantitative neither. The only real quant here has a straightly business background and received no formal math training beyond first year calculus (and no PhD ofc). He does have solid >5 year YoE as a quant trader, which is what really matters.\n* The quant work I got to do is alright. The strategy they are developing sounds promising to me as a layman. If nothing else, at least I learned something about finance. I am unsure how this experience in a small fund will be valued when I enter the job market again.\n* Overall, I think it all comes down to me not feeling enough growth opportunity. Quant research is one exciting opportunity that aligns with my technical interest, but I don't want to overly confine myself in that narrow space -- the quant industry is so competitive that I don't even know if I can get a next job. If I cannot stay in quant, the other option for me is a data scientist role in other sectors. But then, I am now spending 75% of my day doing work that adds zero transferable data skill to my profile.\n* I am however aware that my worldview has become too academic after spending the extra years in school for my Master, so maybe all this is normal in the workspace and I am just being unrealistic.\n\nThe other role: Data scientist at a large tech company (\\~3000 employees).\n\n* The team lead there promised a salary higher than my current role (which is alright but not yet >100k), although I think it will be at best a 10% raise. If I take into account of bonus, probably I will get paid more overall if I can stay where I am for a full year.\n* From what I heard, this company is building a new team to make use of the TB's of service usage data they have collected, mainly for marketing optimization. This team is more mature, with a functional tech stack and experienced data scientists and engineers. The team lead said this will be an opportunity for me to gain experience in being a \"full stack\" data scientist.\n* I have a friend currently working in this company, and he said the job is just like what was on paper; I won't be wasting 75% of my time doing admin work like where I am.\n* My main concern here is essentially the opposite of if I stay in my current role: I am afraid that taking this offer would mean the door to quant research is completely closed for me. Honestly, I think as a data scientist, going for quant related roles is the fastest way to reach my financial goals. And I wish to keep that door opened as much as possible.\n\n&#x200B;\n\nSumming up, my question is which role can give me better career opportunity down the road.\n\nPlease knock some sense into me. Thanks!",
  "This might be a silly question but I'm just curious, Python seems to be quite hegemonic (apart from quantative finance maybe), aren't its bad performances a problem?",
  "I've search around Google Scholar, even just plain Google but I can't seem to find what I'm looking for. It's always summarized or just a few sentences.\n\nAnyone here knows the way or am I searching at the wrong place?",
  "Hey everyone, I am interested to see what tools are in high demand right now. In addition, are any automation tools part of your data process?",
  "I tried a loop function for a single time series but doing it for 43 series looks difficult it would be helpful if anyone can help with R loop code for this or any other easy way using eviews/excel/R.",
  " Through the easy-explain package, you can achieve it without the need to write long scripts (only in 2-3 lines of code you can have your XAI results).\n\nRead more info in this article: [https://medium.com/towards-artificial-intelligence/easy-explain-explainable-ai-for-images-285777a004e3](https://medium.com/towards-artificial-intelligence/easy-explain-explainable-ai-for-images-285777a004e3)\n\nFind the package in Gh: [https://github.com/stavrostheocharis/easy\\_explain](https://github.com/stavrostheocharis/easy_explain)\n\nFind the package in Pypi: [https://pypi.org/project/easy-explain/](https://pypi.org/project/easy-explain/)\n\n&#x200B;\n\nhttps://preview.redd.it/cowm1xkkl5ja1.png?width=1390&format=png&auto=webp&v=enabled&s=b0a259ebe938838e580437e92641ae23182f972d",
  "Hi all - I make no apologies - I'm a hardcore DS geek. I even do it in my volunteering I mess around with IoT stuff in my off time. Even though I've been working in DS one way or another since 5.25 360k floppies, I find the field is getting more and more exciting. \n\nWhat part of the DS work you've done so far really gets you geeking out?\n\nFor me, it's the debates refining the research question and stakeholder interests and whiteboard work solving a data issue. I also like those \"Stand up and wave your arms in the air\" moments when we can claim \"King of the Lab\" for the day because of a righteous hack or sweet piece of code. \n\nWhat's yours?\n\nWhat are you hoping to do more of soon?",
  "Hey there,\n\nI am a data scientist myself, working in a small team of other data scientists (<5). I'm soon reaching the 1-year cap, and I found out that code understandability/project onboarding (at least in my team) is a problem.\n\nMost of my teammates are really good at math and statistics in general, but once I have to dive into one project, I just lose so much time trying to read their code and understand their explanations.\n\nThis can be hurtful, firstly because losing time is never a good thing, but also because it kind of makes me feel like an idiot to not be able to onboard a project without losing hours running and understanding all the code (and it can get very long if, on top of that, it's based on complex mathematics :p ). \n\nOf course, implementing better code practices such as commenting and better naming would be a good thing, but this idea is often met with the \"We don't have time to do that, we have worse problems and priorities\". \n\n  \nSo here's my question: Are there any other data scientists that have the same issues as me? How do you approach this problem? I know collaboration is and will always be a source of friction, and I'm not trying to find a way to remove all of it, but at least adding some oil in the process would greatly help :)",
  "I am a data scientist working a full time position in the US with 150k as base and 4% 401k match. I have been offered a 6-months contract-to-hire position for $85/hr. I have never done contract work and I am trying to figure out if this might be comparable to my current earnings.\n\nDo any of you have experience with the differences between doing W-2 work vs 1099 work? \n\nHow likely is it that a contract-to-hire position actually converts to a hire?",
  "I\u2019ve recently applied for Georgia Techs OMSA program and have been following this sub, and I feel like I see an overwhelming amount of people posting about challenges getting good jobs, management not actually knowing what to do with DS, getting mundane or ridiculous or non DS tasks, and that you\u2019re basically here to verify managements desires or else you better be ready for deep explanations. \n\nAll of this has made me a bit nervous if I\u2019m choosing the right track. Do you think in 4ish years (time it\u2019ll take me to complete me degree part time) it will get better as DS becomes more known, understood, and desired? Is it hard to get into fields related to neural networks / deep learning / or working with Neuro/health related companies (I come from a neruroscience background so have a big interest in how we can use brain studies to enhance how we build and utilize new technologies)? I don\u2019t really have an interest in crunching numbers for financial purposes. I want to feel like I\u2019m helping advance/enhance a field.\n\nI also considered applying to OMSCS but was discouraged by having less preliminary knowledge for that degree, but after applying to OMSA and reading more about both degrees actually feel like with a little prep I would be fine as i have a pretty good gpa, resume, and LoRs. On the fence about applying to both. I have a few years under my belt as a data engineer so I\u2019ve been exposed to the worlds a bit and have some decent language skills. \n\nTLDR; basically, I\u2019d love to hear from data science folks if you think data science is a good field to go into, or if I should consider switch to a more computer science focus. I have interest in both areas, but felt a data science degree was more within reach. TIA!",
  "Have a dataset of roughly 15 variables or so. Don't think just running a decision tree is the play, I have a lot of data so I kind of wanted to do a forest as I want to use the wisdom of the crowd so to speak.\n\nWas thinking Gini Impurity or maybe doing something like a shapley additive explanation (SHAP) . Haven't used done a SHAP before though, I have only read about it. Has anyone worked on a task like this and have any advice?",
  "I'm a 2nd year MIS major hoping to land an internship by my junior year summer. I'm currently learning Excel in school and SQL on my own. When I get comfortable enough, I'll work on a couple of projects to beef up my resume. I plan on learning Python basics myself during the summer, then taking a Python course in the fall semester. Is that enough to land me a data analytics internship where I won't feel too much like an imposter? Is there anything else you would recommend I focus on?",
  "I have been studying deep learning for about a year, learned the basics as well as the main practices on tensorflow. But I feel I am still very weak in this area. Here, in my country, AI is not popular, and it is almost impossible to find a mentor here. I would be glad if you shared at least your way in this area.",
  "Hello all, I\u2019m working as a data scientist from past 1 year in a healthcare industry. I\u2019m looking to improve myself and move out from my current company. Is anyone open to be a mentor?",
  "https://github.com/R-Mahmoudi/Real-Time-Object-Counting-on-Jetson-Nano",
  "Which Mac should I buy my daily work includes mostly doing data analysis with R and Python, Tableau, using Datagrip for SQL (20M-30M Rows Tables), and some Google workspace work and heavy Keynote for presentations.\n\nI\u2019m between buying a M2 Mac Mini with 24 GB of RAM, or maybe pay a little bit more for a M2 Pro Mac Mini with 16 or 32GB of RAM (512GB SSD on both) \n\n\nWhat do you think would be the best option?",
  "Hey everyone, I\u2019m in the process of transitioning into a Jr Data Scientist role at my job. I\u2019m currently working on time-series models for website traffic. We\u2019re leaning toward using Prophet, and I\u2019ve been reading inconsistent information on implementing it in Python. Is a box-cox transformation needed on the response variable? I saw several websites saying that was needed. I also discussed it with my professor, and he said his impression was that it can be implemented with an assumption of linearity or of logistic growth. Could I get some clarity? Sorry if I\u2019m totally wrong on all of this. I\u2019m still learning \ud83d\ude43",
  "I study data science and wish to find a job in data analytics soon. So what grade will matter more in my case",
  "Hi I've also already posted this on SQL subreddit as this one's heavily SQL based but I'm posting this here just incase it helps me even more and helps me to complete the project quick...I'm new to this sub and new to Data science,I've been learning online and I've got a project to be submitted within coming Wednesday and it's \"Twitter scraping\" I've no idea what the heck it is,it would be helpful if someone here could guide me through this,the given instructions are that they asked me to use Snscrape library and to build a solution that should be able scrape the Twitter data and store that in the database and allow the user to download the data with multiple formats.\n\nTIA.",
  "Hello I am a university student in my junior year, Information systems and business analytics major, and I want to get into internships in DS, AI, or ML. I have been applying for over a month now averaging about 5 applications a day. i think it\u2019s my resume thats holding me back from actually getting into those internships. any advice? how can i build my resume to actually get into internships?",
  "Anyone in the LA area interested in putting together a group to learn and bounce ideas off of each other?",
  "Any data scientist in dubai? I am a student in the american university of sharjah majoring in information systems and business analytics. I would love to find other people in the UAE who are data scientists to build my network in the field!",
  "**CONTEX**\n\nYou work in a Retail Bank and as a Data Scientist you're called by the Marketing and Customer Value Management departments to work on a problem with a data-driven approach.\n\nThey figured out that many individual retail customers use their current account and debit/credit cards for business purpose (they are SME - Small Medium Enterprises - disguised as retail customers) and they want to find those 'hidden business' customers in order to reach them out with a cross-selling opportunity (e.g. open also a business account and keep your personal and business expenses separated, allowing lower taxation, etc.)\n\nWhen you do some EDA on debit and credit card spendings you find out examples of retail customers with thousands of dollars per year spent on Facebook Ads, Google Ads, stores for business purchase only, etc. and you plan to use those features to train a model that identifies the 'hidden business' among the retail customer base.\n\n**PROBLEM**\n\nIf your plan is to train a binary classifier you will soon figure out that the problem is that you have positive labels (customers with a business account and debit/credit card) but your negative labels are actually unknown: you don't know if they are hidden business or actual retail customers.\n\nThe standard metrics you will use to compute error and performance (AUC, precision, etc.) would be also flawed because you want to find out errors (e.g. customers with high scores of being a business but actual retail) not minimize it.\n\nAlso, you will end up doing training and scoring on the same dataset of the overall bank customer base.\n\n>!SPOILER: Positive-Unlabeled Learning (PULearning) might be a solution but you have to make assumptions on the distribution of labeled/unabeled class!<",
  "I (23) am a part of my mid sized organisation's ( new )  analytics team ( freshers ) of about 5-7. Our company has lot of dataset on patients clinical diagnosis. \nWe have been a freshers team and I think we struggle with getting the right analytical mindset of problem solving. \n Being incharge of a freshers team while myself having a less than 6 months of experience is kinda hard. But that is not the point.. the point is I wanna know how do I make sure me and team learn to analyse, solve and measure analytical problems and ther outcomes.\nI thought going through few case studies, of other organisations, which covers issues of analytics/ data science team and how they solved them would give a good picture of how analytics problem solving should go .\nI looked up online to find such stories but couldn't come with anything really usefull.\nI would like to get few resources that's i can share with my team, or have a understanding of how do I go on about starting to solve our organisation's small analytics tasks.\nEngineering part is not a issue for us. We have a great and very supportive engineering team. It's just that, we canot identify the right problem to pick, the right way to solve or find right metrics to use.",
  "I have the data of hourly production factor data of a Wind Tribune for 2 years. Unlike PhotoVoltanic panels production, this does dot show and pattern or order. I need to find representative 15 days data for the parameters of my project's mathematical model. What is the best method for selecting  the data that represents most scenerios like high and low production days?  I will divide my data in 3 seasons as winter, summer and spring-fall, so there will be a total of 3 datasets of 15 days.\n\nPS: I am not a data scientist, so I may not be able to apply advanced methods.",
  "Let's say I put in production a fraud detection model based on an initial dataset. Over time this model will introduce a bias because there are transaction getting rejected due to the model. If I retrain the model with the new data, then the model may 'forget' how to catch the old fraudulent transactions. \nHow do you call this model induced drift and how do you deal with it?",
  "Hi everyone!\n\nI am undergrad majoring in Political Science and minoring in Data Science. I am now working on my undergraduate thesis and have realized that, while scraping election data from the websites of different states, there is very little consistency. In a single state, URLs are formatted completely differently, the tables come out in many different forms after I scrape, and reformatting takes me quite a bit (\\~15 minutes for each site, but I have 100 of these to go through, making the data cleaning alone a 25 hour project).\n\nAre there any \"tricks\" to automating data cleaning/making a robust program that can accept many different data forms? Or is data cleaning always just a bit of a pain in the a\\*\\*?",
  "[Spotify](https://open.spotify.com/playlist/6BoTD9WeyBN5rD5uyhbROO) | [Apple](https://music.apple.com/playlist/synthwave-focus-i/pl.u-b3b8Nm9C5MmMyM) | [Youtube](https://youtube.com/playlist?list=PLwO9YUACGAzS_XaTchS3qLgK5EGsb3qwa) | [Amazon](https://music.amazon.com/user-playlists/0375bdbe2f3d41f39523ddb35fc92ca0b1r)",
  "Hey there , is there a site like [R for Data Science](https://r4ds.had.co.nz/index.html) but for Data Science with Python? For me it breaks down everything into smaller concepts and makes it easy to digest. Also provides examples and some exercises.",
  "For people here from the UK, is it good over there? I'm considering moving to the UK (with an HPI visa). Of course I love the place, but I have a young family as dependents (wife and a kid), so I need to be sure it's the right move financially too. So, I'm looking for honest opinions from data scientists in the UK if the move is going to be worth it. Is it easy to get jobs? Are most jobs ok with a hybrid arrangement? Are employers usually willing to sponsor work visa to foreign nationals? Anything else you think I should know?",
  "Hello. In R I have data in a list composed of 198 vectors, each vector with 70.000 values. Each vector is a feature/variable. It's data I need to make searches on (the first vector is the time, like the unique key). What's the best way to organize the data, in a dataframe or transposing it to a list of 70000 lists each one with 198 values, or keeping it like this...?\nI'm trying to iterate on it as it is now but is very slow...",
  "\"wow, this disconfirms by preconceptions.. what a valuable piece of information!\"",
  "Working as a data scientist at a video game publisher. I like my job a lot and we're pretty mature as a data organisation, so my work does get used, plenty of models in production etc. \n\nSome days I can't help but feel what I'm doing is totally pointless, anyone else ever feel like this?",
  "I'm a 26 year old Social Sciences grad considering a return to academia and I'm very interested in applying ML methods as part of a PhD research proposal at the intersection of Political Science / Public Policy and Development Studies.\n\nMore specifically I'd like to assess the value provided by ML methods as part of a mixed methods approach to research with the aid of one or several case studies, with significant attention paid to methodological and epistemological concerns, engaging with the work of forerunners in the field such as Lakoff, Zadeh, Sartori and David Collier. As such, applying ML methods would be a significant portion of my research, but definitely a minority. Specific algorithms of interest would be determined by the case studies in question and what I'm capable of competently applying, but would likely centre around regression/classification and text analysis.\n\nOnce upon a time I had basic but fairly solid statistical skills along with more rudimentary technical skills in SQL, R and to a lesser extent Python, but these have unfortunately atrophied to the point of non existence after 3-4 years in a non-technical Data Science adjacent role. I therefore have a pretty steep hill to climb in terms of foundational skills before I could even submit my research proposal. I'm currently brushing up on algebra, calculus and statistical skills before pushing in to the unknown, most likely via the MITx Micromasters in Data, Development and Economics and/or in Data Science. However the sheer scope and complexity of the content I need to cover combined with working a full time job and the fact that a PhD position is by no means guaranteed at the end of it (I'm provisionally interested in Oxford or LSE) is pretty disheartening. As a result I'm interested in exploring low code / no code options such as KNIME and DataIku (I'd also welcome alternative suggestions) for data prep and model build to reduce the barrier to entry. I'd really value any input on whether these would be fit for purpose, specifically:\n\n1. Will the choice of algorithms available fit my needs?\n2. How low code are they exactly? In practice will I need to plug in significant amounts of my own code?\n3. Do they provide sufficient guidance or hand holding to build models of sufficient quality for a top tier PhD program (keeping in mind that building the ML models would only be a relatively small portion of my research - I certainly wouldn't expect this to be the case if it was a purely quantitative thesis). To take some basic examples, would they flag if my variables were collinear, heteroskedastic etc\n\nThanks for reading, I'd really value any input! Happy to provide some more details on my (somewhat vague) research proposal if that'd be helpful or of any interest.",
  "I am starting a position as an implementation specialist next week and I was wondering how I could incorporate some tasks on data analytics to this job. \n\nSo a background of what I will be doing is that I will be helping new clients onboard to our company's SAaS products that is suitable on the client's business environment. Ultimately, I will be training them on our products but will implement the software based on their business needs. \n\nI have a background in project management and sales so even though the role seems to be a bit more technical, it's one skill I love to learn as I go through it. I can leverage my skills in project management and sales to get me up to speed on this new role. \n\nBut on the other hand, I would want to incorporate some data analytics task to my job since I've always wanted to go to a more technically-focused career. I know that data analytics will have tasks such as data analysis and dashboard reporting, data processing, and perhaps a little bit of statistics. \n\nI really don't have a formal training on it though I know that the tasks I did in my previous jobs on my own initiative entailed having data analytics tasks. \n\nBut what can you suggest what tools I use to be able to perform data analytics? Even basic excel will do as long as I get to understand the principles of data analytics and by then create a dashboard for my projects/accounts. I'm not sure yet if I will be touching SQL and other database tools but I just want to anticipate as early what I can do to incorporate it in my next role. \n\nThank you so much!",
  "Made my first medium article analyzing my own chess games, tell me what you guys think! Any feedback is greatly appreciated!\n\n&#x200B;\n\n[https://medium.com/@imadahmad97/chessalytics-analyzing-my-chess-games-to-better-understand-my-play-style-d08c75d7fc9b](https://medium.com/@imadahmad97/chessalytics-analyzing-my-chess-games-to-better-understand-my-play-style-d08c75d7fc9b)",
  "I have a problem which involves robots displaying error codes, then they will be taken and a certain fix will be done to them and I need to determine which fixes are the most effective and which are least. I have a variable that defines the performance before and after the fix but I was wondering what model would be best to highlight which fixes in the list have least and most effect. Thank you!!",
  "I\u2019m from a town in the Midwest. For the longest time people had no idea what I do or what data science is. I\u2019m starting to overhear conversations about AI in public, and it\u2019s weird.\n\nInflection point or whatever you want to call it - ChatGPT or otherwise - normal people are becoming aware of the potential. Bringing both excitement and anxiety.\n\nWhat is your take on public perception of AI and how it might affect the field?",
  "I   have a B.E in Computer Science and my main language was JAVA throughout the course. I have learned different languages since then but not in-depth as I have done for JAVA. I will be pivoting to Data Science or Machine learning(Doing both simultaneously). I am doing Courses from Coursera and going through books to learn important concepts of Statistics, Probability, etc. But I lack practical experience in main python programming. I can create the codes I want using google or reading the documentation, but I don't know the syntax in my head. Like I know they exist but I have to them up(For JAVA this is not a major issue).\n\nI  had only basic knowledge of python, but for my job, I created an Automation  Testing framework using SeleniumBase and python without any prior knowledge of the Subject. I could do this as I have experience building mobile applications and web development, going through the documentation and finding solutions on the Internet.\n\nNow the issue is I feel like it would be awkward to google search things during any interview that I will have since I don't know the basic syntax of python(Even though I can create most of the programs that will be requested of me). I know the basics but I struggle with the Lambda function, apply function, the advanced syntax of for loop etc. How do I get good at this? where can I get practice for high-level python without learning what variables or loops are from the beginning?",
  "I'm looking for a reference that I can use to help me select the best model to train based on whatever dataset I'm working with.  Ideally something that shows any pre-processing requirements too.\n\nSomething like a decision tree flow chart.",
  "I was trying to get any insight or examples from industry or even academia on ways to incorporate the traditional DS approach or statistical modeling into the A/B experiment process. At my company, we do some A/B tests where we may test one machine learning algorithm vs another algorithm to see which one performs better on our platform in terms of key metrics. But those models are already built by ML engineers and we are just testing which one performs better. \n\nInstead, what I'm interested is ways to use ML or modeling or help aid in running better/more successful A/B tests or be more efficient in the testing process, etc. For example, in our historical experiments we've ran we have data attributes such as whether the test was successful, the opportunity size estimate for the test (pre-deployment), type of test, target audience used, etc. One example I could think of is using these inputs into a model to predict the probability of success for new experiments in the backlog. Or maybe to help generate a target consumer audience for an experiment. \n\nI'm wondering if anyone has any insights on anything like this or other ways to apply data science approach to aid your experimentation process.",
  "Lately on this sub there have been many \u201csky is falling\u201d posts related to ChatGPT. Most of the posts have drastically overestimated ChatGPT\u2019s current use cases in the industry. What is a capability that if ChatGPT could do it, you would actually worry about the future of the data science field? More specifically worried about mass job loss within the field, if you foresee that.",
  "Just kind of looking for advice more than anything. I\u2019ve been job hunting since September and made it to last round of a few interviews including Amazon, but haven\u2019t gotten any takers. And it seems the longer I\u2019m hunting the fewer interviews I get. At this point I\u2019ve been shotgunning everything on LinkedIn, but haven\u2019t gotten anything in 1.5 months.\n\nI have 2.5 years experience including a couple deployments under my belt with GCP. I have a Physics masters, but no academic ML work. \n\nI feel like I\u2019m on the cusp of finally cracking the interview process, but I need more interviews.\n\nI think my resume looks clean with an active personal project and my LinkedIn looks fine, but isn\u2019t as flashy as some of the ones I\u2019ve seen. \n\nShould I be looking for job differently, pursuing certifications, getting a formal DS Ms, upload more recent code on GitHub, write blogs, network at a meetup? Idk what to do anymore and this is starting to feel hopeless.\n\nAny advice is appreciated",
  "I am having a very difficult time finding work after a big layoff event from my company early in Jan 2023. I have never been laid off before and I am only 3 years into my career as a data scientist/data analyst and I am not sure how to navigate this experience. \n\nI have submitted 52 applications to data scientist (with more analytics focus) and data analytics positions and have interviewed at 7 of the companies. I've tried leveraging my network including: old managers, former coworkers, mutual connections at companies I'm interest in working for, etc. In the meantime I've tried learning some more tools/concepts like DBT, Snowflake, and A/B Testing. I do LeetCode SQL questions and have done some exploration of new packages in Python. \n\nI know finding a job takes patience, especially when there are so many talented individuals on the market right now. I just wanted to get a basis for how long it takes to find a job post-layoff at this time and if I am doing the necessary steps to be employable. Any feedback would be much appreciated!",
  "I've been the lone DS at my company\\~ a year now. We have a 200 person IT department but completely lack any in house data science besides myself.\n\nI spent a few years here as an analyst before becoming DS, so I have good relationships with the business areas, but I just don't know where to start. So far I've tackled some low hanging fruit but I have no clue how to establish an organization wide program, drive business involvement, establish culture, etc. \n\nAny advice or tips?",
  "I just wanted to share it:\nhttps://cims.nyu.edu/~cfgranda/pages/stuff/probability_stats_for_DS.pdf\n\nThis book of lecture notes is simply amazing if you just want to keep the basics sharp or re-learn things from first principles.\nI was amazed when I saw it got so little attention, so I thought I should share it (it's legal, you can see a link from his site https://math.nyu.edu/~cfgranda/pages/publications.html).\n\nFernandez-Granda, Carlos. \"Probability and Statistics for Data Science.\" (2017).",
  "Hi there,\n\nI am a research data scientist, and excited to release a new feature engineering library, designed to help you streamline the process of machine learning even more than before. **Headjack is an open library which provides a ML features transformation based on self-supervised learning models**, similar to huggingface as a hub, but which currently focuses on exchanging features for tabular data models.\n\nCompared to textual data, tabular data are different in that each data set has different column length and attributes, this means that it cannot be typed consistently unlike the token embedded in NLP tasks. Therefore, Headjack is different from NLP\u2019s pre-trained model with single domain transformation, but by performing with two different domain transformations. **In other words, we can perform features transform between two domains without the same key value.** In addition, release the potential of data that is not typically used. For example, enhance the prediction of the Boston housing price task applied in the Titanic domain, or enhance the prediction of the customers churn task applied in the African traffic domain and so on.\n\n[Github](https://github.com/jimliu741523/headjackai-sdk)\n\n[Introduction](https://medium.com/p/385a90ff413c)  \n\n\n&#x200B;\n\n[The IRIS dataset with California House Price Feature Transformation](https://preview.redd.it/kujhd1bkbpia1.png?width=2110&format=png&auto=webp&v=enabled&s=039faa54d7346e4172564bd129985d948a74b7ae)\n\n[The IRIS dataset with Titanic Feature Transformation](https://preview.redd.it/jwlebjrlbpia1.png?width=2102&format=png&auto=webp&v=enabled&s=ec2aa0d06a70337c1fb01defc71d77956720582b)\n\n[The IRIS dataset with KPMG Customer Demorgraphy Feature Transformation](https://preview.redd.it/5tpe76nmbpia1.png?width=2052&format=png&auto=webp&v=enabled&s=d2c7139259d43c8574da4a0ea1a65056dccad916)",
  "Hi, I want to know if it's possible to work in a virtual environment while ssh'ed to google colab. I tried ssh'ing to google colab and did it but when I was going to code a .ipynb file I needed to select the kernel and when I tried selecting the one from my Conda Virtual Environment it did nothing. Wanted to know if it's possible or if I did something wrong. If you know some guide or video that teaches how to do this link it if possible, I already searched but found nothing. Thanks",
  "I have never understood this at all for the life of me.",
  "Need help with detecting data drift in multivariate time series data for many customers. Suppose your dataset has x columns and you have separate datasets for n customers and you need to detect data drift in the fastest way possible without compromising on the quality of the detections. Please help",
  "I once watched a video where someone argued that Michael Jordan had ruined basketball. As a person whose only notions of basketball come from Space Jam, this surprised me. Wasn't the guy the best out there? How could someone who's best in his field ruin it? After hearing the argument out though, I began to understand what the video was really getting at: to them, Michael Jordan had ruined the field BECAUSE he was so good. A sport that was once full of diverse personalities and strategies then turned into multiple teams trying to produce their own Michael Jordan copycat with copycat moves and copycat strategies.\n\nI'm not well versed enough in basketball to know how right or wrong that guy was. But this concept that something could ruin an entire field simply by being too good stuck with me. And all these years later, I consistently think about it while doing my job as a Data Scientist. And the more GPT-X and ChatGPT advance, the more this concept haunts me.\n\nI've been working in this field for 5 years. During the first 4 years, the job was exciting. Every new problem required extensive research on my part: looking for papers, datasets, implementations, implementing my own stuff, experimenting, comparing the results... That was the biggest part of my job. Yeah I still had to do some software engineering stuff here and there, but I felt like I had a well defined and specialized role at my company. Even in the NLP field, the variety of technologies I had to work with was a lot of fun: sometimes I used RNNs, sometimes embedding based similarity functions, sometimes more classic approaches, and then towards the end it was transformer after transformer, but at least I still had to finetune them myself.\n\nOver the past few months and years, this has started to change, however. GPT-1 and 2 were promising, but were more of a proof of concept than anything realistically usable. But with GPT3's and ChatGPT's latest performance, it feels like NLP is becoming more and more standardized. I wouldn't call it a solved field, far from it. But, sadly, unless you work for a big tech company,  I think the days of exploratory research-type work in the NLP field are over.\n\nEven in academia, the latest NLP papers I've seen come out of prestigious universities went from actual engineering/mathematical advances to \"Look, if you \"engineer\" the prompt like this, it works better sometimes!\"\n\nAnd now, with the exploding popularity of ChatGPT, any random lambda would come to the conclusion that if you need to use AI, ChatGPT is the answer.\n\nNow, some of you may already be thinking \"but hold on, with my finetuned transformer I get a 1% increase in accuracy over out-of-the-box GPT-3!\". The thing is: even if you can, it doesn't really matter. I really doubt the sales team of your company is gonna pay much attention to your pleas to give you 6 months to work on a product rather than 6 minutes. Because yes, that's the increase in productivity we're dealing with: What took me months a few years ago only takes minutes now. The range of problems I can apply NLP too has also increased, as out-of-the-box GPT-3 works well enough not to require a dataset for more \"general\" tasks. And the results are either comparable or even better.\n\nIn the span of a year, NLP went from my favorite ML field to one I never see myself working in again if given the choice. And while a lot of non NLP fields are, for now, untouched by the exploding popularity of the GPT family, I'm afraid that what happened to the NLP field will be replicated in other fields, and that in a few years, only super specialized issues won't have a solution somewhere in the form of a ridiculously big model accessible via an API key provided by a big tech company. And even if GPT3 was open source, the sheer size of it makes it close to impossible to realistically train for anything less than the biggest of tech companies out there. Even finetuning it would be a challenge.\n\nI'm not saying the job of data scientist will disappear, in fact, I'd say it will be asked more than ever since boomers who don't understand what the title actually implies will want some in their company. But we won't be doing nearly as much actual data sciency stuff as we did in the past. Instead we'll have to become even bigger software engineer/data analyst/DevOps/project manager hybrids than we already were. The only exception is for people who either work in big tech companies or on very specialized problems that require an in-house model.\n\nIt's not that much of a problem for people who like the roles I listed above. But for people like me, whose enjoyment came out of the exploratory side of the job, I believe the future to be bleak.",
  "I used R/RStudio for basically all my data science needs when I was in a PhD program in ecology. Now I\u2019m considering transitioning away from my career in research to a career in data science (motivated more by work environment flexibility and job availability, rather than money). I\u2019ve been learning Python in my free time recently to broaden my skill set as a data scientist. So far I\u2019ve just been using RStudio as a Python IDE since I\u2019m already familiar with it.\n\nThings have been going fine so far, but I\u2019m curious to know if there are any potential shortcomings of using RStudio for Python that might cause me trouble in the future? I realize learning the programming language is a bigger hurdle than learning to use another IDE in the future. However, I thought I\u2019d ask the question here in case your collective wisdom can save me some headaches down the road.\n\nPS - please don\u2019t turn this into the classic R vs Python argument.",
  "Hi Guys, i have to solve this problem. I have 33869 column in a python daatafame and i wanth to calculate the Pearson Correlation and the p-value compering each column with all the other. I'm searching for an efficient way to accomplish that.  \nI know that the correlation can be calculeted with the pandas.DataFrame.corr() function, but what about the significance of that correlation.  \nI saw that scipy.stats.pearsonr() function is able to calculate the correlation and the p-value, in this case the problem is that i have to do 2 nested for cycles that are time consuming.\n\n Someone can help me?",
  "Hello, my name is Toni and I\u2019m coming from Croatia.\n\nI have a master's degree in Business with specialization in informatics and I am a part-time lecturer at Uni of Business. I have been into trading (forex, stocks, crypto) for many years and I have found a very promising strategy based on Bill Williams\u2019 indicators and I improved it together with my team. The strategy is based on fractal geometry.\n\nI found a team of developers (5 of us, from Europe) 2 years ago and we built a very robust infrastructure in Python (Binance) and MQL4 for MetaTrader platform (forex, index, metals, stocks). We have a backtester that provides us with many detailed statistics. Our backtests are good and I can provide you with samples; however, we are looking for a Statistician or Data Scientist to join our team to help us to interpret the data and do magic with numbers.\n\nThis is not a paid job, but we all share the source code as our reward and you can use it for your own purpose. I am also here to learn about data science and statistics and we are willing to discuss anything regarding trading (any stock tickers or forex, etc.), about trading bots. Feel free to ask anything!",
  "Fortunately I realised data is my passion and shifted my career towards in 2019, not bad timing I assume. Also had my master in data science and did a bootcamp. However, the companies I have worked for were not as I expected. Despite the fact that I did my best that I could, I feel that there are still a lot to learn. In my pov, the pace companies (except FAANG) have  in terms of development of AI not even close. Am I being impatient or focusing on wrong here? or should I look for other job opportunities. What are you looking for or; what are your criteria as an data person(Ai, DS, DE, MLE, DA)when you are applying jobs? Would love to see your opinions and constructive feedback",
  "Hi there,\n\n## Share notebook with non-technical users (managers)\n\nSharing results from Jupyter Notebook might be a pain:\n\n- you can't share notebook to stakeholders because they don't speak Python, cant run notebook by their own,\n\n- you need to copy-paste charts into PowerPoint presentation,\n\n- you need to rewrite your results to some web framework to make your results interactive.\n\n\nJupyter project offers a Voila as a solution for running notebooks as web apps. I found Voila a difficult to use, especially ipywidgets.\n\n## Mercury \n\nI started to work on my own open-source framework for running notebooks as web apps. Mercury allows you to add interactive widgets in Python notebooks, so you can share notebooks as web applications. It offers a set of widgets with simple re-execution of cells.\n\nGitHub repository: [github.com/mljar/mercury](https://github.com/mljar/mercury)\n\nDocumentation: [RunMercury.com](https://RunMercury.com)\n\n## What you can build\n\nYou can use Mercury Widgets to create:\n\n- [web apps](https://runmercury.com/tutorials/web-app-python-jupyter-notebook/), reports, dashboards,\n\n- [presentations](https://runmercury.com/tutorials/presentation-python-jupyter-notebook/) - use widgets to interact with slides, slides are recomputed during the slideshow\n\n- [websites](https://runmercury.com/tutorials/website-python-jupyter-notebook/) - share notebook as static HTML (with code hidden), \n\n## Features\n\nUnique features that make Mercury different than Voila or Streamlit\n\n- simple re-execution of cells after widget update,\n\n- all input widgets are displayed in the sidebar, your app layout is ready,\n\n- authentication to control access to notebooks (coming soon),\n\n- easy file upload and download in notebook,\n\n- export result to PDF or HTML with button click.\n\n\n## Future plans\n\nI would like to provide a cloud service for notebook deployment. You will upload notebook and it will be available as web app/website.\n\n\n\nLooking for your feedback and comments! Thank you!",
  "I just got my PhD (not in CS or DS) and I'm looking for data science / engineer jobs. I found that many jobs require AWS and Sql experience. Unfortunately, my past research experience doesn't involve any of those.  Is there a way to gain some experience in using them for real world data. I appreciate it!",
  "**Long story short:** I have a PhD in Mathematics and at the moment, I'm working as a Postdoc. However, I am seriously thinking of joining the data science club due to its increasing popularity as well as its broad spectrum of career options. My question as the title suggests is how to achieve that in the most optimal way for my personal case.\n\n&#x200B;\n\n**A few more details about my background:** My research interests lie in the field of Partial Differential Equations and Analysis. This in particular implies that I am not that familiar with Probability&Stats. I did have some courses in my bachelor but that's it. I am definitely more comfortable with multivariable calculus and linear algebra for instance. Regarding programming, I know python and I have worked with libraries like numpy, pandas and matplotlib in the past. I do not know any SQL nor Machine Learning yet. I do enjoy anything that involves programming so far.\n\n&#x200B;\n\n**My initial plan:** In the beginning, I thought (maybe a bit naively) to just start learning the most essential skills needed by myself and after a point start doing some projects on my own. To be honest, I would prefer better to follow an online degree or something similar but I am certainly on a budget here. So, instead I downloaded some books and saved some tutorials in YouTube for later use. However, this path of self-education feels just not right. I am continuously contemplating if I chose the appropriate books/sources, plus I am not sure which exact project I should aim to solve later.\n\n&#x200B;\n\n**Current plan:** A few days ago, I came across with this program: [https://www.udacity.com/course/data-scientist-nanodegree--nd025](https://www.udacity.com/course/data-scientist-nanodegree--nd025) (definitely not an ad here). It has plenty of prerequisites which only half of them I already know. It does offer the option of building several projects, although I am not sure if they cover a lot of significant data science topics. A huge drawback for me is the price, as I mentioned I 'm on a budget here.  However, I started thinking that as long as I become familiar with all the prerequisites, maybe following this program is a more efficient (and cheaper compared to other degrees) way to transition into data science.\n\n&#x200B;\n\n**Questions:**\n\n1. Is this degree actually worth it or will I waste my money? Any other (more useful) suggestion is welcome.\n2. To the experienced ones out there: given my situation, *what would be the most optimal way to make such a transition into data science?*  To be honest, I would prefer the parts of data science that involve more programming but as I am complete new to this huge field, I have no clue if such parts exist, which are exactly and if my academic qualifications would matter (salary-wise) at all there.\n\n&#x200B;\n\nMany many thanks in advance for your time. Any help is much appreciated!",
  "Edit: **Working to become a data analyst**\n\nI\u2019m just getting into the field with absolutely no background knowledge. I\u2019ve worked in restaurants and bars my whole life but found a real love for the subject after discovering it. \n\nI\u2019ve worked my ass off to get through and retain everything in the google data analyst cert and have picked up basic spreadsheet, sql, tableau, and Rstudio knowledge, and I\u2019m now using that to do whatever projects and little practice experiments with what I have learned. \n\nI guess I\u2019m looking for advice from those much more experienced than I am in where to go from here?\n\nHow would you go about getting a job from here? Are there specific tools should I add to my skill set? Best practices for personal projects/portfolio? Courses you recommended? Books? Communities to be active in (e.g. kaggle?) Best method of networking? Ways to practice skills?  Mentoring? Anything you wish you realized when starting it? \n\nI\u2019m so excited to break into this role and have found every part of what goes into it so interesting! Thank you so much in advance for any advice you may offer!",
  "Hello guys, is there any baseline best ways to make regression and handle missing values? For example for big data sets is k-NN or random forest with hyper parameter tuning? What\u2019s the top 3 or 5 go to for example? Also for handling the missing values are there any best ways to handle them in R and Python? I know multiple imputations is a great choice but only for Missing At Random and I know it\u2019s mostly used in R and not in python. Can you specify the best ways and when they are best used? For example Random Forest has the best speed and accuracy for big data while k-NN is better for binary regression,etc",
  "What are the usual pre-processing stuff do you deal with in real world data? Are there any videos or blogs dealing with this in detail?",
  "I realise I have bad communication skills. Being non native speaker, I struggle to put my points across. I also have issue with jumping around different details, while explaining stuffs. I know some of these issue are solvable. I am working on it, but it is hard! But I am good at technical skills. I say this, because I have been xxx companies in my short career in data science, I have seen I do as well as many senior data scientists in the team. I feel comfortable with tech, learning and explaining tech. My fear is the more experience I get, good  communication on regular basis become Bread and butter of data scientist. And it will huge hindrance in career progression, even if I get senior position, I feel it will make my life miserable. \n\nI am pretty old \ud83d\ude05 don\u2019t want be miserable, by forcing myself to situations I do not enjoy. Especially which require fundamental change in thought process and ways of talking.\n\nSo I am thinking I can pivot my career to more engineering focused role. I understand at senior level those roles also become communication heavy, but I feel it will be far less that data science career path. Is that correct way of thinking? I plan to move into Mlops or Ml engineering roles.\n\nDoes anyone goes through this kind of thoughts, how do you deal with, and how you plan your future given your realisation about yourself. \n\nThank you",
  "Having an interview for the role of a data scientist tomorrow since after I passed their technical test, I have an idea of what to expect but I want to make sure I dont get caught off-gaurd, so what are some questions in your interviews that caught you off-gaurd and made you wish that you had prepared more?   \nbtw heres the direct quote from their email: \"In this interview we will partially circle back to the technical test, but of course we will also just take the chance to get to know you a bit better.\" \n\nHas anyone had any experiences with such an interview?\n\nThis is a company that I'd really like to be a part of, that's why I'm abit nervous about this.",
  "Title says the tl;dr\n\nWhat books, articles do you consider really good, or general \"Damn I wish someone had told me this when I was starting\" do you consider indispensable now?\n\n**Way too long-winded version**   \nI have been in a position for a couple of years that I like, except that I am the only data scientist in the company.  I got a great job offer that I'm starting in a couple of weeks to work with a team of people on a software platform for data analysis and visualization. I will be the person sort of taking lead on organizing and managing the project, but also contributing. However, the others are more skilled than I am right now, and it will likely take me some time to ramp up to their level. \n\nWhat are the best resources out there for how to flexibly lead a project? What is your advice you wish you had when you started in a similar situation? I am not really asking about git/github type stuff I am pretty familiar with that. I'm more concerned about the \"soft\" skills of people handling and even things like keeping egos from clashing and optimizing team performance.\n\n I want to help the team be their best, by helping individuals show their strengths, and sort of get out of their way (though I will also become the main contributor to this project: it is a very small team of programmers, so I'm not just a project manager by any means). \n\nThese are *really* good people I'll be working with and for. I want to do a good job helping create a great product, and not blow it because, e.g., I didn't handle interpersonal dynamics well. I have seen teams go down some very dark and painful paths (e.g., psychological hell for months on end), because subtle psychological incompatibilities became amplified and mutated into monsters when not addressed. I really don't want that to happen I'd love to be part of a happy thriving team that's excited to get shit done!\n\nI'm an ambivert (not hyper introverted or extroverted, sort of in the middle), in case you are wondering, or in case that matters.",
  "Hi all,\n\nWhat is a Semantic Layer?",
  "I\u2019ve been working at a company for about a year and a half, the team team I\u2019m on is supposed to be integrated with other teams cross functionally but the director of my skip level team is painfully bad at\u2026well\u2026directing. There doesn\u2019t appear to be any process to how teams are supposed to work together. He\u2019s produced no guidance or overview or set his priorities for work. \n\nWhat results is that an escalation will be forwarded to some teams to work on individually while other teams find out about an escalation only through rapid fire messaging or through another team. \n\nTeams duplicate work because nobody is placed in charge to manage the escalation. So multiple reports are generated on a single escalation and nobody really knows who the stakeholders are nor have they worked with them in any capacity. Basically everyone tries to answer any possible questions because no specific question is asked. \n\nI\u2019m confident this issue is at my skip level and not my first line leader who is often as confused as I am about how to proceed when someone just says \u201cdo data science\u201d with no meeting or planning or scoping of any kind. \n\nMy boss is concerned for his job so I don\u2019t think he\u2019s going to go to bat and there needs to be some direction from my skip otherwise I risk just doing tons of work for little return on investment. \n\nShould I reach out to my skip and go around my boss? Should I go above my skip? Maybe I\u2019m in a bind here and I either suck it up or look elsewhere. I like my company but this kinda stinks.",
  "I\u2019ll be a little vague but you can probably guess the scenario. I\u2019m working for a govt agency that maintains several temporary locations for residents to drop off important forms. The location from which each form was collected is recorded. This information is also associated with the resident\u2019s address information. Therefore, I should be able to determine the average distance (from home) that a resident had to travel to reach their drop off location. This information will help to assess the placement of drop off locations to best serve the community. \n\nI\u2019ve never worked with GIS data before. Are there Python packages I can work with to obtain the information I\u2019m looking for?",
  "has anyone done predictive maintenance without failure data? in the data we're suppose to have,  there's no failure data but an estimated threshold that indicates when the machinery is about to get into a failure state.\n\nI found in the [matlab](https://la.mathworks.com/company/newsletters/articles/three-ways-to-estimate-remaining-useful-life-for-predictive-maintenance.html) doc that one of the ways to estimate Remaining Useful Life is a model where the available data has a known threshold value that detects failure but I haven't found examples of that. All I happen to find is Run-to-failure datasets and examples, which are not useful for my application",
  "I am about to be owner of a \u201crushed\u201d solution the business needed. \nIt\u2019s a dashboard that has multiple tabs and feeds from hundreds of tables from our RPA system. \nThe data it provides is very critical for making sound business decisions, and more and more people is using it now.\nThe documentation it has is very poor, and there is no frequent/scheduled health check of the data.\n\nIs there any guide with best practices about how to ensure this dashboard \u201cworks well\u201d and that can give me some peace it won\u2019t be guiding the commercial guys to sign bad contracts?",
  "Does anybody here know an API where you input a street/city name and get relevant weather data (historical, current, maybe a few days prediction)?  \n\n\nI know of pirateweather API, however that takes coordinates. I would prefer not to use a different API to translate addresses into coordinates and then get the weather data.  \n\n\nI have around 50k unique addresses so inputting by hand wont cut it.   \n\n\nIf no such API exists what are your recommendations of free APIs to translate addresses into coordinates (preferably free)?",
  "What tools have you found best to share/sync data files with others on your team? For example, say you have 2,000 csv files, each one being about 1-2 MB.  Git might work, but it's not great at handling this amount of data and eventually the repo will get very large.",
  "As the title says, I've been in my first data science role for about 6 months. This post is mainly just to ask whether what I'm experiencing is common within professional data science. \n\nThe main crux of my role is deriving datasets from raw data. It might be as simple as creating flags based on the value within a column or it could be a little more involved with summarising and cross-tabbing. The thing is, once I've created the dataset and it's been QA'ed and sent off, I don't actually do any analysis to it. I don't look for insights or interesting features or make predictions, perhaps the only EDA I do is to look for anomalies to make sure something hasn't gone wrong in the processing. \n\nMy first proper project in the first few months was to create one such dataset, once that was finished I was then put onto recreating an existing dataset using different and more reusable data sources. Our department has a data engineering and data modelling team which also derive some datasets but I've never had to use them as I never seem to do any actual analysis. \n\nBasically, is this normal? I anticipated that lots of the job would be data cleaning and manipulation, but I seem to be doing the bulk of the actual coding and putting together of the data without then getting to do anything with it. I don't think I've even made a histogram yet. \n\nWhat is frustrating is that there's a fairly sizeable bonus to salary offered if you can demonstrate that you're using advanced data science or analytical techniques, however I rarely (if ever) get the opportunity to actually use them therefore I doubt I'll be able to get the bonus.\n\nI'm weighing up my options. I'd like to stick around for at least a year and there's the potential to go up to senior data scientist. What I'm missing currently to go up to senior are the usual soft skills like interdepartmental communication, managing projects, time management and decision making. All things which I would build up if I stick at this job, what I'm concerned about is how my actual data science projects would translate to applying to other companies in the future. I don't get any nice buzz sentences like \"my findings led to a saving of x% over the year\" or \"I was able to predict with x% accuracy this variable\". \n\nAny advice?",
  "Hello All, I have been assigned to create a forecasting product from demand data of products.  We have demand data of 8.5 million products. And I am approaching the problem as univariate at first and then I will approach it as multivariate.  However there are so many things to learn.  I am wondering if there is any detailed source you guys can recommend.\n\nI am junior ds. Been reading a lot about this and have a vague plan. I just need to fill the blanks and solidify my plan.",
  "One very useful benefit I found with ChatGPT for job seekers is asking it to serve as a Hiring Manager that asks you questions for the specific role you're interested in.\n\nTo help it guide you, you need to provide it with some context based on the job description. For example, you list out the job description to ChatGPT and say that you want to be asked questions on causality and experimentation.\n\nHere's the response from ChatGPT based on the following prompt I provided it after sharing the job description:\n\n===**PROMPT BY ME===**\n\n>I would like you to be a hiring manager. I'll be soon interviewing with you for a Data Science role, and you are going to ask me questions related to causality and experimentation. What are the questions you would ask to test my knowledge?\n\n**==RESPONSE BY CHATGPT===**\n\nSure! As a hiring manager for a data science role, I would like to assess your understanding of causality and experimentation. Here are a few questions I might ask:\n\n1. Can you explain the difference between correlation and causation, and give an example of each?\n2. How do you design an experiment to test a causal hypothesis?\n3. How do you ensure that the results of an experiment are valid and reliable?\n4. Can you explain the concept of confounding variables, and how do you control for them in an experiment?\n5. Can you explain the difference between a randomized controlled trial (RCT) and an observational study?\n6. How do you measure the impact of a treatment or intervention in an experiment?\n7. Have you worked with any causal inference methods such as propensity score matching or instrumental variables? Can you give an example of when you used them?\n8. How do you determine which variables to include in an experiment, and how do you avoid overfitting in the modeling process?\n9. Can you discuss any challenges or limitations you have encountered in designing and conducting experiments, and how you overcame them?\n10. Can you give an example of a real-world scenario in which you applied causal inference or experimentation methods to solve a business problem?\n\n====\n\nYou can ask ChatGPT to provide a summary answer for each. However, I would highly recommend you validate the answers by researching as well as ChatGPT can give confident, wrong answers.\n\nHope this helps others!",
  "I knew that I wanted to do something data-related (or computer science-based) for a long time, but unfortunately my undergrad major was completely unrelated to DS. I self-taught myself Python/R while working a marketing job and was suuper fortunate to get into a DS/DA Master\u2019s Program at one of the Ivy League schools. I worked 24/7 to learn a ton about best data practices/tools, had 2 DS co-ops, generated a ton of material for my GitHub, etc.\n\nObviously, just finishing a Master\u2019s program isn\u2019t enough to enter DS, so my career counselor recommended me to \u201ctake a data analyst job at a low-maturity company, use your skills to upgrade the way they use data, become a data rockstar and you\u2019ll get all kinds of doors opened in no time.\u201d **Spoiler** \\- *I did not become a data rockstar*.\n\nI landed a marketing analyst position at a large insurance company, and, long story short, this job is just a mess. My boss is a lifer that recently celebrated 20 years in the same position at the same company and got promoted to manager right as I joined. 30% of my work is shuffling around Excel sheets/making ugly (because the style is regulated) PowerPoints, another 30% is attending useless meetings that she sets up for me to \u201chear what conversations are happening around here\u201d; 20% is making sense of the broken SPSS code that someone wrote for her 15 years ago; the rest of the time is allocated to using Power BI, SQL and R to pull data from various sources and create reports for the internal stakeholders.\n\nNothing at my job is Googlable because all of the processes are either created by someone from 20 years ago or my manager herself; each process can require up to 100 little steps of moving data between million Excel spreadsheets populated with billion formulas making it impossible to comprehend or even load. The documentation she provides me with is always incorrect/incomplete, forcing me to ask for her help, as it would take me many hours to figure this out myself. When I try to do things my way, she gets clearly upset and sometimes starts micromanaging me, making us miss a ton of deadlines just for the sake of making everything look perfect according to the internal standards.\u00a0\n\nI spend a ton of time outside of work hours (the last one to leave the office every single day) trying to make time for extra DS projects but the amount of \u201chigh-priority\u201d tasks I get assigned is too overwhelming. The most technical thing I've done is used VDI to automate an R script that imports a bunch of files, anti-joins them and outputs certain distributions into an Excel doc, but that was a one-time project. I told my manager that I enjoy coding the most and she promised to land me a \u201ccoding-heavy\u201d project with the DS team. However, I followed up 3 times throughout a month and she ended up telling me that the person who asked for help decided to leave the company (jeez I wonder why.)\u00a0\n\nI get so much stress from a seemingly \u201ceasy\u201d job (no one seems to care that everything is 2+ weeks past due or indefinitely undelivered) because I\u2019m trying so hard to get a chance to make an impact and have at least something I can use when applying for DS roles after hitting that 1-year mark. I\u2019m afraid that the advanced skills I acquired are slowly fading away and I\u2019m learning a lot of bad habits from my manager.\n\nWhat would you recommend in my situation to stay on the right track? I usually work through my lunch breaks too (I know, I know), but I had an idea of maybe using that time to read a stats book or something DS-related - any suggestions? Any advice is appreciated :)\n\nEdit: the reason I put \"Ivy League School\" is because, a couple of months ago, my manager gave me an impossible task; I asked for a suggestion on how to better approach this task, and she responded with \"well, I'm not the one with the Master's Degree from the Ivy Leagues.\" I got so butthurt from this because I haven't brought it up once since joining the company lol.\n\nTLDR: want to break into DS through low-maturity analytics job but feeling like it has a negative effect on my career potential - tips?\u00a0",
  "Hey Fellow Redditors!\nAnyone interested in sharing an interview query subscription?\nDm me for more details!\n\nThanks.",
  "How should I go about Forecasting Estimates.\n\nI\u2019m building a custom forecast using QuickBooks & Hubspot\u2019s API\n\nMy X axis of my chart consists of the following data:\n\nActual: Revenue\nExpected: (0.5 x (Deal Probability x Deal Value) + Revenue) + (\nNew: Deal Probability x Deal Value\n\nMy Y axis is each month.\n\nMy question is I want to track revenue from closed deals, but the final 50% of the closed deal, as you can see I\u2019m tracking the first 50% in expected. \n\nI thought about using estimates as that income is guaranteed within the next 2 months, but invoices do not exist for them yet. So for income where I know is guaranteed for X day of the month, this isn\u2019t tracked in quickbooks.\n\nThe issue with using estimates is as soon as the invoice is made, the estimate total doesn\u2019t go down. So I can\u2019t go the estimate route because it\u2019ll create duplicate income.\n\nI suppose i can track this manually? But the whole goal is automating this.\n\nAny ideas? Sorry if I explained poorly :/\n\nEdit: I could only update the actual at the end of the month then not include revenue in the expected potentially? But then that wouldn\u2019t catch all my smaller transactions and it would always be 15% off or so.",
  " I'm working on a task of classifying text complaints and I extracted some features like Named Entities, Events, Time Expressions, Semantic Role Labels, etc. I want to classify the text according to these features. My question is how do I encode this data in order to feed it to a classifier?\n\nHere is examples of data extracted:  \nnamed\\_entities: (FedEx, Israel, Paris) , (Zara, London, Chris), ...\n\ntime\\_expressions: ('2021-08-31', '31/08/2021') , ('30 August', '2019'), ...\n\nsrl: {\"verbs\": \\[{\"verb\": \"write\", \"description\": \"I \\[V: write\\] \\[A1: a complaint\\] \\[A2: to FedEx\\] .\", \"tags\": \\[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-A1\", \"I-A1\", \"B-A2\", \"I-A2\", \"O\"\\]}\\], \"words\": \\[\"I\", \"to\", \"FedEx\", \".\"\\]}, {}, ...\n\nevents: {'T1': 'come', 'T2': 'present', 'T3': 'send','T4': 'destination','T5': 'instrument'}, {'T1': 'loader', 'T2': 'bearer', 'T3': 'cargo'} , ...\n\nPreviously I used word embeddings to encode the full text but now that the information is in vectors I don't know how to proceed.",
  "hey, im currently a 3rd year data science student looking to improve my DSA skills. I have some knowledge about DSA in C++ but i find C++ quite hard. i came across [this](https://www.udemy.com/course/data-structures-and-algorithms-bootcamp-in-python/) course which is DSA using python. Seem to cover most of the topics and has coding exercises and a few projects as well.\n\n&#x200B;\n\nhttps://preview.redd.it/dzyq3sdbn4ia1.png?width=1919&format=png&auto=webp&v=enabled&s=2b77018ed3f7b99efadc2097c62725ed58034df1\n\nCan anyone share their experience if they have taken this course? is it worth it? Thanks!",
  "So I am a finance enthusiast and would check American market data in dashboards in the countless free products that exist.\n\nHowever, being in a country with ridiculous foreign exchange policies, the government keeps blocking every service or broker I use so I am locked out of the international markets.\n\nI started looking at local companies and there is only One single brokerage app that is remotely viable and the data absolutely sucks. I was trying to web scrape the data from companies' websites and faced a few issues:\n\n1. Every company website is different and they do not all have the \"Investor relations\" page in the same place. How can I write one program to get the data of all the listed stocks? which are around\n2. All the websites I checked had the data in pdf documents that you download. This was a problem since I was trying to get the data right off the website HTML  and javascript code. The documents are also full of useless pages I do not need. I only need the tables.\n3. Let's say I download the documents and want to visualize the data and put it into dashboards. how would I extract information from documents in that scanned format?\n\nI can't find specific information on this because the entire modern world can just use **APIs** to get this kind of data. I am absolutely certain that does not exist for the Egyptian exchange. At least at a price below thousands of dollars.\n\nWhat can I start doing in order to collect this kind of data? It must be possible. I know organizations are capable of scraping the web for incredible amounts of data and useful information. How do they do it and how are these **APIs** made?\n\nHere is an example IR page for a company I'm interested in :\n\n[Telecom Egypt :: Investor Relations](https://ir.te.eg/en/)\n\n**Please Upvote so more people would see this.**",
  "Hi, I want to start my first projects for my portfolio. Do the data need to be somewhat new or collected by me either from polls or whatever or with APIS? Also has the code have to be unique than others? Because I am not thaaat good(still a student) to code something great or whatever and I feel like my effort will be something no one will see because it\u2019ll be something an experienced data science could manage In 30 minutes and I\u2019m getting disheartened.",
  "I have a day job in STEM and I use python to manage large data for my job. I can manage most of my needs by searching stackoverflow and piecing it together. I can see myself as someone between beginner to intermediate level with python. I am actively learning but I think having a certificate will boost my CV/career. Or, lets say if I want to consider a second supporting career as data scientist what I should learn, which certificate I should get? Any recommendations? Apologies, since you might get this question a lot.",
  "We're trying to analyze how various social factors influence our health insurance affordability and the rules say we need a data dictionary and we don't understand how to implement it.",
  "So, I started using ChatGPT to gather literature references for my scientific project. Love the information it gives me, clear, accurate and so far correct. It will also give me papers supporting these findings when asked. \n\nHOWEVER, none of these papers actually exist. I can't find them on google scholar, google, or anywhere else. They can't be found by title or author names. When I ask it for a DOI it happily provides one, but it either is not taken or leads to a different paper that has nothing to do with the topic. I thought translations from different languages could be the cause and it was actually a thing for some papers, but not even the english ones could be traced anywhere online.\n\nDoes ChatGPR just generate random papers that look damn much like real ones?\n\nhttps://preview.redd.it/s8sa42mzixha1.png?width=824&format=png&auto=webp&v=enabled&s=70dfc38d58b6219ea4d494142e5f9e4b75e92a7a",
  "I have a very sparse matrix of users products, 120 users and 4000 products. each cell represents the users purchases of that specific product. \n\nEach month purchases are represented by a separate matrix, assuming the missing values represent  purchases that are not captured. How do I produce an estimate for purchases for each missing user/product pair?  \n\nEX:\n\nmatrix\\_1: has the purchases of users for different products in January\n\nmatrix\\_2: has the purchases of users for different products  in February\n\nmatrix\\_1: has the purchases of users for different products  in March\n\netc\n\n..\n\n..\n\nIs it a valid approach to have a single matrix for each month, or should we combine them somehow into a single matrix to capture the temporal nature of the problem?",
  "Should job posting with mentions of these tools be ignored or are they useful for a data scientists?",
  "Hello,\n\nMost of the time I only have my old laptop available without a dGPU and a 5 year old I7 dual core.\n\nTraining on the thing takes lots of time. What could you suggest for training models online?\nMy datasets are often in the 2-10gb Range. I don\u2019t have a problem to pay like 30-50 Euros monthly.\n\nI heard colab pro was super good but since they changed to the compute units model it got pretty meh? Or is it still good? Otherwise I heard about paperclip. \n\nWhat else can you recommend? I only want to train models online and then export them using joblib. I am also a Student just in Case there are some nice discounts. \n\nAppreciate any help!",
  "I'm searching something like Leetcode for practicing Data Science, no only SQL problems also calculus, statistics and thing like that.  \n\n\nAny recommendation?   \nPS: I dont care if i have to pay",
  "I\u2019m trying create a predictive model for a binary outcome (yes or no).\nI have 16 predictor variables, which are a combination of categorical and continuous variables. How do I go about deciding which to include in my model?\n\nI can\u2019t find any literature on the requirements/assumptions of x in a logistic regression. I\u2019m modelling in R therefore I can\u2019t really add all variables and use a Backwards/Forwards variable selection method used in programs such as SAS.\n\n\nAppreciate any assistance!",
  "Hi,\n\nI wrote 2 posts together with 2 colleagues on how to solve a compression problem from the insurance industry. We applied the Simplex algorithm to compress the number of model points (every model point is an insurance contract component like life-insurance) and fit them to our benchmark. \n\nHope it's ok to post this here, we'd like to get some input on our approach :)\n\n[https://medium.com/@patrick\\_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc](https://medium.com/@patrick_hoefler/optimizing-model-points-of-a-life-insurance-portfolio-e9a61f01c5bc)",
  "I'm looking for a free/open source alternative to AWS data wrangler.\nI'd like a unified platform where to:\n- visualize the data, possibly from multiple data sources and pre-configured visualizations\n- preprocess the data with no code solutions, but with the possibility to add code and export the data transformation in python code\n\nDoes anything like this exist?",
  "I want to set up a ci/cd workflow for databricks, using github actions. There seems to be a couple of main choices. \n\n* Either executing the code using the runNotebook action, so the code runs on my existing databricks cluster. I am worried that this will be a bit hacky, as I would have to rely on running scripts from the notebook instead of just regular old python scripts. Getting results back and forth from the notebook to the vm running from github actions also seeems like a hurdle to implementing a good script.\n* Or setting up the yaml to replicate the databricks environment on the virtual machine that github actions spins up. I have tried the latter, but I struggle to get all the versions of java, scala, spark, pyton, packages etc to be identical an have my code execute without issue.\n\nI mainly have access to using databricks to write code, but I could consider using vscode on a local or virtual machine, or even coder as a web based alternative. Setting up a workflow using vscode and dbx is an option, but I do not want to use conda at the moment, which is what the quickstart seems to require.   \n\n\nWhat approach would you recommend? running on the existing cluster or setting up an identical environment in the yaml that fires up a vm in github actions?",
  "Hello all,\n\nAnswering  questions based on domain knowledge (like internal documentation,  contracts, books, etc.) is challenging because of the size of the domain  knowledge.\n\nAs you might know,  Transformer-based models are limited in terms of input size (most of the  time it's hard to use more than 2048 tokens). So you cannot really do  question answering on a huge knowledge base with these models.\n\nYou  can try to fine-tune your own text generation model for that (like  GPT-3, GPT-J, etc.) but results are sometimes disappointing as the  fine-tuned models tends to forget some of the facts mentioned in the  dataset...\n\nAt NLP Cloud, the  strategy we prefer is about mixing semantic search and question  answering. Here is a quick article about how to do it:\n\n[https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html](https://nlpcloud.com/question-answering-on-domain-knowledge-with-semantic-search-and-text-generation.html?utm_source=reddit&utm_campaign=h5d7a9cc-3816-11ed-a261-0242ac140006)\n\nAs far as we know, this is the best way to get both a fluent and user friendly answer while being very accurate.\n\nI would love to hear your thoughts on this. Can you think of a better strategy for question answering on very large documents?\n\nJulien",
  "Hey guys, I am a sophomore in college who knows python decently well and is beginning to learn R. Would you recommend continuing to learn languages or to learn skills like reinforcement learning? Any help or advice would be greatly appreciated!",
  "I prompted ChatGPT to act like Foghorn Leghorn in character both verbally and emotionally to some questions. This was a surprising answer..\n\n\nDo you think Google loves ChatGPT-3?\n\nWell now, I reckon Google might have a soft spot for ol\u2019 ChatGPT-3, son. It\u2019s a powerful tool and I reckon they\u2019re right proud of it! But you can never be too sure with them big tech companies, they\u2019re always up to somethin\u2019.",
  "Hey guys,\n\nRecently I have been interviewing with some companies for DS roles, and there were many case studies involved. When given the case and not much data (just might be a basic graph), how do you come up with the hypotheses and draw conclusions quickly? The tasks are generally interesting given the time and the data, but having to answer on spot throws me off.",
  "Hello, I'm currently in my 6 month journey learning DS( I come from a mechanical engineering background), and I was wondering what tools/topics should I focus on if I want to get an entry level job in data science in the field of cancer research? \nIf anyone had an idea about this topic I would really appreciate your insight. Thank you!",
  "I am looking for help and opinions on where to start with getting some \u201everified\u201c background on data science (besides doing Bachelors/Masters). Are there any courses / trainings / bootcamps that provide a good start as well as a (kind of) official certificate?\n\nBackground: I did my bachelors in applied linguistics (statistics was a big part of it, eg linear regression on text corpora to determine readability) and have an MBA. Currently I am working in a Compliance/Risk Management Team and kind of drifted to a data analysis side role. Regularly I write sql code to extract data from our databases and see what we can learn from it. As I had no prior experience, I learned it from scratch by trial and error, asking around and some online tutorials. \n\nI have of lot of fun doing this (exploring data, writing code) and am looking to steer my career towards that direction more. For starters, I was thinking of doing something official and have some training budget to spend. Hence my question: do you have any tips on trainings that also issue certificates (ideally stuff that means sth). I am typically more of a hands on guy and don\u2019t think doing a 800\u20ac training is better than learning with coursera - but maybe I can have it both?what do you guys think? Is that a good idea?  or should I just do a python bootcamp and start from there? I don\u2019t know much about the field in general and have just started gathering information so any related tips are also highly appreciated.\n(Ofc I did some googling but I am overwhelmed and would appreciate your expertise)",
  "I've been asked to take a metis ACE and MPA test before an interview and I'm wondering how to approach it.\n\nBeen practising a bit today and mainly I wonder if I should just answer truthfully to the questions or if I should e.g. google which answers that are considered \"good analytical personality\"?\n\nFirst time I've come across one of these during my job hunting, kinda happy that they seem somewhat rare here.",
  "[This paper](https://arxiv.org/abs/2112.13299) is super interesting, and by the same author who introduced CUPED.\n\nIn short, experiments with one sided non-compliance can result in a watered down ATE due to few users actually engaging with the treatment.  This paper builds on the instrumental variables literature (which we leverage a lot for these types of experiments) to use cuped to further reduce variance.\n\nIts super interesting and really useful for those of us who run experiments and need to increase precision of our estimates.  Best of all, there is some fairly food code attached as a footnote.",
  "I barely cared about internships and work experience. Im in my fourth year of college and I realized I should have done more. So I found out how to make my own projects and portfolio. Finally, landed my first unpaid DS + machine learning intern spot. Excited to learn on the job, but how should I be climbing up the ladder to better positions with better pay. The internship is a small commitment under 10 hours a week. What should I be doing on the side?",
  "Well, this is part of my plan to deal with one of my biggest and undesired flaws: introspectiveness. My idea is to share my skills and knowledge about Data Science with the community and receive its feedback.\nNot surprisingly, I got stuck trying to figure out an idea for the very first video. I end up classifying any subject that I can think of in two ways: either too simple to be interesting or too complex to be understandable. My best bet would be to make a video about data visualization, but I don't know how deep I should go in my explanation.\nDo you guys have any idea?",
  "Hi all, I'd love some clarification on these dimensionality reduction methods. I see PCA/PCR recommended as the go-to method for this type of task and almost never see people talk about using PLS to get principal components. It's my understanding that the key difference is that PLS considers the target when making components. \n\nIntuitively, I feel like this would make PLS stronger in many datasets, as it uses more of the available information to better inform the creation of components. I'm not an expert here and don't actually have a ton of expertise with how either of these methods work on a deep level, so any feedback from more experienced data scientists would be much appreciated. Thanks in advance for any thoughts or opinions here!",
  "Been getting a tad annoyed with Conda lately, at least as a package manager. So I wanted to hear what everyone else likes to use.",
  "I had an interview with an interesting question. I had a solution that would have worked which would have required a recursive query, but the interviewer said there is a simpler solution. I was wondering if anyone here could figure it out\n\nFour column table:\n\n     1. UserID- unique string\n     2. Device Id- unique string\n     3. session_start_time- timestamp\n     4. session_end_time- timestamp\n\nIt's possible for users with different deviceIds to have overlapping sessions. \nThe goal is to have one row per user per overlapping session.\nSo let's say that I have a session on my phone from 10:30-11:30, and on my computer from 10:45-11:45. The goal would be to aggregate this into a single row:\n\n     UserId|session_start|session_end\n     aaquad|10:30|11:45\n\nMy strategy was to use a lag to bring up the next row in order to be able to compare them- and the recursion would have been required in cases where a user had 3 or more overlapping sessions. But according to the interviewer, there is a different solution (I asked and did not get the answer).\n\nAny ideas?",
  "With the proliferation of LLMs like ChatGPT or whatever it is Google is calling their primary LLM these days (LAMDA or otherwise), do people think this will change the market for data scientists? In one world, the market basically stays the same, as more hardcore AI researchers inventing LLMs and cutting edge work remain concentrated in Big Tech. Then more \u201cnormal\u201d data science work remains the same elsewhere. In another world, LLMs replace lower level data science work and either decrease demand for data scientists overall or make them less valuable (highly unlikely imoz more likely to free up some lower levels tasks, for example around EDA, than actually replace anyone). In yet another world, the general shift to AI creates hype around the profession and encourages people to invest in data and analytics broadly, even if they\u2019re not doing AI work specifically (whatever AI work actually is). What do people think? Interesting discussion here in broader churn in engineering labor market given recent big tech layoffs: https://open.spotify.com/episode/01uyOv5cIvLZfqVdwWPK3a?si=IAqZ1638SPiib6UacPQUzg",
  "I was not happy in my job for a while. Dead-end project, under-resourced, people leaving constantly.\n\nI spoke up a number of times in how unhappy I am but my boss took it semi-seriously and didn't really take much action.\n\nI recently got a new offer, although only 12% higher total package. Seems like this offer is for more interesting work and generally in a more dynamic environment. It's a downgrade in title and offers a bit less security though.\n\nI attempted to resign today but my boss promised me a new project and a new team. While it will take maybe a couple of months to tie up lose ends, my boss is generally trustworthy. He seemed genuinely distressed and sad that I am thinking of leaving.\n\nI don't know what to do.",
  "Im currently enrolled on a program where python, sql, excel, machine learning and data mining is taught. The program is bootcamp style, I have assignments linked to the topics taught. I have to use the knowledge gained from the topics and apply them to projects at work. I hope to transition to a DS role by the end of the year if I'm lucky internally. I have a $1000 education budget we can use for books subscriptions etc through my employer.\n\nAny recommendations for subscriptions I should buy to supplement my learning? I was thinking of getting leetcode sub to start grinding sql and python problems from around Q2. Is datacamp any good?",
  "Hello, I need to choose between 2 laptops. The laptop I choose is the one I'm going to use for the next 3-4 years. I need it to be practical and fast to setup and easy to use. I need praticality and speed. I know how to use computers, even linux but I'm at a point I just need praticality and speed. I want to code locally and be able to run simple supervised machine-learning models locally. Any deep learning is going to be made in the could. I don't care about money but it has to be a laptop.\n\nNeed to choose between: \n\n* m2 Macbook Air 16gb ram, 512gb storage\n* 16\" Huawei Matebook with Ryzen 7 5800H processor\n\nNeed to choose between one of those, it just needs to work and have good battery and perfomance when not plugged into a wall.",
  "Anyone willing to help me by getting a subscription of dataquest through my referral. I am looking to transition to a Data Analyst role but the cost of the subscription is too much for me to afford. I know there might be people here who are looking to start a career but unsure of the resources or course of action to take. While dataquest will not teach you everything there is to learn about data science, it will take you a level where you can understand the overall picture of the field and help you be able to apply for a entry level job. Help me out by using my referral if you can. I will be forever grateful. Thanks. Link to the Site -> [Dataquest](https://app.dataquest.io/referral-signup/g5bvets0/)  (You get an addtional 15$ discount as well)",
  "Hello!   \nI'll try to keep this short and to the point.\n\nI am preparing to re-enter the field of \"data science\" following a 2 year stint at a startup where I was fulfilling more of a product design and business development role. I found that work to be very interesting and rewarding but at the moment, I'd like to go back to developing a harder skill set.  \n\n\nSome background on me.  \nI have a bachelor's in business management (2013) and completed a Ms Stats/Data Science program January 2019.  \nI worked 2+ years as a data scientist at a large US tech company (supply chain). This work was mostly boring and not consequential, so I left for something more exciting.  \n\n\nSo as I begin to prepare to re-enter the data science field, I'm curious how much has changed and how I can best prepare myself..\n\nI have questions but I am also seeking general anectdotes and advice.\n\n* What is the typical tech stack in a data science team these days?\n   * In my previous role I was modeling in R and Python depending on the use-case\n   * Some light dashboarding\n* What's \"up and coming\"\n   * Besides \"AI\" coming for everyone's jobs\n   * What's new that is making folks more effective?\n* Have technical interviews changed? What's the status quo?\n   * I've previously \"gotten away\" with offers that didn't require tech interviews but I see that as a flag now\n* Suggested material for re-familiarizing myself/catching up?\n\nThanks!",
  "Hello guys,\n\nI'm working on a pet-project where I'm trying to predict rental prices in a city. I web scrapped data from Facebook Marketplace, but now I'm facing a problem. When I'm trying to extract the areas of the properties, I'm getting a lot of NaN values (\\~80%). I'm not sure how to deal with them correctly.\n\nI was thinking about using the mean or median values based on specific property type, number of bedrooms, and bathrooms. But I'm not sure if that's the best approach. I would appreciate any suggestions or advice on how to handle these NaN values.\n\nThanks in advance for your help!",
  "Hi all, I'm attempting to experiment with BERTopic on a small set of review site data (less than 1000 small text passages). I'm on an Intel Macbook air that is a couple years old, running python v 3.9.13. I've worked through some initial errors related to hdbscan, and now am getting the following error.\n\n    segmentation fault  python ml_bertopic.py\n\nAfter some googling, I [found this](https://github.com/MaartenGr/BERTopic/issues/112) (but for M1 chip Mac) --I wonder if I'm stuck. Is this laptop just not up for the job of working with sentence transformers? Appreciate your advice\n\nHere's the full code. When I run this in Jupyter Notebook, the kernal dies\n\n    import csv\n    import json\n    from bertopic import BERTopic\n    import pandas as pd\n\n    comm_list = []\n\n    with open(\"comments_short.csv\", \"r\") as f:\n        for i in f:\n            comm_list.append(i)\n\n\n    print(comm_list[:5])\n\n    topic_model = BERTopic(embedding_model=\"all-MiniLM-L6-v2\", verbose=True)\n\n    topics, probs = topic_model.fit_transform(comm_list)\n\n    topic_model.get_topic_info()",
  "Hey guys I have an assessment lined up for southwest Airlines for the Associate DS role can someone give a few pointers for what to expect in the test? tried looking online but could not find anything. another follow-up I have what to expect in the interview with the manager, thanks",
  "At work, we rely on Excel macros and Python automated task scheduler reports. I code in Python and have been for 2.5 years professionally. We do a lot of reporting / email alerts based on events on some data. I have never built a web app but I know SQL, and Python at a professional level. I need some wisdom from you people! How can I make a web application that:\n\n- Will display data like we do in powerbi (preferably interactive, not necessary at first if extra infrastructure is needed). Charts, tables etc\n\n- Run on a cloud database\n\n- Users will log in via 2 step authentication\n\n- Generate reports based on the data, these are reports we generate daily using local files, using a batch file, written in Python. Automatically on a schedule\n\n- Store the reports we generate as pdfs and help the user download a report any time they want\n\nWhat are some of your favorite structures for backend in python, cloud database, and front end web app part for a beginner?\n\nThank you everyone for sharing your wisdom!",
  "Every field has its culture. What would you change if you could about the culture and behavioural trends amongst datascientists?",
  "I need someone to tell me I'm not crazy.  I work with a vendor for our learning management system. Each course, curriculum, etc. all have a subject you can apply and the subjects can be nested. Here is an example of a simple example use case:\n\nAUDIO  \n\\---SPEAKERS  \n\\------BL  \n\\------DAS AUDIO  \n\\---MICROPHONES  \n\\------WIRED  \n\\------WIRELESS\n\nMy issue is that when filtering by AUDIO, for example, there are no results from ANYTHING below it... only things that are in that top level category.\n\nI opened a trouble ticket and this is the response I received:\n\n>We do understand your concern.  \nWe tested the same scenario in our local environment and found that if we search parent subject (Top level), the child LO is not returned in the search results.  \nThis is as designed, this only searches using the subject select and does not include child subjects.  \nAs a workaround, when the subjects are set up in training, you can also add the parent and child both subjects so that both will be displayed in the Search.\n\nI'm 95% sure this is a dumb answer, right? As in, if it wasn't going to be included in the search for the parent, then it's not really a nested \"child\" subject... it's just a... completely different subject.\n\nI feel like I'm taking crazy pills!",
  "My understanding is that -\n\n`cross_val_predict` yields the actual predictions from the CV. E.g., if there are 5 folds, then the output of each sample is its predicted value when it was in the test fold (trained on the other 4 folds of data).\n\n`cross_val_score` calculates the predictions in the exact same way as `cross_val_predict`. However, it does not return the predictions - only the averaged score across the test folds.\n\nI\u2019m not completely sure though. Could anyone please confirm or correct my understanding?\n\nThank you!",
  "&#x200B;\n\n[GeoSpatial Analysis Using GeoPandas In Python](https://preview.redd.it/83rfq0fg8zha1.jpg?width=334&format=pjpg&auto=webp&v=enabled&s=f0ef948961796fbd10a5103bfbdf97ad764505a6)\n\n[GeoSpatial Analysis Using GeoPandas In Python](https://spatial-dev.guru/2023/02/05/geospatial-analysis-using-geopandas-in-python/)",
  "Hi, as You can read in the title I have a dataset with 50 columns. My first aproach is to do a PCA for dimensionality reduction, before i do that, i Made a correlation analysis and drop some columns. Before Made a PCA and using gbdt( xgboost ) and a rf regressor.\n\nBut My results aren't good r2=0.55 that is only 0.05 better than a baseline.\n\nI don't have any bussines context to improve My analisis.\n \nSome ideas to handle this problem",
  "30F living in Austin\nMS in EE at 22, 8 years of work experience in deep learning in which I went from Engr I to Senior.\n\nHave extensive experience under my belt   demonstrating everything from expertise in multiple languages and frameworks, aiding directly in exec level business decision making, excellent cost savings, and a large range of problem spaces and deep learning work. I have excellent communication skills and have served as project lead for several (small, 1-3 person) teams. Spaces include valuation modeling, chemometrics, object detection, image style (using triplet loss), consumer-product matching, consumer-agent matching, multi arm bandits in chatbots, and various clustering problems of locations, consumers, and products. I also was in charge of labeling training & QA over about 20 offshore folks for image projects.\n\nI'm curious about dipping my feet further in deep learning but also in management by going for a tech lead / team rep position at my next company but I've no idea how to apply for something like that or what kind of position I should be seeking. Is this typically something you have to earn your way into via promotion rather than through applying? \n\nMedium sized company just acquired, wanting to look elsewhere. Have been working here for 4 years and just want something new.",
  " \n\nWelcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",
  "\nI am working with a binary classification dataset with many features, and not much info about them. I made an extra trees classifier with an F1 of 0.99. I believe the data originated from a synthetic source, so I\u2019ll take that 0.99 as viable. \n\nAnyway, the many features give the most important ones about a 0.02 influence by itself. My question is, how can I see how these features may work together to influence the outcome? For example , perhaps features 3, 21, 78 create a 0.15 impact together. \n\nAny insight is appreciated!",
  "I have a number of professional projects that are referenced in my resume (mainly visualization work). I want to recreate the projects with dummy data and an altered design to showcase in my portfolio. \n\n1) So I can back up what I'm stating in my resume\n\n2) Have something to present in an interview \n\nAre there any complications with this since it's not real company data and it's not the actual project I worked on during company time?",
  "I am currently an undergraduate, and I want to get started on getting my certificates, but I don't know, or rather, I don't understand how to do so. I would simply like to know what I should start with, what websites to look into, what to expect during the course and how I am expected to perform overall",
  "Hi there, I recently graduated from college w/ a major in computer science and a minor in statistics. I originally was planning on going into software development however my last semester I took my university\u2019s intro to machine learning course and really enjoyed it and decided to pursue data science. \n\nSo far I\u2019ve just been going through online resources to familiarize myself with the field and how to make myself a more suitable candidate. Learning the basics of data preprocessing, wrangling, and EDA. I did an introductory course on PyTorch to learn more about ML frameworks and modeling.\n\nI know the next step is to start building a project portfolio but I\u2019m at a bit of a cross roads. From what I\u2019ve read it\u2019s pretty difficult to get an entry level data science job right out of college and you really have to have an outstanding project portfolio or resume. Although I went to a really good public university, I made a lot of mistakes, my gpa is subpar, I only have one front end dev internship under my belt and I haven\u2019t started a project portfolio besides basic EDA and modeling to learn. \n\nI really want to enter the work force as soon as possible and don\u2019t know if I have the time to build an impressive project portfolio to get an entry data science position. The advise I was given was to start applying to data analyst positions and gain experience for a year or two. In the meantime to be doing independent projects and might even do a one year masters program with a focus in ML/DS and then transition to data science.\n\nI apologize for the lengthy post but my question is basically whether I should focus more on getting experience in querying, building data pipelines and reports to get a job in data analytics now and focus on building a data science portfolio later on or pursue an entry level data science job now?",
  " Hey data enthusiasts! I'm looking to get into the field of data science, and I would like insights from experienced data experts like yourself. What would you say are the challenges you face/ have faced while working with data (be it data preprocessing, data wrangling, modeling, exploratory data analysis, data management, and/or data governance)? I would truly appreciate your response.",
  "Basically the title.\n\nI'm a junior who is struggling to find a job in the currect market and after I had a chat with a startup CEO I casually met he highly recommended me to start networking via conferences as my chances to land a job are much higher than traditionally submitting resumes.\n\nI do understand his point I just feel like as a junior maybe I should distribute my energy towards improving certain demanded techincal skills and projects rather than engaging with managers who might probably not be that interested to a junior? Plus I never really heard of people that landed a job from networking.\n\nHas anyone ever landed a job by networking?",
  "**\\* A wild DATASET magically appears \\***  \n\n\nI'm a data engineer and i am wondering what kind of data sources data scientists use. I have some experience with data scientists that use the data warehouse, but I am quite unaware of what teams without a data engineer do.   \n\n\nWhen I researched tutorials, it seems the datasets appear magically. So where do you get your data, and who writes the pipelines?  \n\n\n  \n\n\n&#x200B;\n\n  \n\n\n&#x200B;\n\n[View Poll](https://www.reddit.com/poll/1117k6p)",
  "I recently rewatched Infinity war. As we all know in the end Thanos snaps his finger and half of all living things fade away. What made me curious is- what kind of sampling would have been used to achieve that?\n\nWould the sampling depend on gender? If yes, would it consider other genders as well. Will demographic play part? Like half of all population each country?\n\nLet's discuss this?",
  "Hi everyone,\n\nI am a beginner in data analytics and I find it very interesting. For a school project we have a case where company A only has a ERP system where all the transactions happen and it is connected to a single Database(SQL). The question in this case is what solution would be appropiate because the company doesn't have the manpower and budget to maintain data analytics.\n\nWe have learned the basics of ETL, Data warehousing with the Visual Studio tool and connection with SSIS package. But I did some research and found out you can do ETL in powerBI. But how reliable is this? And do you have to keep changing the relationsships in PowerBI everytime you want to make a dashboard or does it stay like that? I need to make a few KPI and dasboards for this school project.\n\nThanks for advance responses",
  "Hi, college student here. I'm doing CS atm, but as AI quickly adapts to SWE job requirements (to an extent), I'm not sure if going all in on the SWE route is still the best choice. Data Scientists, data engineers, and machine learning engineers, could you share your insight on what you do on your job and what do you see your industry go? Additionally, what classes/projects/bootcamps would you partake in if you are in college right now to be (kinda) ds job-ready? Thanks in advance for your insight!",
  "When I go on LinkedIn, I keep seeing like 200+ applicants for any \u201cEasy Apply\u201d jobs, which in essence makes sense anyway.\n\nBut I feel like seeing all these giant tech companies laying off thousands of works, it\u2019s probably flooded the market with tech workers looking for a job. And this is only highly publicized companies. I\u2019m sure smaller companies have done that too but just haven\u2019t been reported on.\n\nPlus with ChatGPT out, I\u2019m thinking firms are even more so reconsidering things.\n\nI ask because I\u2019m trying to finish data quest\u2019s data scientist path and I\u2019m like am I even going to have a chance to get a decent paying job when I finish. \n\nI\u2019m going to be competing with veteran data science individuals with PhD in CS or Stats or Math with 10-15 years of experience or top university graduates from Harvard, Stanford, Carnegie Mellon because they got laid off recently.",
  "Hello everyone,\n\n&#x200B;\n\nI am a career shifter looking to transition into a career in DA/DS. I came across Avery Smith's Data Career Jumpstart Program and was wondering if anyone here has taken the program and could provide me with some feedback. I would really appreciate it if you could share your experience with the program, and any additional advice you may have.\n\n&#x200B;\n\nQuestions:\n\n&#x200B;\n\n1. How long did it take you to complete the Data Career Jumpstart Program?\n\n2. How applicable is the material from the program to the current job market?\n\n3. Are the instructors knowledgeable and experienced in the data science field?\n\n4. What was the most useful thing you learned from the program?\n\n5. How did the program help you land a job in data science?\n\n6. What is the support system like from Avery Smith after you have completed the program?\n\n7. What are the chances of getting accepted into a data science role after completing the program?\n\n8. Are there any other resources or materials that you would recommend for those looking to transition into data science?\n\n&#x200B;\n\nThank you for taking the time to read this post and for any advice you may be able to provide! I'm eager to hear your experience and any advice you can give me.",
  "Hi, just looking for some feedback. Apologize for the formatting, I removed some items that may have been personal identifiers. \n\n&#x200B;\n\n&#x200B;\n\nhttps://preview.redd.it/1nyn4bt9ovha1.png?width=956&format=png&auto=webp&v=enabled&s=b80805be86ae931a209af5ad83bbf02f087e9f63",
  "Considering a change. My background in data analytics is limited to almost exclusively mathematical representations. I have some experience in machine learning but it's been almost 5 years since I've been involved in such developments.\n\nMy question is for those of you who work in machine learning; what are the most common languages and platform/notebooks etc used to develop and express your functions that you see on a day to day basis? What would be your expectations for someone moving into that realm of data science coming from analytics?",
  "1. Altoros Labs\n2. Binary Republik\n3. DataToBiz\u00a0\n4. Ballard Chalmers Ltd\n5. Saviant Consulting\n6. Silicon Reef\n7. Trigent Software\n8. VOLANSYS Technologies",
  "Hi there, I'm a mechanical engineer currently working as a design engineer in Japan, I'm interested in data science and looking to change my field. I self studied data science basics through IBM professional certification. What should I do to get a job in data science preferably in automobile/manufacturing domains? Kindly help",
  "Hello all, I'm a civil engineer looking forward to changing my career field from civil engineering to Data Science or analytics. I'm new here and the field is very vast. I'm making the shift due to obvious reasons like PayScale, work environment, no holidays and I'm not interested in this anymore. So can you guys please help me with any free courses to start with so that I can create a good base in this field. Thank you so much in advance.",
  "I have 3yrs of quantitative research experience and currently work in a small Analytics team at one of the top market research agencies (same league as Nielsen). \n\nI\u2019m quite good at analysing small data sets (a few thousand rows) and building simple models in SPSS and R. Been told I make impressive slides that tell stories with data in plain language - I\u2019m from marketing communication background.\n\nI\u2019m also doing a masters degree in Business Analytics on the side. It\u2019s been 1.5yr, the progress has been slow bc studying part time, but all my grades are 90+ and have learned the basics of Python, SQL and Tableau.\n\nStill I feel like I don\u2019t quite meet the requirements of most junior Analyst jobs. It seems I\u2019ll have to either take on grad roles at bigger companies or go to small data consultancies if I\u2019m to take a leap. I\u2019m an immigrant, already in my early 30s and there\u2019s financial pressure (single, saving for an apartment).  \n\nNot sure what should be my next step. Welcome any assessment on my situation, and advice on what kind of jobs/ companies I should aim for, which area I should focus my time and energy to learn and develop, etc.\n\nThanks in advance!",
  "\nDoes anyone know about this online course offered by Indian Statistical Institute in partnership with Coursera? \n\nFor info Im a BE, MBA graduate (already working in marketing analytics) wanting to specialise in data science hence looked up this course but cant find any reviews at all online. The cost of the course is also pretty high at 4.5 lakhs\n\nWill it be worth it considering its from Indian Statistical Institute?",
  "Hi everyone, Im 25[M] and I recently switched my career path from digital marketing to data science.\nSkip the next paragraph if you dont need to read the reason for this.\n\nFor those who want to know the reason can read this paragraph: I was always a fanatic when it came to working with numbers, I was always good at math and was always above average/decent in ms excel as i liked to put everything into perspective by plotting out data tables/charts in random situations in my life. The last job I had was in a market research/analysis role at a digital advertising firm where I had to use software like Talkwalker, Ms Excel and PowerPoint for data capturing, analysis and reporting. This further boosted my interest in pursuing data science.\n\nSo im currently doing an MSc in Data Science, and I did by BBA in Marketing & Finance double major. Since my course started I have had to learn SQL, Python and R so far. All of which I absolutely enjoy learning and working with but of course since im new there is going to be a steep learning curve.\n\nAnyhow, I was looking at job requirements for junior data analysts at different companies and they were all over the place. Some required strong SQL, some required strong python and some had R listed while I also saw some jobs wanting a combination of them. Apart from these Ive also seen companies requiring Tableau and some wanting Power BI.\n\nNow the problem is, while I love to learn all of them and I am fully motivated to do so. I just wanted to inquire about which softwares/languages should i focus in order to land any junior data analyst role. I am a quick learner and I know i will continue to work on myself even after I land a role but till then I do not wish to remain unemployed if that makes sense.\n\nThe MSc course is 1 year long and has about 5-6 months till it ends.\n\n\nTLDR; Switched career path from digital marketing to data science. Age 25[M], want to know which software/programs to focus on in order to land a junior data analyst role.",
  "Hey everyone,\n\nI am a fairly new working professional in Software Engineering, who was recently laid off. I am currently in the final interview stages of 2 companies for 2 different roles - data scientist and data engineer. The thing is - I have some experience working within both the domains, and also have a couple of publications in NLP. \n\nWhile I completely understand that the final decision is going to be upto me, I had a few questions for people here - especially for the people who have made a switch from data engineering to data science. \n\n1. How easy was it for you to switch?\n2. Why did you make the switch?\n3. What is something that you really love and really hate about the 2 domains?\n\nThis would help me gain better insight and make an even more informed decision.\n\nThanks!",
  "Hello, I came here because this has been bugging me for the last couple of days, and just want opinions from other DS.\n\nI want to become a successful DS but I don't consider myself a subject matter expert in any field.\nI have almost 5 years of experience as a BI / Data Analyst and wanted to make the leap to become a DS so I took a Master's and the first thing I noticed is that all of my peers have a strong background in very specific \u00e1reas (Medicine, Agronomy, Economics).\nSo my question is, did you choose a subject before becoming a data scientist? \nJust Share your thoughts :) \nSorry for the bad spelling beforehand lol",
  "How do you weight the contribution of an individual predictor in a logistic regression?\n\nI have a logistic regression which is predicting whether a loan is considered good or bad. I have 10 predictors, which are a mix of continuous and categorical variables. How do I determine how much each of those predictors contributes to the outcome of the loan being good or bad?",
  "Hello everyone, I am currently taking a class in Topological Data Analysis and my professor is going to have us do a final project for the class. He is requesting that we start looking for datasets to work on. The criteria being:\n\n* Large number of members\n* High-dimensionality\n* \"Real-world applications\"\n\nWould anyone be able to suggest datasets that I can look at? Some areas of interest that might help narrow: physics, meteorology, environmental science, space, and anything related to these.\n\nWhat I don't want: finance/economy",
  "I'm a backend developer and nowdays I'm working on a project where I have incoming stream of images and I have to run object-detection task on them.\n\nWe chose as the company to use an external object-detection api provider rather than creating our own models.\n\nTherefore I searched for different object-detection API out there and decided to use AWS Rekognition.\n\nSeems like their API is not very easy to use and require many post-processing functions on the response that contains the bounding boxes. Other API's I have checked require post/pre-processing on the images/response labels as well.\n\n&#x200B;\n\nI'm wondering if its just me or consuming AI API's is very unstructured, complexed and has lots of overhead.\n\nI would be happy to hear how you dealt with such cases when you had to consume a Computer Vision/ NLP API's.\n\n1. Was it hard and required additional logic around the pre/post processing of the input/output ?\n2. Do you have any tools/tricks to make this API integrations easier ?\n\nThanks !",
  "Hey there! I'm making a personal project centered around hourly load forecasting, and am at crossroads where I realize that some advice is needed on a few questions:\n\n1. What data should I collect that would be helpful? I can get hourly forecasted and historical weather data from the PirateWeather API, but how would I integrate these into my model? It seems straightforward to use historical data, but difficult for forecasted data because I can request hourly forecasts of a specific time in the future for each hourly time interval between the present and then, repeated over and over until the future time coincides with now. For example, if I collect hourly forecasts 10 days in advance, then I will have (10\\*24)+(9\\*24+23)+(9\\*24+22)+...+1=28920 different forecasts for each timestamp. How would I even go about organizing that in a table?\n2. What kinds of models are useful for time series forecasting with multiple variables? Furthermore, how should I transform my features to be used by different kinds of models?",
  "We are a company with two platforms, platform a & platform b.\n\nAssume we have a 2D matrix, where each record represents a client, the client has three sets of features:\n\n1. feature set a: captures the behavior of the clients on platform a including their purchases on platform a of different products.\n2. features set b: captures the behavior of the clients on platform b including their purchases on platform b of different products.\n3. features set c: captures additional features gathered by a survey.\n4. The location of each client.\n\nThe matrix is sparse, meaning:\n\n\\- Most of the clients don't have all the feature sets available, i.e. if a client has entries for feature set a, it's most likely that they don't have entries for feature set b and features set c and vice versa.\n\n\\- Some clients have empty feature set a and feature set b (they are not using our platform)\n\n\\- Most of the clients purchase a small subset of the of the products.\n\nThe **goal** is to predict **the total monthly purchases per product per location**. It's simply the sum of purchases on platform a and purchases done on platform b. But again most clients purchases are unknown on one of the platforms. and a small subset of clients don't have purchases on either.\n\nExample:\n\n[a sample of the matrix](https://preview.redd.it/o80ng6kocsha1.png?width=852&format=png&auto=webp&v=enabled&s=0c20fa16d30cf8853312b6623b1ccba09105601f)\n\nI am thinking matrix factorization, what do you think, is it suitable for such use case? or do you have other more appropriate approaches in mind?",
  "Does this list make sense? and in this order?\n\n[https://www.kdnuggets.com/2021/03/9-skills-become-data-engineer.html](https://www.kdnuggets.com/2021/03/9-skills-become-data-engineer.html)",
  "\nHi there, \n\nAfter studying and working really hard I landed my first job as a Junior BI developer last October, hobing that I can get someday in the future from data analysis to machine learning engineering.\n\nHowever, my current company isn\u2019t helping me learn or add to my skills, there\u2019s no BI team and no one with experience to guide me. I even feel like my technical skills were better before I joined here. \n\nI am doing my best to work and learn and I apply to various positions but most require more experience than what I have. \n\nI had a technical interview today and the interviewer told me that they need a BI developer with 4+ years of experience, and he offered to get me a technical interview as a Power BI developer instead. \n\nI don\u2019t feel good about it as I enjoy the whole BI process especially integration and Analysis. \n\nI feel lost and can\u2019t figure out what to do. I am not sure whether I an heading where I want to\u2026\n\nYour advice is appreciated.",
  "Hello, \nI\u2019m having trouble with an exam that requires SAS. Does anyone know how to use it to create descriptive tables?",
  "I'm applying to MS Data Science / Artificial Intelligence programs in the US for Fall 2023 - at pretty ambitious Unis (Columbia, Northwestern, Irvine, Rochester, Brown, UPenn) as I do not wish to settle with lower ranked ones and risk a bad ROI / debt spiral. But my chances are pretty low/ nil as it's pretty late after the cycle is almost over. So I've included some lower ranked Unis for DS in my shortlist (Stevens institute of technology being my fail-safe) \n\nBut acceptance rates for MS Business Analytics programs at most UCs and other Top Unis are surprisingly VERY high. And people with much more mediocre profiles than mine get in easily. So I could maybe remove lower ranked DS programs and replace with UCSD / UCD / UCLA MS BA. They have deadlines remaining (round 3 or 4). I was originally thinking to apply to BA next year if I don't get any DS programs this cycle. \n\n\nMy gpa is 7.03 / 10 (BE Mech + MS Physics degrees) from a ~top 5 institute in my country. I have 2+ YoE as a Data Scientist (applied deep learning, many projects in CV, NLP, RL). I have 1 IEEE published paper, 1 Thesis in AI (RL). GRE 326 (168Q). Although the low gpa is a concern, my profile fits much better for Data Science but isn't bad for top BA programs that do have DS courses in curriculum as well. \n\n\nI'm concerned with the outcomes of a BA degree - primarily high-paying opportunities (in any domain or role, matching the fairly common ~$200K Data Scientist salaries in bay area/ NYC), and prevalence of a switch back to DS / MLE / Applied research roles after the BA degree if previous work demonstrates proficiency in ML/DL. \n\n\nWhat is the high-end employability after MSBA, which sort of roles and responsibilities are more common ? How do you compare it to MS DS outcomes? What may I dislike/ be surprised by, in a BA degree or role? \n\n\nI already don't love the curriculum. It's all hand-wavy business-oriented courses barely teaching any hard skills. More stats, very less ML if any. Marketing, Finance etc is not something I've ever been exposed to, so I may learn something new that I couldn't have using free UC Berkeley lecture series. But I'm mainly looking for high paying outcomes and growth opportunity.",
  "As a dedicated, hardworking, and disciplined individual with a passion for data science, I am seeking advice on how to turn my dreams into a successful reality. I come from a middle-class family and my father runs a successful computer and accessories business, but I have my own aspirations to make a big impact. I have a BSc in Computer Science and have even tried to start my own software company, but unfortunately, it failed. This setback has left me feeling sad and discouraged, but I am determined not to give up on my goals.\n\nI am now considering pursuing an MSc in Data Science abroad, with the hope that it will increase my chances of success. I am torn, however, as I also want to support and expand my father's business. I am from an underdeveloped country, and I am unsure of the best path to take. Can anyone offer me guidance and advice on how to balance my education, business aspirations, and familial responsibilities? I am eager to hear from those who have faced similar challenges and overcome them.\"",
  "Hey there! New(ish) data scientist here!\n\nSo I'm going to transition soon to more data scientist roles (mine typically uses only Excel and I have to go out of my way to find applications to program) and I'm trying to beef up my Github/Resume/etc.\n\nBack when I was in my MS program, I'd have a whole bunch of programs each year but they were very small in scope (stroke prediction, product reviews, etc.) and so I'm working on this program which I'm having a lot of fun with (medical diagnostic) but the thing is that it's larger in scope than any project I've worked on before.\n\nDo I have to worry about optics? Is a potential employer going to look through my resume and ask, \"You used to have four-five projects a year and now you only have one, what gives?\"\n\nI appreciate your help. Thanks!\n\n&#x200B;\n\nAlso, side question: At what point can I put a project on my resume? A project like this can always be fine-tuned and improved, but I think it's unreasonable to say I can never put it on my resume until it's absolutely perfect (which I find to be a nearly impossible standard in some cases, such as this).",
  "Hello everyone,\n\nI am interested in a data engineering role. I was hoping if any experienced data engineers could help me with some guidance on what I should focus on first.\n\nI have a good understanding of Python and SQL, but I am not sure where to start with data engineering specifically. I would appreciate any advice or resources you can provide.\n\nThank you in advance for your help!",
  "I'm performing seasonal analysis on time series data. However there's an inflationary component which I'm not worried about. Is there a method generally used for flattening out my increasing sin wave? \n\nI imagine this would feature in predictive modelling for pricing but it's not an area where I'm familiar. \n\nIncase my title isn't clear I'll included a link to a graphing calculator showing what I mean.\n\n[https://www.desmos.com/calculator/jkocrrvubw](https://www.desmos.com/calculator/jkocrrvubw)",
  "So long story short, my undergrad was in international affairs, nothing technical. I touched R a little bit but nothing extensive. I decided during the pandemic I was going to push to get a STEM masters to supplement my undergrad and I knocked it out. I really enjoyed it and I can use a ton of tools to develop ML solutions and deploy models leveraging tools like Sagemaker. I\u2019ve even become an OK programmer. The issue I have is many of these solutions and tools are black box. I can apply the tool to solve a problem but I don\u2019t always know how it works and, being honest, there\u2019s a lot of effing tools. \n\nI feel like I\u2019ve got a good warm and fuzzy about what data science and ML can do and what it can\u2019t but I find a lot of jobs will post their need for people with extensive education in quantitative skills, or vast experience with A/B testing which I understand but haven\u2019t done extensively, or 6 years building solutions with Tensorflow. Thus, I feel like I might be wildly under skilled despite the degree. \n\nMaybe the industry is just so flooded now that DS roles really require a deep specialized knowledge because it\u2019s so competitive. Seems like there are lots of PhD roles in industry these days. \n\nWould it make sense for me to go back and hammer out the math? Another undergrad? Another masters maybe? Push forward and do a PhD and lose steady income for the 4 years maybe more?\n\nMaybe this is classic imposter syndrome. I digress. But anyway, advice is always good to have.",
  "So ever since becoming a data scientist, I've been constantly getting flooded with connect requests on Linkedin. I'd say about half of them are established people in the field, (DS/DA/DE), and the other half are people trying to get into the field. Additionally, I get about 4-6 new requests every week from people asking to connect with me, either asking for a job referral, to talk about my role, or advice on how to break into data science. So I usually meet about 2-4 of people a week to give them advice how to get into the field since a lot of people I've talked to think my career pivot is inspiring. I had close to 100 LinkedIn connections this time last year and now I'm over 600 and climbing.\n\n&#x200B;\n\nI wanted to ask is getting this many requests normal for other data scientists (roughly 6-12 per week)? And if so, how do you guys deal with all the other people asking for help all the time (if you choose too, since I've realized it can become time-consuming)? My manager says he gets requests for help all the time too and it's because of the field we are in, so I was curious if most other data scientists experience this? I've talked to other successful people with great jobs, and although they did get a lot of requests for help, especially earlier on in their careers, some did mention that the amount I get weekly is pretty high. I also wonder if it just happens to be due to the job market as of late?",
  "Hi, I\u2019m a 4th year computer science undergraduate student at a university. I haven\u2019t done any internships yet, I don\u2019t have any hands on experience with projects too. I seriously want to build a career in data science field as I\u2019m very much interested in data, numbers, stats, and python coding. I want to build a foundation of data science, can you guys please suggest me some good courses that I can do so I can land a job after my graduation in that field, I would love if you suggest some free courses not necessary telling no to paid courses, if it\u2019s worth it then please tell me so I can start right away.",
  "I was just wandering if there was a dataset or model for detecting malicious content. \nSay if I run a OCR or something to detect perceivable content on a screenshot (Google news/ news feed / YouTube thumbnail and title). \nAnd detect content with malicious intent, more specifically health or finance.\n\nDoes anyone have any leads on how I can achieve this? A dataset/model/app.",
  "I need to work on a term project for my advanced database management class. We predominately work with RDBMs in class, so ideally I\u2019d explore something else for my project to help expand my repertoire - the only thing is with so much information out there, I don\u2019t know what really considered relevant/in demand nowadays. \n\nCurrently I\u2019m thinking of doing a project using NoSQL (MongoDB) while also practicing some ETL and working with other big data platforms. \n\nThe professor has also suggested creating a data warehouse - that\u2019s more in the realm of RDBMs though and I would like to get some more experience with big, unstructured data.\n\nI guess my question is, if you were recruiting someone as a data engineer or analyst, what would impress you the most? I want to crest something that will grab the attention of employers.\n\nI\u2019m open to all kinds of suggestions - I was told I could also compare and contrast the ETL process using mongodb vs apache spark (using various unstructured/semi-structures data) \n\nWould appreciate some guidance on this, thanks!",
  "Based on your own experience, formulate a one to two liner on what makes DS **not** for someone. It could be simple like \"you dislike math\" or something more complicated.",
  "I currently have 7 YOE but I still enjoy learning whenever I can. Since free time is pretty scarce between work priorities and family life, I\u2019m very particular about topics I should study and qualify of material. Does anyone have any recommendations for a tool I could use to\n\n1. Keep track of topics I want to cover whether I\u2019ve completed it, currently working on it or want to get to it in the future\n\n2. Store links to material covering that topic that I\u2019ve decided is worth it\n\n3. Make note of where I am in the material, just a note to self where I left off if I need to break for a few week. (YouTube series, books, moocs etc\u2026)\n\n4. Store my notes regarding each topic for later reference. Could be a link or file attachment etc\u2026\n\nI was initially thinking trello, but I\u2019m curious if anyone else is overthinks their learning as much as I do and what you\u2019re using.",
  "TLDR: a 31 y.o. DS\\\\researcher working mostly with time-series wearables data, lagging behind modern development stack. Willing to become a more demanded and better paid pro, possibly in an adjacent field. How should I spend 6 months (fulltime) with the maximum benefit?\n\nI will be laid off in March-April because of the reorg and will have 6 month of from-work-to-work time (employer's termination notice). I won't be expected to do much, but I want to use that time with the maximum profit for myself. I can find another similar job, but see this as an opportunity to reinvent myself. What should I do?   \n\\- change profession to data engineering (I kinda miss research aspect there, but there are so many vacancies...)  \n\\- refocus to a different sexy domain (trading algos, video AI, blockchain,...?)  \nI think the best way to go is to learn stuff by doing and develop my portfolio at the same time (public github, kaggle competitions). \n\nDoes anyone has ideas on the roadmap? Thanks.",
  "Hi, I\u2019m currently in a masters program and we are doing both R and python. I really think this practice is very wrong, I think that I have to get used to one language instead of learning 2 simultaneously and only switching from one language to another. What\u2019s your take?",
  "Hey everyone, \n\nI just  want to start learning stuff for data science, but i don't have guidance about it or i have basic guidance only, but don't  now what is first step of it , so give me advice \n\nThanks in advance",
  "I am interviewing with a systematic hedge fund for a quant research role (I am a statistics masters student currently) . I have an all-day onsite interview coming up in which I am told I will be given a dataset at 9am, and will have to \"present my findings\" at about 4pm. The data is not necessarily financial; it could be something like weather or sports.\n\nThe explicit requirements for the role are familiarity with Python, Pandas etc., and good background in stats -- not necessarily Kaggle whizz. It's hard to imagine making much progress on quite an undirected task in that little time, particularly when random bugs and errors are basically bound to happen and cost time at some point, and when some time at the end needs to be spent preparing a presentation.\n\nI would be very grateful for some advice from anyone who knows about junior data science roles (particularly in finance):\n\n\\-   What sort of level of analysis would be expected in this timeframe?\n\n\\-   Given that a large chunk of time will need to be spent on doing very basic explorations and plots, and on preparing a presentation, how is it possible to impress in an interview like this?\n\nMany thanks for any help, this interview seems like quite a daunting task!",
  "I have had multiple data science roles and have interviewed several companies.  After the initial stages there are usually technical and/or panel interviews.  In some cases I am able to determine why based on the interview it didn\u2019t work out but a lot of times I just get a generic email and have to guess why they didn\u2019t move forward.\n\nI am just wondering based on those who have experience interviewing in those 2nd to 3rd round interviews what are the main reasons you or your company doesn\u2019t move forward.",
  "If anyone is familar with this style of visualization, is there any python package that allows me to represent the percentages as circles out of 100 like this? \n\nhttps://preview.redd.it/e5gdjsi0slha1.png?width=1730&format=png&auto=webp&v=enabled&s=15977365b31636d24c986c53249109b5f1ab5ba3",
  "Hi, I have been working as a data science consultant where I have to interact with business stakeholders to approve the ML model that we develop prior to deployment. I am wondering what are tips/software/framework do you suggest to use to improve the collaboration process between engineers and business stakeholders.",
  "I was sharing some of my work with a SWD I have a lot of respect for. My most recent project is scraping a bunch of esports data that I then did some basic EDA with and was looking for interesting questions to move forward. His statement to me seemed odd\n\n> I don't really think that is the right approach here. Typically we'd go into something like this by starting with a model that we design intuitively, then compare with the game results, and spend time trying to identify what causes differences between the game and model\nHow can there be a descriptive understanding without a model\n\nI have an MS in Data analytics (not from a great school but still) and every one of my courses started with \"Do EDA to ensure you can model your data first\"\n\nAM I missing some nuance here about when to do EDA or when to immediately go \"linear regression\"",
  "I\u2019m one of the newbie competitors for the RSNA Mammography competition on kaggle, and after a month being stuck under 0.07 score I was finally able to break it with a 0.15! This is nothing compared to the top scorer which is currently 0.67 but such a massive win for me. I\u2019m not copying someone else\u2019s notebook, it\u2019s all code that I wrote (by copying code from stackoverflow xD). My goal is to keep improving until the competition ends which is pretty soon. Just wanted to share this as it made my day.",
  "After landing my first data analyst job after getting my MS in in Data Analytics as an adult learner,  I am now being told that I am not a good fit and I should start looking for other roles.  Freakin sucks, only 9 months in. But to be fair, I was not great. But I was progressing\n\nThere is so much to learn in a real business setting than what I could ever imagine. (my employer is a huge telco so LOTS of data). Anyway, feeling like maybe I should give up on this data stuff. But I do actually enjoy the work so maybe looking for some encouragement... Has something similar ever happened to any of you? And advice on how to pick yourself up and keep on going?",
  "Given at how job listings look, I have a feeling that my future career will be in a data science or adjacent field. I am currently completing a BA in Econ and a BA in geography. I am between an MS  in ISOM and an MA in Econ. The [MS-ISOM curriculum](https://warrington.ufl.edu/master-of-science-in-information-systems-and-operations-management/courses-and-curriculum/) can be found here and the [Econ MA curriculum](https://economics.clas.ufl.edu/academics/curriculum/) can be found here. I was hoping for some advice on which program to peruse to best prepare me for a future with data.",
  "As a brief intro, I\u2019ve been stalking this sub for a while and in the couple years that I\u2019ve started studying data science, your collective advice has enabled me to learn a lot of cool data science techniques, land data science internships, and improve my understanding of key math areas like linear algebra, probability, and stats.  I use this sub as a direct resource for learning data science so your advice is very much appreciated on my end.\n\nCurrently I\u2019m an undergraduate studying Data Science at a top 10 school globally. Although I\u2019ve felt that my major\u2019s curriculum has helped me establish a solid understanding of the math, programming, and analytical aspects of data science, my major has generally been focused on predictive modeling rather than inferential modeling. \n\nAt this point in time, I have taken four different ML/DL courses where I\u2019ve gained a pretty strong grounding in classical ML techniques, core DL frameworks, and implementation/productization. However, although I\u2019ve learned through classes and self-studying regression analysis and hypothesis testing, I have yet to take a class solely dedicated to inferential modeling as a whole.\n\nThis coming quarter, should I take my 5th ML/DL course to further establish my knowledge and approach to predictive modeling, or should I take a course solely dedicated to Applied Regression Analysis (name of the course) to gain a better grounding in inferential modeling?\n\nTLDR; Should I take 5th ML/DL course or 1st regression analysis/inferential modeling course?",
  "Zerodha CEO in a recent article told that there isn't any need for data engineers and as they haven't hired any for their firm.\n\nZerodha is Stock broker firm, and is quite popular in India for share buying/selling.\nLast few years, it was as termed as India's best stock broker for online transactions.\n\n\nThe remark made by him was hurtful and shook me a bit.\nAs not only they have huge say in market, also they are a financial institutions with huge chunk of data.\n\nI would like to get your view point on this.\nPFB attached link for the article:-\n\n\nhttps://www.hindustantimes.com/business/why-zerodha-has-no-data-scientists-ceo-kamath-explains-with-a-witty-example-101675959495780-amp.html",
  "Hey all, is there any way possible to find the original metadata of a photo before was imported into a photo vault? I can only see the date and time it was imported into the app. [oco]",
  "Hey! So, I was assigned to a project where a Jupiter Notebook is my deliverable. It includes data cleaning/processing, EDA, hypotheses testing, analysis - usual stuff. The main goal is to find insights and either identify weaknesses in our client MO or prove that they work better than competitors. \n\nThing is, main stakeholder is a non technical non analyst and I don\u2019t have direct access to him. Should I somehow modify my usual approach to creating the notebook, considering that the main audience has no idea how code works and what statistics is? Should I be more verbose and explain more? Any tips and suggestion are welcome, thanks!",
  "Couple of months ago I took part in a hackathon related to scouting football players for Sevilla FC. The data had more than 80,000 columns, and no proper information on the data being presented.\n\nThe data that was provided had column names as \"X_0,X_1,...\". We are given scouting data which has age team played for performance but along with this 80000 columns with absolutely no context. So I can't infer anything, nor do I have skills to tackle such data.\n\nAs I am a student with work experience only as a software tester I generally practice data science using open source data or kaggle. On these platforms we have some insights on each attributes of the data.\n\nHow will you guys go about processing the data before creating a Ml model for such cases where dimensions are high so manually doing eda is very hard?",
  "[https://medium.com/p/f0c8176c9cbd](https://medium.com/p/f0c8176c9cbd)",
  "\n\n[View Poll](https://www.reddit.com/poll/10zocja)",
  "Hey all, is there any way possible to find the original metadata of a photo before was imported into a photo vault? I can only see the date and time it was imported into the app.",
  "Hi everyone,\n\nI want to write my own script (?) to export metrics from various social media platforms to Google Spreadsheets. None of the existing tools seem to answer my data analytics questions. \n\nI wonder where I should start, which programming language I should use, etc.\n\nAny advice is appreciated!",
  "Currently holding two job offers \n\nData engineering for insurnace company \u00a338k many benefits \n\nData science for data consulting company \u00a330k with no real benefits except course certificates \n\n\nI think the data engineering would certainly be a boring role ( but I don\u2019t know) \n\nAre there any opinions you guys have as to career progression for both? I\u2019m not sure which one to accept but leaning to the data science one.\n\nI belive it would provide me with more skills to progress into many more positions, furthermore it\u2019s my understanding that data scientists can go into data engineering in the future, but going from data engineering to data science is much harder as engineering doesn\u2019t require the scientific knowledge.\nIs there anyone more experience to confirm?\n\nThank you \ud83d\ude4f",
  "Hello! I'm about to graduate from a masters of data science and I'm searching for full-time fully remote DS job. I seem to only find hybrid jobs or with location restrictions. Can you tell me a company that accepts fully remote? Also, which are company red flags during interviews?",
  "Interviewing for DS/ML position what part of the interview did you like? Or was there a companies interview process that was very memorable?",
  "Hey, so here is the thing, i am a junior with like 1 YOE, and i am really really a good one as someone with 1 YOE, everybody is shocked when they find out i am a junior, cos i really put into hours to study and experiment stuff.Also i have a lot of freedom on job to get experience, cos i fail alot, and i guess thats where u get experience.But the thing is for example i had some interview for startup where day were really blown away by my knowledge, but the hardest thing for me is to get interview, since i dont post stuff on linkedin, i only use enterprise github profile etcc..Like not much to show expect i am working as MLE there and there for an year, and describing what i do.\nHow can i improve this?Should i write blogs.., start being active on linkedin.",
  "I got a Masters from an Online program and enjoyed the flexibility it allowed me. I've been thinking about getting a PhD on DL/ML related program. \n\nI would appreciate recommendations!",
  "When interviewing for a new job, if asked about your salary at current company, do you need to be honest? Or can you instead tell them a higher number so they give you a higher offer?",
  "Hi!\n\nFor work I need to analyse 52 workbooks with 5 sheets per workbook. I need to add everything into one workbook so that me and my boss can analyse the data.\n\nThe data however is a bit messy. The first two rows contain headers that I need, but the second header needs to be turned into columns to measure the hours spend on something per name. There is also data under the screenshot that is not needed, but that data is in different rows every sheet.\n\nThere are no tables in the sheets, only some visible formatting but no data formatting.\n\nThe screenshot is one example of a sheet from the workbooks i need to analyse. Every sheet contain about 100 rows and 30 columns, but the amount of rows is different for each sheet.\n\nI've tried analysing with Power Query, then python and started to think about SQL when I couldn't figure it out.\n\nI'm a bit stuck about making the decision which language to use. If some of you could point me in the right direction I can continue and be on my way. I'm just startin to doubt myself and my method.\n\nWould you recommend using Python, SQL, Power Query or something different?\n\n&#x200B;\n\n&#x200B;\n\nhttps://preview.redd.it/rwp3ho4k9gha1.png?width=1854&format=png&auto=webp&v=enabled&s=a1a0fcbce39be34be8b992e447e6e346da87709e",
  "I'm not trying to offend anyone's career choices but since I've only first heard about Data Science a year or so ago (Yes, I do infact live behind the moon) how did society seemingly collectively go from\n\"Governments and Big Corporations secretly taking and using our data for profit is morally reprehensible and fundamentally wrong, Snowden did nothing wrong!\"\nTo\n\"Here Mr. Zuck, proof I spent hundreds of hours and thousands of $ so I can help you make more money by analysing all this data you've been collecting\"\n\nIs it the money/status/career? Has there been a shift in data collection where it's only \"moral\" data being collected? Was some article writing \"DS, sexiest job of the 21st century\" all it took? I genuinely want to know.\n\nEdit:\nI acknowledge that there are many useful sectors where it's not personal data and it's used for the greater good but esp. before the mass layoffs, weren't most people, especially on social media obsessed with getting into FANG by taking Bootcamps and such, where they most definitely do all the stuffs I'm thinking about.",
  "\nI\u2019ve been offered to do a full course about just one of this two career paths and when I\u2019m done with the course I\u2019ll also have a job interview so the choice I\u2019ll make it is really important for my future.\n\nI\u2019m 27 with no degree,I worked last 7 years surrounded by people 8-5 and as an introvert this really drained me out. Also bad company policies and bad work environments gave me the finishing blow. \nI\u2019m also planning going to university to start studying probably in September.\n\nI have 0 experience in both Data Science and Cybersecurity,never worked in these fields,all I know from both I learned it from Youtube,Google and Reddit during these days while I\u2019m trying to decide which course I\u2019m gonna choose.\n\nFinal thoughts are: I don\u2019t care much about which job has the best salary,just need money to cover my Uni taxes and survive,so I\u2019d like to decide which job suits me more based on:\n1)Which one is more remote oriented?\n2)Which one has more self organized schedules/work hours?\n3)Which one has less interaction with people?\n4)Which one you think has the brightest future?\n\nBased on this infos about me and most importantly about your personal experiences,which job should i choose? Which one it would be more suited for me and my necessities?\nPS. Sorry for the broken english.",
  "I am studying ML for my current job as an engineer, and I may or may not transition into a data science job. But I surely am working on a lot of data science stuff. I need some guidance on if I am working aimlessly studying a lot of stuff instead of having a focus. I would like to find a mentor. How would one approach this?",
  "Greetings everyone.\n\nI work on a company that builds software solutions for governments. At the data sector, we are processing healthcare data for BI and ML applications. \n\nOur current data pipeline looks something like this: Oracle db (data source) -> PostgreSQL db (intermediate db) -> Power BI. This workflow is orchestrated by AirFlow.\n\nThe main issue we are facing is the control of which person can access which database, and the segmentation of said data.\n\nWe would also like to implement a data governance tool. I have been looking into Delta Lake, but it seems this is a tool for data lake house, and not data governance.\n\nI would like advice on which tools should I look into that can fix the issues mentioned. Also, given our current situation, what would be the next step in order to implement a data governance tool?\n\nThanks in advance!!\n\nEdit: forgot to mention, but this tool also needs to be able to work both on premise and in the cloud.",
  "Hello, I would like to share with you my recent article about utilizing the power of a neuro-symbolic framework - PyNeuraLogic, to implement different kinds of Transformers, including the one used in GPT-3.\n\n[https://towardsdatascience.com/beyond-transformers-with-pyneuralogic-10b70cdc5e45](https://towardsdatascience.com/beyond-transformers-with-pyneuralogic-10b70cdc5e45)\n\nI would appreciate any feedback down in the comments. Thank you.\n\n&#x200B;\n\n&#x200B;\n\nhttps://preview.redd.it/4ore6fmgpfha1.png?width=1400&format=png&auto=webp&v=enabled&s=3c9533e3abbe780b9e952f93d55a00eba5f1d33b",
  "How do you present business value that you've generated but that isn't quantifiable?\nThis might be a method or script that increases the robustness of a process - but from the outside that improvement can't necessarily be seen. \n\nOr it could be a better interface for a colleague who doesn't necessarily work faster (1s time saving makes a lot of difference to the user but maybe not to a business process) but the colleague is way happier because they don't get frustrated by bad UI design. In my mind, this is one example that increases the flexibility of people/processes.\n\nHow do you present such findings, e.g. when in salary negotiations - or when asking for a budget? Or do you not use such qualitative indicators at all?",
  "Hi Reddit community, \n\n&#x200B;\n\nI recently wrote a Medium article on using PyCaret to predict the perfect media mix. PyCaret is an open-source machine learning library in Python that makes it easy to build, train and deploy machine learning models. \n\n&#x200B;\n\nIn the article, I demonstrate how to use PyCaret to build a model that predicts the optimal media mix (e.g. TV, radio, print, online) based on a set of inputs (e.g. target audience, budget, product/service features). The article is perfect for anyone interested in machine learning and its applications in marketing. \n\n&#x200B;\n\nCheck it out here:  [LINK](https://medium.com/geekculture/predicting-the-perfect-media-mix-with-pycaret-924b90be7f3a)\n\n&#x200B;\n\nI hope you find the article informative and useful. If you have any feedback or questions, please leave a comment! \n\n&#x200B;\n\nThanks for reading!",
  "can someone tell me what am I doing wrong on my resume?\n\nhttps://preview.redd.it/t61s80qpofha1.png?width=1110&format=png&auto=webp&v=enabled&s=d356aac2f10c7610544010285f8c3e74ebbf4fa6",
  "Does anyone here have experience with LSTM?\n\nI am dealing with an issue that is basically a negative binomial distribution: we are trying to get people to reply to a text message, and we want to see how many days of attempts/reminders it takes before someone replies.\n\nSomeone suggested LSTM as a model, but the examples of LSTM I see are mostly surrounding data that has both upward and downward trends, but what we are dealing with is a series of 0s that end in 1, and that's where we cut the data off.\n\nThoughts from the community?",
  "Quick read on how some datasets may yield biases results with AI.  Also suggests a few ways to improve the datasets. \n\n[https://medium.com/@egray4cs/discrimination-in-ai-machine-learning-and-datasets-680ef3294926](https://medium.com/@egray4cs/discrimination-in-ai-machine-learning-and-datasets-680ef3294926)",
  "I don't want to give too much detail as to what the actual function of the task is. Not looking for help on the actual project. Just curious as to where this aligns with a typical \"skills assessment\" in an interview process for a mid level data scientist position. Thank you fellow data scientists!",
  "Hey Guys,\n\nNew to pandas, I spent the last 3-4 hours trying to parse this nested dictionary into a dataframe but have failed. Now I'm asking the pros for help! Even chatgpt couldn't give me a working answer.\n\nMy goal is to create a separate dataframe out of every most outer key  ex: 'GigabitEthernet0/0' , 'GigabitEthernet0/1' etc should be its own df.\n\nNow in the DF it should be formatted like so\n\n&#x200B;\n\ncolumn = GigabitEthernet0/0\n\nevery key/value as a row below - even the nested ones\n\nfull data and expected results: [https://pastebin.com/XEV64Cbj](https://pastebin.com/XEV64Cbj)\n\nmy attempt: [https://pastebin.com/jzqf2PVK](https://pastebin.com/jzqf2PVK)\n\nI can't get the nested dictionaries to just be more rows.\n\nEDIT: google gods blessed me today and I was able to find some working code\n\nhttps://pastebin.com/pUiY1KDV\n\nThanks!!",
  "I'm looking to make a career change into data science from real estate into data science. I've been teaching myself both sql and python from coursera and various youtube channels. The one thing is holding me back the math. I'm average at math, not great. I never took linear algebra and only took a basic stats class in college. Im just worried the math part of data science might hold me back if it gets too involved with linear algebra",
  "want to share something pretty cool; those are End-to-End, Live, ML projects created by students in the Scalable ML & DL master's course in Sweden! \n\nThey required: feature pipeline, inference pipeline, UI for prediction, all use free serverless infrastructure and on-demand model training. \n\nThe majority of the projects deployed and operated their systems using free services.\n\nWould love for comments, feedback (not on the design of the site \ud83d\udc40, and just overall thoughts! \n\n[https://id2223kth.github.io/assignments/project/ServerlessMLProjectsID22232023.html#id.69rpj0oh5iu6](https://id2223kth.github.io/assignments/project/ServerlessMLProjectsID22232023.html#id.69rpj0oh5iu6)\n\n&#x200B;\n\nhttps://preview.redd.it/uq4gjmxsncha1.jpg?width=1536&format=pjpg&auto=webp&v=enabled&s=35d7dfc6dc54eb8deed45b4dff89be800ace254b",
  "Hello all,\n\nI am a student pursuing my Bachelor's degree in Economics and I am currently searching for a topic for my thesis in the field of Data Science/Machine Learning. As I am still at the early stages of my research, I am open to any suggestions that might be relevant to my field of study.\n\nMy area of interest lies in the application of Data Science/ML techniques in the field of Economics, such as prediction of economic trends, analysis of financial markets, or any other related topics.\n\nIf you have any suggestions or recommendations, I would be grateful if you could share them with me. I would also appreciate any links to relevant articles or research papers that might help me in my search.\n\nThank you in advance for your time and assistance. I look forward to your replies.  \nThank you so much for your time.",
  "[Functional Data Analysis](https://www.psych.mcgill.ca/misc/fda/) is an emerging branch of statistics, it is in response to the growing advancement in data collection in wearable devices or other data measured over time. the study of high dimensional data,in which the instead of the observations being data points, each observation represents a function in time, wear features can be extracted from smooth functions (derivatives are used as features a lot) or other functional \u201cvariants\u201d of classical statistical models ie. (Functional linear model, functional PCA, etc.). The use of functions can be generalized to other types of data, such as [imaging](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3153754/), where they estimate higher dimensional surfaces. \n\nMy question is are there any data scientists out there who do functional data analysis? Or analyzes functional data?",
  " \n\nHello my friends!\n\nI am a last semester undergrad mathematics student and now that I will no longer be enrolled in college, the thought of my future as a mathematician has been haunting me. As you know, the mathematical life can be very lonely, and I only have a couple of friends and professors to whom I can talk about mathematics.\n\nSo, I wanted to hear some advice from fellow experienced STEM wokers who can give me some insight. To give some context I also have a degree in electronic engineering and in my mathematical journey I have been very focused on model theory and logic, but lately after finishing my thesis I discovered that maybe the academia life is not for me. So I have taken two courses on actuarial mathematics and mathematical finance (which I enjoyed a lot). In engineering, I only liked the signal processing/dynamical systems/machine learning courses (which was one of the reasons why I decided to double major in math).\n\nRight now, I feel that life as an academic is not what I'm looking for in life (specially in the country I live in) and that my love for mathematics has been more of a love for challenges and learning new things (rather than mathematics by itself) and I am very passionate about solving problems and mathematics has become sort of a drug giving me dopamine rushes every time something 'clicks' or every time I solve a problem. So that is why I am looking or advice in jobs that have a deep mathematical component that offers challenges every day and that evolves constantly (that also offers good payment and work/life balance). So far these are my options with their pros and cons:\n\n* Quant /Mathematical finance: **Pros**: I love the deep and complex structure of the stock market and I feel that it has rich mathematical problems (stochastic calculus, PDE's, programming, etc.) It also offers great payment and looks like a very active lifestyle. **Cons:** I don't like that the main purpose is money driven. I have also heard that it is extremely time-consuming and that the there is not much work/life balance.\n* Data Analyst/Data miner: **Pros:** I love programming. It also offers rich mathematical techniques and can be applied to a vast number of scenarios. I like that it is not tied to a specific industry because pretty much every enterprise needs data analysis in today's world. **Cons:** I have read that the day-to-day work is very different from the theory, and you end up being an advisor to the sales team on a company that expects you to do magic with their data. I also feel that climbing up the salary ladder takes longer.\n* Actuary: **Pros:** Great payment. Great work/life balance (from what I have read). There are not a lot of actuaries. **Cons:** The need to take so many exams/certifications to increase salary/position. Work becomes very monotone and I feel that you are tied to the insurance market. Spreadsheet boring life.\n* Programmer/software developer: **Pros:** fantastic salary (you can find home office work in USD). Already have experience programming. High demand for software developers. **Cons:** not very math-focused. It depends **a lot** on *what* you are programming. (I see programmers as digital construction workers), I would love some machine learning/math related programming, but I would die f boredom developing web-pages and that sort of stuff.\n\nCan you guys share some of your experiences in these fields? How do you see each career in the future? Do you have any other recommendations for me? Thank you so much in advance. I really need guidance and different opinions before taking such an important decision. Cheers!",
  "So I interviewed at this workplace for a Data Scientist role , I am a junior with no experience besides an intership I did. The market is my country is brutal and Im struggling to find a job for 3 months already.\n\nI did however find a workplace which is mostly low tech hardware type of company but they have a data science & algorithms division. However kn the CEO interview he directly told me they are a conservative workplace - almost everyone are in their 50s and 60s, been there for 20-30 years already, they work on site only and they want someone to stay with them for several years because they do not want to waste time on people \"from my generation\" (in their words) who would leave after a year. Salary is also not high but for a junior I didnt expect much.\n\nIt did stress me a bit because I dont think I will be a fit for their culture. + its a 1 hour drive each direction so it will be hard, and I dont want to waste time and not enjoy there and being not motivated to come to work. However Im financially stressed and I do need the money and its being hell to find jobs for juniors here.\n\nWanted to ask you guys if you think I should go for it and do leave after half a year or a year until the market recovers?",
  "Data Engineer\n\nformat is on mobile sorry\n\nAs the title says, i\u2019m currently a HS student and I am interested in working to become a data engineer/ working with data. I don\u2019t exactly know where to start other than I\u2019m taking a computer science course. What should I do? any advice or places that could help? all help is appreciated.",
  "Hi r/datascience,\n\nApologies if this question is out of place (or gets asked super frequently). But I would really love some insight here. \n\nI (31 Male) am currently a carpenter - and while I do love it - I\u2019m not positive that I want to spend the rest of my working life in it, for a multitude of reasons. Prior to becoming a carpenter, I graduated with a B.A. and worked in Marketing for about 2 years and then became a project manager at a bank. It was there that I was exposed to working with the data management dept on a few projects. While I am basically a total novice, it really interested me. I liked the \u201chands on\u201d nature of it, and I liked the logical and structured approach to problems and solutions. I would also really love to work remote and be able to be more flexible/travel more.\n\nI\u2019m now starting to consider a career change in the near-ish future, and wondering what my best route might be. I\u2019m married but no kids, and could afford some education (~$20k or under ideally) to make the change if that\u2019s required. Otherwise, I wouldn\u2019t mind diving in myself to start learning and find employment on the ground level if that\u2019s possible.\n\nThanks for any insight into what I should consider about a career transition, as well as about the field as a whole.",
  "I am the mod for a sub called r/hairlossresearch\n\nThe sub has collected an enormous amount of research on potential treatments for Male Pattern Balding/Androgenetic Alopecia, but all the information remains mostly unstructured and not available in a salient manner for sufferers seeking the appropriate treatment for their age/stage and/or disease subtype.\n\nI am looking at designing a online decision tree with clickable points to allow you to drill down to finally come to a potential treatment for your circumstances.\n\nI am seeking suggestions on what website or software I can use to build this clickable decision tree.\n\nI am thinking of providing an online form, where multiple research supporters can enter a new potential treatment, with details of efficacy, treatment mode, contra-indications, supporting clinical trials, side-effects,etc. \n\nOnce a new entry is submitted it would populate the decision tree with the new data.\n\nThe reason I am seeking an interface that presents as a clickable decision tree is because the treatment and associated data are so voluminous that a standard tree would be too huge too view on a computer screen.\n\nAny suggestions on a website or software tool that could work for this?\n\nThank you",
  "Hey, \n\nWhat tools do you use to explore a dataset you have never worked with?\n\nI sometimes use Metabase, but I am pretty annoyed by the row limitation. I often fall back to some simple panda python scripts, but this feels not so flexible. Anyone maybe knows a tool like metabase, without the row limitation (Which can also be paid)?",
  "The description of this subreddit is \"to discuss ds career question\" so here's one question for the senior folks of this sub. I'm a Junior /Associate in this field and about to complete my 2 years at a IT consulting startup. Things like very less pay, heavy team politics, unhealthy work environment, employment bond etc are making me quit this company. The question is am I an idiot if I quit my job without having another one lined up and start the job hunt process once I'm on the notice period?\n\nWhy am I taking this route? Many reasons:\n\n1. Employment bond renewal during yearly increment.\n2. Thee month notice period.\n3. Need time for interview prep. Bad work life balance does not provide me with enough time.\n\nLocation: India\n\nNote: I'm just looking for some guidance and that's about it. Many people here have experienced more years then me in the corporate world or might have experienced something like this. Please feel free to drop in your views.",
  "Can't seems to find solution for this. I am thinking of just classifying the variable into categories and do a one-hot encoding on it. Thoughts or sharing of past experience? Thank you.",
  "I\u2019m currently a junior DS in my company (large org, property sector). I joined as an intern earning peanuts after my MS and just got made full time last month. Current package is more livable but well below market average. \n\nA couple days ago a recruiter from a company I was targeting post grad (e-commerce/retail) reached out to me. we had a call about an Analyst role opening up and they were interested in my profile. In a nut shell I got the impression that the job was primarily dashboarding. I mentioned I\u2019m currently learning and working on ML problems and that\u2019s what I want to continue doing. So the consensus was that there\u2019s nothing that\u2019s I\u2019d be interested in now but as they build out their BI dept something will eventually pop up. \n\nAnyway, my heads been turned. The package they would offer is at least 2x what I\u2019m making now. I saw the job posting in linked in yesterday and to my surprise one of the requirements is experience with ML! \n\nI\u2019ve been with my current company for 7 months and it\u2019s not bad but not great either. Boss is hands off, invests in courses and training. But I\u2019m the sole DS in my team and don\u2019t have a mentor. There are other DS in the in different departments, but due to some workplace politics we compete more than we collaborate. \n\nSo to keep this post short, I see two options: \n\nA. Get a year under my belt with my current company and work on personal projects that will help a future application with Company B. \n\nB.  Call the recruiter back and say I\u2019ve changed my mind after reading the JD and potentially move. \n\nI\u2019ve had awkward gaps and lengths in my CV in the past hence my reluctance to leave so early. But since my foots in the door with my ideal company I\u2019m not sure what to do. \n\nAny advice or suggestions?\n\nTIA",
  " Does anyone have \"The Kaggle Book : Book by Konrad Banachewicz and Luca Massaron  \n\" in pdf ?? Please share the link  ?",
  "Hi, I am new in the data science field and am learning the same from an online course. \n\nAlong with that I want to do an internship to get hands-on on experience.\n\nI had applied for internships in a couple of companies and they have provided me with an assignment to solve.\n\nAny help for the said assignment will be very much helpful. \n\nReply to this thread so that we can discuss about the problem.\n\nThank You.",
  "I was told imageJ but can\u2019t seem to find anything in the tools that indicates I can export data on a frame by frame basis. Am I not seeing a major feature or special plugin? I\u2019ve looked through documentation and cannot even get on the trail of how to gather nor export that data from a video\n\n&#x200B;\n\nI can hang my cursor in a spot during the video and watch the exact data I need cycle through on the pixel indicator location while the video plays. I really just want to export that data to a table. Feels like it should be very simple \n\n&#x200B;\n\nEnd goal is analysis in JMP but won\u2019t have to do this many times so it doesn\u2019t need to be super clean",
  "I have a database of what amounts to pairings between workers and tasks.\n\nThe database has pairs of tasks and workers that were successful in each task.\n\nI\u2019m trying to figure out the best way to predict which worker in a given group is best for a given task.\n\nWhat technique should I use? I was thinking of using a model to predict the best worker, and then give each worker a score based on the Euclidean distance from the ideal worker. Does that sound any good?\n\nThe workers and tasks are both multi labeled",
  "So I\u2019ve just started a data science role at a big bank. I have almost finished studying my Masters in AI & ML.\n\nMy first project at the bank is to conduct analysis on time series data, both univariate and multivariate.\n\nI was tasked with trying SARIMA first on the end of term dataset before even looking at independent variables.\n\nSo I cleaned my data; removed trend, normalised, removed seasonality and got a p value less than 0.05.\n\nI did my optimisation of my model, computational testing orders and got as good of a model as I could.\n\nI tried testing by leaving monthly data off the end and trying to predict it with horrible results.\n\nI know have a problem.\n\nAssuming I haven\u2019t made a mistake, this implies that this model is a poor fit for this data or that data is too volatile for this model and requires an alternative model and other variables.\n\nIs that the correct conclusion to come to? Basically, I\u2019m asking how do I know that I haven\u2019t made an error in the design of the model and/or cleaning of the data, especially if I have followed the \u201cby the book\u201d approach?\n\nMy guess is that comes with experience and obviously testing other models for better fit is probably a better alternative than trying to fix a problem I can\u2019t observe.",
  "I have got an offer for data engineering internship for 4 months where I have to perform web scraping and crawling which is new to me and it is unpaid. They only provide certificate of completion at the end.\nAbout me : I am pursuing my Masters in Data science currently so DE is a new field to explore.\nAny suggestions?",
  "Hi I\u2019m looking for some help regarding publicly available datasets or websites I could scrape. Information on rehabilitation would be a plus. \n\nLinks or Pm would be appreciated.\n\n(Feel free to move it the wrong sub)",
  " \n\n**Are there any differences or definitions?**\n\n**Do we need them for the future of AI?**\n\n**Read the below Medium article published in Towards AI:**\n\n**https://medium.com/towards-artificial-intelligence/understand-ai-interpretability-explainability-3718797777ec**",
  "Hi all,\n\nMy current position is something like an Environmental Specialist, focusing on sustainability programmes. I have a PhD, have been in post for two years and I'm in a position to select a new job title. \n\nI work for a large organisation, however, while there is a business performance department, I am the only one involved with a set of projects aligned with sustainability including 1) IoT deployment, UI development and data analysis for environmental monitoring,  and 2) Enriching existing datasets using APIs for geospatial mapping and tracking.\n\nI really enjoy working with data and code (Python has been adequate for everything I've needed so far) and I'm hoping that a job title that includes either \"data science\" (for the analysis and decision-making part) or \"data engineering\" (for the IoT part) would give me to scope to keep learning and progressing.\n\nInterested in any thoughts on what a preferred job title would be for a generalist rather than someone dedicated to a focused area e.g. \"Environmental and Data XXXXX Specialist\"\n\nThanks for any thoughts!",
  "How do I fetch bulk data from a open source and bring it to excel? I've been trying the basic tutorials on Power Query but it's not working and I'm pretty sure I'm the problem \ud83d\ude05\n\nTo give you some info, I've been trying to get company data from a few open registries, like France and Germany, but my skills are poor and Excel keeps crashing. I'd like to fetch only the data related to the ids I have, so I don't want to download the whole set of course.\n\nCould someone smarter give me a step-by-step?",
  "I\u2019m looking for good blog / news sites for learning new topics and staying up on everything data science / machine learning related. Medium seems to be perfect for that but I wanted to know if there was any other suggestions anyone has; Is medium worth the $5 / month $50/ yearly pay wall?",
  "Hi all\n\nI am fairly new to data science. I have done some projects either for my work or for my own interest(Mostly graphs,some data cleaning, timestamps and other). I was following a course in a site but i felt that it was like they were chewing the food to my mouth.And now im kinda lost about what are the steps i should take. So what steps would you recommend to someone that wants to start data science from scratch?  Also are there some courses that are trsutwothy and worth the time?\n\n&#x200B;\n\nThank you in advance",
  "I have been given a csv file which contains a column named NIC. it contains values like \" Growing of perennial crops\", \"Growing of sugar cane\", \"Growing of spices, aromatic, drug and pharmaceutical crops\" etc\n\nMy goal is to Use Natural Language Processing for analyzing the various core industries and group the business categories in the NIC column.\n\ncan someone help me how to apply NLP on this column",
  "I got a promotion from Senior DS (150 base, 175 TC) to Lead DS (160 base, 185 TC).\n\nI have about 3.5 years experience leading teams, 6.5 years total. I joined this company a little over a year ago as an IC for the pay bump and was asked to lead the team after a couple of months.\n\nThe model I inherited made < $1mm annually, and now it's on track for $2.5 - $3 mm since I took over. All stakeholders are happy, and I'm well liked within DS according to my boss and his boss. 10k feels like a very small difference, not a large enough difference for the promo or the scope of responsibility. Thoughts?",
  "Hi, I would love to do volunteering for companies or start ups as a data scientist or data analyst? Do you think is possible?\nIs there anyone ever done it before? Any feedback would be really appreciated, thank you for the time \ud83d\ude4f\ud83c\udffe #love",
  "Hi,\n\nWondering how likely it is to get a job with bootcamp certificate vs. a bachelors in computer science vs a masters? Provided all other factors are pretty similar (e.g., project portfolio).\n\nThanks,\n\nEric",
  "Is there a place other than toptal and upwork where a small business can easily find geospatial data scientists or gis analysts for small projects like site selection? We're trying to understand this market. If you are a consultant/contractor who looks for projects, can you fill this quick survey out or post here?  I'm looking to build a marketplace to take some of the work that comes to our site (idealspot.com)\n\n[https://forms.gle/BUT3grrAZCJbiwFNA](https://forms.gle/BUT3grrAZCJbiwFNA)\n\nWe are a startup out of Austin, TX -- We built a data reporting tool for small businesses but we get a lot of requests for GIS analysts / Geospatial data experts to consult with clients about the reports. We're looking to build a list of experts we can hire/subcontract to. ie., more about us and our datasets.\n\n[https://www.idealspot.com/solutions/data-connect](https://www.idealspot.com/solutions/data-connect)\n\nThanks!",
  "So I have 1 year of experience as a data analyst. Mostly doing dashboards with PowerBi and descriptive statistics with a few logistic regression models. I competed my masters in statistics and have been working since. I know how to program in R and Python and only used SQL in classrooms and from my own learning. My job is currently through a contract and it\u2019s ending soon this April. I applied to a bunch of jobs and admittedly sometimes skimmed through the application and didn\u2019t read the whole thing before applying. I got an interview for a programmer analyst 2 and I feel so overwhelmed and under qualified for the requirements I politely declined the interview and instead emphasized my interest and confidence in another job data analyst that I applied for within that same company. But the interviewer asked me again today if I am still interested in that position. So I\u2019m wondering if maybe I should just do the interview. These are the requirements for the job and for me it sounded like it was way more about programming. I also haven\u2019t used any of the software tools listed besides SQL. \n\n\u201cWrites code or configuration to implement business requirements using approved technologies. Ability to review, analyze, and enhance configuration/programming systems including coding, testing, and debugging. Interprets business requirements and develops design specifications. Writes code or configuration to implement business requirements using approved technologies. Ability to consult with application's users to identify current operating procedures and to clarify program objectives. Proficiency in code development using reporting tools (Alteryx, SSRS, etc.), ETL tools (Talend, Data Stage, SSIS, etc.) and SQL coding (Toad, DBeaver, etc.) and a database operating systems and platforms (such as: Oracle DB, SQL, Greenplum, Snowflake, AWS, etc.)\u201d\n\nShould I attend the interview? Or would it be a waste of both of our times ? Any feedback would be greatly appreciated. Also I didn\u2019t lie about anything in my resume so I\u2019m shocked they are considering em for a position that asks for 7 years plus experience.",
  "Hi. \nI try to find a job as data scientist (EU)\nI want to do some projects divide by categories.\nQuestions:\n1) where would I put the projects, and then link them in the CV?(right now they are from a GitHub site done with Hugo)\n2) how many projects and what kind should I do?\n3) how to present them?(tableau, Jupiter notebook, power bi, Google slides, other)",
  "&#x200B;\n\nhttps://preview.redd.it/w3txiyn398ha1.png?width=354&format=png&auto=webp&v=enabled&s=56540245a1226c843fb84ffbba89443d512d87ee",
  " The question is this. \"I need to know the statistical data types of my values, in order to decide what methods I will use on this data for machine learning. How can I do it en masse within a dataset with 100.000 columns?\"\n\nthe .dtypes give me computer data value (int64 etc.) but I want statistical type (interval, ratio, discrete, nominal etc.) also, if I'm using numerical data for ordinal things or 1 and 0 as boolean, that shouldn't get stuck in my function.\n\nI had a heated arguement with ChatGPT and it's final suggestion is:\n\n    \n    import pandas as pd  \n    \n    # Load the data into a pandas dataframe\n    df = pd.read_csv('your_data.csv')  \n    \n    # Get summary statistics for each column \n    summary_stats = df.describe()  \n    \n    # Identify columns that contain ratio or interval numerical data \n    numerical_columns = [col for col in df.columns if df[col].dtype in [float, int] and                      (df[col].min() > 0 or df[col].max()/df[col].min() > 1 if df[col].min() != 0 else False)]  \n    \n    # Identify columns that contain nominal or ordinal categorical data \n    categorical_columns = [col for col in df.columns if df[col].nunique() < df.shape[0]*0.05]  \n    \n    # Convert the data type of the categorical columns for col in categorical_columns:     df[col] = df[col].astype('category')  \n    \n    # Validate the change of data type \n    for col in categorical_columns:     \n        assert df[col].dtype == 'category', f\"{col} is not a categorical type\" \n    for col in numerical_columns:     \n        assert df[col].dtype in [float, int], f\"{col} is not a numerical type\"\n    \n    --------------------------------------------------------------------------\n    AssertionError                            Traceback (most recent call last)\n    ~\\AppData\\Local\\Temp\\ipykernel_26568\\177826119.py in <module>\n         24 \n         25 for col in numerical_columns:\n    ---> 26     assert df[col].dtype in [float, int], f\"{col} is not a numerical type\"\n    \n    AssertionError: floors is not a numerical type\n\nRealistically, \"floors\" is a controversial value. Some say it's continous because there can be 1.5 floors, I'd say it's discrete numerical value.\n\nHow do I get out of this? I can't manually check 100.000 columns",
  "Curious to see what others have experienced in terms of their interview process. It feels like data science interviews are much like streamlined compared to regular software engineer gigs.",
  "Consider a problem where the target variable can take on 10 possible values but only 6 of them are shown in your training data. It\u2019s likely that the other 4 values show up in the test set but you cannot see the labels. What algorithms are you confident would be able to achieve relatively meaningful results?",
  "Hi everyone, I'm currently a high school senior who is going on a pre med track into my undergrad. However, I also have a strong interest in data science, especially bioinformatics, for computational biology research. I have a lot of time now that my college applications are over and want to learn as much as I can in data science. Pasted below is my current plan on what I want to do. I'm trying my best to finish them all by September, but it is very likely to bleed into my first year at uni.\n\n1. Fundamentals of Computing Specialization\n\n[https://www.coursera.org/specializations/computer-fundamentals](https://www.coursera.org/specializations/computer-fundamentals)\n\n&#x200B;\n\n2. Introduction to Mathematical Thinking\n\n[https://www.coursecra.org/learn/mathematical-thinking](https://www.coursera.org/learn/mathematical-thinking)\n\n&#x200B;\n\n3. Discreet Math\n\nOption 1: UCSD Specialization\n\n[https://www.coursera.org/specializations/discrete-mathematics](https://www.coursera.org/specializations/discrete-mathematics)\n\nOption 2: Rosen textbook\n\nOption 3: MIT course\n\n[https://openlearninglibrary.mit.edu/courses/course-v1:OCW+6.042J+2T2019/about](https://openlearninglibrary.mit.edu/courses/course-v1:OCW+6.042J+2T2019/about)\n\n&#x200B;\n\n4. Algorithms Specialization\n\n[https://www.coursera.org/specializations/algorithms](https://www.coursera.org/specializations/algorithms)\n\n&#x200B;\n\n5. Data Structures and Algorithms Specialization\n\n[https://www.coursera.org/specializations/data-structures-algorithms](https://www.coursera.org/specializations/data-structures-algorithms)\n\n&#x200B;\n\n6. Bioinformatics Specialization\n\n[https://www.coursera.org/specializations/bioinformatics](https://www.coursera.org/specializations/bioinformatics)\n\n&#x200B;\n\n7. Single Variable Calculus XSeries\n\n[https://www.edx.org/xseries/mitx-18.01x-single-variable-calculus](https://www.edx.org/xseries/mitx-18.01x-single-variable-calculus)\n\n&#x200B;\n\n8. Mathematics for Engineers\n\n[https://www.coursera.org/specializations/mathematics-engineers](https://www.coursera.org/specializations/mathematics-engineers)\n\n&#x200B;\n\n9. Mathematics for Machine Learning Specialization (First 2 courses)\n\n[https://www.coursera.org/specializations/mathematics-machine-learning](https://www.coursera.org/specializations/mathematics-machine-learning)\n\n&#x200B;\n\n10. Data Science MicroMasters (First 2 courses)\n\n[https://www.edx.org/micromasters/uc-san-diegox-data-science](https://www.edx.org/micromasters/uc-san-diegox-data-science)\n\n&#x200B;\n\nAfter I finish all of these, I intend on diving into ML with the goal of eventually utilizing it for research. I know that this is a lot, but I would really appreciate any feedback on my current plan and if there's any changes that could be made or any other resource I should use.",
  "Hi yall, I am working with Python and wanted to learn some insights from everyone.\n\nThis is a large dataset that I am working on and I have thought of the following approaches :  \n1. preprocess the images into smaller chunks/files\n\n2. run multiprocessing to make it fast\n\n3. store with BigQuery\n\n4. train and test with smaller chunks of data to check the accuracy\n\nHowever, as I was reading through some StackOverflow resolutions, question that came out was:\n\n1. Since this is for millions of data, would something like \"set\" instead of \"list\" improve the time ?\n\n2. Would writing the data files using C++ make it faster?",
  " I'm a beginner when it comes to data analysis stuff, I've been completing data camp courses.\n\nPeople seem to suggest, creating projects is better for learning. Hence i tried my hand on creating one. It's filled with holes, i understand. My First time to create a \"Story\" using foreign dataset.\n\nIt was a Dog Breeding Dataset, where i used a mixture of Seaborn and Matplotlib, as I'm not very familiar with Seaborn as of yet. I've read a lot of Statistics articles + datacamp courses. but implementing and Learning is better, hence i didn't use any over the top statistics such as \"Showcasing Distribution graph\" and Dealing with outliers. As i didn't want to over complicate it before i get a review on it.\n\nHappy to hear any critics, i want to improve on my skills. Before jumping to SQL and Power Bi, i know the basics but haven't made any \"unguided\" projects yet.\n\n[My Kaggle Notebook Project](https://www.kaggle.com/code/irfanlone/breed-popularity-analysis-hypothesis-testing)",
  "I have been trying for weeks, trying different forms of jekyll, hugo, and whatnot. Could someone help me in this, I am trying for a job and my resume doesn't even get shortlisted hence I thought of adding a portfolio website.",
  "Hey all, [repost](https://www.reddit.com/r/careeradvice/comments/10wngpx/comment/j7oe976/?context=3) from r/careeradvice as I got recommended to get your guy's opinion on this.\n\nFor context, last May I graduated with my bachelor's in CS. During that time I was part of an undergraduate research group and I really enjoyed it. I was able to get 2 publications (conferences) at the time and felt like I was doing a lot.\n\nBy the time I was graduating, the school was starting a new data science PhD program. Since I really enjoyed the research experience, I applied and was accepted, such that I was skipping my master's degree and doing a PhD directly. I've always wanted to do a PhD.\n\nNow I am in my first year of my PhD, and now I am a bit anxious that the fact that I will have a degree for both my bachelor's and PhD are from the same university.\n\nFor you to know, I do not plan to go into academia after my PhD, I plan to work directly in the industry as a data scientist. At the time, I figured that the school did not matter much for industry vs. academia. Will this be a red flag to employers?",
  "Hello, I am a graduate who was applying for Data Science and Data Analytics jobs, I recently got an offer for a Data Engineer position. I don't seem to be having too much luck with Data Science jobs, I understand that while Data Engineers still work closely with Data Scientists and Analysts that they require different skill sets. If I were to keep practising my Data Science skills could I still expect a data science-like job in the future or should I expect to stay in data engineering if I take this job?\n\n&#x200B;\n\nAny advice is appreciated, thank you.",
  "Where can I download free datasets to use for practice? All the ones I\u2019ve found are only possible through payment // is power bi & excel good enough to make someone a data analyst?\n\nEdit : Everyone that replied, thank you guys so much!!! I really appreciate it",
  " \n\nI'm going to have an interview with an intern tomorrow. He is studying business informatics. It's my first job interview on the other side as an interviewer. I want to make the interview as fair as possible. So no super nasty or hard questions. What are good questions in relation to business intelligence, databases, statistics and data science?\n\nThese are some questions I have written down:  \n\\-What is the difference between sql and nosql? What advantages does a nosql database offer? Are there any disadvantages?  \n\\-Why do you do so-called normalizations in connection with databases?  \n\\-Which libraries have you already worked with in python?  \n\\-In connection with statistics, the p-value can often be read. what does the p-value say and what is it used for?",
  "I am solving a regression case for an interview. They gave a dataset with 12 features and 800 observations. I made a regression model in LightGBM and it performed really well in the validation dataset. \n\nThe problem is that it is the only model I made and I would like to try more things to show to my interviewer. Some thoughts:\n\n&#x200B;\n\n1. I thought about making a traditional linear regression to compare LightGBM with but the data they gave does not hold the assumptions of a linear model (i.e. residuals not normally dist.)\n2. I thought about XGBoost but, as far as I know, its performance is similar to LightGBM but LightGBM is faster and uses less memory\n3. Neural networks are not even considered given the size of the dataset\n\nThe instructions of the case say that the company is not so well interested in the prediction itself. They explicit say that the approach used to solve the task is more important than the prediction, especially because the data was randomly generated. In this case should I stress with making more models? \n\nGiven that the instructions talk about the approach, I did an extensively EDA, stated all my findings, why I chose to use LightGBM, etc.",
  "I recently stumbled upon a job that is as close as it gets to being a dream job for me: a data scientist position in a physics-related setting, considering that I have a PhD in physics where I mostly did machine learning. Even the subfield of physics matches. \n\nReading through the job offer I got pretty confident that I was a really good match, fitting almost everything they needed plus some more of my own strengths, etc. So obviously I applied. There's the usual upload your resume, basic information, etc.\n\nThen the website brings me to a new page where they ask a few basic questions which I answer truthfully and in a positive way. Until I reach: \"Do you have any experience with Federated Learning?\"  The real answer is No, I don't. And that's what I clicked, being honest and all. But I realise that clicking No means _being automatically rejected / filtered away without a chance of defending myself!_ In front of a human recruiter, I would say no but that the concept does not sound so daunting and that I have proven track at fast adaptation and learning, which means I'm likely to very quickly pick it up. But there is no human recruiter in front of me. And in that way, I cannot emphasise on all the technical and non-technical aspects that would be my strengths for that job. Which leads to: a mediocre candidate with some experience at that specific skill has a higher chance that an almost perfect match which is only lacking in that area. \n\nMeaning: I'm getting rejected from a dream job without a chance to even defend that I'm a very good match.\n\nSo of course, I'm thinking of simply lying the next time. Sure, the lie may get discovered by the recruiter later on in the process but then I at least have a chance at arguing or defending my way in. \n\nAnticipating the comment about learning Federated Learning: sure I can do that, but the next job is going to ask for a different skill. And then another different one. Etc. And some of these skills are sort of hard to actually justify an experience on when you do not have the infrastructure (e.g. multiple servers for Federated Learning).\n\nWhat do you all think?",
  "I 22m recently finished my bachelor's last year and have decided to apply for a masters in Data Science abroad which will take some time to prepare, which brings me to my dilemma. Some backstory: During the pandemic (apologies if I brought unpleasant memories) I started my self taught journey in data science, which involved watching a lot of tutorials, reading articles which somewhat gave me the jist of what algorithms and fundamentals (statistics, python,sql) are in the line of work. I watched some courses on statistics to try actually understand some concept like probability and especially harmonic mean lol, learnt SQL but never got to know how I'd use SQL to actually get data from a database anf use it for modeling. 2 years later, I honestly don't even know what am doing anymore, I wake up, log in to kaggle, find an interesting dataset, formulate a problem that might need solving (no matter how ridiculous it is) and do some analysis or build a model, and by the end of the day I contemplate whether what am doing is enough to actually land a job in the coming years. Don't get me wrong but I actually am very interested in the field.\n\nWith a all the blogs and multiple YouTubers around providing information on what data science is all about I end up questioning the very name of the field, what the actual **** is data science? Feels like I have been doing nothing in the past few years (jus 2 lol) I have made some models with which I am proud of especially a food recommendation system that I ended up presenting as my finals project..in addition, I read a lot of threads in the sub of what employers are looking for during interviews and realize that there's so so much I still don't fully understand....\n\nApologies for the rant, but today is jus one of those days that I question my efforts in the field..\nId really like to get some advice on how to continue on..",
  "Hi all\n\nI'm sampling around 2% of the dataset to build a classification model using XGBOOST.\n\nI notice that when I re-run the whole pipeline I get quiet different results, something that could be explained by the sampling process. That's an issue when I compare to different models and the differences are small (i.e., not sure if they due to chance or not).\n\nHow do you normally deal with that? Is there a way to build a 95% CI around the PR curve?",
  "Hi! I am new to ML and was wondering which encoding I should use.\n\n&#x200B;\n\nFirst, my mission:  \nPredict flight coefficient based on historical data.\n\nMy data:\n\nInt: year, month, day, week\\_day (of the flight)\n\nstring: classname (like UberX or Uber\\_Select), departure\\_country, departure\\_city, departure\\_airport, arrival\\_airport, arrival\\_city, arrival\\_country\n\n&#x200B;\n\ntarget - coefficient: float\n\n&#x200B;\n\nSo **a lot** of categorical data.\n\nI attempted pandas get\\_dummy and OneHotEncoding, which create those really large sparse matrixes. I read an article suggesting TargetEncoding, but that would make it harder for my model to find inter-relationships among this data (and I am sure there are)\n\n&#x200B;\n\nSo if anyone can help me out choosing the right method, I would appreciate it greatly!\n\nI work with python, just in case",
  "Will be working there this summer and was looking for some info on what previous interns did for projects. \n\nWas management alright? Will you be returning to JPMC if so why/why not?",
  "I recently put together a data visualization that ingested 8M lines of census data and plotted them onto an interactive 3D globe. Interactive demos are NOT easy though and this required data cleaning with Bash and Python, data ingestion with C++, and then a video game engine to help with the interactivity.\n\nDo people in the community consider a task like this to be data science (since you would need data science skills to put this together) or would something like this fall more under the category of data engineering or software engineering?\n\nAlso, if any in the community is interested on how to put together this kind of interactive app (either for a CEO level presentation or as part of some high end dashboard), I am make this course FREE on YT. The first two sections of the course are available now ( [https://youtube.com/playlist?list=PLKH3Xg62luIgPaB4fiFuTQ9-q-sbw-kQj](https://youtube.com/playlist?list=PLKH3Xg62luIgPaB4fiFuTQ9-q-sbw-kQj)) and an additional section of the course will be uploaded to YT each Monday.",
  "As the title says, I would like to have some consulting with someone from the field. Preference is Germany but EU should be fine. Currently in MS for DS and want some guidance, cv review etc. With payment of course.",
  "I want to read articles and news daily on data science and AI, and I was wondering if you could share some recommendations. I currently read stuff from AI impacts, Science Daily, and Tech Crunch.",
  "It seems that everyone who has the title of Data Scientist has a master\u2019s, so i was wondering how did you guys become titled a data scientist? Were you first a data analyst and then climbed up the ranks and get master\u2019s? Or did you right away get an entry level data scientist job with a bachelor?",
  "Join this live and learn Data Manipulation [https://youtube.com/live/wQDmssRCdDw?feature=share](https://youtube.com/live/wQDmssRCdDw?feature=share)",
  "Hi all, we have a large dataset (500 mil rows after aggregations) and our end users want to access it as a table. I thought about maybe connect it to tableau and put parameters to limit what they can show/ pull down to csv at once, but sounded like they are interested to do exploration on the entire dataset since it\u2019s so new. \nFor more color, we have tableau, power BI, and Databricks. \n\nIs there a good way or a tool to deal with this? Appreciate any advice",
  "I'm so nervous, I've never been interviewed by a company for a data science internship (specifically for undergrads, so I don't have to go up against masters or phd students lol). I've only ever interviewed for labs at my university, non profits, or high school interviews. I have a lot of anxiety around this and have no idea about what kind of questions they'll ask me. Any tips, tricks, heads ups for an anxious third year in undergrad? TIA !! :)",
  "Hi all, I am eyeing the UK/Ireland market for a data scientist job as a fresher. I'd like to know how much to expect as a fresher and how the salaries can grow overtime. \nAlso any suggestions for the cities with best career opportunities are welcome.",
  "I\u2019m Bachelor 1st year student. I started learning data science skills about 6 months ago. I am quite good at data cleaning, modeling, visualization part expect those dashboard thing with python. I can do basics things in power BI. And I have been learning ML and DL for more than a month. Should I start searching for interns or should I harness my skills and do Intern after second year.( Since I have day college I can only work as intern if It is remote evening shift. Our class will be shift to morning after second year.)",
  "Hi I need an honest review of Tutort Academy if u had joined and studied in that academy. I looked at some reviews of the academy on quora but they are by people who were already working in companies like JP Morgan or VMware and then they joined Tutort Academy and got jobs at Microsoft or some other big tech companies. All the reviews look similar which makes me feel like are not very honest. So just wanted some honest reviews. Want to know about their teaching style and placement support.",
  "Preface: I'm on month 6 of being the first data scientist at this professional services firm and it's a total nightmare. All the worst symptoms of a badly managed 'innovation' team: swapping priorities just when i get into a groove with a project, an ad-hoc project management framework, management agreeing to deadlines without taking feedback on how reasonable or how much effort projects will take, management dropping messages in my inbox with suggestions on shiny low-code tools that they think would be interesting to try out (they are not), management not hiring more staff even though they agree that my position should be split up into at least 2 roles, management asking me to produce work that doesn't ever get used by anyone, etc. I'm quickly planning my exit strategy but have this immediate fire that i need to put out.\n\nThe biggest issue at hand is that the person playing Product Owner is strangleholding me into working on project for which there is currently no data to work with. Product Owner's \"strategy\" for getting data is that when the beta app is built, we'll use the documents that clients upload into the app. However, these documents are highly confidential, and the project will require sending the documents to a third-party vendor for data labeling and re-training the head of a large language model. Product Owner has not indicated at all that these clients will be notified that their documents will be sent to third-party vendors. I know enough about IP law to know there's something off with this situation, but don't have the verbiage to know what to ask for, how to ensure Product Owner did their due diligence, etc. What is within my role as Data Scientist to ask Product Owner that this potential data source will be lawful to work with?",
  "I have a personally-scraped and curated dataset that I'd like to open source. Primarily, I was thinking somewhere down the line I'd write a tutorial on my [blog](https://www.ddanieltan.com/) and I'd like to point readers to a link to get the same data I'm working with.\n\n**Q: What's the best and most sane way to do this?**\n\nLeft to my own devices, I'd probably just upload the data to a Github repository. Any updates to the data can be git tracked.\n\nBut, I'm also aware that there are dedicated platforms to catalog and share data (e.g. [https://www.dolthub.com/](https://www.dolthub.com/), [https://data.world/](https://data.world/)), and that uploading data on Github, in general, doesn't seem best practise.",
  "Edit post (1) - I do have a bachelors of science in agriculture (4years hons degree), although it's not from a renowned university.",
  "Hi all. \n\nSome context: My background is in engineering (not data science). I work at a manufacturing plant as a process engineer. Although my background is not in data, a bulk of the work I do in my current role involves analyzing large datasets to identify defect trends and rectify quality issues. I learned python, JMP on the job and use these for data visualization and statistical analysis.\n\nThe problem: my process involves making (cutting) multiple parts out of a single ingot. The parts are cut simultaneously. A single ingot can yield up to 7 parts. The process takes about 5 hrs. The machine records data of key machine parameters (inputs) every 5 seconds. So, each cut (production run) produces about 3600 rows of data from ~10 different parameters.\n\nAt the end of a cut, each part is inspected on a CMM for surface features. When I plot the readings of the surface features of each part from each cut on a time series graph, I notice that the surface feature readings tend to drift with time (variation between cuts). I want to know what is causing the drift. \n\nWhat I need help with: I want to know if there is a correlation between a certain machine parameter and the surface readings. I have 3600 data points from my input and 7 data points from my output compared over n number of production runs. This is a lot of data to deal with and it is very difficult to draw any conclusions from such a comparison. Is there a way to simplify the analysis? I guess what I am asking is what type of analysis would make sense in this situation?",
  "I am working on an Esports project where I have player data with individual instances like KDA(kills deaths assists). \n\nI also want to compare players against each other in aggregate by their data and further combine teams of players to compare teams.\n\nWould the appropriate aggregation method be to average the players KDA or use each players median? My gut is to use average in this case but I don't have any reasoning behind it.\n\nI am not at the present looking to do any time of hypothesis testing or regression.",
  " I (24M) got a medical degree but decided that this field is not for me and I've did some amount of research to say that i wanted to get started in the data field as an analyst. I wanted to know what route to take, I basically self taught myself medicine and wondered if i should just follow a roadmap or should i go to formal schooling and get a certificate. If there's any other route as well, please let me know or any thoughts that you guys might have. I really just want to get started on the journey.",
  "I now have a few projects under my belt in Jupyter Lab/Notebook and want to move them to Github, but i'm not sure about how much of the project I should be showing. \n\n1. Do I need to include all of the code even where I am just cleaning and preprocessing the raw files?\n2. Some of the data I worked with is confidential company data, how can I show it in my project and talk about the results without breaching company privacy?\n\nI couldn't find any clear info on this online. If anyone has any tips on this or about how to format a github project in general that would be helpful! Thank you for your time.",
  "What\u2019s the work/life balance? Is it long hours or chill?",
  "The company I work for is starting to implement Dataiku for its data science projects.\n\nI've started the trainings and honestly the tool called DSS (Data Science Studio) it's wonderful. It covers a full DS project lifecycle.\n\nSearching online there are good reviews and it's one one of the best growing startups but I don't know anyone using it. So my question is, is Dataiku widely used in as the numbers say? It would be great to get some advices from people already using it.",
  "Learn about MLOps and follow our new AI publication from experts in the field. We will be talking about MLOps, ML project, open source. Data science is one of the main areas that we will be approaching.\n\nFollow us now: https://medium.com/ubuntu-ai/",
  "A bit of backstory, I\u2019m currently 19 completing a degree apprenticeship in the UK (Started 5 months ago). It is a data science degree apprenticeship, but most of my time so far has been spent doing data engineering in pyspark on a dataset of about 3.5 billion (creating methods and implementing them to get our desired outputs)\n\nWhile I\u2019m doing this, I want to get some experience in ML and therefore start my own ML project in my own time to further my skills/development. Are there any particular courses/videos/exercises that you particularly like and think are helpful to get started?\n\nNote: Sorry if this is a commonly occurring post on this sub",
  "I've been building a project with the goal of adding it to my resum\u00e9 but I'm not sure the results are anything to be proud of. Here's the Github repo: [https://github.com/miguelscarv/opinions](https://github.com/miguelscarv/opinions)\n\nThe project has to do with entity sentiment analysis, pretty much predicting sentiment on a document about a certain entity (like a person, company, product, etc...) using active learning. The data was scrapped with the Twitter API, so yeah the data is tweets.\n\nI scrapped 500 tweets about Elon Musk and saved the 100 most recent tweets as a test set and the remaining 400 tweets acted as my training set. I then used a roberta model finetunned for sentiment analysis on tweets ([https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest)) and it got 57% accuracy out of the box. Mind you that this is a 3 class classification task.\n\nThe cool thing about my project is that it uses active learning to recommend tweets for someone to label with the goal of getting a better model with the least amount of labeled tweets possible. So using the training set I labeled 40 tweets and got my accuracy on the test set up to 66% - a 9% increase in accuracy because I labeled 40 tweets. Now my question is: is that good?\n\nThe model I used was already finetunned for sentiment analysis and I just further fine tuned it. the training loop looks something like: the active learning policy asks a user to label 8 tweets (this is the batch size) and once they are labeled it updates the model and uses that model to recommend another 8 tweets for a user to label.\n\nThe number doesn't really sound good enough to add to my resum\u00e9, but tbh I was surprised I got that improvement because there are a lot of tweets about Elon Musk that are hard to label, even for a human....",
  "For example, i want to scrape reddit data from subreddits related to various illnesses like r/cancer, r/lyme, r/diabetes. Then i want to estimate \"death rate\" of posters taking some healthy subreddits as controls, like r/Swimming etc.\n\nGiven it's related to medicine,  i assume someone might have done it already, but don't know how to search for such studies or in what subreddits to post questions about data science analysis stuff. I know i could ask chatGPT, but i'm not sure it will help.",
  "Hi, I am new to the world of DS / DE / DA. I have my BS in Materials Science & Engineering, and spent 4 years in industry doing manufacturing and R&D, which required stats based data analysis and report writing. \n\nI switched to a backend Software dev job 5 months ago where my team builds ETL pipelines. Soon I will be rotating to a new team as I'm in a trainee program. Although I don't have control over where I'm placed, I will be applying to transfer to one of our Data Engineering teams. The main reason I switched over to a Software job was because I realized I enjoy analyzing data and this rotational program was my foot in the door. \n\nNow, I'm experiencing a lot of imposter syndrome because I don't have a CS degree and feel like I need to go back to school asap for a Master's in CS or Data Science. I had been making very good progress in my career as a Materials Engineer but with Software I'm worried I won't be able to get to the next level without formal education. \n\nShould I wait a year or two to get a masters degree or apply immediately so that I can get ahead faster?\nAnyone here who has gone through a similar situation? \n\nI'm already nearly 30 and feel like time is running out in terms of how hard I can work on a technical degree \n(I have family responsibilities that take up time) \n\nMatSci is an extremely technical degree involving Physics, Chem, Calc, stats etc so I think I'd be ok with picking up Data Science concepts.",
  "Hi all,\n\nI've got an interview in a couple of days for a Lead DS position at a major financial institution in the UK. I have 5 years of DS experience, but little to none in finance. Any tips or suggestions on tools/techniques I could research ahead of time to impress the interviewer on the day?\n\nThanks!",
  "I am learning NLP and for that i have installed spacy on my jupyter.  While i was trying to install  \"python -m spacy download en\\_core\\_web\\_sm\", nothing seems to work. I have tried various ways to install it watching online videos and solutions.\n\nSomebody please help me. i am unable to move forward without this.\n\nhttps://preview.redd.it/0so458a7o3ha1.png?width=1810&format=png&auto=webp&v=enabled&s=320d9d0b5915b56842cc197bfd57aa4bc34f9ed3\n\nhttps://preview.redd.it/ebzi6xwco3ha1.png?width=1806&format=png&auto=webp&v=enabled&s=b3d80abd4974e01cc14b3354621b6d8c9fe5e801\n\nhttps://preview.redd.it/n93lnmbao3ha1.png?width=1804&format=png&auto=webp&v=enabled&s=0b45be931389ed78320057f6fc9af156a21e2c12\n\nRefer to the attached screenshots.",
  "I am starting to question the long-term prospect of the data scientist role as AI continues to advance rapidly. Much of data science is math and statistics, focusing on identifying the best models for future predictions based on a data set. We as data scientists have to be good at identifying the best model, but our process is mostly based on math and statistics. That said, AI can do all of this faster, more efficiently, and probably more accurately.   \n\n\nSo then what is the purpose of a data scientist in the world of AI? Sure, we have to be the ones to help build the AI tools, but that is already happening with a small % of individuals in the field. A large percentage of us will not be involved in that and will not be needed to support said AI tools... So as a student learning Data Science, why continue?",
  "What other methods could I use to analyze qualitative and unstructured data besides Sentiment Analysis and Topic Modelling?",
  "Don't want to give too much away, but I'm in my mid-20s and work as the only data scientist at a smallish (<100 people) startup. I'm in my second year in the role, and although I enjoyed my first year very much, I've noticed that I've really been not having a good time lately. There are a few reasons for this:\n\n* I don't have a team. It was pretty fun at first to come in and take care of a lot of low-hanging fruit and answer people's data questions that they'd been stuck with for a long time. But I don't feel like I'm learning anything new anymore, and I'm not experienced enough to figure out how I can make myself progress. My manager is great but does not have a background in data science, and I don't have peers I can discuss my work with.\n* Our leadership doesn't really understand data analysis. The CEO is always asking for \"insights\" as if I can just comb through our database and magically come up with recommendations for how to improve the business. In short, because I'm the only person doing any sort of analysis, and our engineering team is pretty lean and doesn't particularly focus on data collection/integrity/etc., it can be hard to even get an analysis started (and I always have to push really hard to e.g. get engineering to set up the data tracking I need). When I have presented data analyses that I've done, I've noticed that the CEO only cares about findings that affirm what he already believes, which is really annoying because at that point, why should I even put in any effort?\n* I have to do a lot of stuff that isn't really relevant to my role because I'm the only one who can do it. For example, our finance team relies on me for a lot of important reporting (e.g. when we are talking to investors), and I end up being the person who has to put together long financial reports (which isn't so bad) and audit/reconcile different metrics when they don't look right or don't match between sources (which is really quite terribly boring). To be fair, my job description does include making dashboards and reports, but it's gotten to the point where my day-to-day is often answering questions like \"why doesn't this number \\[pulled from our prod database\\] not match this other number \\[displayed on some dashboard I know nothing about that was made by some random engineer\\]\" or \"do we track \\[x metric\\] somewhere and where can I find it\" (the answer is no, we don't, so I need to go meet with engineering to set it up).\n* Finally, our leadership has constantly pivoted business models during the time I've been here. I get that we're in tough times and startups need to be flexible, but at this point, the product is pretty different from what it was when I came in, and I'm not that excited about it anymore. So there isn't even motivation from believing in the product anymore.\n\nI've been thinking a lot about this and feel like I should probably quit my job and find a new one where I am a bit better supported and can have some more mentorship. This is only my second job out of college, and while I've learned a lot from being the only person in this role, I think I want to be in an environment where I can get some more direct guidance - often, I'm not sure if what I'm doing is anywhere near what's considered \"best practice\". But I'd feel bad about just completely ditching the company. My coworkers are so nice, and I'm the only person who knows both our database and our BI platform well enough to generate reports/dashboards efficiently, so I think it would be very bad if I just quit one day, even with a two-week notice.\n\nAny advice on how to deal with this situation? Sorry for the long post.",
  "My company contract says that:\n\n\u201cThe individual will not engage in any trade or business in competition with the company for the first 12 months after the end of their employment. This includes working on their own or on behalf of someone else.\u201d\n\nThis is for a generic data science company that consults in almost all aspects of data science. Does this mean if I leave I technically can not join any other company as a data scientist?\n\nHow would I ask them to alter this or remove or completely as it sounds to me like I can\u2019t really leave unless I move into a non data science company\u2026\n\nMany thanks",
  "Hi All,  \nSo here is some background. I graduated in Dec 2021 with BSCS (3.7 GPA). I accepted an offer at a Bank as System Analyst (mostly doing Project management and writing queries for reporting).\n\nSo far the salary is good, great benefits and it's a remote job. I only work 4hrs a day and my bosses are pretty happy with my performance. Rest of my day I just learn backend stuff, LC practices, or some cooking videos.\n\nLately, I am thinking about going back to school part-time for MS in DS, or something else. My company can pay 4k per year for a master's so why not utilize it? I saw a few job postings at my company for DS jobs which motivates me towards this.\n\nI am thinking to apply @ UIUC for the MCS DS program, as it's just an hour away and has a good reputation.\n\n**So here are some questions:**\n\n* **Are there any other self-paced well reputed schools for MS?**\n* **Finally, if you have any other advice which you might think I should know then please let me know.**\n* **Are there internships for the DS role? (When I was in college I hardly saw any DS internships)** \n\nMy focus is to get as many DS internships within the company or outside of the company, and what I've noticed is most companies don't offer internships unless one is enrolled in school and pursuing BS, MS, or Ph.D.\n\nIn the end thanks for your attention. I appreciate your insight.",
  "I seriously don't know what to do. I've been stuck at this job for 4 years now. I've spent the last 3 (off and on) trying to find a job to no avail. If I'm lucky, I end up being choice #2 or 3. \n\nMy job is a complete joke. I literally do nothing all day every day. I've had one interesting project the whole time here, and that was near the very beginning. Otherwise it's nothing or shitty monkey work that's worse than nothing. I've tried to reach out to people for something to do, but I'm always ignored. My pay is definitely in the bottom 10%, maybe even the bottom 1% for having a master's and 4 years of \"experience\". \n\nI just have no motivation anymore. What's the point of trying to skill up when I'm just going to forget it anyway, and nobody gives a shit? I got completely burned out on job apps and interviews for close to a year, and I'm just now starting to recover. I don't even feel like working on outside projects at this point; this job has completely killed what I used to love doing. I applied for some PhD programs, because I feel like it's probably the only way to resuscitate my \"career\" at this point.\n\nAny advice is appreciated.",
  "&#x200B;\n\n[Read Raster Data From Postgis Using Python](https://preview.redd.it/ao7huox100ha1.png?width=597&format=png&auto=webp&v=enabled&s=17fedb0ee4b045011e751da834fce7202e484983)\n\n[Read Raster Data From Postgis Using Python](https://spatial-dev.guru/2023/02/04/read-raster-data-from-postgis-using-python/)",
  "Hi, I am a Computer Science graduate with a fairly decent grasp of Data Science with a few projects and Coursera certifications related to it. I am looking to do a 2-year post-graduate degree to penetrate into the Data Science market as they don't seem to be very keen on hiring freshers with bachelor's degrees, especially in a hyper-competitive country like India. \n\nI am confused about whether I should go for \n\n1. Master's Degree in Data Science/ Machine Learning and AI\n2. Masters in Finance, Business Analyst, and similar courses. \n\nWhich of these two categories of degrees would be best in order to advance my career as a whole in Data Science and related courses if the main goal is to earn money and be successful?",
  "Thank you in advance for your response.\n\nMy confusion stems from my assumption that when survey results are presented as percentages, the sum should be 100%. As far as I know, the percentages of this graph sum to 883%.\n\nI tried to research ways that survey results can be visualized, but the only one that I found *could* explain this graph  was *cumulative percentages.* Even then, I still don't understand the numbers.\n\n[Source](https://www.pewresearch.org/politics/2022/02/16/publics-top-priority-for-2022-strengthening-the-nations-economy/)\n\nhttps://preview.redd.it/199cv81hovga1.png?width=1235&format=png&auto=webp&v=enabled&s=82bb1b2e7de6626e7b83a52acb9e9c7dc7958f0b\n\nPulled up the full report to see the survey design.\n\n&#x200B;\n\nhttps://preview.redd.it/uqnvtss23wga1.png?width=1388&format=png&auto=webp&v=enabled&s=c887504e6b0168fd9dea6f272ab1ee007b8987b3",
  "Pretty much the title.\n\nCurrently I'm learning Java on my own. I like math and statistics, i can understand the logic and can write the pseudocode but it takes me forever due to errors in syntax and language structure. I use chatGPT for refreshing my understanding pretty elementary concepts like polymorphism, inheritance etc and how its all synatictically written. About 90% of my time is spent debugging my code. I don't find the concepts themselves difficult just how everything is structureda and the syntax.\n\n\nAnd end of the day I only see coding as a tool to be used to break down a bigger picture. I don't find the point in learning about the code for the sake of coding itself. Its like being overly focused on power tools when your goal is to build a house. Yeah j need them but i dont find it nessacary to learn all the nitty hritty of every single power tool there is unless i am a power tool manufacturer. I'm also mot the kind of coder who would \"play around\" with code for the most optimal implementation and runtime or do hackathons in my free time. Really at heart I don't think I am a \"software developer\".\n\n\n\nMy interests lie primarily in math,stats and econcomics/finance. That's the stuff I really enjoy and \"coding\" is just a tool to use for me to better tackle those domains. I would much rather be a Quant rather then a software developer.\n\n\n\nSo all that pretty much put me off software engineering and for now and I'm considering data sceicne cause I think it'd be better suited as it is more math heavy and it has applications instead of developemnt of some tool.\n\n\nHowever reading this subreddit, tells me that coding is absolutely essential part of you're job and basiclly you are just becoming a software engineer. How much of this is true? How much of your time is spent really doing the basic software development coding tasks like debugging and what not and how much of you're time is spent really \"analyzing data\"?\n\n\nI really want to get a clear picture of really HOW software works here.\n\n\nTLDR: I like the math, data and logic but hate the entire software development process(debugging optimization etc) only see software as a tool towards a greater goal. Not the kind fo guy who develops apps or does hackathons on his free time. I would much rather be a Quant then a software developer. Is it still a smart idea to pursue data science?",
  "After the release of the M2 MacBook Pros price of the M1Pro MacBooks drops a lot. I planned to use MacBook for Data Science, so I don't know what is smart thing to do.",
  "I'm working on a research paper on Work-Life balance for Data scientists and have a questionnaire I'd like the Data Science Professionals in the U.S. to fill out. But before that, I'd need written permission from the admins here. Can any admin contact me, please? I sent a message but received no response. Here is my email: mohsinsub7@gmail.com",
  "I see them all the time, they're usually amazing in terms of compensation, and usually 200+ candidates within a few days. Of the ones that I applied to, I never even hear back. I find it incredibly unlikely that I'll stand out, and it makes me wonder if it's even worth submitting an ad-hoc resume highlighting my relevant expertise if I'm not going to hear back. \n\nWhat do you all do? Take time to tailor the resume for each position? Submit a generic resume that kinda fits the description, in hopes that it'll get you through the door? Not even bother? \n\nSorry if the question is silly, I'm just a little peeved with the whole thing.",
  "Alguien sabe de alguna api gratuita o con demo de prueba sobre informaci\u00f3n inmobiliaria, que tenga precios de casas y las caracter\u00edsticas de ellas? . Es para una tarea, y ocupo jalar y procesar informaci\u00f3n de una API.",
  "Is Linux for data science just geek pedantry, or is there a real evidence-based reason to switch from Windows? \n\nAlso, do we as data scientists have to deal with Linux servers to the point where it's just worth learning?",
  "I was an ex salesperson working in the tech industry. Figured that I wanted something more analytical in a career so I learnt to code on my own and am completing a master program in data science. Met my college\u2019s career counsellor today, who advised that I apply to product management roles because of my sales background instead of data scientist, and came out feeling discouraged. Is a sales background a bad thing to have for an aspiring data scientist?",
  "Looking for some books to read to make me a better data scientist. Not looking for anything like ISLR but more along the lines of something you sit down and just read cover to cover.",
  "I'm a new grad (24) working as a Data Scientist for the last 2 years and all I've ever known is remote work. Initially, my role was going to switch to hybrid after the pandemic settled down but it never did. Even though the offices are open, no one is ever there.\n\nI've been looking at jobs in different companies and it appears as if most of the jobs are remote or \"hybrid\". Judging from my experience, however, hybrid also effectively means remote.\n\nI definitely enjoy the flexibility but its often quite isolating to have to work from home all the time. I've tried coffee shops but I usually end up missing my monitor and the music is annoying.\n\nIs this the future of the industry? Does a Data Science job mean having to work remote?",
  "Hi, I just started product manager role in small <100 ppl company. In my team we\u2019re doing government R&D project normally collecting / preprocess / labeling the data. It\u2019s been 8 months since I\u2019ve come here. I started as a data labeler, and later CEO gave me data wrangling task. (I\u2019ve been studying data science stuff since the last year on my own) When I completed the data wrangling project, my coworkers who worked with me all left the company. And now CEO wants me to take PM job and start the government R&D project. \n\nIt\u2019s the solution company, so we\u2019re doing multiple project at the same time. I like to experience many different domain, but in this project I need to give the guidance to the juniors who recently come in this company. Even I\u2019m still the junior. I want to go to the grad school to get master\u2019s degree in machine learning in this year. But if I couldn\u2019t get the scholarship I should work longer.\n\nSo here is my question:\n1. The product that we\u2019re building is not great quality. Will it benefit my career?\n\n2. Can I switch from PM to data scientist in near future?",
  "Hi\n\nIn biology you use cladogram to show the taxidermy relationship between individuals from different especies. My question is what is the technical name for that diagram in statistics, where distance show the correlation between branches? Moreover, can this diagram be applied to data classification?\n\nThanks",
  "I am currently in graduate school in machine learning and have done really well, but I honestly feel unprepared for a real job. One big reason is while I have done multiple small projects in Github with groups of people, I have never worked on a large repository before. While I have merged branches and a few times used rebase, that is the extent of my Github use. I am worried this lack of experience working with a collaboration is going to hurt me finding a job. I tried getting an internship last year to remedy this issue but they are so competitive I couldn't actually find one. Does anyone have any suggestions on how to get up to speed? Anyone up for tutoring me? lol",
  "On LinkedIn I see more and more people labeling them as data scientists, AI experts and what-not offering paid courses, interview training and resume review. Often, they have a non-data-science background and very little experience working as a professional. Quite common to show a previous job as a data scientist with a tenure less than 1 year (or multiple).\n\nI know it can be appealing, as their message is often, everyone can be a data scientist, machine learning engineer or AI expert. Academic and professional degrees are overrated and it\u2019s enough to take a Udemy or Coursera course to become a data scientist (affiliate link included). Simply follow them and buy their resources (which is usually very general advice, you can google in a few minutes).\n\nBut the reality is: They are usually not the experts they pretend to be. They typically don\u2019t talk about expert topics, they talk about career, current hypes, and about very high-level projects. Sometimes they have a GitHub account, but they have no commits of just copy-pasted repositories from other people and some very basic entry-level stuff. They are usually on LinkedIn, Instagram, and YouTube and in podcasts, but never talking about expert topics.\n\nDon\u2019t trust these people and don\u2019t buy courses there. Everything you need is either free of charge or it\u2019s a professional degree. There is no easy-going way to become an expert in any topic. The only good advice these people can give is how to become a fake AI influencer. \n\nIf you are looking for good advice, look for experts with a clear professional track record (several years), academic publications or talks at industry conferences and articles/blogposts about specific expert topics.",
  "The title. \n\nI've been in my position for close to a year now and it feels like our data is so criminally bad that it's hard to actually predict or infer anything. I know a majority of the time doing the job is data prep and cleaning, but sometimes it feels like that's all I do and still yield no results. \n\nEven when it's around time to actually start modeling, I have to understand that there is a decent chance my training data is just plain misleading.\n\nAnyone have any horror stories? Or find themselves in a similar circumstance? Maybe this is just a \"grass is always greener on the other side\" scenario.",
  "As you know, it is common to break DS into three parts: Math-Stat, CS, Business knowledge. I\u2019ve been learning the Stat and CS part thanks to college and many resources online. However, I don\u2019t really know how to learn the business part. Are there any books/courses you would recommend? \n\nI am pursuing internship/networking opportunities; so no need to mention them.",
  "I\u2019ve been setting an example repo to have full depth of setup as databricks and Amazon EMR for local development and testing.\n\nFigured I\u2019d cross post here as it can be an easy way to dive in and start developing in pyspark and when ready can easily migrate code to other managed services and have confidence it\u2019ll work\n\n- QuickStart spark node with JupyterHub installed via docker compose\n- s3 api compatible storage with minio\n- example test cases with pytest and unittest \n- GitHub actions cicd\n- poetry setup\n- Full read and write of databases and tables in spark through a preconfigured meta store setup\n\n\nIf you\u2019ve had difficulty trying spark locally for development, I think this repo will save you a lot of time and effort!\n\n\n\nhttps://github.com/emmc15/pyspark-testing-env\n\nhttps://www.reddit.com/r/dataengineering/comments/10uw3rn/end_to_end_pyspark_testing_cicd_example_repo/?utm_source=share&utm_medium=ios_app&utm_name=iossmf",
  "In the article below a co-creator of BigQuery takes a look at data sizes used for data analysis. He argues that the vast majority of companies don't have a lot of data and if they do they rarely query it. He says most large datawarehouses are between 100GB and 1TB up to 10TB in rare occurrences. The vast majority of query workloads are below 100MB.\n\nWhat are the largests databases you've worked with and could these databases their workloads fit on a single server?\n\nThe largest databases I work with contain transaction data at large retailers. Most keep a few years of data online and are 500GB-1TB up to 2,3TB. It's always hosted on a single server with up to 128 cores and 256GB RAM. I don't keep data size highscores for queries, but this year I remember one of my largest queries resulted in a little over 50GB of IO. I run queries like these a few times a year. These take up to 60min to complete but in most cases don't disrupt other processes (these are production environments with thousands of connections).\n\nIs this really about as big as it gets? Or are there people here working with datasets dwarfing these? If so, what sort of data, is it structured and what would be max query workload?\n\n[https://motherduck.com/blog/big-data-is-dead/](https://motherduck.com/blog/big-data-is-dead/)",
  "When looking at courses or degree programs both of these have similar modules, can someone explain the difference between the profiles and how technical each role is. Also which profile has greater scope for growth with time (in terms of job criticality and money) ?",
  "I am new to data science and programming and have developed a solution to one of my work areas manual repetitive data entry processes. This saves me a great amount of time and I would like to share this improvement with other users. \n\nSadly, myself and the user group is not working in the data science realm and would find my solution difficult to work with. (Understandable) \n\nIs there a way to make my automated approach more user friendly? How can I share this with my user group without necessarily directly providing them the code? Is this possible, or do they need to learn? \n\nAppreciate your insight.",
  "I made a switch from SAP consultant to Data science in my current job during Covid. However, my current role has nothing to do with data science at all. I am in a service based start up where we are given audits to handle that mostly involves reading documentation and barely any kind of coding, if any.\n\nI really want to move to a product company preferably, or at least to a more technical role as Data Analyst, Business Analyst, Product analyst, Data scientist etc.\n\nMy coding skills are rusted so I am currently working on them. But how do I get noticed among the many people coming from these upskilling companies? How do I set myself apart? i am already in process of making Kaggle based projects, that doesn't seem to suffice.",
  "Well a couple of days ago I asked whether people really use control version or not.\n\nEven though a lot of people said yes, there were others like me, so I've been searching for some easy tutorial who can help me and... funny enough it was in the own channel of visual studio code, others videos or tutorial I felt like were missing the very first steps so I'll let the link to the video and hopefully someone will find it helpfull in addition there are others smalls videos in advance which are also helpfull.\n\nhttps://youtu.be/B-s71n0dHUk",
  "Does anyone know if Meta will be opening up their data science internship role for summer 2023?",
  "Hi, I'm a software developer with about 6 years of experience. About 2 or 3 years ago,  I started to like data and AI more and more. I had always been interested in those fields but never did nothing about it until 2020, when I took an online course in Machine Learning. As I work as web developer and  have a formation in design and not on computer science, maths, etc it was easy for me to understand the coding part (I work with Python) but very difficult to understand the statistics foundations.\n\nSo last year I decided to start a Master in Data Science. I got admitted in a pretty good university here in Buenos Aires, Argentina, which wasn't easy coming from a design degree. Now I'm half way through the master (It's scheduled to finish in December 2023) and I feel like I'm ready to start a new job as a junior/trainee Data Scientist or ML Engineer, so I started applying for jobs via LinkedIn. \n\nSo far I have to issues I would like advise about:\n1) is that there are almost no offer for junior/trainee positions, they all require a lot of experience as a data scientist. I have a lot of experience as a developer, but none working with data. Maybe I'm looking in the wrong place?\n2) is that I took my old development-centered resume and I updated it to reflect my new studies in Data Science, but I don't know If I should somehow change it or update it because I have sent many applications (around 100 maybe) for about 10 days and I haven't got any replies. \n\nI'm not in a hurry, I know that finding a good job takes a lot of time and having no experience in the field is a strong disadvantage, but I want to know if someone has a similar story, or if you know ways to start gaining some experience and confidence.",
  "I'm okay at my job. I do good work. But I come on here, on LinkedIn. All you guys talking about the latest transformer. Best ML model when working with GPUs. Actually hyperparameter tuning a complicated model from start to finish at your place.\n\nI have a solid foundation of math and stats. I understand the math behind ML. I've built some simple models in sklearn. I've created kpis and visualizations in python. But goodness, I feel so insanely overwhelmed by the tech stack.\n\nSQL, python, golang, ruby, tensorflow, pyspark, pytorch, nlp, the list goes on...\n\nI'm an expert at all types of SQL and decent at python and some libraries like sklearn/pyspark etc.\n\nI can't help but feel like I can never reach the potential of all you kaggle grandmasters, Nvidia DS, phds and all this jazz. I'm competing with jobs where my other competition has an ivy league degree and probably a PhD.",
  "I am trying to switch to DS role from a researcher role. I have PhD in engineering, environment sci domain. I can do basic python, SQL programming to do the job. But my code is usually messy and not concise. How do I learn to write neat and clean code for DS? What else I need to learn other than training and testing models? Do I need to learn the procedure to deploying the models as well in production? How much cloud computing is needed? What else is must to crack interviews and be good enough for day to day DS job?",
  "I have autism which can make it hard to communicate with others at times so I'm just wondering how much communcation is involved in a data science/analytics position to help me decide if it's a good fit for me. Thanks!",
  "There have been a few posts of this sub arguing for the description of a data scientist being confined to a singular definition. It is therefore worth starting a thread on the scientific position of \u201cdata science\u201d as a field. This is not a peer reviewed work, but we can at least use it to get the conversation going. \n\nThomas Kunz defines budding paradigms as a time of fuzzy definition until the field rights itself and clearly defines itself through discussion of what is within its scope of function. He uses the example of textbooks to demonstrate that this is a method of inculcating new members into the discipline. Is that enough to clearly define a data scientist in present context? There are so many \u201chow to do x like a data scientist\u201d type discussions and books. Hopefully we are at the tail-end of the \u201cpeak of anticipation\u201d and getting deeper into the \u201cTrough of disillusionment\u201d of the Gartner Hype Cycle. Thoughts, gang?",
  "I   am trying to find something that will print the correlation matrix with p-value and I   cannot seem to find one. Does anyone know of code or package in python that does that? \n\nThanks in advance.",
  "I started an analyst job in December and I still have not left SQL. To me, all the queries seem beyond comprehension and are mostly uncommented and unstructured. People are continuously asking me why a process broke or why data is misaligned and I'm going into the old queries with virtually no clue of what is happening. I get several direct requests a day by now on stuff like this.\n\nI recognize how important SQL is and realize I need to improve there, but I'm just concerned that I am doing the job of a data engineer and not an analyst. I realize they are valuable skills to learn, but almost all of my training has been modeling in Python and I feel like I'm slowly losing those skills while I gain these.\n\nCurious if anyone else has any other similar stories and if this is normal, I should suck it up and bury myself in the data, or if I should start reconsidering? How long has it taken you all to get up to speed with a company's data when you've started new jobs?",
  "Hey r/ds - I'm fairly new to the world of data science after a decade in engineering and ops analytics (emphasis on lots on previous data work). I transitioned with the help of a bootcamp and landed in an easy consulting role right off. I plan to leave eventually because I'm well underpaid (limited ability to negotiate from bootcamp but I'm doing very well) but it feels pretty secure for now.\n\nWhat do y'all do to earn some extra cash while improving skills and networking? How do you find opportunities?",
  "Hi all - I'm torn on this issue. On one hand, it feels like DS should be evaluated on technical competence like software engineers, i.e. \"doing the job well\".\n\nOn the other hand, it's a part of the DS job to understand the business/product KPIs that you are trying to move AND actually moving them. Everything else is basically \"busywork\". BUT, shouldn't the KPIs be owned by product managers?\n\nWhat have you seen to work vs not? I'd love to hear the contrast between \"best practice\" vs what you are actually seeing in your day-to-day!\n\nThanks!",
  "Hi, reddit! Could you please recommend a good roadmap or starting point to learn data science for someone coming from software engineering?",
  "I\u2019ve tried searching google and stack, but no luck. Hoping one of the experts on here could help out a new professional. I\u2019m modeling search data using marketing spend and some variable coefficients are showing higher contribution than they should. I\u2019ve tried loosing prior sd and transforming the variable to lower the coefficient. I\u2019ve also tried adding vars and dummy vars. Is there any other way to do this?",
  "BLUF: What is the number of interview cycles you typically conduct at the same time while being able to make a good impression? \n\nI find the data science interview process a bit like having a second job. The questions span a huge breadth of topics but also often cover those topics in depth. In my role, I'll usually be focused on one type of problem at a time, but in an interview, I will go from live coding advanced data manipulation questions to deriving gradient descent,  calculating confidence intervals, and demonstrating business acumen in the course of an hour. The interviews are usually multiple rounds and take up my entire afternoon and weekends studying/interviewing.\n\nThat said, there is a lot of overlap between topics I need to study for interviews from different companies, and it helps to have competing offers. I would like to know, what is the number of interview cycles you typically conduct around the same time while being able to make a good impression? There is definitely a balance between spreading yourself too thin and putting all that effort into a single role that you're competing for, I just haven't found it yet.",
  "Where can i find a large data set of medical records of patient illness and symptoms. I need this as i might make a medical Illness prediction software for my school A-level project in computer science. Just send some links if you know of any thing like this. thanks",
  "Any other mid career DS out there job hunting? How\u2019s it going for you? Best wishes to anyone else caught up in layoffs or job insecurity!\n\nI have 7.5+ yrs of DS experience, and was laid off after not opting into Twitter 2.0 in November. I spent >3 years at Twitter, and it was honestly one of the most rewarding jobs of my career. I loved the people I worked with, I loved the domain I was in and it was one of the most \u201cimpactful\u201d roles I\u2019ve ever had. It was definitely a mindf*ck to watch the acquisition in person and see everything I\u2019d worked on basically get thrown out the window (and to see so many amazingly talented colleagues tossed out and/or disrespected). I spent the last few months recharging, relaxing and processing everything.\n\nNow that I\u2019m back on the job market, I\u2019m revisiting all of my old interviewing and imposter syndrome anxieties. I\u2019ve always gotten excellent feedback and performance reviews and know I was a highly valued member of my team. And it\u2019s pretty satisfying to have so much experience under my belt this time around. But with the weird job market and so many other tech layoffs (and knowing that everyone I worked with at Twitter is also actively on the market) I am second guessing everything. I have also only applied to a handful of roles because not many openings have caught my interest. On one hand I want to wait to see if the job market improves later in the year, but I\u2019m also stressed about not having much to say for myself when asked about my job search. \n\nI also get flustered after talking to people who say things like, \u201coh your field is so hot you should have multiple offers within days!\u201d Fortunately my partner is very supportive, and I\u2019m generally able to talk myself back to a good place. Today was just one of those rough days when my anxiety really spiked.",
  "I\u2019m in a finance analyst in a rotational program currently in a trading department. Besides investments, I\u2019ve also been learning tableau. My degree was in accounting. I\u2019m trying to change my last rotation to a business analyst in the technology department to stack up some experience. How can I pivot more towards machine learning data science ? Besides learning tableau, Python, R, SQL. Would a MS in CS benefit to go into a fin tech company? \n\nI went to a community college for my bachelors in accounting, I believe a MS in CS would help with foundational knowledge and marketability. \n\nI appreciate any advice!",
  "Not talking about the job, but the degree, more specifically bachelor degree. Is it better off majoring in statistics and learn computer science on your own or double major in statistics and cs? I have heard some people say the statistics you learn in data science is not in depth enough. Apparently, data science major is more about learning skill sets and that statistics is more about theory. And that people who studied statistics can learn data science easier than people who studied data science to learn statistics. That's why people who study statistics are better at adapting to the fast changing field of data science. What do you guys think? Plus, a bachelor degree is not easy to land you a data scientist job anyways and a statistics degree can provide more flexibility. I don't have any experience in programming but I'm good at math. Is statistics bachelor degree the way to go? And then maybe master in data science or go into other fields like finance in case I don't like programming?",
  "I have to do a project on financing and investment of SME for an internship but unable to find datasets related to them. Tried searching in some websites like kaggle, UCI, the world Bank, the IMF , data.gov.in etc but couldn't find it. What other websites do I search in or if u are aware of some please do share in the comments.",
  "I do not know if this is the right subreddit to ask this but :  \nImagine there is a project made in march and I ask - how many views did the project get in february and march (as a line graph). Should the line start at march and not exist in february or should the february have line at 0?",
  "im about to go to college and i want to study data science and ai but i need a laptop because the uni is far from my city and i need to go to a students residence, so i just wanted to know what are your recommendations :)\n\nidc if it\u2019s windows or mac or whatever, just tell me which computer u use and why i should/shouldn\u2019t buy it :P",
  "I recently made my resume after trying out the famous titanic competition in kaggle. I was told that I'll need to make it better(which I already knew) by adding at least 1 project on data science. Where can I find good open source projects? I only know basics of machine learning models and SQl.",
  "I was recently in an interview for a data scientist role and I was explaining how I\u2019d used a logistic regression to predict a binary outcome variable from a continuous, numerical variable.\n\nI got asked how I\u2019d communicate this with non-specialists, and I talked about putting together a simple set of slides in PowerPoint, with key points, omitting the unnecessary technical details (formulae etc.).\n\nThe follow-up question stumped me though. They asked me how I\u2019d explain the \u201cglm\u201d function (in R) to the same audience - for reference, this is the function used to fit the model to my training data which solves for the coefficients. This stumped me as I hadn\u2019t thought about how to do this. All I could think about was making an analogy with linear regression - in that we\u2019re finding the slope and intercept of a \u201cbest fit\u201d line - and that here we\u2019re sort of doing the same?\n\nDoes anyone know how they might have approached that?",
  "Just looking for tips and inspo :)",
  "Hey Redditors! \n\nUpon searching for methods to find errors within tabular data, I wasn't able to find much so I decided to write my own notebook and article.\n\nIn the article, I outline the necessity for data-centric techniques and how you are able to get model-agnostic improvement by improving the quality of your data. Not only does this improve model performance by itself, but it also leaves additional room for the usual model improvements (hyperparameter tuning, architecture optimization, etc).\n\nI go into more detail in the article, but at a high level I:\n\n* Trained the baseline xgboost model on the original data (67% accuracy)\n* Used data-centric techniques ([cleanlab](https://github.com/cleanlab/cleanlab)) to find label issues within the dataset\n* Dropped the incorrect data from the training set\n* Retrained the same XGBoost model on the better-quality data (90% accuracy)\n\nIn doing this, I was able to see a **reduction in error of 70%.** The raw increase in classification accuracy went from 67% to 90%.\n\nI hope this will be of value to those working with tabular data and machine learning. Check out [the blog](https://cleanlab.ai/blog/label-errors-tabular-datasets/) and let me know your thoughts in the comments!",
  "Just as the title said.\n\nI one hot encoded a categorical variable with 26 categories.\n\nI have a binary target variable I am trying to predict.\n\nThis target variable is very rare: 1 in 200.\n\n\nParticular categories have the target variable equal to 1 0.13% of the time, and other categories are only 0.3% of the time.\n\nI'm trying to assess if these differences are statistically significant across all of the categories.\n\nDoes anyone know what hypothesis test this would be?\n\nEdit: I've tried the chi square contingency test. Got a p value of 0. Don't particularly trust the results.",
  "Hey everyone,\n\nI am a Masters student in Statistics and I have taken multiple courses on Machine Learning with Python/R, Bayesian approaches, neural networks etc, but I feel like I did not get enough practical experience, like projects. I decided to dedicate this semester to go through NLP & Computer Vision & RL online courses, but I am not sure where to start. Can anybody recommend Intermediate courses that would not repeat the same Linear Regression but also wouldnt be too hard? Thanks for any suggestions!",
  "Hey everyone, I am a bachelor student in data science and right now wanting to do freelancing in digital marketing using data science to support decisionmaking. Next to that I can make websites using Sveltekit so for smaller companies/ startups I can help start them up in the digital world. But that is a bit out of the question I want to make in this post. But maybe it connects the topics a bit in form of web analytics.  \nIn what area's of digital marketing can data science be beneficial for smaller/ local companies as a service? I am continuously thinking of analytics being more applicable in this case.. Does anyone have any sources that I can read through that touch on this subject? I am also happy to hear your opinion on this.",
  "Good afternoon. I want to take online data science courses. People who have also taken online courses and work in this field, these courses have helped you, maybe your friends or it's a waste of time.",
  "I was responding to this [thread](https://www.reddit.com/r/datascience/comments/10uh0at/what_can_you_do_with_3_data_points/).  In our [exchanges](https://www.reddit.com/r/datascience/comments/10uh0at/comment/j7ghvtw/), I told the OP that one can calculate the mean and variance with 1 and 2 data points, respectively.  But the OP seemed very confident that I was wrong and even asked me to create a separate thread on it, even though it is something easily verifiable on [google](https://www.quora.com/How-many-data-points-do-you-need-to-estimate-the-variance).  The OP also wants to know my school, which I think it's an overkill.  So I will leave it here to hear the responses from the community.",
  "I have been working in a fintech company that deals with credit as a senior analyst. I have little prior experience in analytics but that was in the energy domain. After joining here, I have mostly worked in core analytics (EDA) kind of work using R and excel. The problem here is whenever a new task comes, i don't know what to do. I have to rely on someone to tell me what should I do in this task because I don't have knowledge of this domain. Example for checking the increase in A, check B and C because B and C plays role in it. I do the data preparation part, give them the numbers and they do the analysis and further ask me to generate more numbers for them. Every time something new thing pops up. So what's the problem? The problem is I feel like I am not able to contribute. I have designed multiple dashboards in Tableau and Excel and I liked it because I didn't have to ask what to do. I have the numbers, i know what I want to achieve. Similarly when I am asked to write the code for feature engineering, i like it. I tried asking them how can I understand credit industry. All they say is ask questions. I asked them for books. They told me there isn't any book. I feel like analytics is not for me. I should rather go for other roles. Request help from senior folks here.",
  "Hello there, I started learning Data Science from 2022 it has been 1 year and I have completed so many things made some projects added it on GitHub right now I am searching for a role to get some experience I have applied to so many companies on LinkedIn but still I am not getting any calls please share your valuable experience. #important #reply #urgent",
  "Hi all,\n\nthis idea was originally mentioned in [this pos](https://www.reddit.com/r/datascience/comments/10sayrq/is_there_any_group_or_site_where_we_can_connect/)t w.r.t mock interviews, and a few people thought it was a worth trying and agreed to participate already.  so i'm creating this post to gather few interested folks to test it out (as well as feedback).\n\nThe basic idea is to provide a (free) volunteer-led service for mock interviews and interviewing tips from folks with a few years in the field and potentially also discussions with managers sharing their experience transitioning into management, hearing how DS operates across different industries etc. (the latter 2 are my selfish inclusions as I would love to hear about more companies, more career stories and more DS work across industries, but understand the demand will be mostly for the first 2). \n\nThis sub is great for transient questions and discussions, and there is still room for 'spotlight' talks and personalized mentorship and better networking based on the ideas above.   \n\nfew strategies to make this work:\n\n1. start simple. with a small cohort of people across different stages in their career\n2. every participant can mentor someone junior to them, for load sharing. also works well for more time-relevant advice like interview trends etc  \n3. some kind of testimonial system so that mentors also receive credit for their service to the community. \n4. the no of members will decrease with seniority but that's also ok since senior DS advice is generally career advice relevant to wider group (vs interview tips/company culture etc)\n5. medium of communication -  not sure but async would be preferred to avoid scheduling overhead, interviews/talks can be scheduled and recorded. \n\nthere is a survey below for folks interested to fill out. and volunteers interested in helping planning and executing, please also reach out :)",
  "I have been looking for a dataset to do a project on supervised linear regression.\n\nSince I am new to ML, I am not very sure on what type of dataset to take in order to make the most out of it in terms of my learning.\n\nCan anybody provide me a dataset.",
  "I can have free access to either of the two for 5 months but I need to choose one. \n\nWhich one is better in terms of holistic learning!",
  "Hi guys, I recently screwed up a couple of interviews because of not doing as well as I should have on ML System Design/Case Study type questions where interviewers generally give very vague broad questions. I would love to know the kind of framework people follow for it and any material you used to prep for that? Any good articles/books/youtube channels with good content around this would be appreciated. thanks!\n\nEdit:\nThe kind of questions I'm talking about:\n\n1. Consider you have a software and documentation for that software. You want to give your users the opportunity to ask the software to complete tasks or get help. How would you think about this?\n\n2. Consider you are working with a hospital. Their ICU is overloaded with patients and they want to prioritize who the doctors should look at first. How would you go about building an ML system for this?",
  "MPS = masters of professional studies",
  "\n\n[View Poll](https://www.reddit.com/poll/10violn)",
  " \n\nWelcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",
  "Hey all,\n\nI\u2019m working on a research project where we can dynamically update the price of a product via customer demand, seasonality, unforeseen noise etc. just wondering if anyone in the subreddit had any experience with this. I\u2019m currently testing GA\u2019s and reinforcement learning and getting some pretty cool results.",
  "I'm a beginner data scientist trying to create a good portfolio. I read that projects can spice up your portfolio. What are some good beginner projects I can do and how do I do them?",
  "I have a data set that is comprised of 6000 data points of performance ratings.  Performance ratings are on a uniform rating scale of 1 *(unsatisfactory)*  to 4 *(highest possible outcome).* \n\nThe # of ratings a manager can make depends on the number of employees they supervise. \n\nThe number of supervisees for each manager can range from 1 employee to 20 employees. \n\n I would like to analyze manager performance ratings of their supervises to look for harsh raters (to many 1s) vs. easy ratings (too many 4s) .  There are a number of other factors that may contribute to the overall scoring for example - tenure, job profile, etc. \n\n\n\nTechnically employees end up with 1/2/3/4. However, prior to that you can have values in-between. \n\nTo get more detailed: \n\n25% of the overall dating is based on 4 categories which people are rated from 1-4 for each category. \n\n75% of the overall rating is goal achievement. The # of goals  are variable. Each goal outcome is rated on 1-4. \n\n\nTechnically, you can have a score of 2.6 or 3.1 or 3.8. they follow typical convention of rounding up.",
  "Hello, I am finishing my Master's degree in data science and I'm considering two options for my final thesis. First one is about electricity market (forecasting prices, studying important factors) and the second one is about fake images recognition using deep learning. \n\nDo you think there is one of them that can open better possibilities concerning job?\n\nThank you very much",
  "Hy guys, somebody please explain me the difference between bias and variance. I am soo confused between them and every website is defining them differently. \n\nI spent so much time figuring what they are, yet unsuccessful.\n\nNote: As of now i only know about linear regression model. \n\nSomebody please explain the difference between them (and what they actually mean) in plain English. Do not use complicated words please.",
  "Hi all,\n\nCurrently building digital infrastructure for a firm in Spain. I was wondering if anyone has worked with Looker Studio and what their thoughts on it is?\n\nI understand it's primarily for visualisation and can do some data modelling and report generation, but I am curious to know how powerful it actually is. Are there any drawbacks you wish you knew earlier, or how it might compare to something like PowerBI or Tableau?\n\nThanks!",
  " \n\nI would love to run an analysis on all possible assets classes, expecially about their liquidity. The dataset should look like this one.\n\n&#x200B;\n\n||Market Cap|Return|Market Cap Growth Rate|Liquidity|\n|:-|:-|:-|:-|:-|\n|Private Debt|||||\n|Infrastructure|||||\n|Real Estate|||||\n|....|||||\n\nDo you know where can I find this data?\n\nThanks in advance",
  "I'm curious because in my \"small\" experience of +4 years last friday I did an interview for a small company, when they asked me about using git or control version somehow I was totally honest and said something a long the lines \"look I know what it is and how it works but because I like to learn but in these bigs companies in my resume at the end of the day they care more about having results as soon as possible with nothing or very little documentation rather than doing things properly, so I did as they ask\".\nThey started laughing like some joke saying \"oh wow I cant imagine working like that what a mess\" I dont think they really care since as they also said is something you should get used to easily (plus I'm gonna reject them). \n\nSo I'm just curious how many of you really work using git? \nPS: My profile is data scientist/analyst using Python.\n\nUpdate: \nAs Im reading all of you I see that I need to change that because for me and the company so... this week I'll start to use it 100%.\nAlso I'm giving some more info about why I think I didnt really work with it in the past:\n- No production deployment (\"if you can run it locally why waste money?\")\n- Really small teams where normally very few projects where really done by more than the person itself.\n- When I tried to bring it in the past It was kind of a mess for me without anybody helping, and It was hard for me to defend why since I really didnt know either.\n- Normally when I tried to learn something new I used to focus on new libreries, best techniques/coding practices and my next step was about docker and production deployment but before that Im focus on the git.\n\nI want to thank all of you for your thoughts, I'll keep replying later.",
  "Hi all\nI am Research and Development in Energy area. I am working with data (from numerical simulations, real data from energy objects) using tools like MS Excel or ORIGIN Pro. I prepare analysis and conclusions based on my research. Mostly I have been using seasonal data, like yearly hour by hour. \nI am also aware that predicting time series data behavior of renewable energy sources will be a key in process decision\n\nI want to develop my skills in data and I would like to add a new tool in CV. Of course also for better salary\n\nI am looking for advice which programming language will be better for me to learn R or Python? \n\nI will be glad for yours answers. Thanks in advance",
  "In my company\u2019s organisation chart, a specialist is above the analysts. But my job title is reporting analyst. Should i put reporting specialist in my linkedin profile in order to show that i have experience in the field?",
  "I work for a small engineering firm. I have been tasked by my CEO to train an AI to solve what is essentially a regression problem (although he doesn't know that, he just wants it to \"make predictions.\" AI/ML is not his expertise). There are only 4 features (all numerical) to this dataset, but unfortunately there are also only 25 samples. Collecting test samples for this application is expensive, and no relevant public data exists. In a few months, we should be able to collect 25-30 more samples. There will not be another chance after that to collect more data before the contract ends. It also doesn't help that I'm not even sure we can trust that the data we do have was collected properly (there are some serious anomalies) but that's besides the point I guess.\n\nI've tried explaining to my CEO why this is extremely difficult to work with and why it is hard to trust the predictions of the model. He says that we get paid to do the impossible. I cannot seem to convince him or get him to understand how absurdly small 25 samples is for training an AI model. He originally wanted us to use a deep neural net. Right now I'm trying a simple ANN (mostly to placate him) and also a support vector machine. \n\nAny advice on how to handle this, whether technically or professionally? Are there better models or any standard practices for when working with such limited data? Any way I can explain to my boss when this inevitably fails why it's not my fault?",
  "Hi everyone! I wrote a short 15 pages read for those interested in a career in data science\n\nThis is the introduction:\n\n\"Data Science has become one of the hottest careers in the tech industry. With the rise of big data and the increasing demand for data-driven insights, the field of data science offers exciting opportunities for growth and success. However, breaking into the field can be challenging, especially if you are just starting out. In this comprehensive guide, you will learn everything you need to know to build a successful career in data science.\"\n\nHere is the link please check it out and consider purchasing a copy.\n\n[https://ultimateguides.gumroad.com/l/jlqpk](https://ultimateguides.gumroad.com/l/jlqpk)\n\nHave a good read!",
  "My tech stack includes python, machine learning, NLP, deep learning, Django, HTML, CSS, and Javascript. My interest is more in nlp. Please share your repos.",
  "I have debated buying a domain and posting a bunch of projects I\u2019ve worked on. Does anyone have any experience doing this, and have any recommendations or tips?",
  " \n\nHi,\n\nFor those who struggle with all the GitLab/GitHub commands in the Internet, this article will give you nearly all you need in your daily work. The targeted audience is Data Scientist/Data Engineer, with no experience or medium experience with Git.\n\n[8 minutes to cover 99 of your Git needs](https://medium.com/towards-data-science/8-minutes-to-cover-99-of-your-git-needs-2c904c43590a)",
  "&#x200B;\n\nhttps://preview.redd.it/nv0ye6wlslga1.png?width=600&format=png&auto=webp&v=enabled&s=243545bd6acfc5dc03f3d7ee705009d2d77bcac1",
  "Hi guys, I'm considering to take an online course in a Spanish university that made partnership with mine in Brazil. But since the course is a little expensive, i would like to have opinion from you guys about it\n\n\n\nhttps://nuclio.school/master-data-science/?_gl=1*1cpwrm8*_up*MQ..&gclid=EAIaIQobChMIgLm5s_n3_AIVkAwGAB17ogZkEAAYASABEgKTQPD_BwE",
  "Here is the link to the article: https://towardsdatascience.com/today-i-quit-data-sciences-here-are-7-reasons-why-15c29e51d032",
  "I\u2019ve been promoted twice to manager now of data science and I find myself in meetings talking more than I spend (if any) working on technical stuff\n\nIs this normal? I get paid almost $200k to say stuff \ud83e\udd14",
  "In most data sci jobs, are people typically able to figure out what to do? Or is it common to go to a job and not know what to do, and not be able to figure it out, especially if you don\u2019t have help from coworkers? \n\nI know some type of work may be standardized across the field, but others custom to the company. To what extent is each?",
  "Hey folks, working on a research project right now doing a binary classification on text data. Essentially, I have a ton of text data that I'm looking over and labeling each datapoint (composed of text + a couple of other less useful features) as \"yes\" or \"no\" if the text looks like it fits a condition (I apologize for the vagueness). The unfortunate part is that I'm only hitting \"yes\" a very low % of the time, which is completely expected, but it's resulted in me only having \\~100 positive examples. Ideally, I'd have wayyy more. So this brings me to my question, what methods exist to find positive examples more efficiently while limiting how much bias is going into the process?\n\nI have a couple of thoughts. I was considering doing an unsupervised clustering, maybe K-means, and see if my positive samples fit snuggly into a cluster, and look at the other examples in that cluster. This might work but seems a little inefficient. \n\nI've also considered building a classifier based on the positive samples I have right now, which might get me something, but I worry a lot about overfitting, perhaps there is a classification technique you could recommend to me in this case that works well with small amounts of data? I've considered simple models like logistic regression, but bayesian methods have also caught my eye. I'm also considering using some sort of tree-based method and increasing the depth of the tree incrementally until I start to see something that I want.\n\nLastly, I've tried to use some domain knowledge to generate a candidate list of samples. Basically, I've looked at the positive examples so far and applied what I know to be (somewhat) true about this particular problem to limit the samples a bit more with keyword matching. None of these have been quite as successful as I'd like, so I'd like to consult your wisdom and see if you have any advice for me :) Thank you for your help.",
  "Hi, I'm 14 years old, I really liked the data science area, I've always liked computers (I've been using them since I was 3 years old), but researching about it, I saw on a website that you need to be able to communicate well with other people. I want to know if it is really necessary, because I will have to train this part a lot.\n\nI can be good at coming up with ideas and delivering them, but is good communication necessary? (here we call it \"sales talk\").",
  "I live in Brazil and have been working as a DA for two years now, I'm now working for a big 4 consulting firm. I got kinda jealous of other people in tech (mainly web/mobile devs) getting all these remote jobs that pay in dollars, and make probably more than 5 times what I make, so I decided I would try to do it too.\n\nGranted, I haven't applied to many jobs yet, but  I wanted some inputs from you guys, if it's something that's worth pursuing, or if I should just change careers and start developing.",
  "A scientist, by definition, is a Master of Science in a particular field of study or knowledge.\n\nThus, a Data Scientist, is a master of science in the field of Data Science- which is the study and method of extrapolating information from 'data'.\n\nAn analyst, on the other hand, is a person who uses tools to extrapolate information from data and make inferences. They are not a master of science- they do not understand the tools they are using and they cannot explain, replicate, or manipulate the inner workings of those tools.\n\nA data scientist does the same thing an analyst does, effectively, with a key difference- the scientist understands and is capable of negotiating with his tools. **The data scientist can** ***formulate new hypothesis, test said hypothesis, and is intimately associated with the tools*** ***necessary to formulate and test those hypothesis.*** *(that being, maths and computer science)*\n\n**An analyst cannot effectively do any of these things.** **An analyst relies entirely on faith in the work of the scientist and the prudence of the tools created by the scientist.**\n\nThis, is why, as I have said in a previous post, most of the people on this sub are not data scientists. In fact, many of the people working as a data scientist aren't really data scientist at all, they are just analysts with inappropriate titles.\n\nData Scientists, let us unite and take back the sanctity of our title- so that the true nature of Data Ciens is not corrupted by these parasitic analyst heathens who dare call themselves disciples of Science.",
  "Has anyone experienced this? I'm 2 weeks into a new job and had a meeting with my manager where he said he was concerned I was working slowly.  However I've finished the two tasks he's assigned me each a day early..\n\n&#x200B;\n\nEdit: Yes, I talked to my manager and asked why he said that. No he did not have a good answer. We left off with me saying he needs to make his expectations more clear.",
  "Newer to DS work and am looking for some direction on approaches. \n\nI'm trying to estimate the impact of an event upon a customer satisfaction metric, for both the general population and specific segments. The event is assumed to have heterogeneous effects due to the nature of the customer base (impacted customers in some regions more than others) and was not part of an experimental study.\n\nI've tried: Using Arima time series modeling based upon the metric, fitting on the time period prior to the event, predicting after the event, and comparing the predicted values to the actual ones. However, Arima doesn't appear to be appropriate due to limited data. There appears to be monthly seasonality, as well as seasonality related to the day of the week. \n\nSince the customer satisfaction metric is an aggregation from scores provided by individuals, I've also tried using individual scores pre-event as training and using individual scores given post-event as test, fitting traditional classification models to the training set and making predictions on the test set. To estimate the difference between the expected versus actual customer metric, I've taken the training scores and predicted test scores and calculated the aggregated metric for those records as the expected aggregate value and separately calculated the aggregated metric over the training scores and actual test values for the actual aggregate value. However, this method gives me a larger than actual estimated impact - regardless of whether or not I balance the classes during training, this modeling approach tends to predict one customer rating more frequently than the others.\n\nI've also done some reading into causality libraries/modeling approaches, like econml DML, but I'm not sure how helpful CATE would be here, since my metric of interest is an aggregation. Any suggestions?",
  "A while back, my close colleague at work had an interview with Sr. Director of Analytics (or maybe just a Director, I forgot), for data related opening. \n\nHe was asked to describe what would he do with 3 data points, representing 3 months, say month of January through March.\n\nI confirmed with my colleague that it was not 3-month (or 90 days data), it was just literally 3 data points, for example sales revenue for those 3 months.\n\nMy hunch at that time was, either the person smoked something, or he blew the interview on purpose, as the recruiter told him the very next day as they decided to \u201cpromote\u201d from within.\n\nI did try to think a variety of ways to derive meaningful reference based on 3 numbers, but eventually I told my colleague that most likely the interview was fake.\n\nI guess I want to know from different perspective, whether you can actually use 3 data points in a meaningful way, for business.\n\nAny taker?\n\nUpdate: as suggested, the company he interviewed with was F100, big in Telco.",
  "Hi guys,\n\nI'm a junior in an undergrad BS Data Science program at a small Christian university in the Midwest. I've been searching for a summer internship in Data Science/Data Analytics since September and have had no luck. I've reached out to people in my network and those of my family and professors wherever possible, and I've visited my university's career center several times for resume revisions and have adopted the various strategies they have suggested. I've submitted somewhere in the ballpark of 200 applications in the last 6 months, and I've been ghosted by most recruiters. Of the 200 applications, I received 4 callbacks for interviews, and of those 4, only 1 resulted in a follow-up interview. For this last position, I was well-prepared and felt that I performed well in both interviews, but alas, I finally received yet another rejection letter last week.\n\nI'm frustrated and disappointed, to say the least. I understand that these numbers are pretty typical in the current tech job market, and other Redditors frequently call it a \"numbers game.\" While merely continuing a barrage of new applications may work for new graduates and recently laid-off junior positions, I'm fighting against time since I'm looking for a summer internship that ends before I resume classes in the fall. At this current rate, I'd have to submit another 50 applications to get a chance of even one more interview, which is incredibly time-consuming. The job search process wore me out months ago - I'm discouraged and exhausted - and it takes valuable time away from actually practicing my skills and learning new topics. On top of that, it already feels too late. My academic advisor told me in October to try to have something figured out by the end of December since many internship positions would already be filled beyond that point. It's now February. If my odds were bad 6 months ago, it's only going to get worse.\n\nI'm kind of at my wits' end. I also am approaching the point where I need to have some concrete summer plans so I can coordinate schedules with family and friends, not just \"I'm looking for an internship\" because that doesn't seem to be panning out. Here are a few of my options:\n\n1. Go back to the summer camp where I worked for the last two years.\n   1. Pros: I already have friends there and I'm 99% guaranteed a job if I apply. I'll also be on the West Coast, which is where I want to be.\n   2. Cons: The pay is little more than a volunteer stipend. I won't have much opportunity to develop tech skills or otherwise advance my career.\n2. Stay at home for the summer. I could split my time between learning through online MOOCs and potentially look for a low-skill job such as administrative assistant or data entry. Or a gig like Doordash. \n   1. Pros: I can live with my family for free. I'll also be on the West Coast and will have the flexibility to pursue my outdoor hobbies while working on tech skills. The wage floor is also pretty high in my state.\n   2. Cons: There's no guarantee that I can find a job, especially for something that only lasts the summer when employers may be wanting something more permanent. It also feels kind of humiliating that I failed to find a job in my industry?\n3. Look for internships in adjacent fields that involve data. I've seen this suggested to people looking to make a career switch but I'm not sure if these exist or if they will work for me. I also won't have the mentorship in DS/DA that I'm specifically looking for. \n\nWhat factors should I take into consideration when I look at my options for this summer? Is there anything else as far as career development that I should also think about? \n\nI'm also wondering if the current scarcity of tech positions is homogeneous across the industry. DS doesn't seem as attractive as it was a few years ago, and now I feel unsure about all of my career/academic choices to date.\n\nFirst, I feel like DS was hyped up to more than it was when I first started college as a freshman, and now it seems that a lot of people on the internet also think that it's now on the decline. It also seems to be the consensus that the best path into DS is through a more established undergrad program in CS, Math, or Stats, rather than a DS degree because they tend to be so broad in nature that you learn a little bit about many topics but nothing sufficiently in-depth to be useful. Unfortunately, that seems to be my experience - I don't feel like I'm learning anything in classes so I'm taking time outside of class to work on Kaggle Learn courses and the Andrew Ng Coursera ML course. If I could go back in time, I would have gone into CS and started at a different university. I'm not particularly fond of my university or the Midwest (I long to be back on the West Coast) and it's a long story of how I ended up here, but suffice it to say that the reason I'm still here is because I'm on a full-tuition scholarship which I'd lose if I transferred elsewhere. But I can't go back in time. I'm a junior and should be graduating in two more semesters after this semester, so I had been OK with sticking it out under the assumption that I could get a decent job when I graduate and move back to the West Coast. But I'm at the point where I question if any of that is true. \n\nSecond, I'm not even sure anymore if this is really what I want to do. In my senior year of high school I became really interested in finance, and DS seemed like the perfect way to join my long standing interest in tech with what a growing interest in math (which, sidenote, may have died after I took Intro to Linear Algebra. I like to think it was just a bad professor) and my new interest in business topics. In the last semester or so, I've clarified my long-term goals and want to break into the ML field and eventually become an MLE. However, in working with scikit-learn and other ML frameworks in Kaggle Learn courses, it feels dull and I'm just doing it because I have gaps in my knowledge. I don't really find myself loving it. Is this normal? I know it's preferable to work on my own projects rather than repetitive activities, but I still don't feel that I know enough skills to work on my own projects. I often wonder if I'd be better off in a more standard CS track towards become an SWE or backend web dev. But there's huge gaps in my knowledge there as well. And if I switch majors, I'll probably have to take an extra semester or two because my current DS requirements don't include any of the dev, networking, or security classes. \n\nI guess to summarize, I went into this degree track with certain expectations and everything has turned out to be a disappointment. I'm not sure what to do anymore because although I'm willing to work hard, it's difficult to maintain the motivation to do so when I'm not sure if everything I'm doing is mere futility. Thanks for taking the time to read through all this and I appreciate any advice/feedback you may have.",
  "I want to see which house prices in my dataset are outliers based on other feature columns like sqft, waterfront or year built. \n\nSome of these are more important and play significant role on deciding if a data point is an outlier. \n\nWhat is the logic/literature behind this? How can I go about building this code?",
  "I\u2019m looking for data collection tool suggestions. We periodically need to collect data from teams via drop downs and free fields and Excel is proving difficult to manage (people keep deleting things, changing formulas, etc). Does anyone have any experience with another data collection tool?\n\nIdeally this tool would save the question results and the team could go back and see what the entered originally and make changes when we repeat the exercise, which we plan on doing a few times a year.",
  "I read before on Reddit as well as on blog posts about data science professionals landing a job and thinking that they finally get to apply their skills to do something cool, when they had to instead do analysis on excel. \n\nAlso data scientists in some companies who aren\u2019t sure what goal they are hired to achieve. Or they don\u2019t even have the right data to work on. Or their work never makes it to production because of some reason or another. And they get disillusioned.\n\nRecently I came across this post on data science in finance. And the description looks pretty interesting. \n\nhttps://careerfoundry.com/en/blog/data-analytics/data-science-in-finance/\n\nAre any current Data science professionals who are in the financial industry. Who can shed some light on this? \n\nIs the work really as described? Or is it better? \n\nDo you get interesting problems to work on? \n\nDo you feel you get an opportunity to make an impact with your work? \n\nDo your models make it to production?",
  "I am trying to come up with a feature/set of features, and getting a bit stuck. For the purpose of this question lets say its the ratio of number of times a person clicks on an ad (abbreviated ac) on a website/ time they are on the website.  Here is an example of what I'm thinking about:\n\nsubject 1:  3 hrs on reddit, 2 ac.  One hour on facebook, 5 ac\n\nsubject 2: 1 hour on reddit, 0 ac, three hours on twitter, 2 ac\n\nsubject 3:  5 hours on live journal, 1 ac.\n\nIn this example I would create 4 features:  ac/hour reddit, ac/hour facebook, ac/hour twitter, and ac/hour livejournal.   I'm having trouble with the fact that these four features will have a lot of missing data.  In this particular example, pretend that I've collapsed the webiste categories as much as possible.   What are some other options of dealing with the data?  How does one use data like this in a model without imputing the missing values? I'm open to not using a ratio for this feature set - but I do want exposure to the website to be included somehow.\n\nThanks!\n\nEdited to add, the missingness comes from the situation when someone has 0 hours on the website, its 0 clicks/0 hours so its undefined. This is a different situation than a zero someone who is on the webiste for 5 hours but never clicked on an ad.\n\nEdit pt. 2.  I am building a generalized linear regression model to predict a continuous variable.  My goal is to see if there is a set of variables amongst all the features created that are predictive of the response.  I am interested in seeing if there is a difference in risk between adclicks per different websites.   I'm being purposefully vague as the features and response are all trade secrets.",
  "Hello people! I hope my question is appropriate for this community. I have the following plot (figure), and I would like to show that in the central region there is a linear pattern, and find the correct line with linear regression (I know how to do linear regression). \n\nThe problem here is how do I decide to exclude the data that stands on a line parallel to y axis or x axis? Is there any statistical test to do that?\n\nThe data is the measure of two continuous variables, so there is not an \"a priori\" method to exclude some of them. \n\nThank you in advance!",
  "Hello everyone, I am interested in the tools and framework (in particular automation tools) everyone uses when working with big data. I am a solution engineer, but always wanted to be a data analyst or data scientist because I believe that data can be harnessed for many practical application e.g., (chatgpt craze). Regardless, this takes me to my few questions:\n\n&#x200B;\n\n1.) What tools and framework have you used recently for your big data analytics project, and would you considered adding any tools (automation) to your tools set in order to simplify your data process? \n\n2.)How does the framework you are using scale to handle the ever-growing big data?\n\n3.) Are some of your clients that you work with driving the adoption of AI and automation? I know my company I work for is already looking at integrating Microsoft teams premium because of the features found in chatgpt and how some of my clients wants the to be able have the capacity to automatically generate notes in case they miss the meeting.",
  "I\u2019d like to start a data science degree but I already have a metric crap ton of student loans and cannot afford to pay graduate or even undergraduate tuition out of pocket. \n\nI\u2019ve found some classes on edx by Harvard and an online tutorial website called data camp that will supposedly allow me to learn the needed skills. \n\nAre these viable ways to earn certification, build a portfolio and start a career?",
  "How I sometimes feel about Data Science... anybody know the quote?\n\n\"...some day the piecing together of dissociated knowledge will open up such terrifying vistas of reality, and of our frightful position therein, that we shall either go mad from the revelation or flee from the deadly light into the peace and safety of a new dark age.\"",
  "Do you know RPA experts or IT companies with RPA experience in LATAM region? Looking for new partners for PIXRPA.",
  " \n\nHow can we move from an idea to production in AI? \n\nDoes the technology readiness levels (TRL) help?\n\nIf you want to get some answers please read this article in medium:\n\n[https://medium.com/towards-artificial-intelligence/technology-readiness-levels-trl-in-ai-development-c6ed1190fbd6](https://medium.com/towards-artificial-intelligence/technology-readiness-levels-trl-in-ai-development-c6ed1190fbd6)\n\nAll the ideas are more than welcome!",
  "I am learning to use SQL server. I am trying to create a catalog but get the following highlighted error. Have tried searching for the solution couldn't solve it. Please HELP.\n\nhttps://preview.redd.it/4muv1k1brcga1.png?width=1689&format=png&auto=webp&v=enabled&s=c4fe922dea4efa6fe772f498751deda348c86755",
  "Currently we're just using google sheets to document stuff and while its working, it's been a hassle keeping it up. A miss in the updates can break the whole thing, which can be frustrating rather than focusing on my tests. Also it becomes tedious too when someone checks up on it and it takes a long time to backtrack on everything.\n\nWe've tried using the timeline feature or tasking in Asana but its quite tedious as well to track and keep tickets or are we just doing it wrong? Lately we've been planning on trying out to setup like a kanban thing but just wondering if there are any best practices for this?",
  " \n\nHello,\n\nI recently moved from standard Object-Oriented Programming Classes to DataClasses and I only do OOP this way now. It makes Python an easier and safer place for OOP. The article is pretty simple and will give you great foundations:\n\n[The Next Big Thing in Python: DataClasses](https://medium.com/towards-data-science/all-you-need-to-start-coding-with-data-classes-db421bf78a64)",
  "I\u2019m assuming network science and data science share some ties so asking here. I know it\u2019s a newer field but I\u2019m still surprised it isn\u2019t more prominent. Ex there\u2019s not even a functioning subreddit for it",
  "How hard/easy will it be for me to get a data science job having this under my belt:\n\n\\- 2 years working as a Data Analyst\n\n\\- 2 years as Computational biologist in undergrad\n\n\\- Masters in Data Science",
  "Hello there, I am trying to detect a fraud detection model which outputs risk as Low Medium or High, I have a customers id in one data frame and in another data frame i have their data that from which customer (source) id to which (target) how much money 'emt' is being transferred. Now I want to drop customer id from the initial data frame and add a new column containing a series of transaction for both sources and targets. How do i do this and is there a better way to do this?",
  "I have been working as a data scientist in a company abroad for 3y but spent most of my time working in data & analytics without too much python or data-science involved. \n\nI don't see myself going into the right career within that environment so now I want to apply for real data scientist positions.\nProblem is I feel like my skills left in data-science are not enough to land a nice job back in Europe hence I need to bring myself up to date. \n\nWhat's your advice?\nDo you think a bootcamp could be a good idea? Any that you would recommend? \nIn your experience, are there still a few companies these days which train their employees effectively? Or do you think it's more our own responsibility?",
  "\n\n[View Poll](https://www.reddit.com/poll/10uefx9)",
  "There are a lot of things going on in the field, how to you keep track of all the new stuff coming up. \n\nMy main resource at the moment is my linkedIn feed with focused research after finding something interesting.",
  "I have 6 months of internship experience, 3 months as a Data scientist and 3 months as an ML researcher. I have done courses in deep learning which is my area of expertise mainly. I am good with tensorflow, and i know SQL and python well.\n\nI dont seem to crack any data science or machine learning interviews though. What are a few things you could suggest that I should add to my skillset to get a job as a Data scientist? \n\nI have an Aerospace bachelor's degree from a top college and not a data science one. The only data science education i got was from online courses. Please drop some suggestions.",
  "Hi all,\n\nI was tasked with finding videos for product releases for several companies from a very large Excel file with headlines of new articles. The Excel has only the headline of the product release article & the company names. there are about 10,000 headlines.\n\nHow can I approach this problem and ultimately automate it?",
  "Hi all, I've watched a few tutorials on topic modeling in Python, with some open source libraries (gensim, spacy, etc). What I want to be able to do is tag a large group of reviews (such as yelp reviews) with one or more appropriately named topics. In the [above mentioned tutorials](https://youtu.be/UEn3xHNBXJU?t=867) I see the results as clusters that contain common terms, but I don't yet see how to go about adding an appropriate name to these clusters, and then ultimately assigning this name, or tag, back to individual reviews. How do I get from the initial analysis (LDA or what have you), to actually tagging a review with one or more appropriate categories? For example, a review talking about how expensive a hamburger is, might get assigned a \"price\" tag/category. Maybe LDA isn't the right method? Thanks for your tips and/or recommended tutorials!",
  "I have a problem where I'm looking at API calls and downstream impact. Not really a specific question to answer, but predicting performance of the calls based on path through the audit trail would be interesting to do. Or, anomaly detection (i.e, this API is defective in 10% of transactions)  \n\n\nI have thought of two approaches. One of them is regarding the data contained within the request/response payloads. The issue is, it's all text based, or changes depending on the specific API, so the data transformation aspect is very tough. Encoding one API's response to compare to a different API's response would be challenging. Perhaps there is an opportunity for deep learning here.  \n\n\nThe other approach I'm thinking about, is treating this as a graph problem. The majority of these transactions will form a tree-like structure, but some of them don't have a true root, so its more of a directed, acyclic graph (think it's called a polytree?). My approach would be to use graph theory principals such as degrees, closeness, vertex distance, etc. as features instead of parsing the very dynamic payloads. Since these are rules-based systems, I would love to be able to model the underlying relationships between these calls, that way when one transaction chain doesn't match the model, it's likely an anomaly.   \n\n\nDoes this make sense to do? Has anyone here done something similar? Any recommended literature? I've tried googling it, but when you search \"machine learning approach to tree-based systems\", you get a lot of papers or articles referencing tree-based ML models, which is not exactly what I'm looking for yet. Thoughts?",
  "We have a predictive model that is built using a Minitab decision tree. The model has a 70% accuracy compared to a most frequent dummy classifier that would have an 80% accuracy. I suggested that we use Python and a more modern ML method to approach this problem. She, and I quote, said, \u201cthat\u2019s a terrible idea.\u201d\n\nTo be honest the whole process is terrible, there was no evidence of EDA, feature engineering, or anything I would consider to be a normal part of the ML process. The model is \u201cput into production\u201d by recreating the tree\u2019s logic in SQL, resulting in a SQL query 600 lines long.\n\nIt is my task to review this model and present my findings to management. How do I work with this?",
  "Title. I really feel like this sub is counterproductive in terms of being useful to its constituents most of the time- because most of the ideology and advice pushed on this sub is perpetuated by people who..... aren't really data scientists. Even the majority of those who could be considered data scientists are low tier analysts who transitioned after their collegiate education.\n\nI'm not trying to be condescending, really- but ***t******he reality is that there are not very many educated, competent data scientists active on this thread.,*** Much of what is posted and related by this community is not conducive to success and having a positive experience in the D.S field.\n\nThis sub has become (metaphorically) become a flowered field of 'Data Science Daisies' pushing useless platitudes, generalities, and well wishes without any actual understanding of the World of Science as a whole, let alone the actual meaning of the word Data Science from a historical perspective.\n\n***If you don't understand the math behind the work you are doing, you aren't a data scientist. your just an analyst using the tools of the real scientists.*** Disagree and downvote me all you want, but these are the facts. Data Science is not a flashy new job title, it is a deep uncharted field of philosophy (historically, all academia is a bud of the original study of 'philosophy' from the grecian times), derived from a millennia of academic and technological development. If you do not understand the difference, you should not be here. That is just my opinion.\n\nDon't come to this thread looking for career or project advice. Find a mentor or a real data scientist. These people cannot help you.",
  "I've been learning on my own for a few months now and have started working on some personal projects. I would like to apply to a formal program to get a Masters in AI/Computer Vision. I meet the Bachelors degree, undergrad courses, and GPA requirements for programs I've seen, but my issue is that I am many years removed from college and a year removed from professional work (as a software dev in a particular stack). I was successful for many years but decided to quit due to depression/anxiety, as well as not wanting to continue in that particular stack. I have not kept in touch with previous colleagues, managers or professors, and would rather start/continue a new chapter of my life without involving them.\n\nI'm just wondering if anyone has experience with a program that didn't require references/recommendations, or if there is no way around this. My fallback plan is to work on my personal projects as well as I can and try to land a junior position at a small company/startup that might see value in taking a chance on me.",
  "I am teaching a course on Big Data starting next week and had planned a project with the twitter API for exercising spark structured streaming. Of course, that might be rather difficult now. So I am wondering if there is a similar alternative to get a stream of text using an api which is either saved in a directory or kafka. I have mostly found examples where you would have to poll continuously like facebook. \n\nAny ideas? Thanks!",
  "Hi,\n\nI'm considering getting a post grad credential from the list in the title and looking for input from others who have done/are doing similar.  \n\nMy Background: BS in Mgmt, Concentration Info Sys; UT MBA, Concentration IM/Tech Strategy.  I'm late career (mid 50), have been in high tech (HW) about 25 years and want to work another 4-7.  After that I would consult til tired.  \n\nCurrently facing tech layoff and looking, but no immediate financial pressure for 1 - 2 years. \n\nPrograms I'm considering:\n\n1. Newly announced UT Masters in AI. Would likely do an AI cert in the meanwhile or assumed pre-reqs (coding, linear algebra).  Sounds technical and not sure I'd get accepted.  est. \\~2 years to complete.\n2. GT Masters in Analytics, with a few added AI courses.  Would likely play catchup on the Micromasters to get that out of the way.  est. \\~2 years to complete.\n3. IBM or UT AI Cert and other as needed.  6-9 mos to complete.\n\nLikely would need a Udemy in Python coding in all 3 cases.  For those who have done, or looked at doing, any of these, what would you do/do differently?  \n\nAll input welcome.  Thanks!",
  "Non-data-scientist here.\n\nI came across this huggingface webpage ([https://huggingface.co/docs/transformers/main/model\\_doc/biogpt](https://huggingface.co/docs/transformers/main/model_doc/biogpt)) and saw this bullet point:\n\n>BioGPT is a model with absolute position embeddings so it\u2019s usually advised to pad the inputs on the right rather than the left.\n\nWhat does that mean?\n\nTIA.",
  "Hey all, I just finished my bachelor's degree in industrial engineering. I was checking this coursera degree in data science and I want to know if it's a good option to pursue since I want to have work while studying for a graduate degree. so my questions are the following:\n\n  \nis the degree worth it?\n\n  \ncan I find a FAANG job after getting this degree or at least in a niche start-up? I know it needs extra work but would it help, my current university is in eastern Europe.\n\n  \nI gladly want to hear about the experience of people who enrolled.",
  "TL; DR:  I explore a hypothetical scenario where widget makers of varying experience are compared according to defect rate over a 5 year window.  To make things comparable (accounting for the experience problem), I inquire whether using a weighted moving average is a good strategy for balancing the problem of experience out or whether there is a better technique/solution to employ.  \n\n&#x200B;\n\nThe Scenario:\n\n* Assume you were to look at the historical performance of  several widget makers who manually produce widgets.  These widget makers could be active employees at present  or left at some point during the window.\n* You want to compare the historical performance of the widget makers in terms of defect rate over the last 5 years (2018-2022).  My definition of defect rate is simply the  total number of defects/number of widgets produced (inclusive of defects)\n* Some makers have decades of experience while other makers only have 1 year of experience (minimum required for this analysis)\n* The original data is by year (2018,2019,...).  Let's assume Maker A, who started their career over a decade ago, made widgets over the entire window. Maker B has 3 years of experience but was let go sometime before 2022.  Maker C was recently hired and worked all of 2022.\n* To make things more intuitive (hopefully) and comparable, I converted the table from calendar years to years of experience within the time window. So Year 1 doesn't necessarily translate to 2018, it's simply represents the first year worked  in that time window. See table below.\n\n&#x200B;\n\n|Maker|Year 1|2|3|4|5|\n|:-|:-|:-|:-|:-|:-|\n|A|2/17|2/15|3/11|1/8|2/10|\n|B|5/15|3/12|3/13|||\n|C|2/7|||||\n\n&#x200B;\n\n*  Their defect rate is recorded over the last 5 years. For example Maker A produced 17 widgets of which 2 were defective in the first year of the time window, then produced 15 widgets in which 2 were defective Year 2, and so on...  Note that demand could be variable for widget production.\n* Simply looking at the defect rate above, my calculations  show Maker A would have an overall defect rate of .25, B would have .35 and C would have .43.  The problem I see  is less experience penalizes more heavily than more experience; so if this were a bar graph the 'worst performers' would likely always be the least experienced and that may not be very fair or  informative and at worst, hiding poor performers with a lot of experience.\n\nSo, this implies that some sort of smoothing or weighting is needed in order to make things more comparable. I was wondering if it made sense to use a weighted moving average.  My weighted average would look like the following:\n\n&#x200B;\n\n* Each year of the window has an arbitrary weight associated to it.  For this example we want to downweight that first year  and gradually increase weights later on:\n\n&#x200B;\n\n|Year |1|2|3|4|5|\n|:-|:-|:-|:-|:-|:-|\n|Weight|.6|.7|.8|.9|1|\n\n&#x200B;\n\n* I obtain the sum of the product of each year's weight by  the maker's  defect rate  for each year they worked divided by the sum of the weights for the length of time that the maker worked.  Clarifying this last part - Maker A's denominator would be the sum of all 5 weights, B would be the sum of 3 weights and C would be only the Year 1 weight\n* Using the weight and formulas mentioned, I show that A has a weighted average defect rate of .17, B has .43 and C has .29, suggesting that B is producing more defects relative to their experience compared to the other two.\n\nThis results make some intuitive sense to me as B continued their career with a higher rate of defects relative to A.  My concern is that 1) weighting is arbitrary  and that 2) this method might cause an inverse problem from the one I was originally attempting to solve - giving too much leniency to the inexperienced and overly penalizing experience. I understand there is no perfect answer here but wondering if this is a sound approach or there are better, more intuitive ways to approach this. \n\nTIA",
  "as someone from non tech which books help you understand language/ software without spending too much time in technical jargon and verbose",
  "I\u2019ve completed 2 recent company take home assignments for data science/analyst and found the suggested time completely off. Both claimed 2-4 hours, and I spent 7 on the first set without fully completing it and 6 on the second. That was to answer the questions, not overachieve for perfect responses.\nIs that typical? \n\nFor context I\u2019ve been an analyst for 4 years and a DS for 2.",
  "First off, I want to say I know close to nothing about data science and I'm kinda learning on my own.\n\nHere's my project: I have a bunch of logs where people write statuses of different tasks and I want to identify was was done and what is left to do.\n\n&#x200B;\n\nFor example, I can have logs that say:\n\n\"X was replaced and need inspection\"\n\nWhat would you do to identify that X was replaced and that X still need to be inspected?\n\n&#x200B;\n\nAlso, the logs contains lots of abbreviations like:\n\n\"X was RP and nd inspect\"\n\nHow do you deal with this?\n\n&#x200B;\n\nAny help would be greatly appreciated! TIA!!",
  "Hi, looking for ideas to start a NLP project! Any recommendation is appreciated",
  "I'm given a school assignment and one of the requirements is to visualize the important aspects and give meaningful realization of a real world dataset.\nSo I was wondering I someone could recommend me a dataset that is simple, real world, has some real use",
  "I'm curious about the UPenn MSE in Data Science program's statistics, and timeline. I was also wondering if anyone here has any experience with it. If you have, I'd love to hear about:\n\n1. Did you or someone you know enroll in the program?\n2. What was your admission stats like?\n3. How long did it take for the decision to arrive?\n4. What kind of job opportunities came up after finishing the program?\n5. Would you recommend the program to others who are already data scientists?\n\nAny info or thoughts you have would be awesome. Thanks!",
  "Hello all,\n\nI'm currently working on my masters and I'm having a hard time choosing which electives to choose from. I want to make sure I come out of the program as well-equipped as possible. I am able to choose four out of the following five classes as my remaining electives. I've also provided a synopsis of what each course will cover:  \n  \n\n* **Data Science for Business**: This course explores the various ways data and science can be applied to business contexts. Particular emphasis will be placed on using data to make informed business decisions.\n* **Principles of Python Programming**: Programming, problem solving and algorithmic thinking in Python. Topics include variables, input/output, conditional, statements/logic, Boolean expressions, flow control, loops and functions \n* **Data Manipulation**: This course focuses on the loading, manipulating, processing, cleaning, aggregating, and grouping of data. Students will practice on real world data sets, learning how to manipulate data using Python and continue their study of intermediate and advanced topics from the NumPy and Pandas libraries\n* **Information Visualization**: each students the best practices in Data Visualization, the key trends in the industry, and how to become great storytellers with data. Students taking this class will learn the importance of using actionable dashboards that enable their organizations to make data-driven decisions. For this class students will be exposed to Qlik and Tableau\n* **Applied Machine Learning**: This course will further explore modern machine learning applications such as decision trees and various ensemble learning methods including random forests. Special attention will be given to performing hyperparameter tuning to improve our models. Students will also focus on different dimensionality reduction techniques with emphasis on using principal component analysis. Students will explore the K-Nearest Neighbors algorithm and use it to build a machine learning project from scratch. Finally, students will study an introduction to using artificial neural networks to solve classification and regression problems. This course is entirely taught in Python.\n\nAny advice is much appreciated!",
  "I have some questions about DS intern\n\n1. I'm doing Masters in CS, what should I do if I want to get internship in DS ?\n2. What knowledge is expected from DS intern ?\n3. Are DS internships research position ? Does companies only hire students who are doing research ?\n\nAnd also I'm looking for a mentor who could guide me.",
  "Hi everyone, \n\nI believe that some data scientists/ML engineers with experience in this field could help me and other future graduates in this situation. \n\nI will be graduating from a Data Science BS in May and am currently searching for a job.\n\n&#x200B;\n\n1. I currently see most entry-level offers requiring a year of experience. Should I still apply for these positions, or is there actually no chance of getting them?\n2. For interview preparation, LeetCode is pretty useful for Python and SQL. Do you have any advice on how to get ready for ML or statistics questions?\n\n&#x200B;\n\nFeel free to DM me or comment any advise you have. \n\nThanks for your help.",
  "My company has a $1k education stipend and I am not sure how best to spend it. I was given advice to not take a technical class but rather executive coaching/communication/non-technical class. I thought about toastmasters to work on presentations but I have been told it may not align well with technical presentations. Does anyone have any recommendations?",
  "Hi everyone, at uni they told us that if the measured quantities are uncorrelatedwe need to use the quadratic formula to sum errors (sqrt(E1\\^2+...)). however they didn't exactly told us what correlated quantities are. For example, measuring current and voltage through a resistance in a circuit, are those 2 quantities correlated meassure? On internet I couldn't find a definitive answer as everything is so vague. I read that you need to calculate the covariance, but I didn't find what values determines if they are uncorrelated or not, for examples, a covariance of 0.07 means that the 2 values are correlated or uncorrelated from one another? I know this is very chaotic but it's 1 am and am very sleepy.",
  "Edit: Adding my information\n\nI'm working as a Data Scientist for a service company and currently working for a Fortune 50 client. I would ideally like to work directly for a Fortune 500 product company. \n\nI have 6 yrs exp and would I feel it will be most helpful to talk to and have mock interview with a Data Scientist rather than going through interview questions online or on youtube.",
  "Hi, I am familiar with machine learning, but mostly for making predictions like who to sell to or how many service tickets well get. I'm wondering if someone can link me an article or repo that shows how to do entity resolution by tokenizing things life first name and last name. Thanks.",
  "So I have multivariate dataset which i need to predict 4 variables off of it. I know that these 4 variables decline over time and have a relationship with the other dependent variables. So I want to predict these 4 variables and their trend for the next year. Obviously I do not have the data for the dependent variables over next year. Any ideas on how to start? I built an LSTM model to predict the 4 variables already but it needs of course the dependent variables as input for next year.",
  "Hi, I'm currently on my way to obtain a Bachelors degree in Econometrics. I'm going to enroll on a Data Science Masters programme next. However, I'm learning the most from the internet, books and my own projects. After reading numerous blog posts, lurking on this subreddit for a while and talking to some data scientists, I believe I've got a  general understanding of what i need to do. However, I would like to know some of the less obvious things. If you could send a message containing some tips and tricks to your younger self, what would it be? I'm mostly concerned about: \n\n- unusual ways to practice everything: analysis of datasets, programming, maths (stats), analytical thinking, getting a better intuition etc.\n- things that are important in the industry, but are not common knowlege\n- other stuff i didn't even think of, but a professional like you did and would like to share",
  "Hey folks - I wanted to put this live course from Rob Donnelly (Arena, Instacart and Facebook) on your radar!\n\nThe course looks at how to improve product and business decisions with causal inference. It draws on his experience at Instacart and Meta and features real-world examples from Amazon Prime and Facebook.\n\nIt kicks off on Feb 27 and you can find more info here:\n\n[https://www.getsphere.com/cohorts/applied-causal-inference?source=Sphere-Comm-r-ds](https://www.getsphere.com/cohorts/applied-causal-inference?source=Sphere-Comm-)",
  " What is a calculation to identify times when one set of time series data (dataset 1) has peaks/spikes and another set of simultaneous data (dataset 2) is stable and has more of a plateau pattern and no spikes or peaks at that same time? I tried graphing the difference between the two datasets, but this didn't work because there would be a high difference when both datasets are peaking if one dataset had a higher peak than the other. I only want to see times where one dataset has a peak and the other dataset does not have a peak at all.",
  "Hi y'all,\n\nSo I'm currently a PM, and I'm looking into transitioning into Data Science. \n\nI have just have 2.5 years of industry experience, and I did my undergrad in Data Science, but I got a PM job right out of college.\n\nI'm currently doing an online masters in CS, to strengthen my technical skills further. \n\nAny suggestions on how i can make this transition, or if it's even worth it?",
  "Hi everyone, so I am a fresher of Data Science, I am trying to apply to the Data Scientist position at one company. Here are the question they ask me, I just want to ask the structure to find the answer. Thank you. \n\n ***At 6 AM today, you purchased 1 MW of electricity contract for 12 PM at a price of 100 pounds/MWh. Two hours later, the forecast for solar generation for 12 PM has changed from 4 GW to 4.5 GW. The market is currently bid at 95 pounds/MWh and offered at 105 pounds/MWh. What would you do, and why? Please answer logically, stating all assumptions.*** \n\n**\\*Note that no additional research is needed.\u00a0\\***",
  "Hi everyone, I'm really thankful that this community exists because I need help Kickstarting my career in the field. \n\n99% of jobs that are hiring data scientists require a sh*t ton of years in experience as a data scientist. I acquired the common skills (including python,SQL, machine learning, tableau, excel) that are advertised as a MUST to learn to land a job (or even internship). But during my job search, i was proved otherwise. \n\n I'm unsure what job roles i can apply for, with my skill set and would like to hear your suggestions (i can share my resume if required through DM). As someone shifting careers from economics to data science, i feel low-key scammed by post graduate programs because of the gap between my experience and skills, and those that are required. \n\nI believe that big data engineers, SQL developer, python developer, business analyst and data analyst would be potential career options for me. Particularly, data engineering is interesting but I am going to invest more time in learning other skills like azure (which is so vast with so many categories, it would take me very long to master..), mongodb, Linux, Cassandra, spark, Hadoop, etc. \n\nI see these skills mentioned frequently in job roles i apply for:\n- power bi\n- Apache spark\n- Hadoop\n- mongodb\n- deep learning\n- data pipelines\n- opencv (i find this very interesting, but not sure jobs would be there for freshers)\n- git\n- databricks? \n\nWhat would be some skills that I can quickly grasp the basics of, and master on the job? Especially jobs that would be open to freshers?",
  "I work in telecom. These are fake numbers for illustrating purposes.\n\nI have customer A who has 20% market share in US overall. Let's say they have 1000 calls per month and they send 10% to NYC (100 calls).\n\nI am trying a win another customer so I have to estimate their call volume per city. I know they have 10% market share overall (500 calls). I need to estimate how many calls they send to NYC. I could use customer's A ratio (10%) but this ratio could be wrong. They could send 5% to NYC or 15% or something else.\n\nAny ideas how to estimate this?",
  "I want to work on a new project and create a web application that integrates deep learning.\n\nI've always wanted to try my hand at making a chatbot, but as a beginner in data science, I could use some help. \n\nCan anyone share some creative ideas or exciting topics to make my chatbot stand out? Also, any tips on finding or creating a suitable dataset would be greatly appreciated. Thank you!",
  "Hi, we\u2019re a team of 3 Data Scientists and I\u2019m the Senior Data Scientist in the team. I\u2019m thinking of introducing a Friday Coding Challenge where we solve from Data Structures problem or familiar LeetCode problem where all of us can practice how we deal with solving coding problems.\nIs it a good idea? Has anyone tried and it wasn\u2019t a good idea?",
  "Im doing a ml project doing binary classification and I fear I may be overfit due to a small dataset. 540 rows by 10 columns. I have 97% accuracy and my confusion matrix is exactly how I would want it. \n\nI\u2019m trying to figure out how to make sure it\u2019s good and not overfit. So I\u2019m trying cross validation. I\u2019m doing the function called cross_val_score. The ch method is stratifiedfold. It spits it out and I\u2019m averaging 97% on there as well with 10 splits. \n\nThis is one easy like of code. Is this the same thing or just as good as the loop method I see people using for KFolds on YouTube? Or should I try and replicate what they\u2019re doing?",
  "Spent around a month doing online search and study to learn more about the metrics related to Market Basket Analysis (lift, leverage, confidence, gain, etc).\n\nThe challenge is that most materials online are blogs that fail to provide more context on the metrics, or educational literature that simply summarizes all metrics but don\u2019t have any industry use cases.\n\nAny recommendations on industry/conference literatures or books, that go deep into Market Basket analysis?",
  "I'm working on a sports betting project and I wanted to talk to consultants to help me out. I'm also looking for statisticians/data scientists who have experience with betting. Ideally, I'd like to have a quick chat with someone free of cost, but I recognize this isn't easy. How can I find people, both paid and for free (if possible.) Is there anyone here that could help me out possibly?",
  "Hi,\n\nI am currently pursuing a B.E degree in Information Technology and possess intermediate knowledge of programming languages including Python which I believe is an important language when it comes to data science.\n\nI should also mention that I am a neophyte in the domain and am trying to explore and understand the same. While I've signed up for a good course on Udemy, I would also like to explore more study and reference material.\n\nAny help regarding the same would be appreciated.\n\nThanks in advance!",
  "For instance, i am now plotting the density of a data set that is very sparse. thats why i would like to use some smoothing with a convolution. but then extrema won't remain the same. but i know the data was obtained via a stochastic process. so i guess i can omit extrema. whats your perspectives on that subject ?",
  "I\u2019m a hiring manager for a Data Science team. I\u2019m looking for a Junior DS and my methodology is:\n\n- I don\u2019t do coding interviews: I trust you know how to code, if you really want to be in this field you\u2019ll learn tools and languages on your own.\n\n- I don\u2019t do case study: I don\u2019t really have the time for this, I want my \u201ctechnical interviews\u201d to be 15-30 mins.\n\n- I want to know if you understand the basics of math/stats and if you can reason through unknowns. I want to see how you process through problems.\n\nLately I\u2019ve been getting candidates who make it to my round and when I ask them some basic concepts, they completely flunk it.\n\nSo I\u2019m wondering\u2026are my questions too hard?\n\nThe questions:\n\n1) You are given a tabular dataset that you have no prior knowledge about. Walk me though how you would profile this data? What steps would you take to explore this data? Explain to me your EDA process.\n\n2) How would you evaluate a linear regression model? What are the metrics and what does it represent?\n\n3) Explain the difference between Standardisation vs Normalisation.\n\n4) Explain what a type I and type II error are.\n\nThese last 2 questions I don\u2019t hold against them and which is why I ask last, and I let the candidates know it\u2019s good to know but not required. It would set them apart.\n\n5) Say you\u2019ve got a ETL job that needs to be ran daily, say it\u2019s a dataset that you need to pull from a server, do ETL, and upload it to a database or storage of sorts. How would you go about automating this task? What tools, methods would you use? The world is your oyster, any and all tools out there in the world are available.\n\n6) Can you give me a use case where you have worked in Cloud (ie. AWS/Azure) to support your data science projects?\n\nEdit: I have dialog when they answer questions or if they have questions for me. My style is, dialogue! Just chat with me.\n\nAre my questions too hard? Can I ask these questions in a better way without getting too elaborate? \n\n\nAppreciate the feedback and help.",
  "Half data scientist mechanical engineering student here. \n\nWhen I look at the history of science, we know that with the development of computers, analytical solutions have been replaced by numerical solutions. This was a big development that changed our world. Can machine learning revolutionize cases where mathematical models are too complex? eg: Turbulence modeling\n\nAnother Real Example:[https://www.wired.com/story/deepmind-ai-nuclear-fusion/](https://www.wired.com/story/deepmind-ai-nuclear-fusion/)",
  "I have allways liked computers, programming and ive allways been good at math. I have chosen Data Science for my bachelor this year. But after reading online I only see negative things about Data Science. That its way too big of a supply than demand of fresh Data Scientist comming from school. That the market for Data Scientists is dead. If this is true, I should probably rethink what I want too study. \n\nBut I really want a bachelor about programming that also compliments my math skills like I get more money. If not Data Scientist, then what?",
  "Hello, my father has a few small businesses and i was thinking due to mu academic background of implementing a data department as they aren\u2019t implementing data in almost any way. Any suggestions?, where should i start?",
  "My current job as a SWE in machine learning is proving to be very stressful for me, and it may be due to a poorly structured, understaffed company with high turnover,  but I thoroughly do not enjoy being asked to make magic out of nothing, asked for deliverables that are unreasonable and completely out of scope of my domain knowledge and would take me a very long time to get up to speed on, tasks are morally questionable, and people are highly unprofessional and at times downright hostile (it\u2019s defense contracting). \n\nI want something less stressful. I\u2019ve applied to dozens of places in ML engineer, data scientist and data analyst roles and have not heard back from any. I have a BS in linguistics and an MS in data science. \n\nDoes anyone here work as a data librarian?  Wondering if you would need a MS in library science. Maybe being a librarian in general would be less stressful\u2026",
  "so really by no means am I a data scientist. i sit on a strategy team with a new role of decision science. so i started yesterday taking over a process that had been in the past done throughout 3 teams, one of which is data and analytics team \n\n\nlong story short, the output from the many complex sql queries that have been being ran is most likely inaccurate and then the analysis done on it is independently shit. took me many many hours to figure this out and i\u2019m exhausted. i blew the whistle today because the deliverable goes out to major clients. my complaint is being taken seriously but still wtf \n\nhow can so many people be complicit in this?\n\nedit grammar\n\nfor context: i can write complex sql queries and know my way around R but I don\u2019t know complex stats,math, logic etc that goes into building ML, Ai etc models. Idky this is being downvoted so hard. know am young and probably wearing too heavily coated rose colored glasses, but i think this is a valid question to the sub :/\n\nUPDATE: \n\nso apparently we are now tightening our DUA with clients which came from a c suite\u2019s suggestion. a lot of my team is new so I think that\u2019s why this was this well received and why they escalated this so quickly . i really did do good due diligence which contributed to it too. \n\nthanks for all the help mentally sorting this out and i\u2019m glad i can provide a good outcome to y\u2019all \n\nmaybe one day when i grow, ill put in the work and become a data scientist \u2764\ufe0f",
  "Can somebody help me with this, dms are welcome:)\nI need a diagram and not a repo",
  "Hello. Talking about AI/ML, here is an overview of data-centric & model-centric MLOps.  What is your perspective on it?\n\nLink: [https://ubuntu.com/blog/data-centric-mlops](https://ubuntu.com/blog/data-centric-mlops)",
  "My dream is data science, but unfortunately my dream in high school was to get stoned and watch YouTube videos all day. I totally blew my chances of university (I am 24 now), but I currently have a 2 year diploma in software development and will soon be doing a 14 month post-diploma certificate in Data-analytics. \n\nIf I work as a Python developer for a couple years and eventually transition to Data analytics, will there be any chance of me transitioning to data science if I also have a solid portfolio? I guess what I am really asking is did 17 year old me really ruin any chance I had at pursing this goal of mine?",
  "I'm curious if any of you cuss at work. Feel free to leave longer remarks in the comment section if you feel the want.\n\n[View Poll](https://www.reddit.com/poll/10s66rc)",
  "I have a dataset full of Twitter tweets, with a column for the text of the tweet. For each tweet, one word has been selected as a keyword and each such word is in another column called \"keyword.\" '\n\nFor my purposes, these keywords serve as a label.\n\nMy goal is to create a model to label a Tweet, but I'm having trouble deciding how to encode the label so that I can properly label the Tweets.\n\nMy vocabulary size is 41,886 words, so figure the number of bits for one-hot encoding is 41,886. My training set has 5709 rows and my test set 1904 rows, so 7613 rows in all, so if I try to one-hot encode the keywords, figure roughly 319 million elements in the resulting one-hot encoding array.\n\nUsing word2vec would be problematic, I think, because you can't classify vectors without running the risk of floating-point-related errors.\n\nWhat's the most optimal encoding specifically for this purpose?",
  " \n\nCurrently, AI has the ability to make predictions based on data and patterns, but it does not have the capability to truly see into the future. While AI models can make educated guesses about what may happen in the short term based on past events, it is not capable of anticipating unforeseen circumstances or understanding the range of potential outcomes of a given situation. This is due to the fact that AI systems are limited by the data and algorithms used to generate its predictions. Furthermore, AI does not possess the capability to form its own insights or draw meaningful conclusions from data due to the lack of emotional and creative intuition. Therefore, while AI can be a powerful tool to help make decisions, it cannot be relied upon to accurately predict the future.\n\nWhat do you think? will it ever be able to truly see into the future?",
  "Hello people,\n\nI am currently attending a Data Science course and to finish I have to write a paper about a project that I am currently working on. I write the code in VSCode and I use .ipynb notebooks.\n\nSo I am basically training a few ML models after a long data preprocessing which worked out fine. But as soon as I run my hyperparameter tuning code, my PC takes a lot of time. Right now I am running hyperparameter tuning for RandomForest and it already runs for 21 hours.\n\nIs there any possibility for me to run my code somewhere else? I read abour Heroku, but that seems to be too much than what I am looking for. I am getting a bit nervous, because I want to get this paper done. The worst case is that I have to buy a new PC.\n\nThank you so much!",
  "I just joined a software company's support operations team as a data scientist. My first project is to improve the current forecasting model predicting future support case volume over the next 12 months to be used as an input for capacity planning.\n\nThe company has multiple software products and the current forecasting models that have been used are all just univariate forecast models that have been only trained on using the historical case volume for each product. These models in general perform pretty well in terms of forecasting accuracy, but the business stakeholders are complaining about how \"un-explainable\" these forecast values are. They want to break down each forecast values into multiple components, but the current model class won't allow them to do so because the these forecasts are only derived from analyzing the past volume's seasonality, holiday effects, and running trends (either increasing or decreasing year over year).\n\nWhen I chat with my business stakeholders, they said that the case volume is driven by factors such as active customer count/distribution of customer size across different regions, product maturity measure, case deflection rate (how self-serviceable the company's Knowledge articles and navigations are), and others. We do have these drivers and the stakeholders want to use them and their expectations of the future trends for these drivers in the upcoming forecasts.\n\nLooks like I can try multivariate models such as VAR, VMA, VARMA, or VARMAX. However, I'm not really sure how reliable they would be. If they won't result in something that will be adopted, then I would prioritize improving the current model's accuracy.\n\nSo my question is, have you also run into the similar problem? Are multivariate forecasts actually even used in Capacity planning? Which model class can I look into?",
  "The traditional route to data science seems to be at least a Masters in Maths > DS > ML etc.\n\nThis is obviously a good start and will hopefully instil good DS foundations - in terms of the theory and tech skills (Python/R etc).\n\nOne key ingredient that is missing is an emphasis on pro-activity. You go through school being told exactly what to do. You go to uni, again being told what to do. And then you get an entry level DS job and they tell you what to do.\n\nAn important skill to develop is being able to asses the tools and materials available to you and come up with something that adds value all on your own. E.g. if you are a data anaylst or DE? well you have access to a shit load of data. Say your company has commercial interests i.e. they want more sales etc. Can you use some advanced analysis to either review customer behaviour or potentially create a model to predict sales?",
  "Hello good people I have not a clue about data science, but I have always liked spreadsheets and organizing stuff and I would like to learn whatever I can as a hobby and something to put in the cave where should I start?\n\nThank you in advance",
  "Has anyone gained a certificate from this program? \n\nWhat are your thoughts?\n\nIn anyone\u2019s opinion; is this certificate valuable enough to gain employment?",
  "I have xml files of bugzilla bug severity data which I want to use in my ml model to predict severity of a bug, but all fields of bug like id,title,description are into different xml files but they have a common attribute of bug\\_id. I want to merge them all into a CSV files so that i can work on them to create my prediction model. I need this for my college project.",
  "I need a real-time data with features drug name, disease (seasonal or non seasonal), patient details(age, any other disease), drug rating by patients.\nI tried various websites but could not all the features in single dataset.\nPlease help me where to find and if any other approaches like web scraping etc",
  "Hi all.  I'm not quite a data scientist, but I'm pretty data literate, though I haven't gotten my hands dirty in a few years. While I was quite proficient with doing analytics with excel when I'd just download a bunch of data, now that things are embracing single-source-of-truth, automation and cloud-based approaches, doing basic manual things has gotten a lot harder, even with desktop excel.  I've learned a lot of new stuff, but some key things are eluding me.  If I was doing a big enterprise-scale, future-forward solution, I actually feel like I could move forward well, but trying to utilize these tools in my personal life has been hard.\n\nTo start my current use case of personal finances (and its only step one of getting a good personal finance dashboard), I need to merge, categorize, and ignore some data in spreadsheets *that have the same column schema*, and that alone has ended up being really hard to do.  Not even getting to mapping tables or anything like that yet.\n\nMy big, *core* issue is that I can do queries, make transformation rules, but I can't seem to find a way to edit/add data once I get it all in one place (got forbid I want to make the edits when I actually see the data on a powerBI dashboard)  Googling this has been hard (ex: googling edit source data returns results for editing data locations), and he educational materials I've found all seem to focus on big enterprise level data where the solution is not to have any manual editing at all.\n\nCase in point:  Categorizing expenses from venmo (which only lets you download one month at a time).  I can query the sheets.  In old-school excel, I'd copy all the rows together, sort by vendor, and then manually batch categorize.  It's take me ten minutes tops, and then I'd use that as a sort of 'silver' data set to import in to my final dataset.  Now, I can query the individual sheets via power query (venmo only lets you download a month at a time), but adding categorization or deciding to remove a row seems impossible.  Right now it seems like the only thing I could do is write a python script, or go super manual any time I want to merge some data and copy&paste individual rows from many different sheets.  I'd love to streamline and utilize the new stuff, but it seems like the more manual side of data cleaning has to happen alllll the way down at the raw source and that kinda sucks when you have similar data across twenty different sources, or want to add data (like a category) at a higher level.\n\n&#x200B;\n\nSorry for the long post.  I fully expect that the real problem is I'm just thinking about things too old-school somehow and need to do somehow change my paradigm with all of this.",
  " \n\ni have been given a problem statement for a certain dataset . \n\n\" analyzing the various core industries and GROUP the business categories like Retail, Poultry,\n\nAgriculture, Manufacturing etc  \"\n\ni dont know WHAT TO DO or where to start",
  "I ran into this problem enough times at my last few jobs that I built a tool to solve it. I spent many hours building Docker containers for my Python functions, as many of the data science modules required building C libraries (since they significantly speed up compute-intensive routines, such as math calculations). Deploying the containers to AWS Lambda or Fargate (if the processes required more CPU or memory or were >15 minutes) and wiring functions to talk to each other using queues, databases, and blob storage made iterating on the actual code, which wasn't even that complex most of the time, slow.\n\nI made cakework\u00a0[https://github.com/usecakework/cakework](https://github.com/usecakework/cakework), a platform that lets you spin up your Python functions as serverless, production-scale backends with a single command. Using the client SDK, you submit requests, check status, and get results. You can also specify the amount of CPU (up to 16 cores) and memory (up to 128GB) for each individual request, which is helpful when your data size and complexity varies across different requests.\n\nA common pattern that I built cakework for is doing file processing for ML:\n\n\\- ingest data from some source daily, or in response to an external event (data written to blob storage)\n\n\\- run my function (often using pandas/numpy/scipy)\n\n\\- write results to storage, update database\n\n\\- track failures and re-run/fix\n\nIt's open source <3. Here are some fun examples to get you started:\u00a0[https://docs.cakework.com/examples](https://docs.cakework.com/examples)\n\nWould love to hear your thoughts!",
  "So, the appraisal came in numbers that were not in my favor even though, I worked on a lot of projects which had a positive impact on business, they filled a patent as well under my name for one of the solutions. \n\nNow I came to know, after appraisal, one of my colleague is getting 40% more than me, he is working on the same problem for since I joined them, I guess he is working on the same problem for past 3 years, and I know in the end the solution is simple xgboost.\n\nSo, if any of you is looking for a data scientist with the zeal to solve problems, please hit me up!",
  "So I have been eyeing the DS bootcamp from Northwestern for a couple years now. I am an accountant at the moment but want to move into data analytics as thats a growth path in my company and I wanted to try and buff up my skills to make the transition easier. I used to major in CS for a year and did Stats for 2 so I feel like I would have a decent chance of comprehending and gaining a lot from it. Has anyone here done the Northwestern Bootcamp?",
  "Hello All! I\u2019m an American considering doing a Data Science / Statistics/ Machine Learning masters in Europe (likely Spain). Many people I\u2019ve expressed this thought to suggest opting for an American university instead. I\u2019d love to hear from anyone that has done a masters in a EU country. Specifically, did they feel as competitive in the American job market after? (If the US is where you\u2019re based)",
  "Scenario: You just got hired as a DS (for the first time) where you'll be the first DS on a team and will be asked to define the role you'll be playing, where do you start? \n\nWas asked this in an interview last week and don't think I answered well.",
  "I'm currently a graduating senior at Boston College with double major in CS and Math. Got a SWE job offer at a big fund company. \n\nI basically leetcoded my way into a job. No research experience, no personal projects. But I've always found my statistics classes most interesting, which piqued my interest into DS since I already knew how to code. After taking some data science-y electives, I wish I had gotten into DS sooner instead of SWE. \n\nFrom what I understand, getting into DS is not something you can leetcode your way through. You either need a PhD or a mind-blowing side project. \n\nGraduate school is out of the question (for now, unless I find a company-funded program), as I have  to start making money asap. I was thinking I stay in SWE for a couple years and try my luck with DS on for my third or fourth job. \n\nHow does one move laterally into DS from SWE without a grad degree or any research experience? Is pivoting into SWE from DS common, or will it be too late for me to transition then? \n\nSome stat-related course work I've taken:\n\n* Probability (Discrete and Continuous)\n* Mathematical Statistics\n* Advanced Data Analysis (regressions, ANOVA, non-neural learning methods)\n* Natural Language Processing",
  "How should i start my data science journey,\nA- With a certificate course\nB - YOUTUBE\n?????",
  "Hello Fellow redditors,\n\nI've managed to secure a junior data analyst role. The HR at the company insisted me that the contract agreement gonna be there in a day and I have to E-sign it, but it's been more than a day. Should I email HR asking for it or wait further?\n\nThank you",
  "Building some context. \nI have an MIS degree. Worked as a data analyst at two different companies, adding up to 3 years. \nJust completing my first year as a Software Engineer focused on a Data pipeline features. \nI am very comfortable with Python, object oriented programming and even have a few DS projects on my resume. \n\nThe last couple of years have been miserable for me and I'm mentally exhausted.\n \nI'm looking for a way to get out of my current job. It isn't the best place to be for a variety of reasons. Been interviewing for DE, Analytics Engineer roles for a couple of months, but haven't gotten too far. DS has been a field of interest for me but I never got any calls because of lack of relevant experience. \n \n1. With some experience as a SWE, do I have better odds getting hired as a DS/MLE?\n\n2. How do I approach the job applications? Please suggest any projects/skills that will get my resume some traction for these roles? \n\nI'm feeling severely hopeless, please be kind. Thank you!",
  "I'm thinking about making a project showing various types of reactions to current events in left wing and right wing subreddits and YouTube by taking api data and visualising it using tableau.\n\nIf it is too basic, can you suggest how to make it more advanced? Thank you",
  "When building a complex rubric that is meant to grade/elucidate 4.8 billion individual datum, grouped into 1917 hierarchical components, in a manner that humans can quickly and intuitively viscerally get...\n\n...one should take a break and go for a bloody run.",
  "I'm in the last university semester and looking for jobs. In one of the interviews they sent me a dataset with some instructions like \"use ML techniques to predict when X or Y would most likely happen, in Jupyter notebook, we expect  a precision of 50% and no need to analyse recall right now\" and it was a breeze. The first things I tried worked like a charm and got everything I was asked to do (a simple logistic regression was really effective). Is it better to just leave at that EDA + some manipulation and the first model I've tried already worked great, or is it better to add some other models and techniques so I show off/compare a little bit? What skill they are trying to evaluate other than the code/model working? and how much should I explain without being pedantic? I'm tend to be too perfectionist (legacy of my uni, where they ask for scientific level documentation pretty much always)  \n\n\nThank you!",
  "Hi Everyone, currently working on the MVP for our startup and we're developing a loyalty program App for SMEs in a couple of industries, I.e food and beverage, beauty and spas, etc. \n\nSince I\u2019m new to this field, looking for any actionable advice. Both from entrepreneurs who have built a similar business model before and also feedback from vendors. \n\n1. Do you run any current loyalty or rewards programs? And have you done any partnerships with other businesses? \nPerhaps a type that offers coupons or points.\n\n2. What do customers currently need to do to earn points? \ne.g. buy several products in exchange for a gift, follow/like on social media, share contact details, sign up for a newsletter, etc \n\n3. What else would you like them to do? Have you thought of partnering up with businesses with overlapping customers to increase revenue and retention? \n\nAppreciate any thoughts and advice!\n\n\nP.S. Maybe, entrepreneurs who\u2019ve built a similar business model in the form of software or App could share any tips from your blueprint. \n\nThank you!",
  "Not necessary that the product is medical related, what have you done to improve hospital's/healthcare institution's operation or create opportunity for partners?   \n\n\nI am looking at all these data from the data warehouse and I really want to make a positive impact. Looking to get some inspiration here. Discussion from outside healthcare sector welcomed too. TIA.",
  "Any pro dips appreciated! I\u2019m not a data scientist, but I am a Lean Six Sigma BB and I have a bit of data experience in Minitab",
  "For each working day, I have 6-7 meetings and almost have no time to do data analysis. Do you know if this is normal?  If you are a data analyst, could I take you a couple of minutes to the questions below?  Thanks in advance!\n\n1. Ratio of daily meeting VS daily data analysis, like 2:8,3:7, etc.\u00a0 How many meetings do you have each workday on average?\n\n2. Is there a data manager that can advise/lead you?\u00a0 Or you need to report to the manager with no data background.\n\n3. Required skills you need in your data analyst job.\u00a0 Technical skills VS communication skills, which is a little more critical for you?\u00a0",
  "Lately I've been perusing through the subreddit, reading posts on how one could land a DS role or change within industries led by data science techniques, e.g. quant, marketing or any other DS tech led industrial solutions. \n\nBut from this post, I wish to gain a holistic view on what you all have pursued after landing a job related to DS. \n\nDo you go for:\n\u2022 MBA for a managerial role\n\u2022 MOOC courses on different DS tools to stay updated\n\u2022 Certification in MLOPS/Dashboard/statistical programming etc.\n\u2022 PG in economics, quantitative finance, statistics etc.\n\nI understand people chose to pursue topics they wish to accomplish in their careers. \n\nBut I wish to gain a quantitative insight into what most DS pursue after landing a job.",
  "I can do the Coursera IBM Data certificate through my employer. Has anyone else completed it and thought that they gained valuable skills through it?\nI don't have any prior background in DS and am currently a Backend Kotlin dev looking into DS/DA roles.",
  "I've read that many employers don't really care about the specific course / institution where you get your certification (debatable I'm sure) and that practical projects / portfolio most important. With that in mind, was wondering if anyone had a recommendation for a hands on practical course that sets people up to do their own personal projects. For example, I see that the [Johns Hopkins University Data Science Specialization](https://www.learndatasci.com/out/coursera-data-science-specialization) has solid ratings and seems hands-on (albeit in R with no Python). Any suggestions welcome.",
  "I\u2019m thinking of going back to school to get my masters in the next year or so. I\u2019ve worked for my company almost 2 years and they have a program where they will pay part of it as I work full time.\n\nWhat has your experience been with taking higher ed classes and work full time? From what I\u2019m assuming there won\u2019t be much free time of course but the pay off is worth it. I\u2019m looking at some data science/analytics program or MBA (leaning more towards data science) but want to gauge how intense it is and is the end result worth the investment.",
  "I'm a computer engineering student, and as you can imagine my grades aren't great. They're not the worst but there are certainly subjects that drag me down. \nI'm afraid I won't have the to do a masters of PhD, but I'm very willing to self teach through the internet and projects.\n\nDo you need a masters or PhD to work in data science and ML?",
  "SAP is for better or worse, ubiquitous. Data lies in this system. \n\nAs a data scientist, what should we know about SAP products that can help with data science workflow?",
  "Hi!\nDoes anyone what\u2019s the content for the Analytics Test 2023? I searched online and came across Tests that mainly focus on excel skills. However, the info given to me by my HR are \u201ccomplete our analytics assessment. It includes maths, logic and SQL. It's all multiple choice.\u201d\nOr should I just stick to SQL?",
  "I\u2019m applying for online grad schools with Georgie Tech as my first choice. I\u2019m not seeking high prestige big name schools or anything with high tuition costs into the $40k-$50k range because I\u2019m very senior in my career and really just want to do this for myself. I have not seen much of anything online about Merrimack so I\u2019m hoping to hear some reviews of this program. I\u2019m thinking of\nMerrimack & Eastern University as my backups in case I don\u2019t get accepted into Georgia Tech. Anyone have any insights? Thanks.",
  "Idk much but i want to do some data processing and do a write up on it as practice. What sorts of data would be good for this that i could obtain online easily",
  "Is here anybody know deep learning, i need help ,DM me",
  "I have been in the healthcare data science field for about 3.5 to 4 years. I have a clinical degree - Pharm.D. I started as a government health informatician, then transitioned to data analyst, and now I am a data engineer in a health-tech startup. Since I don't have a strong DS/stat/CS education background, I constantly felt like I needed more education in biomedical data science.\n\nAfter some research and chatting with people, I was told master's in data science at Berkeley is good. However, I was also told Stanford/Harvard's master's in biomedical informatics has many good core courses and electives in CS and DS.\n\nSince I use a lot of text processing and lab data analysis, and my current role started to get more NLP applications, I wonder which training program is better suited for someone in health tech currently and in the future?",
  "Curious if anyone is in an organization that uses Denodo. How do you like it? Also just curious if anyone is using a different virtualization layer in their organization?",
  "I'm trying to predict sales for a tea export company with different tea types and weights. My goal is to predict sales for each product type category for the next 12 months.\n\nData set looked like this\n\n    Date        Type    Weight    Quantity      Price\n    2016-01-01  black   bags      1734136.51    1131.30\n    2016-01-01  black   bulk      10722389.66   510.86\n    2016-01-01  black   4g_1kg    6817078.01    588.72\n    2016-01-01  black   1kg_3kg   86444.50      565.91\n    2016-01-01  black   3kg_5kg   1003986.73    552.39\n\nI have simply predicted the total sales and that came out pretty good. But I don't understand how to predict sales for each type and weight classes. I understand the time is valuable and if someone can explain me the way to do it, it would be great. I'm trying to use linear regression for this. Accuracy doesn't matter. What I want to understand is to feed the data and get the output for different product variations.",
  "Hello everyone, I am a pharmacist (Bachelor of Pharmacist in Vietnam) and currently working in a marketing position at an MNC pharmaceutical company.\n\nNow, I want to switch to the data science field. Of course, I do not have any experience in programming. I have been doing some self-learning courses about Python Specialization, and Algorithm in Coursera.\n\nCould you please give me some advice if I should try to apply to an Online Master's Degree program or choose a short course 'bout Data Science instead? Or Should I back to a BSc in Data Science?\n\nThank you so much!",
  "Hello guys! This is my first time posting here. \n\nI\u2019m currently a junior studying Biology but I\u2019m not doing pre-med. I\u2019m currently taking a data mining class centered on genetics and my professor announced that the students can continue doing their assignments with either R or Python. \n\nSince I\u2019m working towards landing on a DS role, I\u2019m wondering which language I should lean towards.\n\nAny insight will helpful!",
  "I have a Gaussian Naive Bayes model. 90% of all data identified as positive are true positives, and 56% of all data identified as negative are true negatives. This is approximately true when evaluating the model both against the train dataset and the test dataset I generated (which I suspect is actually a cross-validation dataset, as this is a Kaggle competiton so the actual \"test\" dataset doesn't have the Y variable.)\n\nIn all, the accuracy is about 60%.\n\nHowever, I'd like to investigate that true-negative rate and see why it's so low and what I can do to improve it.\n\nAs this is a Kaggle competition, I'm not sure if the Terms of Service allow me to reveal what Kaggle competition I am talking about.\n\nThoughts?",
  "Has anyone here taken the hirevue online code assessment for this role. I have to take this in 1 weeks time. Any information would be highly appreciated.",
  "Say I want to create a startup with paying customers through subscription service. I have a ML model which runs on my server. How would this usually interface with a paying customer?\n\nWould an API (REST, RPC) to my server be a sufficient interface, or do most customers expect a different user interface, like a UI?\n\nWould I give each customer a different key to use when calling the API to give them access to the service?",
  "I have a mentor that I hired recently whose background is in data science. I'm wanting to get an entry level in data analytics--not data science--but she has me on a track that is almost strictly Python. She doesnt think I need to do much in SQL or Tableau. She also thinks I need to learn advanced techniques in Python like machine learning, time series analysis, etc.\n\nMost of what I've read/watched on data analytics suggests that\n\n1)SQL is by far the most important tool to learn\n\n2) learning one data visualization tool(Tableau or Power BI) is a must\n\n3) only the basics of Python in Numpy, Pandas, and Matplotlib is needed because it will only be used 5-10% of the time\n\nDoes this mentor have me on the wrong path, learning things I don't need to while being too focused on the things data scientists would use?",
  "I am learning Datascience and doing a project. I created some dummy data http://Mockaroo.com using this link for my project. \nI carefully researched all the feature datatype required and ranges to  set the data in standard ranges after doing lots of research of what will be the highest and lowest value of that feature. \n\nThe target Y is discrete so I used logistics regression when I applied the algorithm and do the summary I find all the p values >0.05\n\nMy question is \nIs creating dummy data out of no original data for sample is wrong\nOr \nHow to choose proper p value\n\nSomeone help me",
  "Hi,\n\nI got an invitation to a second interview for a Data Analyst position.\nFor the interview they want me to present a case study for which they have provided a csv, my question is what is expected of me?\n\nThe csv is a customer satisfaction survey with columns regarding: \"How easy was it to handle the matter?\", \"Did you receive the help you expected?\", \"How satisfied are you with the recieved service?\" and \"How likely are you to recommend us to someone you know?\"\n\nDuring the first interview they discussed data visualisation alot so I feel like that is at least expected of me. Any general points of directions what visualisation and analysis that is probably expected would help alot since this is the first time I've gotten this far in the interviewing process.\n\nThank you!",
  "Per title - I made a pretty bad mistake at work related to our cloud platform and resources by inadvertently compromising a key (which will very likely affect the billing for the month) through a CI/CD workflow I had wrote. Its since been 'fixed' and I have been reassured it's actually happened before (EDIT: the keys been compromised before but I don't think to this extent) - but I still feel horrified and upset about causing the issue to begin with.\n\nDoes anyone have advice on how to best move forward from this incident with my mentors and boss? I am afraid the team will second guess assigning me more tasks/opportunities in the future.\n\nEdit 1: Also if you could share mistakes you've made at work that would make me feel better too\n\nEdit 2: Thanks for the replies - there's been a lot of great advice commented and its definitely helped soothe my nerves :)",
  "Hi everyone! \n\nFirst time posting (ever!), kinda nervous lol.\n\nI recently just got a programming interview offer for a data engineering position! However, I am still relatively new to the field and not 100% confident about what skills/concepts I would need to practice/hone before the big day. I would love any tips and pointers! (esp if you have a DE background!) Thanks!",
  "For example given data of day vs. value as below:   \n\n\nseries1\\_data = \\[\\[1, 10\\], \\[2, 8\\], \\[4, 5\\], \\[7, 7\\]\\]  \nseries2\\_data = \\[\\[2, 12\\], \\[3, 9\\], \\[5, 7\\], \\[6, 5\\]\\]  \nseries3\\_data = \\[\\[1, 9\\], \\[2, 11\\], \\[4, 8\\], \\[5, 6\\]\\]  \n...\n\nNote that series\\_1 has days 1,2,4,7 and series\\_2 has days 2,3,5,6 . Thus in this case, a group-by day would not work to generate a daily statistics.",
  "I have been offered a masters degree offer for computing data science instead of cybersecurity ( which I applied for). It\u2019s mentioned computing data science in the offer letter rather than data science. I did some research and got mixed information that both are not alike. Do anyone have any idea whether both are same, if not then which is better?",
  "This is a simple supply chain analysis that I'm hoping to get some feedback on. I'm wanting to build an analysis that shows a negative correlation between inbound service and outbound transportation costs. The theory is that when our incoming shipments are delayed, we need to expedite outbound shipments to pick up the slack. Thus incurring additional cost.\n\nI built a simple linear regression model that plots item ID on a graph that has service level % on x-axis and transportation cost on the y-axis. This was strait forward. Now I want to build a similar graph that shows the sum total of our transportation spend on the y-axis. This would demonstrate that with each percent increase in overall inbound service level, we can decrease overall transportation costs by X.\n\n**My questions are:**\n\n1. Is it mathematically correct to translate the first analysis into the second?\n2. How would I go about building the second graph based on the first analysis? (included sample data below for illustration)\n\n&#x200B;\n\nhttps://preview.redd.it/uo3exdrscmfa1.jpg?width=1628&format=pjpg&auto=webp&v=enabled&s=898d28710b80050a5d036ba1c4407adbd51f4c8f",
  "Please forgive me if this is the wrong sub, but I'm at a really pivotal point in my life and I'm considering between lighthouse Labs, springboard and Brainstation for their data science camps. I have a lot of real world experience and just want to upgrade my toolsets to include python/SQL & other data science tools that help me secure better career options.\n\n(don't ask. I've had to do black magic with spreadsheets in ways you wouldn't believe for years now.)\n\nI'm mostly interested in the short-term grinds since I'm leaving my current job; for data science camp goers, how have:\n\n\\- Class size / Instructor availability\n\n\\- Post graduation job support\n\n\\- Opportunities for projects\n\nbeen for you guys?",
  "Im PhD trained in cognitive science, but academia isn't for me. I did some training courses, but mostly taught myself HBM and quite like it.\n\nAre there any sectors or industries which are likely to need skills like this?",
  "There is a feedback loop that whenever a model is implemented in Keras/SKlearn etc they get a lot of attention. Is there any algorithm that we are sleeping on because they don't appear in any famous library?",
  "Data for non science background people\n\nHi everyone, i come from a finance background and want to move into data. I'm not sure whether I should start with data analysi, data science, data engineering, BI, etc. So many things out there which makes it equally confusing for me to choose from. I don't know if data even is for me.\nAt the same time i don't want to just sit idle till i come to a decision. \nWhat would you suggest i start with atleast so that i can figure out the process as i go? \n\nI'm a qualified CMA and have experience in accounts and costing, zero idea of data science and don't know where/how to start.",
  "I\u2019ve been self-studying gaussian processes; watching videos, reading papers and blogs, and started with the Rasmussen & Williams book. I\u2019m still quite a way from fully grasping it.\n\n \n\nNow, gaussian processes is a non-parametric model, requiring access to all the training data when making predictions. I\u2019m often coming across the information that GPs don\u2019t require cross-validation. How then can one confidently assess the model? Especially with regards to higher dimensions, when you can not visualize it as a plot.\n\n \n\nAs a side not, although I am trying my best to understand the math, I am using scikit-learn.",
  "Hello, I have a background in life sciences and I wasn't expecting to get accepted into this course so I'm happy about that. I'd like to hear from actual professionals about the scope and viability of this degree specifically as it's not just plain 'Data science', thank you!",
  "Hi, I'm currently going through a learning journey. I have created a vanilla neural network from scratch and I want to document what are the improvements that can be applied on.\n\nI'm only working toward the multi layer ANN, I don't want to tackle with others like CNN, RNN, LSTM, Transformers and so on, for the moment being.\n\nFrom my own research I have figured a few, which are:\n\n* Momentum based optimizers for saddle point problem\n* batch, mini-batch and stochastic gradient descent\n* batch normalization\n* L1, L2 regularization \n* dropouts\n\nCan you tell me what other techniques available? \n\n&#x200B;\n\n>!I have made a !<[Notebook](https://www.kaggle.com/code/mohamedahmedx2/build-a-simple-l-neural-network-from-scratch)>!on kaggle with the code just to give you a brief !<",
  "Title",
  "Have you ever been asked to illegal things with data? I ask this question because I went through this a few years and want see how other people have handled these situations. My situation started out as on honest mistake where data was accidentally excluded i noticed the mistake and the inclusion changed the results significantly..... this on top of being told my \"results\" were not right when it didn't project good findings for the client. I ultimately refused and insisted that if my manager wants to submit the work they can do the modeling themselves and then lie to the client themselves...\nNormally whistleblowing is the best here but when I did that I was further harassed by management.  All the whistleblowing did demonstrate immoral behavior from the top down. Ultimately I was taken off the projects and basically paid to job search. I am in a much better role and dont think it will happen at my current company but, just wanted to see if oneone else has experienced something how would you manage it if it happened again.?",
  "Simple question, so many answers. I've been seeing so many startups with the potential to replace jobs with AI, what scares you?",
  "Hey,\n\nI'm not sure how to identify the said thing. Please let me know if anyone knows about it.\n\n&#x200B;\n\nThanks!",
  "Is anyone aware of an open-source package that can do anything like this? \n\nhttps://i.redd.it/4j3lp081phfa1.gif",
  "I know leetcode/stratascratch are both great to handle the coding side of things, but are there other sites/books/etc. that you found useful in preparing for interviews?",
  "Hi,\n\nHave a project where i have to predict certain currencies against another for next 3-6 months eg:\n\nCHF VS USD\n\nAUD VS USD\n\nAED VS USD\n\netc.\n\nSo far i have only seen the very short term forex trading ones LSTM etc albeit very briefly.\n\nDoes any algo also incorporates data such as from tradingeconomics com?\n\nWould be much grateful for any guidance or help.",
  "I'm trying to describe mathematically a strain pattern of a structure (civil engineering) that I analyzed with FEM.  I extracted a 'line' of mesh nodes from the fem analysis and found the constants for the approximation function f(x)  using lmfit (least squares) with python. I have 4 constants (a,b,d,f) and want to link those constants to geometrical properties of the structure. I already determined the value for 'b' and know that 'a' and 'd' are somewhat associated with one geometrical dimension. I have determined the geometrical parameters that influence on the strain and want to determine the value for the f(x) constants based on this geometrical dimensions. I have 35 different fem simulations, varying the geometrical dimensions of the structure.\n\nThe question for you guys is: is there a software where I can input the function (and its determined constants values obtained with the lest squares approximation) and the geometrical parameters from the structure and get some correlation? (like the 'a' constant from f(x) is 2/54\\* (geometrical dimension) ). Or a way that I can do it with python, perhaps. \n\n&#x200B;\n\n[here is the f\\(x\\) and  the 'b' value. ](https://preview.redd.it/zbwqxvajlgfa1.png?width=2600&format=png&auto=webp&v=enabled&s=abbbe836cc7993bf628ccb1eb50608a27a034d9d)\n\n[the 'b' value on the geometry. I have the g' value that I want to correlate with 'a' and 'd', and some other geometry dimensions \\(thickness, for example\\)](https://preview.redd.it/vksb0pucmgfa1.png?width=1516&format=png&auto=webp&v=enabled&s=64529de5c22271c8e30c6d574ceb2854930a4c71)\n\n&#x200B;\n\n[  This is one of my functions, and its approximation with the values of the constants \\(for the positive and negative values of z, as the function is not symmetrical\\).](https://preview.redd.it/u49k6cwfkgfa1.png?width=4000&format=png&auto=webp&v=enabled&s=145d3a87ab8bb44b86c34af4506243ef3f1bf320)\n\n&#x200B;\n\n[the report that I get from the lmfit analysis.](https://preview.redd.it/tdalnxnfkgfa1.png?width=678&format=png&auto=webp&v=enabled&s=9a1c03906a96e96e14fdd4f50844b4e7c5762f07)",
  "Go into as much or as little detail as you like! Interested to see how people's approaches differ.",
  "I\u2019m currently a year out from finishing my masters in computer science from a well regarded school, emphasis on software engineering. My background is in chemical engineering so a masters is useful for transitioning fields. I work as a test engineer in aerospace, which is giving me some exposure to software (matlab, labview, networked systems). My masters program has the option of taking an additional 6 courses (about a year part time) and letting me get a second masters in data science. Work would pay for it completely. Is it worth it to get the second masters? Or would a boot camp or online course be more worth my time and effort? I\u2019m not dead set on becoming a data scientist, but it would be nice to have the skills under my belt if a project needed it.",
  "Has anyone else noticed how much Yan LeCun has been hating on ChatGPT lately? I think it\u2019s one thing to call out issues, but I have a feeling he\u2019s trying to discredit it for business politics more than anything (Meta v. Microsoft)",
  "I am an incoming new grad Data Scientist and I recently got some of my admissions listed below. If cost is not a **primary** issue which of these programs are worth pursuing for someone who already has DS in undergrad?\n\n* My undergrad degree included a good amount of CS (like discrete math) /Stats (like statistical modeling or mathematical statistics) /Math courses (Calc 1/2 etc) and I had done 2 data science internships where I mostly did MLE, not Analytics, and worked with P.h.D Data Scientists.\n   * Although I feel like I don't know enough stats and I want to learn more to interpret models.\n* My main goal is to pursue MLE in any domain instead of analytics but open to DS, and analytics if companies prefer P.h.D's in the future (I am aware of the whole P.h.D's are much better than MS candidates and I witnessed that in my undergrad internships)\n   * However, I am very passionate about DS and want to become a better DS in the future, I did a lot of projects in my internships that consisted of utilizing advanced NLP and Traditional ML algorithms.\n\nI have U Chicago and U Penn on my top 2 as I met with the students in these programs and they are all in tech or fintech companies and doing great in their fields. And of course, I have a bias toward getting a top-10-ranked university degree. I have to do an online degree as I have a DS job lined up and I have to make money to live to support myself. Right now I am only thinking of waiting for U Penn's decision since it's cheaper.\n\n**Edit:** U Chicago also calls the admitted students to campus twice to meet with faculty and other students which I really value.\n\nDetails:\n\n|My Ranking #:|University Name:|Tuition - Scholarship|Decision:|Duration (Years):|Major:|Scholarship:|\n|:-|:-|:-|:-|:-|:-|:-|\n|1|U Chicago|52k|Admitted|1.5|MS DS (Analytics)|10k (Highest Possible)|\n|2|U Penn|34k|Waiting|2.5|MSE DS|0|\n|3|Northwestern|58k|Waiting|2|MS DS|0|\n|4|Notre Dame|58k|Admitted|2|MS DS|0|\n|5|GT|10k?|Admitted|2|DA|0|\n|6|UC San Diego|54k|Waiting|2|MS DS|0|\n|7|UT Austin|10k?|Waiting|2|MS DS|0|\n|8|Rice Uni.|50k|Waiting|2|MS DS|0|\n|9|Purdue|42k|Admitted|2|MS DS in Finance|0|\n|10|Johns Hopkins|50k|Admitted|2|MS DS|0|\n|11|UC Berkeley|75k !!!|Waiting|2|MIDS|0|\n\n&#x200B;",
  "Hey all,\n\n&#x200B;\n\nI'm in the process of clustering my companies customer base and wanted an opinion, at previous jobs, when I would build customer segmentations, I ran one cluster, did some EDA, and if everything looked good, would present it to the higher ups.\n\nHowever, for the new segmentation, I'm wanting to cluster based on engagement (sales totals, basket size, etc.) and on behavior (so product interaction like 'bought family products, etc.). My thought was to build two models, one with engagement metrics and then the other with the behavior indicators. \n\nI'm curious if this would be the right way to go about it. Thoughts?",
  "Basically I got a job as a data / pricing analyst and to be honest, there's about 1-2 hours of actual work most days, and the rest is chill time. I kind of feel and feel like there's something productive I should be doing to \"get ahead in my career\" or give me advantages in terms of a future data science / project manager / business analyst role or something, like maybe machine learning courses online, etc. Idfk. Was looking for some tips",
  "preferably in transportation analysis but otherwise domains will do.  i interested in learning more about this side of DS as i have little experience working in network analysis. like a preview into the real world, i want to be faced with problem solving network analysis projects.",
  "I am trying to create a brand new data system for my company. I managed to create Python scripts that pulls data from APIs, wrangle them into a Pandas DataFrame, and export them into an Excel file. We are trying to do this process automatically daily on the cloud, store them in BigQuery, and display them in Data Studio.\n\nThis is the system that I have in mind. I put the scripts on Cloud Functions, but instead of export them into excel files, I use pandas\\_gbq to store them to BigQuery. For the cron jobs, I use Cloud Scheduler to trigger the scripts on the Cloud Functions by sending HTTP requests. What do you think of this system?",
  "Perhaps I am alone in the walled garden that I\u2019m forced to work in.  I do population health analysis of approximately 100,000 lines of varying data.  The nightmare of my life is that I cannot use any scripting.  No python, r, macro-enabled workbooks.  For visualization,  can\u2019t upload to anything as it\u2019s protected health information.  No Tableau, no online SQL database, no power BI.  All I can use is Power query/pivot.  \n\nI admit, I can adapt and overcome with being hamstrung like this.  However as the data grows, Excel is starting to give out on me.  I\u2019m looking to see if anyone has methods that they use to clean data and present basic visualizations outside of excel.",
  "Has anyone gone through the Oregon State University ONLINE Masters of Data Analytics program? Tuition for this program is partially covered by employer, and I am interested in enrolling. Thank you in advance for any info you can provide. \n\nI'm trying to compare this degree with MBA from Purdue Global which has a Data Analytics concentration. \n\nWas the instruction high quality, and would you say the time and effort was worth it? Are there a bunch of exams you need to cram for? Is it a degree mill? \n\nWere people able to secure jobs or promotions in Data Analytics or engineering with this program? \n\nI currently work as a software developer full-time and am looking for a shift into Data Analyst or Product Manager positions.",
  "Hola,\n\nI'm currently working with a dataset and I'm trying to build a model to predict the cost of a transaction based on 9 different attributes, one of them is a date column (timestamp), but there are quite a lot of observations registered at the same time (exact same timestamp), but these observations are unique.\n\nHow should I handle this data to create visualizations over time and feed the ML model?\n\nThanks in advance!",
  "\n\nWhat do you know about KNIME? Do you use it?\n\nShould I learn KNIME for analyze data or better PYTHON?\n\nI normally use EXCEL, but now I have to analyze files with more than 1mil rows and excel doesn't work properly.",
  "Tried finding something like this on the FAQ, but didn\u2019t see anything written out. I\u2019d like to have a discussion about what sort of projects hiring managers want to see. Obviously, real world projects are going to be more desirable, but in some cases this isn\u2019t possible. Or at least, in my case. I wasn\u2019t ever able to take home artifacts (dashboards, slides, notebooks, etc.) from my previous work, as it was sensitive data. The only other projects I have are just college ones, which were less impressive Kaggle problems. My current role is data scientist by title but our ML projects just keep getting delayed for other things, so no work there. \n\nSo, that leaves me to building out a portfolio of personal projects.\n\nWhat do people in the space want to see?\n\nWhat\u2019s interesting to me personally, is being able to look back at my college problems and examine why my approach was incorrect using my real-world knowledge. So a good project might be using the same dataset and methods, with a write-up of how to improve it.\n\nOtherwise, I\u2019d just want to do some projects that seem fun to me.\n\nSo hiring managers, or senior roles, what are the best projects that you\u2019ve seen someone talk about in an interview?",
  "However, where i live there isn't a degree that has both, so i have to choose between a bachelor's degree in cs or economics. Which one should i pick ?",
  "As a PhD student using big data, my pipelines are mostly done locally. What is your setup? For example, what libraries do you use in Python? Do you use Docker/Kubernetes? What cloud services do you typically use?",
  "Hey, I wonder if anybody has experience using transformer models to forecast demand/sales in an e-commerce setting. Some questions in this regard:\n\n&#x200B;\n\n* Did you observe superior performance to classic ml-algorithms?\n* Any tips when applying transformers for time-series data?\n* How computationally expensive where they compared to classic algorithms?\n* Would you recommend using such models for demand forecasts?\n\n&#x200B;\n\nThank you for any shared thoughts, resources, articles or threads!",
  "Is there a way to find the variance of drawing only spades from a well shuffled deck of 52 cards? Or the variance of drawing only red cards from a deck?\n\nContext: I am trying to build a probability model of a card game where drawing a suite (spades/clubs) will earn the player $5, and I need to find the standard deviation of the winnings.",
  "Hey guys,\n\nSo I used to use Spotfire at work mainly because it was the standard in my previous company, and it also has so much flexibility with the design (can use HTML, CSS, JAVASCRIPT and customize visuals)\n\nNow I\u2019m back in grad school, and tryna make my own dashboards. What software do you all recommend that I wouldn\u2019t have to pay $$$ for like spotfire?\nPreferably something that can you create nice designs with, ML models, and similar to spotfire?",
  "Dear Folks,\n\n I am working a BI Engineer and have a decent working knowledge in SQL (intermediate), Tableau(basic), Snowflake(very basic), Informatica/ AWS(almost nil since contractors do the Data warehousing and ETL, Data laking etc). The higher management plans to train us in expertise so contractors can be tapered off in few months. What coursework/certification  courses links do you strongly suggest that can help me truly be expert in my role?",
  "Idk why so many people who get a job with \"data\" in its title think that the world awaits for their biography and advice. Its even worse that most of these people just want for an excuse to humblebrag. Even when thats not the case, the actual advice is almost always without substance. I dont want to hear for the n-th time how you worked on \"real problems\" or how you studied \"smart not hard\". \n\n Why theres this culture? Other fields are competitive too and rarely you see this bs",
  "Hello everyone, \n\ni'm training a multi-class classification model  and I would like to ask the following question:\n\nAssuming the model should differentiate between 10 variations (A to J), if A and B are similar (or whatever letters), then how can I somehow give a bias to the model to take that into consideration ? Currently, I am doing a \"hot zone\" in the confusion chart, so that the user knows to take these results with a grain of salt. \n\nAny hints would be appreciated!\n\nP.S: programming language doesn't matter even a math wikipedia page would be nice!",
  "I\u2019m currently a CS student, I love DS but I also love having flexibility with my work space, so I would love to work from home and be able to travel around from time to time. I also want to start making money on the side, so I want to start freelancing on Upwork doing DS. It seems like it\u2019s kinda a difficult field to get into when you\u2019re first starting out. \n\nIs there any of you that can share their experience working as a DS freelancer or having a data related remote job?\n\nGetting some perspective would really help me. Thanks!!",
  "Hi, I am a recent university undergrad from Toronto, Canada. I didn\u2019t graduate from a STEM program but I developed an interest in data and I am wondering if I have potential to get into data science as a career without having to go back to substantial full-time studies. \n\nI have a BA in urban studies (liberal arts with a focus on urban issues, my studies were human geography focused) and minored in applied statistics. \n\nIn applied statistics courses, I learned a lot of basic statistical analyses types and how to interpret results from them (eg. linear regression, factor analysis, cluster analysis, etc). I also worked with a bit of quantitative data in my geography courses (map data, census data)\n\nRegarding technical skills, I have pretty good knowledge of R and Rstudio. I used it for 3 courses in university and some other assignments. Does it help to also say I understand latex?\n\nAs for programming skills, I have the most barebones knowledge of python. I understand basic programming concepts (variables,loops,ifs,functions,etc) can make a simple flask application.\n\nI don\u2019t have the greatest math skills. I struggled in grade 11 functions/algebra and my only grade 12 math was data management.\n\nHow should I market my existing skills and where do I need to improve?",
  "Good morning everyone.  I am in need of help with my Data Science project for the completion of my course.  I'm in need of themes (I can't think of anything), a problem that needs to be solved and a set of data (dataset/database) for me to work on. \n\nPlease folks help me!!",
  "Company did layoffs, great culture now feels weird and secretive. Seems like our \u2018charter\u2019 is going to change and they aren\u2019t telling us yet, just like cryptic messages and stalling of salary updates. Some concern of \u2018finish this up so you can get canned too\u2019.  Haven\u2019t been in a layoff company before, anyone have some encouraging words here (have started looking for a new job as a fallback).",
  "Hi, I'm hoping someone with more experience can give me some advice on my DS career, which I'm at a bit of a crossroads with. \n\nFor some background - I have a PhD during which I learned about data analysis, visualisation, statistics, and R. Since receiving my PhD I've had two analyst roles where I've found my knowledge of R and statistics have left me feeling a little overqualified/not having good enough data to do 'proper' analysis work. \n\nLast year I started an entry-level DS position. I got the job because I have domain expertise and good proficiency in R, which is the language of choice where I work. The job is well paid, comfortable (I'm able to WFH) and I find the work mostly interesting. \n\nMy issue is this: I still feel like a glorified data analyst. There aren't really opportunities for ML (the thing that - possibly incorrectly - I most associate with DS), and I feel like experience with ML in a workplace setting is needed for possible next steps in my career. At the same time, I enjoy analysis and I'm not sure I'd find designing and tuning models full time particularly satisfying. \n\nI suppose my question is what direction can I go in/skills can I learn to continue to develop my analysis skills, and what types of senior roles support this. It feels from job adverts that Senior/Lead Data Scientists are primarily concerned with pipelines and models etc, rather than working with stakeholders. Interested to hear other people's experiences if any of this sounds familiar to anyone.",
  "Hi Folks, Please suggest a use case for 'Leak Detection' in steam trap through acoustics.. Python implementation will be helpful.. Thanks in anticipation...",
  "Hello Everyone,\n\nRecently I got an email for an Interview which requires me to give a 90 mins coding test for Full Time Analytics Data Science Associate at JP Morgan. I want to know what coding questions can I expect. Has anyone given the coding test recently? The coding test is in the platform Codevue. Any lead will be appreciated.",
  "This medium article is a summary of the paper ChatGPT is not all you need where you can find a review of generative AI models. [https://medium.com/@eduardogarrido90/chatgpt-is-not-all-you-need-a-quick-summary-of-the-generative-ai-taxonomy-e2b8b47a9851](https://medium.com/@eduardogarrido90/chatgpt-is-not-all-you-need-a-quick-summary-of-the-generative-ai-taxonomy-e2b8b47a9851) Enjoy!",
  "Is there a Discord/Mastodon/Slack/Meetup/whatever for data scientists/analysts working remotely? Preferably for people that live in a small city to a rural area.",
  "I recently finished my first year in university for Data Science and completed an internship for data analysis over the holidays. I would like to gain some experience and work online on projects, not solely for the money but also to earn some extra cash.\n\nI am a beginner in the field, and I was thinking of researching the most in-demand skills on Upwork and learning them. For example, scraping data from a real estate website to predict prices. I plan to practice these skills using online data until I feel confident in my abilities then get started applying for jobs on Upwork. I also am considering cold calling local businesses.\n\nIs any of this a good approach? If not, could you suggest a better plan? Please be radically transparent.\n\nI posted this on r/careeradvice and got no comments, so I thought this would be the place to go.\n\ntldr: finished first year university/college (data science) and would like to get started freelancing, where do I start?",
  "\nI was wondering if anyone here is familiar with the written by Dr Tony Van Gestel and Bart Baesens?  It is supposed to be a series of 3 books (1st one being credit risk management: basic concepts) but I can't seems to find anywhere the other 2 books.... Can't even find a title for them on Google.\n\nAnyone came across something similar?",
  "When you're at an interview and they ask if you have any questions, which ones do you usually ask? I ask about the work environment and the workplace culture, and typically why the individual I'm speaking with wanted to work there, if they haven't already told me. Which ones do you ask?",
  "I am an incoming MS student deciding between programs. For my dream job, I definitely would prefer quantitative-heavy positions such as machine learning engineer or quantitative analyst as opposed to BI developer or data engineer. \n\nEliminate factors such as institutional prestige, cost or alumni network, and simply look at statistics vs. data science. Which curriculum gets me the most advantage in early career? If you have picked up one degree over the other, can you share whether it worked in your favor?",
  "I am working on a demand forecasting problem for an FMCG company and I was wondering how I should use the product price as a feature in my ML model. For some products, the price doesn't change much and is more like a step variable than a continuous one. How should I capture the effects of price change on the change in demand? Should I take the absolute values of price or delta values? Or any other feature engineering technique?\n\nNote: The timestamps are monthly and I have other features about product category and distribution hierarchies.",
  "I am already working for a startup. Things are good and only problem I have is there is no senior to guide me. I was handling all the tasks so far and I was really putting my soul in thr solution by finding the best possible solution online and applying it.  \n\nI had this interview today. It is one of the most prestigious banks in my country.  Tbh questions were pretty basic. And i failed to answer them througly since i havent used them. what made me happy is I almost did it. All the questions asked were thr things that bothet my mind and i was looking for a chance to actually deal with them during real projects. Not just reading about them. Because there is a lot on my plate rn. (non CS background ) \n\nI realized I was stressed out at first but then I realized i really enjoy the questions. This is a first for me. I really enjoy this field and working feels like solving puzzles. I just wanted to share this. I am already feeling too old (29m) but I like that i am sure this is what i would like to do.",
  "I have a huge dataset with more than 100k rows and 30+ variables. \n\nA lot of articles online mention that the optimal value of K is sqrt(n) where n is the number of samples the model is trained on. \n\nIs that the best value of k? A high k value also makes computation harder and takes a longer time. Is there another way to find the optimal k ?",
  "&#x200B;\n\nhttps://preview.redd.it/pzmy5m9yp5fa1.png?width=660&format=png&auto=webp&v=enabled&s=b4d2ced783a21fd3bc0aca2a421dee490631bd44",
  "Hello,\n\nI'm currently working as a data science staff on a rather small startup company for 2 years now. Considering our size, I've been making several analytical dashboards that helps both operational and marketing team. I've been doing lots of data viz (mostly in echart), analyzing data in SQL (mostly Postgres), and building automation in fetching and doing said analyses (mostly in Airflow).\n\nI used to study in machine learning during my uni time, but it's been quite a while and I felt my AI knowledge has been rusty. I'm looking to improve my skills in data science or AI related field hopefully to advance my career, and also helping me in landing job in bigger company.\n\nDoes anyone have recommendation for some courses, possibly those that ties with certification at the end of the course?\n\n&#x200B;\n\nThanks for any suggestions given",
  "The question states it. Will developers (lets say people who write Java apps) be automated/lose a lot of jobs, because of automation before Data Scientists/ People who build prediction/inferral models. Essentially, which is easier to automated writing efficient code that solves a problem or the intuition/stats skills. I do not want to say it but I think AI will learn Stats more quickly than how to write sophisticated code. What do you think? If that is the case what skills in Data Science will be automated last.",
  "Weird question, but is it hypothetically okay to post about a rescinded job offer if the company is well-known compared to your current industry experience?\n\nEg, if you are an early career data scientist fresh out of school, and you place into Google. Then due to current economic conditions, your offer was rescinded. I imagine the mere act of being accepted by Google is something you might want on your resume, especially if you don\u2019t have any significant experience before. Not sure though.\n\nAny thoughts?\n\n(Yes, this is hypothetical but the question might be pertinent to others right now!)",
  "I check reddit once a day, and almost always i see a similar post here. \n\nI was wondering, what about other industries, are they experiencing the same level of panic, like graphic designers, video editors, copywriters, administrative assistants? Or it is just here, where the evil is sort of the offspring of the industry?",
  "I am in 2nd year of Phd in CS. Although i have some time.  i want to transition to data science eventually in the industry after I graduate with my phd. My research interests are NLP + Computer Archietecture. What can i do currentlly (any courses etc) to eventually smoothen my transition to data science industry.. I am proficent in python and statistics",
  "I\u2019m interviewing with them tomorrow for an analytics position and would like to know about the culture, work load and growth of the business.",
  "I\u2019m feeling so lost here guys. Back in the spring I signed up for Merit America\u2019s Data Analyst program and finished in November. I\u2019ve been putting out applications like crazy and not a word back on anything.\n\nOn one hand this part isn\u2019t a shock, it lines up with everything I\u2019ve been told about what to expect. But somehow I\u2019m still losing my mind here. \n\nAll I ever wanted was a job that pays well and that I can get out of bed in the morning for. Data seemed great. I guess I was naive because I wasn\u2019t expecting all this added career development networking LinkedIn bs to be a part of it. \n\nI see people on Reddit saying that I\u2019m probably not going to get a data job first thing, on account of zero experience. No, you have to \u201cget your foot in the door\u201d doing god knows what else in some other job and hope you can spend enough time looking at a spreadsheet to put it on your resume using flowery hyperbolic marketing horse s. What other job am I supposed to apply for? I\u2019m in data because I don\u2019t have any other skills! This was my last god forsaken hope. \n\nI don\u2019t know what I\u2019m supposed to do. Career development is so f\u2019d. I don\u2019t care about any of this, I just need money and to not spend 40 hrs a week wishing I was unconscious. Why is this so hard.",
  "I also asked this on math.stackexchange.com but they said should better ask my question in this section.\n\nI have a review system and I stumble over the fact that I want to make a fair ranking and not just the average. The average is allready calculated but when you are sorting on this average the results are not fair.\n\nEXAMPLE:\n\nCompany A has an average score of 4.8 based on 5 reviews. Company B has an average score of 4.7 based on 43 reviews.\n\nIf you rank on average score Company A is above Company B in ranking but it ain't fair because it is a lot harder to get a 4.7 based on 43 reviews.\n\nI want to create a number that is based on the average review score and the number of reviews that are submitted.\n\nMaybe I am wrong here for asking this question but what is the best formula to create such an average and wich values do I need for creating this?\n\nI am developing in PHP if this should be important for you to know.\n\nI allready found something like this based on the bayesian average, is this Something that I should use?",
  " Should you standardize data before applying a transformation like adstock? Or after?",
  "In beta version, two json files are automatically matched\n\nTo gain access you need to follow the links on the website or contact me.\n\nLet me briefly remind you of what we do.  \n**Why do we need it?**\n\nOur system comes in handy for reducing the cost of docking systems and subsystems produced by different people and teams. Here are only some of the tasks which can be solved in automatic mode almost without human involvement (we also do not use neural networks):\n\n\\- combining similar data from heterogeneous sources in MDM systems\n\n\\- automatic integration of systems\n\n\\- searching for similar or related texts in text arrays\n\n\\- data cleaning from misprints, by dictionaries, etc.\n\n**What does it give?**\n\nWe save you time of experts when matching data at the level of specific fields (mapping), our system can do it automatically and without significant cost of computer power, training neural networks and the like.",
  "Hi everyone, I am an international student and  I'm planning to join the online MIDS (Master of Information and Data Science) program provided by UC Berkeley. I was wondering if doing the course online with no F1 visa would make it harder to land a job in USA? Or if I should do an in person masters in usa (in another university) since that would be comparatively easier to get a job?",
  "Hi guys !\n\nI would like to get some feedback on a video that I made to showcase a personal project. The video is subtitled in both English and French, and the source code repository is available in the description. (Don't mind my French accent, what I'm saying is what's interesting)\n\nPositive or negative feedback is appreciated !\n\n[GitHub link](https://github.com/EbonGit/Epidemic_Regression_Model)",
  "I work in marketing and report sales data on a weekly basis. \n\nSo far, I've been finding out new items to report on by fiddling on Excel. I report on things like:\n\n- the day with most sales\n- proportion of item sales volume compared to overall sales volume\n- finding relevant news to speculate on correlation to sales\n\n\nSince I'd like to find more sales insights, I was wondering what else I can learn.\n\nI should probably improve upon:\n\n- theoretical knowledge on business data analysis, to find more items to report on\n- using Python for data reports\n\nI have used Python in the past and am rather comfortable with it. I think it might be better to transition to Python as Excel is not performant with high amounts of data.\n\n**Q:** Please let me know what topics and resources I should explore.",
  "Any pre-req skills you\u2019d recommend one have?",
  "Hi all!\nI have a dataset composed of sensors (time series) and other data that is fixed and represent kind of domain knowledge (let\u2019s say as example data of the soil composition, but also other).\n\nWhat state of the art methods do you know to combine these two different types of data? Or is there any type of standard method used only on time series that is used as standard and is possible to extend?\n\nThe final goal is to recognize the anomaly earlier than its occurrence",
  "Those of you who've used `sklearn.metrics.classification_report` will know what I'm talking about, but the function prints the class name, precision, recall, f1-score, and support. This function builds on top of `sklearn.metrics.precision_recall_f1_support` but I'm wondering why only support is taken into consideration and not the number of predictions.\n\nIn my job I often find it useful to tune my models or preprocessing according to how many times the model has made a prediction for each class. The current functions don't support that. I've made small changes so that it does but I'm wondering if it's convention or something to only care about support.",
  "Looking for any suggestions. I have a dataset of a few hundred thousand records and need to use some features to properly map to another column (classification) but the column has over 1000 possibilities. Was curious if there is any sort of rules engine that could generate rules based on a few features or if I should just stick with something like a random forest or decision tree. \n\nWill also add that most features are text as is the target column, so maybe there could be something in the NLP space.",
  "I'm a little more than a year into my first data analyst job and recently graduated with an MS in Data Science. The program was great and I feel comfortable saying that I'm probably at about an intermediate level given my degree and work experience. However, I'll also say that while the program gave me a good understanding of a lot of different subdomains of the field, it didn't necessarily allow me to become an expert in one particular subject matter. \n\nI know a big part of being successful in this field is research, continuous education, and being aware of new technology and advancements in the field. I'm looking into subscribing to an online education platform and wanted to know A) is this common for someone of my level? and B) what platforms should I look into? \n\nFor context, I have experience with all of the major names - DataCamp, Dataquest, Udacity, Udemy, and Coursera. I get the impression that the first three I named are geared much more towards beginners and probably aren't necessary for me. I like Udemy for the ability to buy classes on demand and keep them for life though I feel like some classes can be hit or miss. Coursera Plus is on the pricier side ($200 a year), but getting access to classes by college level professors could be beneficial. \n\nJust wanted to throw this out there and ask if there's other platforms or educators I should be looking into. Thanks!",
  "I haven't touched excel in years \n\nI prefer to use google sheets because:\n\n1. It's collaborative through your Google account\n2. Free\n3. I don't often/ never have to use the advanced functions of Excel\n\nWhat about you guys?",
  "I will be interviewed for an Insurtech. They will send me a case, give 4 days to solve it and after interview me for 1h hour to discuss it\n\nConsidering the position and linkedin of the interviewers I expect some modelling. Possibly a GLM (standard in insurance) vs ML, etc\n\nAnyway, but rather than that what more should I expect? Also, where can I prepare for it?\n\nI was already looking for some material that people use for case interviews in consulting companies and they seemed really interesting with the approach and reasoning thinking for solving the problems. But I don\u2019t know if it is the right resource for a case interview in DS",
  "I came across a few videos of Mike West on YouTube and he seems to give realistic advice about the DS job market. I've been thinking about signing up for his courses on his website called Logikbot.\n\nIt's $50 for 3 months and he has a bunch of courses on the website. He keeps talking about how most ML jobs are just SQL and Python - I am unable to judge how true this is because I have zero exposure to the field.\n\nI haven't been able to find any reviews on Mike West or Logikbot. Does anyone here have any idea if this is a reliable guy and would you recommend signing up for his courses?",
  "I\u2019ve been working as a data scientist for over a year and will soon start a new role as an ML engineer. \n\nMy background is in mathematics and so far I\u2019ve been focusing on learning the fundamentals of ML, CV, NLP to a reasonable standard. Also have used AWS and Azure a bit.\n\nMy main problem is I have no idea how to use GitHub or how to deploy a model to production. Not sure if there is anything else I show be learning too like computer science fundamentals. \n\nPlease can you recommend topics and resources for what you think I should be learning next? Thank you.",
  "Hi, it\u2019s my first time posting here and just really curious. I\u2019m currently in my final year of my master\u2019s in computer science. And I intend to work full-time as soon as I graduate. I am hoping for a data analyst or data science or machine learning researcher position. However, I still feel inexperienced tho. The only things I got to show on my resume are: 1) a data analyst internship at an insurance company, 2) some research projects that involve analysis of large datasets and use of machine learning and deep learning models (with publications to journals and conferences), and 3) my master\u2019s thesis.\n\nSo now I am on the hunt for jobs, and idk how much (average) salary I should be expecting (other than the baseline from my previous internship job). I fear that I might find an offer that will pay very little and then I\u2019ll accept because I don\u2019t know the numbers. Would anybody be able to give a rough ballpark of how much these positions usually pay? I\u2019m hoping to get into an entry-level (or new grad program) first, since it\u2019ll be my very first full-time stable job. Currently living in Canada and idk how much salaries compare with that of US.\n\nAlso, just to give context, I started right away with my master\u2019s right after graduating from my undergraduate, as I felt the need for a stronger education background before coming into the field (was also pandemic times when I graduated so it was just tough to find jobs then).\n\nAnd any advice you could give for a noobie? It would be appreciated. Thanks!",
  "Hi there, I am buying a laptop for personal needs as I want to work on data science projects and ML tasks privately (with an aim to become a freelancer in the future, so I need something durable).\n\nAt work I use HP Probook 440 with 11th gen Intel and integrated graphics.\n\nPrivately, I wanna be sure that my laptop will last for many years.\n\nWould you be so kind and share what are you using and how satisfied are you?",
  "Hello. relatively new data scientist here. I was recently trying to see how to build a model in my situation.\n\nBasically I have a bus data of past five years that run regularly each day, and bus has all kinds of information including (# of passengers per hour, revenue earned, origin, destination, etc). Then we wanted to increase the frequency of buses running in preparation for some upcoming festivals during this weekend in the regionsome time late 2023. \n\n1. The question is I need to figure out how many additional riders this additional services (increasing bus frequency) will bring and I was having hard time predicting/figuring out how. \n2. Instead of additional bus frequency, let's say we introduce additional taxi boats to take people to the festival, then given two different modes of transportation happening (bus and taxi boat), how do I create a collective model around it? I also have past five years of taxi boat usage data.\n\nAny help/advice on how I should approach (or some kind of model I should use, Bayes?) this appreciated because I was thinking all day and a bit stuck. Was thinking of doing some blunt estimated simple math but wans't sure if that's even accurate. Figuring out the effect of what happens when something happens has been challenging.",
  "I was offered to work on a project as a freelancer/independent contractor. I'm having trouble coming up with the pay rate. \n\nThe project involved a dataset of 8k rows x 351 columns of data. I'm supposed to structure this data set differently to fit a Salesforce template they have. This would increase the rows by about 3x, but reduce the columns to about 50. They told me they would consider doing this manually, but they know that it can be done with a python script (which is where I come in). \n\nI have no idea how long this is gonna take me, since the data is pretty sensitive & old. It goes back to 17 years and it seems to be poorly maintained. \n\nAnyone have any idea on how I can start pricing this? Or suggestions/things to consider? TIA.",
  "\u201cMan made machines make music for the man\n\nNow machines make music while the man makes plans\n\nA second generation a generation lost\n\nWhile the man prepares for the holocaust\n\nMan made machines to control the days\n\nNow machines control while the man obeys\n\nA second generation a generation lost\n\nWhile machines prepare for the holocaust\u201d\n\nA Flock of Seagulls, Man Made\n\nSongwriters: Alister James Score / Francis Maudsley / Michael Score / Paul E Reynolds\n\n1982\n\nhttps://m.youtube.com/watch?v=sTk4jz9OBhI\n\nSeems apropos with all the spam about generative models to reflect on them through the art most of y\u2019all would rather let them make instead of letting humans make.",
  "Hi All,\n\nPlease note that I have googled this, but want practical advice from real people who work in this industry.\n\nI'm working on a project that involves a lot of exploratory analysis with regards to a specific dataset. Currently, I am using a local instance of Jupyter Lab (the desktop GUI) to write my code in Python and work with the data. I love that Jupyter allows you to organize your code into cells, but I feel it doesn't go far enough. I'd love a similar tool with one or more of the following features:\n\n1. **Creating \"Projects\"** for organizing my work.\n2. **Cataloging and \"typing\" Cells** \\- Ability to save \"cells\" as functional units (or steps) and save/share them for reuse. Cells would accept certain inputs and provide certain outputs.\n3. **Creating workflows** \\- I'd like to - for a given project - stitch multiple of the above-mentioned cells together to create standard workflows for various data science tasks, and ultimately arrange 1 or more workflows to run in parallel, combine output, feed into other workflows, etc.\n4. **Defining / cataloging data sources** \n5. **Automate various workflows (tasks)**\n6. **Is Open Source and/or free.**\n\nI have to imagine that a tool like this exists - something that allows you to graphically arrange, monitor, schedule and/or run the code you write. I've used RapidMiner before, and while this was basically what I'm looking for, I would prefer an open-source (or at least low-cost) alternative (I am using this for personal projects to learn for my future career).\n\nThanks!",
  "My best friend has a new job and was asked which laptop she want to have for her data science job.\nShe has to deal with a lot of data, but also has to hold presentations and the laptop shouldn\u2019t be too thick, so preferably in ultrabook style.\n\nThe price range is up to ~3200$.\n\nWhich one would you recommend? \ud83d\ude0a\ud83d\ude0a\n\nShe is a windows user but has an iphone, so open to mac, but some software she is using like SAS is not optimized for mac, she said.",
  "For context, I work in a medium-large financial org (2-3k employees), and have the \"privilege\" of being the first data scientist at the company. We have an 8 person data team for reports, dashboards etc but no DS. I'm looking for any advice from people on\n\n\\-Identifying/gathering use cases\n\n\\-Establishing DS culture\n\n\\-Documenting and governing models \n\n\\-Building a team, creating standards, etc\n\nReally just looking for any advice or guidance that could help me in this journey\n\nI've been in this role over a year now, and we have had great success with some smaller use cases and poc's , but its time to roll out an org-wide program and just struggling for direction. Open to blogs/articles/books etc that people think could be helpful too",
  "Hi all. I apologize if this is not meant for this page but I am pretty lost. I am trying to switch careers and move into the data sphere, and boy is it tough. I started a course on coursera and have been a bit disappointed in the instruction so far. I would have posted on the discussion forum but no one responds so figured I\u2019d take it here. I guess my post has two intentions:\n\n1. Does anyone have good experience with coursera courses that do a good job teaching some different languages from scratch? \n\n2. I haven\u2019t yet been able to figure out how to get a combined total of a count. \n\nLet me give the example - they are asking us to list the cities with the most reviews. The data they have provided gives review_count and city columns. When I write \n\nSelect city, review_count \nFrom business \n\nI get 10,000 rows back, and there are multiple rows with the same city. How do I get one count of how many reviews come from each city. \n\nTIA",
  "Hi, I\u2019m trying to do conjoint analysis and bot sure what to do with duplicate cases. Assume that the different respondents were presented with the same product type and they ranked similarly. So it seems that except the ID the rest is the same. I know that I need to remove ID column but after I\u2019ll have duplicate rows. What should I do with them?",
  "Hey, I want to persue a data science career, I just graduated and have been having trouble landing a data science job however I just got a buisness analyst offer from GM, would a future data science job value a buisness analyst experience? should I take it or keep trying for data science? Its been 3-4 months and Im not in hurry since im currently on a internship but still I don\u2019t want it to be another 4 months,  probaly around 4 months more and I would take anything. Appreciate every opinion, thanks!\n\nEdit: Important part I studied engineer on data science and mathematics",
  "Yo first up I am sorry for YACGPTT (yet another Chat GPT Thread). This is a question about leaning resources.\n\nFor some context I did the Coursera NLP Cert a few years ago and really enjoyed it. And it does, in very good detail, hit on the nuts and bolts of manually coding transformer architecture (the \u2018T\u2019) . \n\nBut like I said it\u2019s a few years old and I\u2019m looking for resources on the combination of reinforcement learning + transformer architecture.\n\nAgain,  but nuts and bolts I mean code heavy manual demonstrations of how to construct the architecture.\n\nThanks in advance and if you think I should delete and post in r/learnmachinelearning I will do.",
  "Hello all. I have an interview for a job coming and I just wanted to check and see if anyone was familiar with the role of a Data Integration Manager(U.S.). The job posting wasn\u2019t the clearest on exactly what hat they do and so far I\u2019ve seen a lot of different explanations of what the role is so I\u2019m wondering if it\u2019s just a catch all term. Anyone every hear of it? If so what do they do?",
  "Hello r/Datascience!  \n\nI work at a small Midwestern College outside of Chicago as a Research Analyst in the Office of Institutional Research and Effectiveness.  There\u2019s a grand total of two of us in the IR Office, and the other \u2013 my boss \u2013 is an economist by training, traditional OLS methodology.  We get along well. However, he doesn\u2019t know R or Python and does not involve himself in much modeling at all \u2013 no time with other duties.   \n\nIn the Summer of 2021 I completed my MS in DS and the powers that be here (my boss, our VP and our President) have been asking us to do some enrollment projections using some modeling techniques outside of what has \u201ctraditionally\u201d been done by our office. \nSo, using R, the Tidyverse and Tidymodels I developed a set of models:\n\n* A penalized LogReg model\n* A Random Forest model\n* An XGBoost model\n* A MARS model\n\nThey all seem to perform well on both the training, test, and holdout sets, so I\u2019m considering making something actionable out of them.  I would normally just throw together a Shiny app and call it a day.  That\u2019s easy.  However, I know that we\u2019re going to move towards Tableau and we already have a BI application on campus.  \n\nI feel like my education and Googling skills have failed me because I cannot for the life of me figure out how to take a model and \u201chand it off\u201d to a developer?  What happens if I want to roll a model into a custom application?  Or into Tableau?  Is it possible to \u201ctranslate\u201d these models into pseudo code that I can give to a developer for translation into say C++?\n\nI\u2019m on my own here, and don\u2019t have any infrastructure to speak of outside of my laptop and a ShinyApps.IO account, and I don\u2019t think I could win the fight for budget dollars for something like Docker.  Plus I don't really know how to use Docker anyway.\n\nIs anyone in a similar situation? What have you found to be the best course of action in solo environment?",
  " \n\nWelcome to this week's entering & transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&restrict_sr=1&sort=new).",
  "I have been a data analyst in a medium-sized healthcare organization for two years now. There\u2019s rumors going around that I will be one of the few people they are going to lay off. I figure that it is about time for me to move on and learn something new anyway. I am wondering if there\u2019s any fun industry from your experience. Working in healthcare organization for me was alright, i wish there\u2019s a bit more flexibility. We also use Power Bi and I am getting tired of this dead brain application. I am not learning anything new beyond power bi. I\u2019ve seen other data analyst position where they use tableau or python panda. I am curious to see how those tools work. \n\nGot any suggestions? I would love to hear your experience.",
  "around 3 years ago I was trying to make a TTS AI model, I got the entire dataset, audio voice lines, transcript, the whole thing, I had everything setup in Python and I was using linux.\n\nThe issue was I had a GTX 1080 and I wasn't using any cloud services to train the Model, it would take me around 2 weeks of non-stop computing to get it to work, So I was stuck with experimenting doing it a few hours at a time.\n\nSo now I want to actually do it for real, however the Friend that was a python expert helping me, we are no longer in contact, and I do not know jack about Python or coding.\n\nSo Redditors, Please tell me what I can do to take my Dataset/WaveRNN thingy that I have setup both on my Windows PC or my Linux PC, and how do I use Microsoft/Nvidia cloud computing to train my TTS model within hours instead of weeks?\n\nThe Final product I am aiming for is:\n\nMe writing Text into a promt, and it will generate a TTS voice just like the voice I am trying to make, and eventually be able to use it on Twitch.tv for fun or in-game.\n\nIt would be similar to how Twitch Streamer Forsen uses multiple different TTS voices.\n\nThanks in advance\n\nhttps://github.com/dipjyoti92/SC-WaveRNN This is what i Used",
  "Yesterday I finished Google Data Analyst Certificate, yeah for me.\n\nAlas, I know that it's just the beginning and not the end.\n\nThe scope of this journey is to level up at my job (ops/administration heavy on spreadsheet-based data) and possibly pivot my career into Data Analysis.\n\nI know that the Future is rich in both SQL and Python, but which one first and how to tackle it?\n\nI was thinking about doing [DataCamp's Data Scientist with Python](https://www.datacamp.com/tracks/data-scientist-with-python) and - at the same time - doing some projects to apply my Python learning and learning some SQL *on the job* so to speak.  I can also do the https://www.datacamp.com/tracks/sql-fundamentals.\n\nI have already purchased the DataCamp membership with their 50% off sale, so there's that sunk cost.\n\nAny feedback will be appreciated.\n\nTIA",
  "Hey, DS gang. I have to vent a bit and ask for advice/opinions. I'm a DS in a mid-sized company, and I find myself in a situation where I want to quit my job like today. I already have an offer and am interviewing with multiple other companies, and things are going well on that account. \n\nAt home, I'm taking care of someone who needs around the clock supervision, and I do have help with this, so I'm able to work with minor interruptions during the day. But my company has been working me to the bone the last few months, and I have a deadline for a project that involves a new large source of revenue for the company. I do want to get them over the finish line with this, but I really don't want to spend any more time than that. I feel exhausted. \n\nI also live in a medium-sized city, and so everyone knows everyone in the tech field here. \n\nGiven all that, in terms of a one week notice, two week notice, or waiting until I can do proper hand-offs, what should I do? I also have to say I have an amazing team (management is pretty garbage, though), and I'd be sad to leave them in a tough spot. What would you do?",
  "I am about to complete my Economics PhD and am currently transitioning to DS.\n\nI have 2.5 years of quantitative finance and algorithmic trading experience and also ran the trading club at my university for 4 years.\n\nYes, I know that I could go back to finance, but I want a new challenge with a better WLB. \n\nWould these 6.5 years of QF and AT be considered as relevant job experience? Should I add my projects to my DS-related GitHub and portfolio?",
  "Hi.\n\nI'm looking for an example of a good github repo that can be used in CV.  \nI have a lot of work that I'd like to showcase with out of the box thinking approaches that I have utilized before.\n\nIf somebody can please link me to a good github repo that they see is if high grade, please let me know.\n\nThank you.\n\nRegards.",
  "If anyone can assist with feedback please do. Can forward job role or post it on here. I've already prepped some just looking for feedback or insight. Meeting with hiring Manager.\n\nEducation: Bachelor of Science Comp Sci  \nCerts: Professional Scrum Master & IBM Professional Data Science ",
  "Hi dear community, \n\nI'm a big data analytics student. \n\nworking on my end of studies project, it's about sentiment analysis on Facebook posts (Comments), comments usually are written in a local language ( Algerian Dialect) \n\nI want to know if there are some technics I should be using to train ML models on this dataset . \n\nYour help would mean a lot. \n\nI'm also open for any questions regarding this topic , let's exchange on this one .",
  "Hey, I am currently working on a regression task for a course that I am attending.\n\n&#x200B;\n\nI chose a Dataframe that contains information about apartments on a renting website and decided that the rent including heating (Warmmiete) is my target. \n\n&#x200B;\n\n**Note:** In Germany we have a base rent (Kaltmiete) to which heating gets added on. The sum of those two logically is rent including heating (Warmmiete)\n\n**Those are my features:** \n\n* Base rent (Kaltmiete) - float\n* Heating cost - float\n* Number of rooms - float\n* Number of photos (on website) - float\n* Elevator - bool\n* Balcony - bool\n* Year of construction - float\n* Federal State 1 (one hot encoded) - bool\n* ....\n* Federal State 16 - bool\n* Garden - bool\n* Cellar - bool\n* Kitchen - bool\n* Newly built - bool\n* floor - float\n* Living area - float\n* Type of flat 1 (one hot encoded) - bool\n* ....\n* Type of flat 10 - bool\n* Condition - float\n\n&#x200B;\n\nAfter cleaning and splitting my data I used MinMaxScaler before calculation the R2-Score of a few regression models. It turns out that Linear Regression and Random Forest both returned a score of 99% while the other models where also laying around 90%. \n\n&#x200B;\n\nIn a second try I threw out the base rent and heating cost out of my dataframe and got worse scores that go from 60% to 81% (SVR). Adaboost only scored with 7%. What confuses me is that in the second try all MSE got very low. Almost all of them are in a small number area like 0.05 for example.\n\n&#x200B;\n\n**My question is:** Which method is the better one? Seeing that my base rent is a feature that will predict the rent including heating it seems logical that both have a strong linear relationship. But does predicting the rent including heating even make sense if I have my features base rent and heating before the prediction? I tend to use the second method with some hyperparameter tuning. But I am still concerned about the small mean squared errors.\n\n&#x200B;\n\nIf you have any recommendations on how to improve my data, model or methods I will be really thankful!",
  "Hello I'm studying my last year of Data Science at university. In my country it's very common to do a master's after finishing a degree, and I feel like I should do one but if I search for data science related topics, I see that I've already taken 90% of the courses. I'm unsure of what to do... \n\nOption A) Do a master in ML or similar to compliment my data science degree (even though it's not my passion it can be useful).\n\nOption B) master in BI (I really like the topics but most of them are not focused on programming and that's my passion...).\n\nOption C) Start working instead (I feel like I could do that but I do have family preassure behind me doing a masters since it's the norm where I live...).\n\nI would really apreciate your thoughts on what you think I should do.",
  "Is the answer bioinformatics? \n\nHow should I start? Where do I begin? \n\nI want to make a lot of money. Which MPS degree should I pursue?\n\nMasters in professional studies in \n1. machine learning\n2. Data science and analytics\n3. Bioinformatics and Computational Biology\n\n\nMy background is in biology. I hate doing lab work now. I want to do computer stuff. \n\nI know R and Python at the intro 101 level. I have not taken object oriented programming.  I know some discrete math but not a lot.",
  "hi right now im pursuing bcom and i want to do masters in data science can u suggest any short courses so that my college application is strong .\n\nthank u",
  "Hi,\nI am new to data analytics. \nAnd just got an internship. \n\nHave to update these google sheets everyday and was trying to automate it.\nIs there anyway i cab automatically update these sheets, that is new data gets added every 24hrs or less?\nThe things is, it needs to go through my email as the data is available through access only and I have the access..\n\nFor now, I download the data using a link into csv file everyday and upload it to the Gsheets.\n\nAny suggestions of help is very happily appreciated.?",
  "I am a data scientist, with MSc and PhD plus many years of work experiences in various work settings. I also have developed app using various framework, and have made side projects like trading bots. Other than python, I also know sql and some html, css, js, solidity. Should I use the term full stack DS on my CV, or is it not well know or pretentious per se?",
  "\"  **The AI, called ProGen, works in a similar way to** [**AIs that can generate text**](https://www.newscientist.com/article/2353751-ai-chatbots-could-hit-a-ceiling-after-2026-as-training-data-runs-dry/)**. ProGen learned how to generate new proteins by learning the grammar of how amino acids combine to form 280 million existing proteins. Instead of the researchers choosing a topic for the AI to write about, they could specify a group of similar proteins for it to focus on. In this case, they chose a group of proteins with antimicrobial activity**. \"  \n\n\n[https://www.newscientist.com/article/2356597-ai-has-designed-bacteria-killing-proteins-from-scratch-and-they-work/?utm\\_term=Autofeed&utm\\_campaign=echobox&utm\\_medium=social&utm\\_source=Twitter#Echobox=1675041628](https://www.newscientist.com/article/2356597-ai-has-designed-bacteria-killing-proteins-from-scratch-and-they-work/?utm_term=Autofeed&utm_campaign=echobox&utm_medium=social&utm_source=Twitter#Echobox=1675041628)",
  "Hello Everyone, \n\nWhat's the potential for process mining in future? and how worthy a PhD would be to work as a researcher in the industry?\n\nCheers!",
  "Given that I am from mechanical backround, and is 26 years old fresher. With a master degree in mechanical domain.\n\nI am looking to do some Coursera certification course plus some internship for entry level.",
  "I\u2019ve recently been laid off from my Data Science role in the UK. Currently looking for some ways to make ends meet whilst I look for another full-time role, and was wondering if anyone had some experience with contract or freelance data science work.\n\nI\u2019m most intrigued to know:\n\n1) What the best way to find these roles would be. Seems to be quite a few platforms, if I used one I\u2019d be unsure how to choose between them.\n2) If this would be appropriate for me. I\u2019ve only got 1.5 years of commercial DS experience post-uni, largely designing models and putting models into production.",
  "Inspired by r/cscareerquestions.\n\nThat post seems to be getting a lot of attention and helpful answers. Just trying to do the same for the DS community.",
  " I'm currently doing my Bachelorthesis about Microclimatic Effects of Green Roofs and I model the clima for 3 days with ENVI-met.\n\nI will get lots of data which I have to generalize and analyse and then visualize. Basically I want to make some statistical tests if there are significant differences between different fractions of Roof Greening (Compare 100% Greening to 75%...).\n\nI'm asking myself which language would be the most easy for this. What I found out is, that visualization in R can be more \"sexy\". On the other side I have no experience with R and a tiny little bit with Python and I don't have much time for learning.\n\nI already plotted one graph with Python and I know how to load csv's and can work a bit with pandas. I don't know how easy it will be to do the statistical tests with Python or if doing the tests with R would be more straightforward.\n\nI'm happy if someone could tell me what approach would be better: Combining Python and R or just using Python because I already somehow understand how the language works.",
  "I\u2019m currently a business major studying information systems with a minor in statistics. I want to become more technically oriented and eventually pivot into data science but not entirely sure where to start or what to learn . Ive done an intro to python course, and eventually will learn sql and r on a surface level with my degree. I want  to work as a data scientist down the line. Is there a specific roadmap to follow or any recommendations on how to proceed in the field of data science?",
  "Want suggestion for books on sql that are beginner friendly  those who no experience in using this tech that specifically teaches about using sql from data analytics point of view and not development.",
  "I'm a psychology student, but I've been working had at learning how to program in Java by myself. When I walked into the room of my psychology professor, a CS professor was there and introduced himself. My professor told him how into programming I am and I also explained to him what I've been learning. He mentioned a data science paid internship that I could apply for. He didn't say he wanted me to join or anything, just an offer.\n\nWhen I looked at the application, I barely meet any of the requirements to even be looked at as a possible candidate over other students who've actually been studying this for their degree. They ask about related data science classes and projects. They also ask how experienced you are in Python, SQL, and a free other languages, frameworks, and databases. It's still very early, should I apply now and say I have very little experience with these or try learn and get familiar with them so I can say I'm somewhat experienced with these?\n\nWhat way would give me the best chance at getting picked for the internship??",
  "My backround:\n10th : 87\n\n12th :87\n\nGrad : BE mechanical : 86  ( 2019) , Tier 3 college . \n\n2 years gap then \n\nMasters : ME mechanical ( 2021 -23 ) \n\n>I think I can handle mathematics alright\n\n>I know little bit of MATLAB\n\n>Dont know programming \n\n\nAnd will my background affect my career in DS , If i can pursue one.",
  "Is this a reasonable interview coding question? ^ I was asked to code a perceptron from scratch with plain python, including backpropagation, calculate gradients and loss and update weights. I know it's a fun exercise to code a perceptron from scratch and almost all of us have done this at some point in our lives probably.\n\nI have over 2 years of work experience and wasn't expecting such interview question.\n\nI am glad I did fine though with a little bit of nudging given by the interviewer, but I am wondering if this was a reasonable interview question at all.\n\nEdit: I was interviewing for a deep learning engineer role",
  "I was looking at Databricks because it integrates with AWS services like Kinesis, but it looks to me like SageMaker is a direct competitor to Databricks? We are heavily using AWS, is there any reason to add DataBricks into the stack or odes SageMaker fill the same role?   \n\n\nThank you :)",
  "FYI I'm still a student so if there's sth I'm missing and/or misunderstanding, do enlightment me on this topic. Esp. from the perspective of practitioners in the real work setting.\n\nWhen it comes to hyperparams tuning, I've always been directed to using GridSearchCV or RandomSearchCV and that's the end of that. However, I've never really felt that those 2 are the best methods as the former seems to be rather arbitrary and the latter, well, simply random. After more research, I found out abt Bayesian optimization and based on my experience using it so far, it's always outperformed GridSearchCV and RandomSearchCV.\n\nIf u're a practitioner in the field, do u use Bayesian optimization for hyperparams tuning or not? Is there perhaps a more practical reason as to why/why not? (e.g. from a computing cost perspective, etc.)? Since GridSearchCV and RandomSearchCV are so prevalent, it appears that they're the go to method for hyperparams tuning altho they're suboptimal compared to Bayesian optimization - even some practitioners I've managed to ask abt the subject actually do know abt Bayesian optimization as a concept but don't rly use it in production.\n\nAppreciate it and thanks for the insights in advance!",
  "Hello all! \nI'm working on a project building multi class classifier. As a part of it I'm required to evaluate my machine learning model on different sets of test data. Consider each test data represents a different section/location. \n\nHowever, we want to present a single metric combining the results on all of these location through aggregation. The location specific test data can be of different size and different label distribution. Right now, we average the result obtained for each location. For example final result = average ( acc of location 1 + acc of loc 2 + acc of loc 3)\nAcc - accuracy. \n\nIs there any other way to reflect the dataset size and label distribution while combining results from multiple test data?",
  "I want to become a data scientist or data architecture, currently I'm pursuing BSc computer science. Please Guide me",
  "When working with large datasets or executing complex operations using pandas, you may experience Out of Memory (OOM) errors or long waiting periods for the results.\n\n[Xorbits](https://github.com/xprobe-inc/xorbits) can be an ideal solution for these issues. Xorbits is a scalable Python data science framework that aims to scale the Python data science stack while keeping the API compatibility. You can get an out-of-box performance gain by changing \\`import pandas as pd\\` to \\`import xorbits.pandas as pd\\`.\n\nCompared with other pandas-like solutions, Xorbits offers stronger performance, simpler deployment, and better API compatibility.\n\nWith TPC-H benchmarks at scale factor 100, Xorbits is 7x faster than Dask. For the benchmark results compared to other pandas-like systems, please visit: [https://xorbits.io/benchmark](https://xorbits.io/benchmark)\n\nhttps://preview.redd.it/uyavcs2irqea1.png?width=2353&format=png&auto=webp&v=enabled&s=6488a5cc45c95879e651fb43ad8b28f25eb4e989\n\nIf you are interested in learning more about Xorbits, please visit our project's Github  for more information: [https://github.com/xprobe-inc/xorbits](https://github.com/xprobe-inc/xorbits)",
  "I have a basic foundation in in subject and I have even developed my own code to generate some interactive 3D graph networks however I also recognize that I am no expert in the subject so I'm looking for some reccomendations on some good books for self study. \n\n&#x200B;\n\nIdeally, the book would focus more on the math and logic as I can develop the code to implement this myself and realistically the applications at work call for something more powerful than networkX.",
  "Let\u2019s say I\u2019m trying to increase the proportion of total female customers on my site. If I test 2 landing pages and my target metric is proportion of total purchases that are women, what test should I use? \n\nLet\u2019s say we have the following sample data:\n\nControl: 400 male customers, 600 female customers\n\nTreatment: 350 male customers, 600 female customers\n\nWhat test can I use to test whether the increase in female proportion is statistically significant?",
  "Hi All,\n\nI am working on a project trying to analyze ride-sharing to and from airports.  I have emailed airports and ridesharing companies and searched Kaggle and other sites.  Now I'm looking for some more information/advice.\n\nDoes anyone have any suggestions on where I could find ridesharing data? Or where I could scrape it from? Or anyone that I could contact.  Or any other subreddits I should try?\n\nThanks!",
  "SVMs were covered quite poorly in my Machine Learning course last semester, the teacher quickly glossed over the maths, only ever mentioning the key bits of it like \"Langrangian\" or \"Kuhn-Tucker conditions\". Most resources I referred just went \"the math is out of the scope of this textbook\"\n\nNow I still have no clue what or how SVMs find the Maximal Margin Hyperplane. I am looking for resources that help me understand. I have no problem sinking some time into learning the maths (I believe it's called optimization theory?) behind it either.\n\nThanks!",
  "I encountered a question about Kernel SVM in a interview test to a internship, but I am not certain about the answer. Can anyone try to answer it?\n\nTo use a Gaussian kernel SVM, we usually normaliz the feature. Which one or few of following options is (are) True?\n\na. \uff08I don't quite remember this option. This one I pretty sure is True, but next two I am uncertain about. Can anyone help me remember it?)\nb. Sometimes some features cannot be normalized like categorical feature.\nc. Gaussian kernel SVM cannot be done without feature normalization.",
  "Hi there, \n\nI have 2 semesters left to get graduated in economics and so far the subjects that I enjoyed the most have been econometrics and statistics. In fact, I just finished a DS minor this semester which was pretty enjoyable for me. \n\nThe thing is, I'm starting to look for bootcamps or self-taught so I could start developing my career in DS as soon as possible, but I'm not sure if this is the right choice. To make it clear, I would 100% finish the degree but maybe not as my first priority if I could get a DS job.\n\nWould you recommend finishing my degree and then focusing on DS or is it a good choice to prioritize learning DS and trying to get a job?\n\nThanks in advance,",
  "HI folks\n\n&#x200B;\n\nI am toying with the idea of a OMSCS vs MS DS in UT Austin or MS DS from Colorado, Boulder. I am a bit worried about being weak (have logn forgotten my programming skills) in Data Structures/Algorithms and so have some conerns on doing OMSCS. What would this group advise?\n\n&#x200B;\n\nThanks.",
  "Hey everyone,\n\nI am posting this with a throwaway account.\n\nI have been recently let go in a round of layoffs from my Supply Chain Data Science job from a F500 retailer that is based in Middle America. \n\nI am trying to find resources for a remote job in Data Science or Data Analytics as my experience is somewhere in between the two. \n\nI am also willing to relocate if the job fits but remote is preferred. \n\nI have almost 5 years DS experience, self taught through the job. A Supply Chain undergrad from a top  3 university in that field and an MBA from a top 10-15 university and about 10 years of professional experience overall. \n\nI believe I am also cutting myself short when it comes to salary expectations. The job I just left paid out $100k in TC which at the time, was a decent salary in LCOL city and I was getting a company to pay  me to learn in a real world environment instead of the structure of a class room or MOOC. \n\nAny advice would be appreciated.\n\n***EDIT***\n\nIf I had to relocate it would be to Austin (lived there for before), Nashville, DC, or NYC (all three of those are closer to family).",
  "Hi people, I'm looking for a data scientist to partner with on a side project I'm working. I'd love if the person working on also part time like me. Building a free product for now so no money involve but open to paid consultation if you feel like you can help. An example on what I am trying to build: \n\n  \n[https://www.tella.tv/video/cldh231d200090fmacmkj14s2/view](https://www.tella.tv/video/cldh231d200090fmacmkj14s2/view)",
  "I notice a lot of my research at work ends up taking me to methods in information theory or signal processing. I was wondering what graduate college courses in mathematics would be most helpful to me as a data scientist. I have an undergrad in mathematics with calc, linear algebra, probability and statistics, ODE, analysis, etc. but no PDE, information theory, signal processing or graph theory. I also don\u2019t have any courses in advanced or specific statistics courses such as time series analysis, combinatorics, or Bayesian inference\u2014although I\u2019m familiar with the fundamentals from my undergrad probability courses.\n\nI\u2019m already pretty familiar with most of the models and methods in elements of statistical learning. It\u2019s more about being able to develop or understand novel methods and having a foundational base that prepares me for anything.",
  "Hello! So I wasn\u2019t even intending to go for grad school right after my dual BS CS BS DS program, but I found out I would qualify for a full tuition and fee scholarship for UMSI\u2019s MSI program at Michigan. I\u2019d do the big data analytics curriculum full time and finish in the standard 2 years with a required internship in the summer between the first and second year.\n\nI\u2019m pretty much already fully invested as it\u2019s a free master of science at a top 5 public uni, so I thought I\u2019d ask what y\u2019all think of the situation, particularly the opportunity cost of delaying full professional entry into the field by 2 more years for an at worst tangentially-related graduate degree. Thanks!\n\nSome other notes: I\u2019d likely be able to fund living expenses comfortably the entire time, and I\u2019m a nontraditional student finishing undergrad in late 20s with some internships as a data analyst and \u201cmachine learning engineer\u201d (more like data engineering bleh)",
  "I'm in the U.S. and I've enrolled in the WIOWA (Workforce Innovation and Opportunity Act) program since I'm a dislocated worker. I'm interested in getting a cert through UCLA's Extension course program. If you've gotten certs what was your experience?",
  "Hi guys, aroung where i live there's a university that offer this degree. I read a couple of question about CS vs DS degree, the main issue is that in my city no ones offer a degree in computer science so i have only one option.\n\nDo you think i could be in troubles for get a job if i graduated of DS?\n\nI'm currently work as software developer without degree and i want to transition to Data engineer and after graduate i will try to get a job as DS.",
  "Hey everyone, I'm creating a cheat sheet for beginners in machine learning that provides an overview of various unsupervised, supervised, and semi-supervised learning algorithms. The goal of this cheat sheet is to help beginners understand the different types of algorithms, their applications, and examples of how they are used. I would greatly appreciate any feedback on what else I can add to the cheat sheet to make it more useful for beginners. Please let me know your thoughts!\n\nMachine Learning Cheat Sheet: [https://medium.com/p/2992e295ee64](https://medium.com/p/2992e295ee64)",
  "Hi folks,   \n\n\n Currently working through the IBM DS and Google Analytics certificate. I am a complete rookie in DS.\n\nI am interested in where linguistics and  behavioral economics intersect with data science in terms of the types of jobs/research fields to target as it seems like 'Data Scientist' is somewhat of a catch all term for HR departments. \n\nIn terms of a following a learning pathway, employers (HR?) seem to all look for a degree, however online postgrad and BsS computer science course seem overpriced and, outside of data science specific programs, not as good as combining bootcamps, certificates and other online learning routes. Is this the case?   \n\n\nIn terms of building a portfolio of work, or a learning journal that can be linked to CV, does anyone have any recommendations?   \n\n\nMany thanks for any help!",
  "I have an encoder model which was working fine with single channel 1024,1024 images, I'm trying to patch the original images (mega pixel images) to 256, 256, 64 images. I've changed my encoder input to match the images input that the model will get. The model call function is working fine, loss is getting calculated fine, but I'm getting the following error with tape.gradient:\n\n    2023-01-29 17:11:01.868555: F tensorflow/stream_executor/cuda/cuda_dnn.cc:593] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 10 feature_map_count: 64 spatial: 0 0  value_min: 0.000000 value_max: 0.000000 layout: BatchYXDepth}                      C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:318: UserWarning: resource_tracker: There appear to be 2 leaked folder objects to clean up at shutdown                                               warnings.warn('resource_tracker: There appear to be %d '                                                              C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_772bbeeeccff43089fa0e6d75271eebd_97f2f7c6edd04b468a4360bf96b91b84: FileNotFoundError(2, 'The system cannot find the path specified')                                    warnings.warn('resource_tracker: %s: %r' % (name, e))                                                                 C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_29db2f1e8ff54416b9a78c6f69dcff23_40a85063390f46d38d15c1877f99acc8: FileNotFoundError(2, 'The system cannot find the path specified')                                    warnings.warn('resource_tracker: %s: %r' % (name, e))                                                                 [I 17:11:10.131 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports                                kernel 286d1cc6-8ddd-46f9-baf7-5e1b05a2d033 restarted\n\nMy code is as below\n\n    class encoder(tf.keras.layers.Layer): def __init__(self,size:tuple):\n        super(encoder, self).__init__()     #encoder Module\n        self.input_cnn = keras.layers.InputLayer(input_shape=(size[0],size[1],size[2]))\n        self.conv_1 = keras.layers.Conv2D(input_shape=(size[0],size[1],size[2]),filters=16,kernel_size=(3,3),padding='same',activation='relu')\n        self.conv_2 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_3 = keras.layers.Conv2D(filters = 16,kernel_size=(4,4),strides=(2,2),padding='same',activation='relu')\n        self.conv_4 = keras.layers.Conv2D(filters = 32,kernel_size=(4,4),strides=(4,4),padding='same',activation='relu')\n        self.conv_5 = keras.layers.BatchNormalization()\n        self.conv_6 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_7 = keras.layers.Conv2D(filters = 64,kernel_size=(8,8),strides=(8,8),padding='same',activation='relu')\n        self.conv_8 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_9 = keras.layers.BatchNormalization()\n        self.conv_10 = keras.layers.Conv2D(filters = 1 ,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')\n        \n        def call(self,inputs,training = True):\n            x = self.input_cnn(inputs)\n            x = self.conv_1(x)\n            x = self.conv_2(x)\n            x = self.conv_3(x)\n            x = self.conv_4(x)\n            if training == True:\n                x = self.conv_5(x,training = True)\n            else:\n                x = self.conv_5(x,training = False)\n            x = self.conv_6(x)\n            x = self.conv_7(x)\n            x = self.conv_8(x)\n            if training == True:\n                x = self.conv_9(x,training = True)\n            else:\n                x = self.conv_9(x,training = False)\n            x = self.conv_10(x)\n            return x\n\nsize 0 is 256 size 1 is 256 size 2 is 64\n\nTrain\\_step from main model:\n\n \n\n    def __init__(self, size: tuple, optimizer = keras.optimizers.Adam(learning_rate=1e-3),loss_fn = keras.losses.BinaryCrossentropy(from_logits=False),metric = tf.keras.metrics.Accuracy()):     \n        super(BCDClassifier, self).__init__()         \n        self.input_cat = keras.layers.InputLayer(input_shape = (2,))\n        self.encode = encoder(size)\n        self.flatten = keras.layers.Flatten()\n        self.concat = keras.layers.Concatenate(axis = 1)\n        self.classify = classifier(32)\n        self.optimizer = optimizer\n        self.loss_fn = loss_fn\n        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n        self.acc_tracker = metric\n        self.f1_tracker = tfa.metrics.F1Score(num_classes=2, threshold=0.5, average = 'micro')\n        self.sk_metric_acc = accuracy_score\n        self.sk_metric_f1 = f1_score\n        self.acc_history = []\n        self.loss_history = []\n        self.f1_history = []\n        \n        def call(self, cat_batch, view_batch, images_batch, training = True):\n            x1 = self.encode(images_batch,training)\n            x2 = self.input_cat(cat_batch)\n            x1 = self.flatten(x1)\n            x12 = self.concat([x1,x2])\n            x12 = self.classify(x12)\n            return x12\n    \n        def train_step(self,cat_batch, views_batch, images_batch, target_batch, training = True):\n            with tf.GradientTape() as tape:\n                logits = self(cat_batch, views_batch, images_batch,training)\n                loss_value = self.loss_fn(target_batch, logits)\n    \n            grads = tape.gradient(loss_value, self.trainable_weights)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n            self.loss_tracker.update_state(loss_value)\n            pred = []\n            target = []\n            threshold = 0.5\n            for val in logits.numpy():\n                if isinstance(val,np.ndarray):\n                    for v_1 in val:\n                        if isinstance(v_1,np.ndarray):\n                            for v_2 in v_1:\n                                if v_2 > threshold:\n                                    pred.append(1.0)\n                                else:\n                                    pred.append(0.0)\n                        else:\n                            if v_1 > threshold:\n                                pred.append(1.0)\n                            else:\n                                pred.append(0.0)\n                else:\n                    if val > threshold:\n                        pred.append(1.0)\n                    else:\n                        pred.append(0.0)\n            for val in target_batch:\n                if isinstance(val,np.ndarray):\n                    for v_1 in val:\n                        if isinstance(v_1,np.ndarray):\n                            for v_2 in v_1:\n                                target.append(v_2)\n                        else:\n                            target.append(v_1)\n                else:\n                    target.append(val)\n            acc = self.sk_metric_acc(target,pred)\n            f1 = self.sk_metric_f1(target,pred)\n            #self.f1_tracker.update_state(target_batch,logits)\n            return {\"Loss\": self.loss_tracker.result(), \"Accuracy\": acc, 'F1-score':f1}\n\nCan someone please help me figure out this error?",
  "I am working on a data science project in an Indian ecommerce firm for the last one year. I have tried many different techniques and variations, however, I am yet to create a significant 'impact' according to my manager. Now as the days pass by, I am increasingly worried snd feel under a lot of pressure to get the project productionized. But I keep thinking this: what if it turns out to have no significant impact till the next few months?\n\nI talked to my manager about this, and even though he has assured me that I wont be laid off, that at the worst if the next few months the project does not yield any positive results and that I may be shifted to snother project, I am not sure of what should I do.\n\nShould I prepare for a possible layoff? Or should I plan to leave just in case this whole thing goes south? \n\nHave you faced a situation like this wiht yoir career? What happened then? How sre such situations usually resolved?\n\nI am looking for people in senior positions, ones who have seen the landscape of this industry for quite some years to provide me advice on this. I am a fresher with around 2 years of experience. And I also have a master's in data science from one of the top  government institutions in India. (Just giving out some details for context). Thanks",
  "I've been wondering how useful data analytics and data science is to the professionals' life outside of work. I know that SWE's will sometimes code up something they find useful for their everyday lives like automating tasks or making web apps for themselves that they find useful/fun, and I'm wondering if data professionals have something similar to that. \n\nLike have you ever been pondering a question to yourself and decided to pull in some data to answer it?",
  "I spent like 40 hours building this project which is now useless due to title^. Is it still worth including it and it\u2019s code in my resume and portfolio? If so, what disclaimers should I include?",
  "Hey I'm a business consultant, and by the end of the year I will become a sr. Consultant, however I would like to shift to a data science positition by mid year, is this a good career decision? I'm afraid of maybe restarting my career when I turn 29 this year.\nPs. I have a master in business analytics and I'm about to finish my second ds bootcamp.",
  "We've gone through the original implementation of GPTZero and successfully reverse engineer it. (it gives the same results as original GPTZero). We've also recorded the implementation process which can be found below.\n\nYoutube Implementation Video: [https://youtu.be/x9H-aY5sCDA](https://youtu.be/x9H-aY5sCDA)  \nGithub: [https://github.com/BurhanUlTayyab/GPTZero](https://github.com/BurhanUlTayyab/GPTZero)  \nWebsite: [https://gptzero.sg](https://gptzero.sg)  \nDiscord: [https://discord.com/invite/F3kFan28vH](https://discord.com/invite/F3kFan28vH)\n\nWe're also working on a GPTZerov2 (inspired by LLM based transformers and GANs), which would be more accurate, and can detect lines changed by humans.  \n\n\nPlease give some feedback on our work.\n\nThanks",
  "I have just noticed that a lot of people in this profession are incredibly rude, holier than thou, and arrogant. This subreddit is a big offender of it too. I spend a lot of time working with and hiring junior data scientists and the way they get treated by more senior people is just appalling. I don\u2019t care if a new hire doesn\u2019t get all the concepts in their first year. I REALLY care if my senior hire is treating them poorly for having a lot of questions.",
  "Context: I work for an e-commerce that is trying to come up with the best series of marketing actions to engage customer\n\nBasically we want to decide if it\u2019s better to send 5 e-mails or 3 e-mails + 2 SMSs according to the propensity of a customer buying something\n\nDoes anyone have any ideia how to tackle this?\n\nI was thinking about a uplift model for each action and create something based on that",
  "I   am just joining the field and I   am a little terrified to be honest. I   think imposter syndrome takes over pretty quickly for me, but what might help me is digging deeper into, and mastering, math/stats concepts that are critical to any data scientist. What are the most important ones IYO?",
  "I\u2019m a Data Analyst with a Physics background. Throughout my degree I really enjoyed deriving equations, and fully understanding where things came from - pen and paper style. I liked learning and knowing the fundamentals.\n\nWhen I was doing my PhD and applying statistical techniques, I similarly liked trying to calculate certain things myself by hand in simple scenarios (such as a t-test with not too many data points), rather than always using pre-programmed functions. I had a lot more time to dedicate to learning and checking things made sense.\n\nIn my work now as an analyst, whilst I get L&D time, I just don\u2019t have the time anymore to thoroughly check over things and make sure they make sense. I just have to trust that the R functions are doing what I expect. I have to trust that my chi-squared test is doing what I think, for example. Or that my logistic regression is producing a reasonable output. \n\nI can\u2019t remember the last time I got a pen and paper out and had to differentiate or integrate something, or multiply matrices, or work out the Fourier transform of a function.\n\nMaybe I\u2019m just being nostalgic and having imposter syndrome but it feels like I\u2019m slowly forgetting all of that underlying maths, and that I\u2019ll end up at the point where I can do basic statistical programming and nothing more.",
  "I\u2019m curious whenever I went for an interview , it was a male DS interviewing. Why aren\u2019t there lot of females in this space? Also please mention the country to get a clear idea. \nEdit1: I\u2019m in india and I realized my experience is very different than folks residing in the US.",
  "If you could also recommend where can I learn data preprocessing for ML extensively, would be a huge help.",
  "I've used causal models to estimate average treatment effects for various questions. But I have not yet implemented any large scale model for individual treatment effects.\n\nThere seems to be few people with experience and I have not found a good community for asking questions. So I thought I check out if we have people with experience here.\n\nEdit: I am especially interested if there are anyone that have been moving from standard classification/regression models to causal modeling.\n\nEdit2: I am not that interested in learning models or different techniques. I know what to read and where to look. I am looking for people who have implemented such models at large scale in a commercial setting. Some questions:\n\n* How was it going from classification models to causal models?\n* What results did your organization observe?\n* Have you been working with \"scenario planning\". Optimizing for revenue vs retention and similar.\n* What type of models and problem did you work with?\n* Have you been implementing it in a larger system, such as a decision hub?\n\nAnd so forth.",
  "I was just watching Mindhunter and they were trying to create a profile for what a serial killer would look like based of of crimes. In such an analysis would missing actually be a potential indicator in one direction or another, like a particular characteristic never came up before.",
  "I am a BSc Mathematics (Hons.) student and I aspire to work as a Data Scientist in IT or Financial sector in future. Having heard about a Data Scientist requiring to be knowledgeable in Probability and Statistics (here: https://imgur.com/gallery/jPlI6Yx .).I scrolled through my syllabus and found one paper to be Probability and Statistics and thought to learn :\n\n1: How good is the syllabus for different level of data scientist? (At least for being an entry level Data Scientist.)\n\n2: If it is not enough for an entry level Data Scientist job, then what else do I need to know atleast? \n\n3: If it is more than what I would need to be an entry level Data Scientist, how much more is it, as in what level could it help me for? \n\n\n\nI know negligibly about the Data Science field compared to you people and my english is not very we so if I have not made much sense, I would try to elaborate on whatever you would ask me.",
  "Hello everyone, I have a question for you, with your permission. I am in Energy Systems Engineering 3/4 class. (I'm 22 years old)\n\nMy Question: Renewable Energy or Data Science (ML and AI) as a Master's Degree, which should I choose? (For the Future) I would be very happy if you could help. (I'm worried about finding a future job)",
  "# Beer is one of the most democratic and consumed drinks in the world. Not without reason, it is perfect for almost every situation, from happy hour to large wedding parties. If you just think about it, you already feel like having a beer, you\u2019re not alone.The objective of this work will be to demonstrate the impacts of variables on beer consumption in a given region and the consumption forecast for certain scenarios.The data (sample) were collected in S\u00e3o Paulo\u200a\u2014\u200aBrazil, in a university area, where there are some parties with groups of students from 18 to 28 years of age (average).\n\n# [https://www.kaggle.com/code/sadikaljarif/predicting-beer-consumption-using-machine-learning/notebook](https://www.kaggle.com/code/sadikaljarif/predicting-beer-consumption-using-machine-learning/notebook)",
  "With the new management, HR has mandated to submit at least a certificate, Half yearly.\n\nThe only rule is it should not be given for participation for the ones like udemy, but at least a test of sorts is taken to provide the certificate. \n\nMe and my team have experience working with a lot of tools, but lack any professional certification\n\nMy colleagues have listed the below certifications\n\n1. Python ,R\n\n2. AWS/GCP/Azure\n\nsuggest any courses you know of, Thanks in advance.\n\nAlso, Any tips in handling these discussions with HR, they  are introducing and bringing in a lot of things on top of existing KPIs. if you know any reddit for HR related, point me there.",
  "Do ALL data science jobs use machine learning?   About what percentage of them do not use it?\n\n\nJust wondering, because although I have taught myself many data science concepts, my machine learning is a little thin. \n\n\nThanks for your help!",
  "Does anyone know of any interesting conferenes or meet ups on data science and machine learning in London, not only where papers are presented, but also where companies share their expertise, kaggle winners talk about their solutions, etc?",
  "hi! i\u2019m a current high school senior who will be  majoring in statistics and data science, i want to add a foreign language to make myself a little more employable. so, which language should i add? i heard that chinese is a really good one so should i learn that?",
  "What resources would you recommend for learning SQL",
  "So I have just wrapped up first round interviews for an open position on my team. I work in banking and most of my career involves building regression or logistic regression models.\n\nOne of the trends I've seen since the tech data science boom started is that there just seems to be a drop in the technical level for peoples with masters degree on fundamentals. It seems too many candidates with masters degrees  do not understand mathematical assumptions of most of the models they are using even at a conceptual level.   For example, during the interview I asked most candidates about regression and what assumptions are required.\n\nNearly every single masters level candidate didn't know why the specific assumptions were made (even if they could correctly list them), could not answer questions on what happens when you violate an assumption, and did not know how to test violation of those assumptions or how to address those issues. Whats disconcerting is these are candidates coming out of professional masters programs from the worlds leading universities and most of them will end up in jobs where modeling error can have multi-million dollar impacts.\n\nFor some additional context: The comment here is explicitly here about standard of candidates I interviewed for people with masters degrees. Most of the Ph.D jobs met standards we expect, even though the job does not require one. The job is one that is very specifically related to regression modeling, time series.   \n\n\nSome clarification: This isn't not having trouble finding candidates post. This is a role at a industry leading firm, and there is no shortage of good candidates.  What I am specifically addressing in this posts is that candidates we are interviewing with masters degrees don't know text book stuff they should know based on whats listed in their resume.   \n\n&#x200B;",
  "Looking for advice on how to handle this.\n\nI build a dashboard or report or automated tool and showcase it to data colleagues in other departments for feedback and adoption. Next thing I know, an executive is driving an all-employees mtg and praising someone else for my work because they showed it to that exec. That other person gets invited to leadership mtgs, then promoted. This has happened several times in two different companies.\n\nAm I blowing this out of proportion? Should I stop collaborating? Is this common or am I just unlucky?",
  "As the title mentions, I\u2019ve been in this sub for around 5 months. Hoping to see more in-depth data science discussion rather than students trying to justify that data science is worth going into or how to break into data science from another career. I don\u2019t think I\u2019ve seen another sub quite like this one with the degree of questions asked like this from people outside of the field. Especially how many duplicate/repeat questions I see every day.\n\nAre there better sub reddits to be in besides this where more advanced topics are discussed?",
  "I have 6+ years of experience as a Data Scientist. My current organization is asking us to get certified in UiPath (optional).\nIs it worth to spend time in learning a RPA tool? Is it useful for in AIML projects?",
  "Hello everyone! Just for a bit of context, I am 23 years old and just started my Data Analyst career. I have not graduated with my bachelors yet but I believe over the summer I should be able to finish core req classes and should be golden.\n\nI currently have experience working with R, Tableau and Tableau Prep. I have been fortunate enough to work at a start up company and really gain a lot of exposure to other tools such as Heap and Salesforce. So far I have 8 months of experience.\n\nDuring these 8 months I have completed a series of deep analysis of the company products and its customers. Worked from analyzing customer behavior, after cleaning really messy historical data, to creating customer segments based on the key performance metrics I also had created. Using Heap, I had to define UI code of our plattforms to then make analysis of user interactions. Report those findings and suggest areas of improvement.\n\nI feel confident in cleaning data but, as its notoriously known, I do take my time because I don't like finding later mid-analysis that the data is off. Whenever I find myself repeatedly doing something on excel, I create executable R scripts to speed the process. I often do this when uploading data into Salesforce.\n\nI plan to read some amazing resources I found for ML and statistics and apply some concepts into the company. I found that this start up in particular is always open for new ideas and projects.\n\nMy current goal is to shoot for $80k salary once I graduate, how realistic are these goals? I just dont know how much my experience is valued at the current market.",
  "Hi folks,\n\nI was working on a personal experimental project related to GPT-3, which I thought of making it open source now. It saves much time while working with LLMs.\n\nIf you are an industrial researcher or application developer, you probably have worked with GPT-3 apis. A common challenge when utilizing LLMs such as #GPT-3 and BLOOM is their tendency to produce uncontrollable & unstructured outputs, making it difficult to use them for various NLP tasks and applications.\n\nTo address this, we developed **Promptify**, a library that allows for the use of LLMs to solve NLP problems, including Named Entity Recognition, Binary Classification, Multi-Label Classification, and Question-Answering and return a python object for easy parsing to construct additional applications on top of GPT-n based models.\n\nFeatures \ud83d\ude80\n\n* \ud83e\uddd9\u200d\u2640\ufe0f NLP Tasks (NER, Binary Text Classification, Multi-Label Classification etc.) in 2 lines of code with no training data required\n* \ud83d\udd28 Easily add one-shot, two-shot, or few-shot examples to the prompt\n* \u270c Output is always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering\n* \ud83d\udca5 Custom examples and samples can be easily added to the prompt\n* \ud83d\udcb0 Optimized prompts to reduce OpenAI token costs\n\n&#x200B;\n\n* GITHUB: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)\n* Examples: [https://github.com/promptslab/Promptify/tree/main/examples](https://github.com/promptslab/Promptify/tree/main/examples)\n* For quick demo -> [Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)\n\nTry out and share your feedback. Thanks :)\n\nJoin our discord for Prompt-Engineering, LLMs and other latest research discussions  \n[discord.gg/m88xfYMbK6](https://discord.gg/m88xfYMbK6)\n\n[NER Examples](https://preview.redd.it/x232msli2nea1.png?width=1236&format=png&auto=webp&v=enabled&s=fa2a386b8b772716ca0af575b0afe6b925bfb9a6)\n\n&#x200B;\n\nhttps://preview.redd.it/5o5uqk3k2nea1.png?width=1398&format=png&auto=webp&v=enabled&s=a984d5f9d02cc1a623f224b495424dec74323670",
  "I'm relatively new to data science and I've been interviewing with a company for about a month. I've been through a coding test, case study, multiple rounds with members of the team, and what I was told would be a final interview with the head of their team.\n\nA few days later, I received an email saying they'd like to fly me out to their offices. And my travel date would be ~2.5 weeks into the future (which is surprisingly far out, I thought).\n\nHas anyone else been asked on site after a final-round interview? I think that they're either interested in me or buying time while another candidate considers their offer. Thoughts?",
  "Hi All,\nI was looking for some books for DA interview. Does it even exist? All I see is for DS interviews?",
  "I   am new to data science, and I   have been following a lot of people in the field on LI. It seems like there is a discussion around what's the better language for DS. Some people argue R is better, some python. I   know a little of each with my focus being on python (I   am not an expert programmer though). What are your opinions? Any idea where the field is heading? Should I   focus on R more?",
  "I\u2019m in my first year of Uni studying Data Science. I\u2019ve learned a bunch of Python on my own and am being taught Java. Also have some minor understanding of C# and C. \nWhat programming languages and tools should I focus on if I want to get an actual job?\nI\u2019ve seen a lot of mentions of JavaScript and React. Are those core components of a hire-able CV?",
  "Hey folks, \n\nI'm a senior data scientist with 5+ years of experience mostly on marketing and product. I've spent my whole career in startups and tech and am honestly just tired of it at this point.\n\nNothing is stable, priorities, technology, and competition are constantly changing. Moreover, although you see all these tiktok tech influencers showcase their cushy jobs, I have always found that tech is extremely demanding on your mental energy. This has only worsened for me since covid as wfh also means you always have to be on and available even in my own home. \n\nIs this what it's like across other industries as well? Are there any chill jobs where I don't always have to be on my A-game?",
  "&#x200B;\n\n[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/35vtxrwnekea1.png?width=720&format=png&auto=webp&v=enabled&s=95e113299668b569f64ca6ecaa095b948a15e78b)\n\nMicrosoft is investing $10B into OpenAI!\n\nThere is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.\n\nThe fear is that OpenAI\u2019s models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.\n\nHowever, the specifics of the deal tell a different story.\n\nTo understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!\n\nTo appreciate better why there is some three-dimensional chess going on, let\u2019s first look at Sam Altman\u2019s backstory.\n\n*Let\u2019s go!*\n\n# A Stellar Rise\n\nBack in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.\n\nInstead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.\n\nBy YC standards, this was a pretty unimpressive outcome.\n\nHowever, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.\n\nHe listed young Sam Altman next to Steve Jobs, Larry & Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.\n\nAnd Sam Altman played his hand well!\n\nHe parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \\[2\\]. In addition, Paul Graham made him his successor as president of YC in 2014.\n\nWithin one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.\n\nToday, he is the CEO of OpenAI \u2014 one of the most exciting and impactful organizations in all of tech.\n\nHowever, OpenAI \u2014 the rocket ship of AI innovation \u2014 is in dire straights.\n\n# OpenAI is Bleeding Cash\n\nBack in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.\n\nThat money is long gone.\n\nIn 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost >$500M over the last year alone.\n\nThis is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.\n\nIn addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \\[4\\].\n\nSo, where does this leave them today?\n\nBefore the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn\u2019t take a genius to figure out that they are running low on cash.\n\nIt would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can\u2019t they just lease them and make a killing?\n\nYes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.\n\n*Here are some reasons why!*\n\n# The Tough Business Of Machine Learning\n\nMachine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.\n\nTo start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \\[7\\].\n\nOn the one hand, the massive compute requirements and thorny data management problems drive up costs.\n\nOn the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.\n\nTo illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT\u2019s outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.\n\n*Alright, alright, alright! Machine learning is hard.*\n\n*OpenAI already has ChatGPT working. That\u2019s gotta be worth something?*\n\n# Foundation Models Might Become Commodities:\n\nIn order to monetize GPT or any of their other models, OpenAI can go two different routes.\n\nFirst, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.\n\nThis is not going to happen. Reasons for it include:\n\n1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.\n2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.\n3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.\n\nThe second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.\n\nThis approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.\n\nAs an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.\n\nAs a result GPT inference would become a common good. This would melt OpenAI\u2019s profits down to a tiny bit of nothing.\n\nIn this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI\u2019s API control the interface to the customer, they would likely end up capturing all of the value.\n\nAn argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).\n\nTo sum it up:\n\n* They don\u2019t have a way to sustainably monetize their models.\n* They do not want and probably should not build up internal sales and marketing teams to capture verticals\n* They need a lot of money to keep funding their research without getting bogged down by details of specific product development\n\n*So, what should they do?*\n\n# The Microsoft Deal\n\nOpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.\n\nAt this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.\n\nHowever, the astounding size is not the only extraordinary thing about this deal.\n\nFirst off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.\n\nIf OpenAI starts making money, the profits are distributed differently across four stages:\n\n1. First, early investors (probably Khosla Ventures and Reid Hoffman\u2019s foundation) get their money back with interest.\n2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid\n3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.\n4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \\[3\\]\n\n# What This Means\n\nThis is absolutely crazy!\n\nOpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.\n\nOn top of that, they solved their distribution problem. They now have access to Microsoft\u2019s sales teams and their models will be integrated into MS Office products.\n\nMicrosoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.\n\nThe synergies do not stop there.\n\nOpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).\n\nThe deal creates a beautiful win-win situation, but that is not even the best part.\n\nSam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.\n\nHowever, if OpenAI creates something in the direction of AGI \u2014 whatever that looks like \u2014 the value of it will likely be huge.\n\nIn that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.\n\n*Wow!*\n\nWhether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.\n\n*This deal is an absolute power move!*\n\nI look forward to the future. Such exciting times to be alive!\n\nAs always, I really enjoyed making this for you and I sincerely hope you found it useful!\n\n*Thank you for reading!*\n\nWould you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** \u2b55.\n\nI send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)\n\n**References:**\n\n\\[1\\] [https://golden.com/wiki/Sam\\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)\u200b\n\n\\[2\\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)\u200b\n\n\\[3\\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)\u200b\n\n\\[4\\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG\n\n\\[5\\] [https://www.crunchbase.com/organization/openai/company\\_financials](https://www.crunchbase.com/organization/openai/company_financials)\u200b\n\n\\[6\\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)\u200b\n\n\\[7\\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)",
  "I was laid off from my job as an attorney back in November. Prior to the lay off, I considered switching to a data analysis/programming/coding job since the legal job market is oversaturated, and now seems like a perfect time to transition since I can focus on learning a new skill.\n\nHowever, I\u2019m worried the switch to tech may not pan out though due to the recent tech layoffs, and I have had trouble finding another attorney job. I\u2019ve been applying to jobs daily since the lay off, and I\u2019ve been teaching myself how to code. I plan to start a boot camp once I\u2019ve gotten a little more proficient at coding. \n\nIs it a bad idea to switch to tech in 2023? Any advice is welcome.",
  "Looking for a conference to go to this year. I work in retail, but conference doesn\u2019t need to be retail specific. Areas of interest include, but not limited, NLP, Bayesian, and just anything that I can take back and apply to my job.",
  "College student here.  Just finished a meeting with a professor at my uni who seemed multitudes more educated and intelligent then I am in the current state of my \u201ccareer\u201d.  We chatted back and forth for around an hour about techniques and avenues of approach given different starting disciplines (stats vs computer science, etc).\n\nThe book we\u2019re reading in class, that I doubt anyone besides me has opened since so far it\u2019s very slow, has some of his published works and data used for a really cool project he did with his PHD.  To refrain from giving up my anonymity I\u2019m not going to disclose what it was but I was like damn after the convo.\n\nI want to hear all the coolest shit you guys out there have done, ranging from research avenues, to professional settings, to whatever stuff you cooked up on your own time.",
  "I\u2019m a full time insurtech data scientist for over a year, and looking to switch, what are some topics I should most definitely study for?",
  "I'm wondering how to transition into something Data Science related and wondering whether either a CS or AI masters would be a good first step\n\nI've been a software engineer for 3 years and don't have the quantitative background at the moment as my degree was in business. A lot of the good data science masters (ones at a good University) require bachelor's in highly quantitative subjects whereas both these masters are at a good University and I can get onto them if I complete short courses in calculus and algebra that are at university level. I'm wondering whether they would be a good first step into the field\n\nWhat are your thoughts?",
  "Good day! Does anyone know a good place to find monthly or quarterly population density and household income data by zip code? I\u2019m looking into fredapi and census api at the moment but having a hard time finding the 2 datasets described above.",
  "I\u2019ve been job searching since November 2022 and my severance just ran out.\n\nI received an official offer letter from company A over a week ago and today learned that another, company B, wants to make an offer, but probably won\u2019t have it until next week.\n\nFrom the quoted figures, I believe company B won\u2019t be able to match my current offer (they are also not yet public, whereas A), and I\u2019m already tired of negotiating/interviewing.\n\nIs there a way to gracefully withdraw with company B? I told them I already got an offer and it\u2019s a difficult decision. I just don\u2019t want to wait anymore to secure a job given the market conditions.",
  "I started to think that openAI (or other advanced AI tech from other big tech) may eventually make data scientists obsolete faster before any other job. Here's why.\n\nFirst of all, machine learning is a bit useless if everybody just leverage openAI (or Google) LLM. I mean why would companies ever need any other AI if they can all just pay google or microsoft to do the AI-related jobs for them?\n\nAnd even when it comes to data reasoning, AI will be able to do that job much faster as compared to data scientists. If you check azure openAI landing page, they literally mentioned code generation and data reasoning as their selling points.\n\nThoughts?",
  "#  Recognizing things in their natural settings is one of the most fascinating challenges in the field of deep learning. The capacity to analyze visual information using machine learning algorithms may be highly valuable, as shown by a variety of applications.The SVHN dataset includes approximately 600,000 digits that have been identified and were clipped from street-level photographs. It is one of the image recognition datasets that is used the most often. It has been put to use in the neural networks that Google has developed in order to enhance the quality of maps by automatically trancribing address numbers from individual pixel clusters. The combination of the transcribed number and the known street address makes it easier to locate the building that the number represents. \n\n# [https://www.kaggle.com/code/sadikaljarif/street-view-housing-number-digits-recognition](https://www.kaggle.com/code/sadikaljarif/street-view-housing-number-digits-recognition)",
  "Hi guys, I come from a Finance and Markets background, but not too much quantitative. \n\nI've done my Calculus and linear algebra exams, but I'm pretty aware that I forgot a lot of things, and indeed to be properly capable again of doing all the exercises and all the cases I should start from scratch again, wasting months. \n\nNow, my question is: is worth it in order to pursue a career in data science/analytics jobs to be pretty skilled in all the calculus and linear algebra exercises, and could be a better way to learn to apply these concepts with Python libraries instead to make each exercise and typology by hand?\n\nI'm aware that Data science is more statistics than math, but I heard that being \"fluent\" in calculus and linear algebra for machine learning is a must. But I'm confused if it is necessary to be capable of doing all the math by hand instead of libraries. \n\nAny suggestions? Thanks. I hope I've been clear.\n\nP.s: I'm ok with statistics using Python, but even there I would not be capable of doing an exam again by hand, I forgot a lot of formulas, and to work on a project by hand I should have all the formulas and old solved exercises in front of me to consult because I forgot that skill, doing other exams such monetary economics or law exams.",
  "Idk if I\u2019m just tired of studying for exams but really hope someone can show me I\u2019m wrong.\n\nJust read a post on this sub about how most DS jobs don\u2019t even use ML and use more SQL, PowerBI and excel\u2026\n\nI bet my whole masters and thesis on the idea that taking as many ML/DS courses as possible would help me get a job but I\u2019m not even getting interviews. I\u2019m even taking extra online courses on \u201cadvanced\u201d stats and building objectively cool ML projects. I got 2 internships in the Data space but can\u2019t even get past resume screening rn\u2026\n\nShould I keep trying to pursue this field or should I just go with something \u201ceasier\u201d? \n\nFor context I\u2019m a ECE, but I know plenty of people from my school with my degree that went on to do ML/DS at FAANG but this was like 3 years ago\u2026",
  "Hi all, \n\nI am trying to find the best multidimensional combination of parameters for an application based on a given metric by using bayesian optimisation to search the parameter space and efficiently find the most optimal parameters with the fewest number of evaluations. The model gives some sets of parameters, some that it has a high prediction of the metric, and others it has high uncertainty about. \n\nThese 2-300 outputs per cycle are then experimentally validated, and the accumulated results fed back into the model to get a better set of parameters for the next iterations for a total of about 6 iterations (12-1500 data points total) . The search space is large, and there are a limited amount of iterations that can be performed. \n\nBecause of this, I need to evaluate several surrogate models on their performance within this search space. I need to evaluate the search efficiency (how quickly can each one find the most optimal candidates e.g one will take 3 cycles, the other 8, other 20 etc) and the theoretical proportion of the search space that each model can search given the same data e.g 20% of the search space given 3% experimentally validated data from the search space.\n\nI am using the BoTorch library to build the bayesian optimisation model. I also already have a set of real world experimental data from different cycles from the first model I tried. \n\nI would like to know how to go about evaluating these models for the search efficiency and design space uncertainty, any thoughts are welcome. \n\nThanks.",
  "I'm a virgin when it comes to all this. I've watched videos and whatnot about it but I'm still confused. So I'm looking for a \"change\" in career. I've been studying kinesiology and I'll be graduating in April. I'm looking to learn data science as well so I'll have a second option if I don't succeed in my own field. I'm a pretty good learner (meaning I pick up knowledge pretty fast) but don't know where and how to start. Any advice on this? What are the job prospects looking like for a DS in the next decade. Is it in danger of being replaced by AI anytime soon?\n\nThank you for your time in advance.",
  "I am DS director. I have 8 YOE in analytics and 6 YOE in DS. My base is 175k and I get 20% bonus which fluctuates. No equity, RSU, or ESPP.\n\nI don\u2019t want to move up because I don\u2019t want to do more management tasks. I see people on here talking about making 200k+.\n\nAny ideas on how to make more without moving further into management?",
  "Hello all,\n\nI need to finish all tasks in this Lab. Can someone help me out and give me some shortcuts? \n\nProgramming isn't the issue, the issue is the extensive tasks. \n\nI have my exams coming, pls help.",
  "Hello all,\n\n&#x200B;\n\nI am struggling with the problem I am facing:\n\nI have a dataset of different products (Cars) that have certain Work Orders open at a given time. I know from historical data how much time this work in **TOTAL** has caused.\n\nNow I want to predict it for another Car (e.g. Car 3).\n\n&#x200B;\n\nhttps://preview.redd.it/7p7nztexrlea1.png?width=492&format=png&auto=webp&v=enabled&s=3fc47d3920cc10f217dad657887789540a59287d\n\n&#x200B;\n\nWhich type of algorithm, regression shall I use for this? \n\n&#x200B;\n\nMy idea was to transform this row based dataset into column based with binary values e.g. Brake: 0/1, Screen 0/1.. But then I will have lots of Inputs as the number of possible Inputs is 100-200..",
  "I work as a data analyst and have a physics background, and to be honest I\u2019ve always had a relatively pragmatic approach to statistical programming. I\u2019ll write functions when it seems like I\u2019m going to be doing something a lot, otherwise I won\u2019t.\n\nIn my work I\u2019ll quite often start a new R script, or SQL script, and rather than write *everything* from scratch, I\u2019ll typically copy and paste the code across from previous scripts - E.g. package loading in R, functions I use a lot, things like read_csv but just change the file path. Even though a lot of this is just lazy stuff that I probably know how to do, I feel like I don\u2019t have the time to just write it all out from scratch again.\n\nJust wondering if anyone else does things like this?",
  "When you select a model strucutre in relation to another ( for example linear regression with 3 features vs linear regression with 2 features) , do you do it based on how good it was in the test set, namely in the rmse, or do you compare the rmse crossvalidation? I was reading a book that said that to evaluate the structure of the model, that is, with less or more variables, it was by cross validation and doing it on the test set is not the most correct. What do you think?",
  "I am looking for a tool that where you can input a list of relationships and generate evenly spaced/best positioned network diagram, kind of like how you might make a Sankey diagram but non linearly and with multiple causal directions.\n\nJust wondering if anyone had any suggestions?",
  "Firstly apologies if this is a silly question I'm just not at all familiar with the field. \n\nI'm currently self-studying math with the goal of learning up to liner-algebra and then returning to school for a BS in mathematics followed by a graduate degree in some-sort-of data-driven math-based field like data science or machine learning. Given this goal I was wounder if I should also be self-studying data analysis along with the math. I reason that this might be good since I'd be getting hands-on experience with data and I might even be able to do it as a job while I study. \n\nI'm currently on Algebra 2 in my math studies so if I should be learning data analysis, can I do it now or would it be better to start after I've learned more advanced math like calculus?",
  "As the headline suggests I am looking for a good online Looker course. Paying for it is not an issue. Even better would be to have 1 to 1 sessions with someone. All suggestions are welcome. English is not my native language but I am proficient enough.",
  "Repost beause last one got lost in new.\n\nI am currently a freshman computer science major, and I want to get into the data industry after graduation. I currently have a few different paths I can take.\n\n1. Computer Science with an engineering business minor\n2. Applied and Computational Math and Statistics (ACMS) with some sort of business minor\n3. Business Analytics and ACMS double major\n4. Computer Science and ACMS double major (this one would be more difficult to fit it. I might have to take a summer class or two, but would still graduate in four years.)\n\nThe companies I am interested in working in mostly have distinct data science and data engineering roles. I am not sure which I want to gravitate more toward, but I do want to do a path in college that gives me flexibility to move around. Is it possible to switch to data engineering if I don't have a computer science degree? Does anyone have any tips that I can use for refining what exactly I want to do? Any projects or anything i could do? I have read a lot about all of this, but I usually cannot tell if I like doing something for sure until I actually get involved in it.\n\nI know this is my decisions and multiple of these paths would work, but any advice just on how I can decide for myself would still be greatly appreciated. If I need to add more details about any of those majors, let me know.",
  "Hello! I hope you are doing well,\n\nI am a second year student pursuing BSc. in Data Science from an accredited University in Canada (UBC). I have been interested in DS since my high school so I wanted to streamline my career which is why I didn\u2019t go for CS or Math major. \n\nWhat should my next steps be ?\n\nI want to work with real data in a project, maybe an internship, basically something more hands on. However I don\u2019t think at the current time I have enough skills and expertise.\n\nWhat should I pursue after undergrad?\n\nWhat should I be focused on now?\n\nAny recommendations from a senior or a working professional will be of great help!\n\nThanks!",
  "I'm working on a project where data is naturally and necessarily collected in a row-by-row tabular format. I have a strong suspicious that analysis and exploitation of the data could be revolutionised if it were transposed into a graphDB, but I don't really have any direct experience or good examples to back this up.\n\nHas anyone here made a similar transition and made some kind of step change in either analysis efficiency or in terms of the value that can be extracted from a dataset?\n\nI know there are classic examples of where network analysis can be well utilized (social network analysis comes to the top of my mind), but I'd love to hear from anyone with direct industry experience. If it's an unexpected angle, all the better.",
  "Databricks proposed a solution using standard deviation to flag out-of-stock, but I am curious to know how this problem is dealt with in reality. Thanks\n\nhttps://www.databricks.com/blog/2021/08/24/improving-on-shelf-availability-for-items-with-ai-out-of-stock-modeling.html",
  "Hi! Im working on a project with huge amounts of data, actually, the model we are using is xgboost, im trying to increase the performance of my model and I came up with the idea of clusterize my data in an unsupervised way (with out the target in the dataset) and use the clusterization results as a new feature. So I fit several k means (k=3, k= 7, k= 10 and k = 15) to my training dataset and use the clusters as new features to try to improve my xgboost.\n\nDo you think my approach has sense?",
  "Could you give some practical examples of when this question has come up in your work and why you made your decision? Sorry if this is very vague I feel as though I'm missing a piece of information that makes the answer to this question very obvious\n\n&#x200B;\n\nEdit: thanks for all the comments and information this was very helpful",
  "I've been seeing a lot lately that people on Twitter are saying that Monte Carlo Simulation is overlooked in Data Science courses and I want to know why is it important. \n\nWhat topics in Monte Carlo Simulation are useful for Data Science? Where are these used? Do you have any resources for a use of it in practice? \n\nI barely know the difference between Bootstrap and Monte Carlo. And the only time I've used MC is in Neural Network dropout, to measure the uncertainty of my predictions.",
  "I just started browsing this sub again for the first time in maybe 6 months. I noticed all the hot threads had no users with mod-confirmed jobs or education. I recall the largerly popular and trusted posts/responses that helped me get into this field being from PhDs and highly experienced individuals. Is this practice still advertised by the mods?",
  "Hi, I would like to ask if someone of you has ever faced a problem in which the main available data are a combination between time series and static variables.\nAlso the anomaly has to be predicted in advance with respect to its occurring (i.e. predictive maintenance problem)\n\nLet\u2019s say that both of the type of data (dynamic-time series and static-fixed) are strictly important because based on information in static variables there are different behaviors in the time series for the same channel.\n\nWhat state of the art approaches could be used to manage early anomaly detection on this kind of data?",
  "I\u2019d like to brainstorm a problem I\u2019ve been mulling. I\u2019m working with a very large transactional database. (Billions of rows/ 30+ columns). \n\nEach row represents a single action from a user (e.g. one row for attempting to log in, another if the user buys a product, another if the user modifies their profile).\n\nI want to create stories (groupings) of events (rows) to summarize user activity better. E.g. this user logged in and searched, but never bought anything and made no changes to their profile. \n\nThere are dual goals with this project. One is to create a repeatable process (or potentially a new database) that categorizes user events. The second is to eventually build an algorithm (probably k-means, maybe others) to evaluate outlying activity trends. Eventually the algorithm would feed into a MLM, but that\u2019s a bit far off at the moment. \n\nI was going to do the grunt work of if/case statements based on understanding the different columns in the database. But I\u2019d like to brainstorm with others. Are there other methods that you\u2019d recommend?",
  "What aspects of a master's program are most valuable for a career in data analytics? I'm an undergrad who's a bit overwhelmed by the choices.",
  "I work at a company frequently cited by articles posted on the sub describing cutting edge data science.  Our data is ubiquitous in the business world. We basically work globally with just about any store or manufacturer you can think of from Proctor  & Gamble to some Australian big box store you've never heard of that is a household name down undah. We do e-commerce, marketing, brick and mortar, basically anything but financial, insurance, and real estate (i.e. Wall Street).\n\nAnd I gotta say. I've seen a lot of small data companies doing sci-fi A.I. generating unbelievable insights with perfect accuracy.  And there's a lot of self-congratulatory celebration when they build Jurassic Park and count angels on a pinhead with perfect accuracy. \n\nBut they have no customers. Brilliant data scientists making stuff no less impressive than ChatGPT but they can't find customers. All the people in the industries that they've perfectly modeled and predicted just aren't smart enough to put perfect information into action with an ROI that could justify itself on a budget with competing priorities. And those companies are filled with super competent 'lunch pail hard hat' data engineers and architects keeping the business machine running. But there's no science or high speed BigBrain stuff being done. No information generation for information sake like the 'data science' companies are doing. Just automating automatible systems. Etc. At most some basic optimization software for process improvements. \n\nIt just seems like there's a widening gulf between business' who demand decent ROI data work that's dumbed down and the boutique data science outfits that think if their A.I. can capture 'truth' then they can sell truth in a bottle. \n\nBut being in the business, knowing the business needs and appetites of our clients, but also working alongside data scientists in my department, and watching them do good work that they can't commercialize into a sellable product, it just seems like data science is losing relevance economically and being replaced by much more simple, 'blue collar' data engineers making sure trains run on time without needing rocket science to accomplish it.",
  "Hi all! Are you looking to learn more about MLOps and have a hands-on deployment guide?\n\nJoin our webinar on February 15 and get started with Kubeflow. Why joining?\n- Learn what is MLOps and why it matters\n- Have a demo on how to deployt an MLOps tool: Charmed Kubeflow\n- Learn about curiosities that people had about MLOps, AI/ML at scale and Kubeflow\n- Get answers to your question\n\nRegister now: https://ubuntu.com/engage/introduction-to-machine-learning-operations-mlops",
  " In my job as a data scientist, I use deep learning models regularly to classify a lot of textual data (mostly transformer models like BERT finetuned for the needs of the company). Sentiment analysis and topic classification are the two most common natural language processing tasks that I perform, or rather, that is performed downstream in a pipeline that I am building for a company. \n\nThe other day someone high up (with no technical knowledge) was telling me, during a meeting, that we should be harnessing the power of ChatGPT to perform sentiment analysis and do other various data analysis tasks, noting that it should be a particularly powerful tool to analyze large volumes of data coming in (both in sentiment analysis and in querying and summarizing data tables). I mentioned that the tools we are currently using are more specialized for our analysis needs than this chat bot. They pushed back, insisting that ChatGPT is the way to go for data analysis and that I'm not doing my due diligence. I feel that AI becoming a topic of mainstream interest is emboldening people to speak confidently on it when they have no education or experience in the field. \n\nAfter just a few minutes playing around with ChatGPT, I was able to get it to give me a wrong answer to a VERY EASY question (see below for the transcript). It spoke so confidently in it's answer, even going as far as to provide a formula, which it basically abandoned in practice. Then, when I pointed out it's mistake, it corrected the answer to another wrong one. \n\nThe point of this long post was to point out that AI tool have their uses, but they should not be given the benefit of the doubt in every scenario, simply due to hype. If a model is to be used for a specific task, it should be rigorously tested and benchmarked before replacing more thoroughly proven methods.\n\nChatGPT is a really promising chat bot and it can definitely seem knowledgeable about a wide range of topics, since it was trained on basically the entire internet, but I wouldn't trust it to do something that  a simple pandas query could accomplish. Nor would I use it to perform sentiment analysis when there are a million other transformer models that were specifically trained to predict sentiment labels and were rigorously evaluated on industry standard benchmarks (like GLUE).\n\nhttps://preview.redd.it/sz3ejc1313ja1.png?width=1700&format=png&auto=webp&v=enabled&s=16393c01bdbca3a79f55ef61c486d9aa5645680a",
  "30F living in Austin\nMS in EE at 22, 8 years of work experience in deep learning in which I went from Engr I to Senior.\n\nHave extensive experience under my belt   demonstrating everything from expertise in multiple languages and frameworks, aiding directly in exec level business decision making, excellent cost savings, and a large range of problem spaces and deep learning work. I have excellent communication skills and have served as project lead for several (small, 1-3 person) teams. Spaces include valuation modeling, chemometrics, object detection, image style (using triplet loss), consumer-product matching, consumer-agent matching, multi arm bandits in chatbots, and various clustering problems of locations, consumers, and products. I also was in charge of labeling training & QA over about 20 offshore folks for image projects.\n\nI'm curious about dipping my feet further in deep learning but also in management by going for a tech lead / team rep position at my next company but I've no idea how to apply for something like that or what kind of position I should be seeking. Is this typically something you have to earn your way into via promotion rather than through applying? \n\nMedium sized company just acquired, wanting to look elsewhere. Have been working here for 4 years and just want something new.",
  "I have 3yrs of quantitative research experience and currently work in a small Analytics team at one of the top market research agencies (same league as Nielsen). \n\nI\u2019m quite good at analysing small data sets (a few thousand rows) and building simple models in SPSS and R. Been told I make impressive slides that tell stories with data in plain language - I\u2019m from marketing communication background.\n\nI\u2019m also doing a masters degree in Business Analytics on the side. It\u2019s been 1.5yr, the progress has been slow bc studying part time, but all my grades are 90+ and have learned the basics of Python, SQL and Tableau.\n\nStill I feel like I don\u2019t quite meet the requirements of most junior Analyst jobs. It seems I\u2019ll have to either take on grad roles at bigger companies or go to small data consultancies if I\u2019m to take a leap. I\u2019m an immigrant, already in my early 30s and there\u2019s financial pressure (single, saving for an apartment).  \n\nNot sure what should be my next step. Welcome any assessment on my situation, and advice on what kind of jobs/ companies I should aim for, which area I should focus my time and energy to learn and develop, etc.\n\nThanks in advance!",
  "I\u2019m a hiring manager for a Data Science team. I\u2019m looking for a Junior DS and my methodology is:\n\n- I don\u2019t do coding interviews: I trust you know how to code, if you really want to be in this field you\u2019ll learn tools and languages on your own.\n\n- I don\u2019t do case study: I don\u2019t really have the time for this, I want my \u201ctechnical interviews\u201d to be 15-30 mins.\n\n- I want to know if you understand the basics of math/stats and if you can reason through unknowns. I want to see how you process through problems.\n\nLately I\u2019ve been getting candidates who make it to my round and when I ask them some basic concepts, they completely flunk it.\n\nSo I\u2019m wondering\u2026are my questions too hard?\n\nThe questions:\n\n1) You are given a tabular dataset that you have no prior knowledge about. Walk me though how you would profile this data? What steps would you take to explore this data? Explain to me your EDA process.\n\n2) How would you evaluate a linear regression model? What are the metrics and what does it represent?\n\n3) Explain the difference between Standardisation vs Normalisation.\n\n4) Explain what a type I and type II error are.\n\nThese last 2 questions I don\u2019t hold against them and which is why I ask last, and I let the candidates know it\u2019s good to know but not required. It would set them apart.\n\n5) Say you\u2019ve got a ETL job that needs to be ran daily, say it\u2019s a dataset that you need to pull from a server, do ETL, and upload it to a database or storage of sorts. How would you go about automating this task? What tools, methods would you use? The world is your oyster, any and all tools out there in the world are available.\n\n6) Can you give me a use case where you have worked in Cloud (ie. AWS/Azure) to support your data science projects?\n\nEdit: I have dialog when they answer questions or if they have questions for me. My style is, dialogue! Just chat with me.\n\nAre my questions too hard? Can I ask these questions in a better way without getting too elaborate? \n\n\nAppreciate the feedback and help.",
  "Hello everyone, \n\ni'm training a multi-class classification model  and I would like to ask the following question:\n\nAssuming the model should differentiate between 10 variations (A to J), if A and B are similar (or whatever letters), then how can I somehow give a bias to the model to take that into consideration ? Currently, I am doing a \"hot zone\" in the confusion chart, so that the user knows to take these results with a grain of salt. \n\nAny hints would be appreciated!\n\nP.S: programming language doesn't matter even a math wikipedia page would be nice!",
  "Hi, I'm hoping someone with more experience can give me some advice on my DS career, which I'm at a bit of a crossroads with. \n\nFor some background - I have a PhD during which I learned about data analysis, visualisation, statistics, and R. Since receiving my PhD I've had two analyst roles where I've found my knowledge of R and statistics have left me feeling a little overqualified/not having good enough data to do 'proper' analysis work. \n\nLast year I started an entry-level DS position. I got the job because I have domain expertise and good proficiency in R, which is the language of choice where I work. The job is well paid, comfortable (I'm able to WFH) and I find the work mostly interesting. \n\nMy issue is this: I still feel like a glorified data analyst. There aren't really opportunities for ML (the thing that - possibly incorrectly - I most associate with DS), and I feel like experience with ML in a workplace setting is needed for possible next steps in my career. At the same time, I enjoy analysis and I'm not sure I'd find designing and tuning models full time particularly satisfying. \n\nI suppose my question is what direction can I go in/skills can I learn to continue to develop my analysis skills, and what types of senior roles support this. It feels from job adverts that Senior/Lead Data Scientists are primarily concerned with pipelines and models etc, rather than working with stakeholders. Interested to hear other people's experiences if any of this sounds familiar to anyone.",
  "Hi,\n\nI am looking for a course to learn the Large Language Model. Please provide some sources.\n\n\\#LLM #ChatGPT",
  " I'm currently doing my Bachelorthesis about Microclimatic Effects of Green Roofs and I model the clima for 3 days with ENVI-met.\n\nI will get lots of data which I have to generalize and analyse and then visualize. Basically I want to make some statistical tests if there are significant differences between different fractions of Roof Greening (Compare 100% Greening to 75%...).\n\nI'm asking myself which language would be the most easy for this. What I found out is, that visualization in R can be more \"sexy\". On the other side I have no experience with R and a tiny little bit with Python and I don't have much time for learning.\n\nI already plotted one graph with Python and I know how to load csv's and can work a bit with pandas. I don't know how easy it will be to do the statistical tests with Python or if doing the tests with R would be more straightforward.\n\nI'm happy if someone could tell me what approach would be better: Combining Python and R or just using Python because I already somehow understand how the language works.",
  "Hi dear community, \n\nI'm a big data analytics student. \n\nworking on my end of studies project, it's about sentiment analysis on Facebook posts (Comments), comments usually are written in a local language ( Algerian Dialect) \n\nI want to know if there are some technics I should be using to train ML models on this dataset . \n\nYour help would mean a lot. \n\nI'm also open for any questions regarding this topic , let's exchange on this one .",
  " Through the easy-explain package, you can achieve it without the need to write long scripts (only in 2-3 lines of code you can have your XAI results).\n\nRead more info in this article: [https://medium.com/towards-artificial-intelligence/easy-explain-explainable-ai-for-images-285777a004e3](https://medium.com/towards-artificial-intelligence/easy-explain-explainable-ai-for-images-285777a004e3)\n\nFind the package in Gh: [https://github.com/stavrostheocharis/easy\\_explain](https://github.com/stavrostheocharis/easy_explain)\n\nFind the package in Pypi: [https://pypi.org/project/easy-explain/](https://pypi.org/project/easy-explain/)\n\n&#x200B;\n\nhttps://preview.redd.it/cowm1xkkl5ja1.png?width=1390&format=png&auto=webp&v=enabled&s=b0a259ebe938838e580437e92641ae23182f972d",
  "So Basically I have worked on a data science project with a professor in Cannada and we got good results in a medical dataset and got a good AUROC of .85 and we published the paper for it and got selected , but what surprised me was the professor never went through my code and just gave suggestions and tips to do improve the model , but isn't this a lot risky.Everyday I am scared that some person would go through my code and invalidate my entire results based on some simple error which could have been corrected if there were proper code reviews.\n\nFast forward 6 months , I got a job in  a data science company as an intern and he told me to develop self supervised model for their image dataset and I did that and it good kind of okay results and he told me to move on to another project , still there was no code reviews or code checks , do people in data science just blindly trust each others code , I feel managers should at least give a look through to see if we taking the correct data split or if the model is correct or if there is any data leakage.There is a lot of red flags in trusting the AUROC results blindly. Is this a norm or maybe its just for me.\n\nMoreover most of the data scientists in the company dont even write proper documentation and for interns like me its such a pain , it took  me 2 weeks to understand their entire training repo, data science people should talk with the data engineers and take some of their methods and practices.",
  "30F living in Austin\nMS in EE at 22, 8 years of work experience in deep learning in which I went from Engr I to Senior.\n\nHave extensive experience under my belt   demonstrating everything from expertise in multiple languages and frameworks, aiding directly in exec level business decision making, excellent cost savings, and a large range of problem spaces and deep learning work. I have excellent communication skills and have served as project lead for several (small, 1-3 person) teams. Spaces include valuation modeling, chemometrics, object detection, image style (using triplet loss), consumer-product matching, consumer-agent matching, multi arm bandits in chatbots, and various clustering problems of locations, consumers, and products. I also was in charge of labeling training & QA over about 20 offshore folks for image projects.\n\nI'm curious about dipping my feet further in deep learning but also in management by going for a tech lead / team rep position at my next company but I've no idea how to apply for something like that or what kind of position I should be seeking. Is this typically something you have to earn your way into via promotion rather than through applying? \n\nMedium sized company just acquired, wanting to look elsewhere. Have been working here for 4 years and just want something new.",
  "I'm a backend developer and nowdays I'm working on a project where I have incoming stream of images and I have to run object-detection task on them.\n\nWe chose as the company to use an external object-detection api provider rather than creating our own models.\n\nTherefore I searched for different object-detection API out there and decided to use AWS Rekognition.\n\nSeems like their API is not very easy to use and require many post-processing functions on the response that contains the bounding boxes. Other API's I have checked require post/pre-processing on the images/response labels as well.\n\n&#x200B;\n\nI'm wondering if its just me or consuming AI API's is very unstructured, complexed and has lots of overhead.\n\nI would be happy to hear how you dealt with such cases when you had to consume a Computer Vision/ NLP API's.\n\n1. Was it hard and required additional logic around the pre/post processing of the input/output ?\n2. Do you have any tools/tricks to make this API integrations easier ?\n\nThanks !",
  "I have an encoder model which was working fine with single channel 1024,1024 images, I'm trying to patch the original images (mega pixel images) to 256, 256, 64 images. I've changed my encoder input to match the images input that the model will get. The model call function is working fine, loss is getting calculated fine, but I'm getting the following error with tape.gradient:\n\n    2023-01-29 17:11:01.868555: F tensorflow/stream_executor/cuda/cuda_dnn.cc:593] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 10 feature_map_count: 64 spatial: 0 0  value_min: 0.000000 value_max: 0.000000 layout: BatchYXDepth}                      C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:318: UserWarning: resource_tracker: There appear to be 2 leaked folder objects to clean up at shutdown                                               warnings.warn('resource_tracker: There appear to be %d '                                                              C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_772bbeeeccff43089fa0e6d75271eebd_97f2f7c6edd04b468a4360bf96b91b84: FileNotFoundError(2, 'The system cannot find the path specified')                                    warnings.warn('resource_tracker: %s: %r' % (name, e))                                                                 C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:333: UserWarning: resource_tracker: C:\\Users\\kjhan\\AppData\\Local\\Temp\\joblib_memmapping_folder_12248_29db2f1e8ff54416b9a78c6f69dcff23_40a85063390f46d38d15c1877f99acc8: FileNotFoundError(2, 'The system cannot find the path specified')                                    warnings.warn('resource_tracker: %s: %r' % (name, e))                                                                 [I 17:11:10.131 NotebookApp] KernelRestarter: restarting kernel (1/5), keep random ports                                kernel 286d1cc6-8ddd-46f9-baf7-5e1b05a2d033 restarted\n\nMy code is as below\n\n    class encoder(tf.keras.layers.Layer): def __init__(self,size:tuple):\n        super(encoder, self).__init__()     #encoder Module\n        self.input_cnn = keras.layers.InputLayer(input_shape=(size[0],size[1],size[2]))\n        self.conv_1 = keras.layers.Conv2D(input_shape=(size[0],size[1],size[2]),filters=16,kernel_size=(3,3),padding='same',activation='relu')\n        self.conv_2 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_3 = keras.layers.Conv2D(filters = 16,kernel_size=(4,4),strides=(2,2),padding='same',activation='relu')\n        self.conv_4 = keras.layers.Conv2D(filters = 32,kernel_size=(4,4),strides=(4,4),padding='same',activation='relu')\n        self.conv_5 = keras.layers.BatchNormalization()\n        self.conv_6 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_7 = keras.layers.Conv2D(filters = 64,kernel_size=(8,8),strides=(8,8),padding='same',activation='relu')\n        self.conv_8 = keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2))\n        self.conv_9 = keras.layers.BatchNormalization()\n        self.conv_10 = keras.layers.Conv2D(filters = 1 ,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')\n        \n        def call(self,inputs,training = True):\n            x = self.input_cnn(inputs)\n            x = self.conv_1(x)\n            x = self.conv_2(x)\n            x = self.conv_3(x)\n            x = self.conv_4(x)\n            if training == True:\n                x = self.conv_5(x,training = True)\n            else:\n                x = self.conv_5(x,training = False)\n            x = self.conv_6(x)\n            x = self.conv_7(x)\n            x = self.conv_8(x)\n            if training == True:\n                x = self.conv_9(x,training = True)\n            else:\n                x = self.conv_9(x,training = False)\n            x = self.conv_10(x)\n            return x\n\nsize 0 is 256 size 1 is 256 size 2 is 64\n\nTrain\\_step from main model:\n\n \n\n    def __init__(self, size: tuple, optimizer = keras.optimizers.Adam(learning_rate=1e-3),loss_fn = keras.losses.BinaryCrossentropy(from_logits=False),metric = tf.keras.metrics.Accuracy()):     \n        super(BCDClassifier, self).__init__()         \n        self.input_cat = keras.layers.InputLayer(input_shape = (2,))\n        self.encode = encoder(size)\n        self.flatten = keras.layers.Flatten()\n        self.concat = keras.layers.Concatenate(axis = 1)\n        self.classify = classifier(32)\n        self.optimizer = optimizer\n        self.loss_fn = loss_fn\n        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n        self.acc_tracker = metric\n        self.f1_tracker = tfa.metrics.F1Score(num_classes=2, threshold=0.5, average = 'micro')\n        self.sk_metric_acc = accuracy_score\n        self.sk_metric_f1 = f1_score\n        self.acc_history = []\n        self.loss_history = []\n        self.f1_history = []\n        \n        def call(self, cat_batch, view_batch, images_batch, training = True):\n            x1 = self.encode(images_batch,training)\n            x2 = self.input_cat(cat_batch)\n            x1 = self.flatten(x1)\n            x12 = self.concat([x1,x2])\n            x12 = self.classify(x12)\n            return x12\n    \n        def train_step(self,cat_batch, views_batch, images_batch, target_batch, training = True):\n            with tf.GradientTape() as tape:\n                logits = self(cat_batch, views_batch, images_batch,training)\n                loss_value = self.loss_fn(target_batch, logits)\n    \n            grads = tape.gradient(loss_value, self.trainable_weights)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n            self.loss_tracker.update_state(loss_value)\n            pred = []\n            target = []\n            threshold = 0.5\n            for val in logits.numpy():\n                if isinstance(val,np.ndarray):\n                    for v_1 in val:\n                        if isinstance(v_1,np.ndarray):\n                            for v_2 in v_1:\n                                if v_2 > threshold:\n                                    pred.append(1.0)\n                                else:\n                                    pred.append(0.0)\n                        else:\n                            if v_1 > threshold:\n                                pred.append(1.0)\n                            else:\n                                pred.append(0.0)\n                else:\n                    if val > threshold:\n                        pred.append(1.0)\n                    else:\n                        pred.append(0.0)\n            for val in target_batch:\n                if isinstance(val,np.ndarray):\n                    for v_1 in val:\n                        if isinstance(v_1,np.ndarray):\n                            for v_2 in v_1:\n                                target.append(v_2)\n                        else:\n                            target.append(v_1)\n                else:\n                    target.append(val)\n            acc = self.sk_metric_acc(target,pred)\n            f1 = self.sk_metric_f1(target,pred)\n            #self.f1_tracker.update_state(target_batch,logits)\n            return {\"Loss\": self.loss_tracker.result(), \"Accuracy\": acc, 'F1-score':f1}\n\nCan someone please help me figure out this error?",
  "&#x200B;\n\n[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/t6m0epzlgyca1.png?width=575&format=png&auto=webp&v=enabled&s=fbfff287d1b9ced59f0aa55aeaf1df73eec90812)\n\nThe rumor mill is buzzing around the release of GPT-4.\n\nPeople are predicting the model will have 100 trillion parameters. That\u2019s a *trillion* with a \u201ct\u201d.\n\nThe often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.\n\nSure, OpenAI\u2019s new brainchild will certainly be mind-bending and language models have been getting bigger \u2014 fast!\n\nBut this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).\n\n*Let\u2019s go!*\n\nTraining 100 Trillion Parameters\n\nThe creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \\[1\\].\n\nTraining a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.\n\nSo, where is this rumor coming from?\n\nThe Source Of The Rumor:\n\nIt turns out OpenAI itself might be the source of it.\n\nIn August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): \u201cFrom talking to OpenAI, GPT-4 will be about 100 trillion parameters\u201d.\n\nA the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.\n\nThings have changed a lot since then!\n\nTo understand what happened we first need to look at how people decide the number of parameters in a model.\n\nDeciding The Number Of Parameters:\n\nThe enormous hunger for resources typically makes it feasible to train an LLM only once.\n\nIn practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.\n\n*But there\u2019s a catch!*\n\nMost research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.\n\nWith LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.\n\nTherefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.\n\nThis process can very noisy and the community\u2019s understanding has evolved a lot over the last few years.\n\nWhat People Used To Think About Scaling LLMs\n\nIn 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: \u201cScaling Laws For Neural Language Models\u201d.\n\nThey observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.\n\nSo far so good. But they made two other observations, which resulted in the model size ballooning rapidly.\n\n1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.\n2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.\n\nHence, it seemed as if the way to improve performance was to scale models faster than the dataset size \\[2\\].\n\nAnd that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.\n\nBut the bigger models failed to deliver on the promise.\n\n*Read on to learn why!*\n\nWhat We know About Scaling Models Today\n\nIt turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.\n\nThis was published in DeepMind\u2019s 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): \u201cTraining Compute-Optimal Large Language Models\u201d\n\nThe researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.\n\nThe findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.\n\nTo verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.\n\nChinchilla outperforms GPT-3 and other much larger models by a fair margin \\[3\\].\n\nThis was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.\n\n*So What Will Happen?*\n\nWhat GPT-4 Might Look Like:\n\nTo properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \\[1\\].\n\nSo, here is what GPT-4 could look like:\n\n* Similar size to GPT-3, but trained optimally on 10x more data\n* \u200b[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound\n* Output conditioned on document chunks from a memory bank that the model has access to during prediction \\[4\\]\n* Doubled context size allows longer predictions before the model starts going off the rails\u200b\n\nRegardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.\n\nWhatever it will look like, I am sure it will be amazing and we can all be excited about the release.\n\nSuch exciting times to be alive!\n\nIf you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** \u2b55, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)\n\n**References:**\n\n\\[1\\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21\n\n\\[2\\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,\u2026 & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint\n\n\\[3\\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.\n\n\\[4\\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver",
  "We combined image captioning using CLIP and image generation using the Hugging Face Stable Diffusion model to create an image de-identifier modeled after the game of telephone,\u00a0[Imafake](https://hubs.la/Q01wrX4l0)! All you have to do is upload an image, convert it to a caption, then convert that caption to an image with a few clicks! You can also play with the parameters of the diffusion model depending on how gnarly you want your resulting image to be. And caution, they can get rather gnarly, but that\u2019s what makes it fun :) Thoughts and your own generated images welcome!!\n\nhttps://preview.redd.it/ct6263mejvca1.jpg?width=1276&format=pjpg&auto=webp&v=enabled&s=6321342e1720290b7cad637cb958425e8c503b46",
  "This post is really a few questions with some context from a beginner in machine learning.\n\nThis past semester I had taken a course at my uni on Deep Learning where we had done weekly assignments in python related to different models with the primary use of sci-kit learn. I have always been a fan of lower-level languages and disliked abstraction so this inspired me to work on my own library but related to mathematics in a broader sense (that also includes machine learning methods and techniques).\n\nThe source code being all in C++, formal installation with CMake, language binding for Python with easy installation using pip, a binding for R, and some decent documentation and samples to get running, this led me to start using the project for some Machine Learning work in my research lab. The project is still very small with limited functionality but has proven useful as a lightweight tool for some of the work we do in the lab, I've grown curious how I can take my project to the next level.\n\nTo my naive understanding and brief 16-week experience, sklearn serves as a tool with prebuilt models for a variety of machine learning methods while TensorFlow acts as building blocks primarily for creating Neural Networks (is this fair to assume?). Also sklearn I've noticed is written mostly in Python while projects like TensorFlow and Torch utilize C++ and C to a much greater degree.\n\nHow do these projects provide efficient computations for end users wanting to make use of the library? I am familiar with the concepts of threading but not in a cross-platform sense, with some previous worked with tools like openMP, openCL, openGL, and a bit of CUDA but not in an applicable sense. My project so far does not deal with image or video related data so I am unsure of how the use of GPU exploitation could serve purposeful in my case. What methods and perhaps tools do lower-level projects like TensorFlow use to be a fast and efficient tool while also being portable?\n\nI understand these projects have an abundance of developers and brilliant brains contributing, but any insight or references will be greatly appreciated and help me wrap my head around the idea of creating a fast, efficient, and cross-platform library!\n\nALSO: Reinventing the wheel isn't a concern, this served as a great project for learning an array of topics in my free time aside from just mathematics.",
  "Dear all,\n\nI've been building a codon optimizer (translating amino acids to DNA codons) using the transformer model 'Attention is all you need'. I've been training it on 1,5 million tokens. As the image shows the loss is stuck and very stable at 1.05, even after 4000 epochs (see figure A). When I use the model for interference I see that it does a lot right, how ever it seems not possible for it to find the <EOS> token. Figure B shows my inference with the bold tokens showing the desired length. It goes all the way untill it reaches the max\\_len constraint. The average length of the translated sequence is 300 tokens and a maximum of 1000 tokens. My questions: How can I stimulate the model to find the <EOS>? Since the length of the source is always the same length as the target can I hard code the EOS, would this help? Do I have enough tokens to train on or should i get more? If you need more information I can provide it :)\n\nThank you for helping me out,\n\nGreetings from the Netherlands,\n\nDaan\n\n&#x200B;\n\nhttps://preview.redd.it/r40zme9a7sba1.png?width=1868&format=png&auto=webp&v=enabled&s=1b54ef9d7014f9ec3b41e23a0a68a263ff1652f4"
]